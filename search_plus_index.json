{"./":{"url":"./","title":"Introduction","keywords":"","body":" &#x1F40D; æ·±åº¦å­¦ä¹ å­¦ä¹ è®°å½• å…¶ä¸­æœ‰äº›æ¥è‡ªä¸€äº›åšå®¢è®ºå›ï¼Œèƒ½åŠ ä¸ŠåŽŸæ–‡åœ°å€çš„éƒ½å·²åœ¨æ–‡ä¸­å°½å¯èƒ½åŠ ä¸Š å¦‚æœ‰ä¾µæƒï¼Œæ¬¢è¿Žè”ç³»ä½œè€…~ 1832044043@qq.com ä¸ªäººè®ºæ–‡ä¸»é¡µé“¾æŽ¥ gitbookä½¿ç”¨æ•™ç¨‹: gitbookä½¿ç”¨æ•™ç¨‹ markdwoné«˜é˜¶è¯­æ³•: Markdownè¿›é˜¶ï¼ˆæ›´æ”¹å­—ä½“ã€é¢œè‰²ã€å¤§å°ï¼Œè®¾ç½®æ–‡å­—èƒŒæ™¯è‰²ï¼Œè°ƒæ•´å›¾ç‰‡å¤§å°è®¾ç½®å±…ä¸­ï¼‰ Cmd Markdown ç®€æ˜Žè¯­æ³•æ‰‹å†Œ EMOJI CHEAT SHEET pythonå®˜æ–¹å‚è€ƒèµ„æ–™: Python 3.8.3 æ–‡æ¡£ NumPy å‚è€ƒæ‰‹å†Œ Pandas: å¼ºå¤§çš„ Python æ•°æ®åˆ†æžæ”¯æŒåº“ scikit-learn (sklearn) å®˜æ–¹æ–‡æ¡£ä¸­æ–‡ç‰ˆ Matplotlib æ•™ç¨‹ https://pyecharts.org/#/ pythonå…¶ä»–å‚è€ƒèµ„æ–™: Python æ ‡å‡†åº“ Python è¯­è¨€å‚è€ƒ Pythonæ–‡æ¡£å†…å®¹ Python æ ‡å‡†åº“ pythonç´¢å¼• PEPç´¢å¼• pythoné’å—-ç‚«æŠ€ èƒŒæ™¯ã€é¼ æ ‡ç‰¹æ•ˆã€2dåŠ¨æ¼«è§’è‰²ç­‰å‚è€ƒé²¸ä¹‹å£°demoè¿›è¡Œäº†è‡ªå®šä¹‰çš„ä¿®æ”¹ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/LLMæ¨¡åž‹å¾®è°ƒç³»åˆ—.html":{"url":"chapters/LLMæ¨¡åž‹å¾®è°ƒç³»åˆ—.html","title":"LLMæ¨¡åž‹å¾®è°ƒç³»åˆ—.md","summary":"LLMæ¨¡åž‹å¾®è°ƒç³»åˆ—","keywords":"","body":"LLMæ¨¡åž‹æ¦‚è¿°å¾®è°ƒå‘å±•è„‰ç»œPrefix/Prompt-TuningPrefix-TuningPrompt-TuningP-TuningP-Tuning V1P-Tuning V2LORAç³»åˆ—LORA(è½¬)AdaLoRA(è½¬)QLORARLHFFlash_Atten(è½¬)æ¦‚è¿°æ ¸å¿ƒè¦ç‚¹æå‡ºé—®é¢˜è§£å†³æ–¹æ¡ˆForwardStandard AttentionFlashAttention(Tiling)IOå¤æ‚åº¦åˆ†æžStandard AttentionFlashAttentionBackwardç†è®ºåŸºç¡€ä»£ç å®žçŽ°Block-Sparseå®žéªŒéªŒè¯LLMæ¨¡åž‹ ä»€ä¹ˆæ˜¯LLMï¼ˆå¤§è¯­éŸ³æ¨¡åž‹ï¼‰ æ¦‚è¿° Large Language Model(LLM)ï¼Œä¹Ÿç§°ä¸ºå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼Œæ˜¯ä¸€ç§åŸºäºŽæœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„æ¨¡åž‹ï¼Œå®ƒé€šè¿‡å¯¹å¤§é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæ¥å­¦ä¹ æœåŠ¡äººç±»è¯­è¨€ç†è§£å’Œç”Ÿæˆçš„èƒ½åŠ› LLMçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¤§è§„æ¨¡çš„æ— ç›‘ç£è®­ç»ƒæ¥å­¦ä¹ è‡ªç„¶è¯­è¨€çš„æ¨¡å¼å’Œè¯­è¨€ç»“æž„ï¼Œè¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»çš„è¯­è¨€è®¤çŸ¥å’Œç”Ÿæˆè¿‡ç¨‹ ä¸Žä¼ ç»Ÿçš„NLPæ¨¡åž‹ç›¸æ¯”ï¼ŒLLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆè‡ªç„¶æ–‡æœ¬ï¼ŒåŒæ—¶è¿˜èƒ½å¤Ÿè¡¨çŽ°å‡ºä¸€å®šçš„é€»è¾‘æ€ç»´å’ŒæŽ¨ç†èƒ½åŠ› è¿‘å¹´æ¥ï¼ŒLLMå¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ï¼Œå…¶ä¸­æœ€å…·ä»£è¡¨æ€§çš„æ˜¯è°·æ­Œçš„BERTå’ŒOpenAIçš„GPTç³»åˆ—ã€‚è¿™äº›æ¨¡åž‹åœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå·²ç»å–å¾—äº†æ˜¾è‘—çš„æˆæžœï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€å‘½åå®žä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æžã€æœºå™¨ç¿»è¯‘ã€è‡ªåŠ¨é—®ç­”ç­‰ ç„¶è€Œï¼Œåœ¨å®žé™…åº”ç”¨ä¸­ï¼ŒLLMé¢ä¸´ç€æ›´å¤šçš„æŒ‘æˆ˜ é¦–å…ˆï¼ŒLLMéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œå¤§è§„æ¨¡çš„æ•°æ®é›†æ¥è®­ç»ƒï¼Œè¿™å¯¹äºŽä¸€èˆ¬çš„ä¼ä¸šå’Œä¸ªäººæ¥è¯´ååˆ†å›°éš¾ å…¶æ¬¡ï¼Œç”±äºŽLLMæ¨¡åž‹çš„å¤æ‚æ€§å’Œè®¡ç®—é‡è¾ƒå¤§ï¼Œå¯¹äºŽå®žæ—¶çš„è¯­è¨€å¤„ç†åº”ç”¨æ¥è¯´ï¼ŒLLMåœ¨åº”ç”¨æ•ˆçŽ‡å’Œå“åº”é€Ÿåº¦ä¸Šè¿˜å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ å› æ­¤ï¼Œå¦‚ä½•è§£å†³æ¨¡åž‹è®­ç»ƒå’Œåº”ç”¨è¿‡ç¨‹ä¸­çš„è®¡ç®—æ€§èƒ½å’Œæ•ˆçŽ‡é—®é¢˜ï¼Œæ˜¯LLMé¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ å¾®è°ƒ LLMå¤§æ¨¡åž‹ä½Žèµ„æºå¾®è°ƒp tuning v2å’ŒloraåŒºåˆ« prefix, p-tuningv2, lora finetuneè¯¥æ€Žä¹ˆé€‰æ‹©? è®©å¤©ä¸‹æ²¡æœ‰éš¾Tuningçš„å¤§æ¨¡åž‹ï¼šPEFTæŠ€æœ¯ç®€ä»‹ 2023-04 å¾®è°ƒ(Fine-tuning)æ˜¯ä¸€ç§å¸¸ç”¨çš„æŠ€æœ¯ï¼Œç”¨äºŽå°†é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡åž‹é€‚åº”äºŽç‰¹å®šçš„ä»»åŠ¡æˆ–é¢†åŸŸã€‚å¾®è°ƒçš„ç›®çš„æ˜¯é€šè¿‡åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œæœ‰ç›‘ç£çš„è®­ç»ƒï¼Œè°ƒæ•´æ¨¡åž‹å‚æ•°ä»¥æé«˜å…¶æ€§èƒ½å’Œé€‚åº”æ€§ ä»¥ä¸‹æ˜¯å¾®è°ƒåœ¨é€‚åº”è¯­è¨€æ¨¡åž‹ä¸­çš„æœ‰æ•ˆæ€§çš„å‡ ä¸ªåŽŸå› ï¼š è¿ç§»å­¦ä¹ ï¼šé¢„è®­ç»ƒçš„è¯­è¨€æ¨¡åž‹åœ¨å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œäº†æ— ç›‘ç£çš„å­¦ä¹ ï¼Œä»Žä¸­å­¦ä¹ åˆ°äº†é€šç”¨çš„è¯­è¨€è¡¨ç¤ºã€‚é€šè¿‡å¾®è°ƒï¼Œæˆ‘ä»¬å¯ä»¥å°†è¿™äº›é€šç”¨çš„è¯­è¨€è¡¨ç¤ºè¿ç§»åˆ°ç‰¹å®šä»»åŠ¡æˆ–é¢†åŸŸä¸Šï¼Œå› æ­¤å¯ä»¥åˆ©ç”¨æ¨¡åž‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå­¦åˆ°çš„çŸ¥è¯† å°‘æ ·æœ¬å­¦ä¹ ï¼šå¾®è°ƒé€šå¸¸åªéœ€è¦åœ¨ç‰¹å®šä»»åŠ¡çš„ç›¸å¯¹è¾ƒå°çš„æ ‡æ³¨æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œä¸æ˜¯ä»Žå¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªå…¨æ–°çš„æ¨¡åž‹ã€‚è¿™å¯¹äºŽè®¸å¤šä»»åŠ¡æ¥è¯´æ˜¯éžå¸¸æœ‰ç›Šçš„ï¼Œå› ä¸ºèŽ·å¾—å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®å¯èƒ½æ˜¯æ˜‚è´µæˆ–å›°éš¾çš„ã€‚é€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¾®è°ƒå¯ä»¥åœ¨å°‘é‡æ ‡æ³¨æ ·æœ¬ä¸Šå®žçŽ°è¾ƒå¥½çš„æ€§èƒ½ é¢†åŸŸè‡ªé€‚åº”ï¼šé€šè¿‡å¾®è°ƒï¼Œå¯ä»¥å°†è¯­è¨€æ¨¡åž‹ä»Žé€šç”¨é¢†åŸŸé€‚åº”åˆ°ç‰¹å®šé¢†åŸŸã€‚é€šè¿‡åœ¨ç‰¹å®šé¢†åŸŸçš„æ•°æ®ä¸Šå¾®è°ƒï¼Œæ¨¡åž‹å¯ä»¥å­¦ä¹ åˆ°è¯¥é¢†åŸŸçš„ç‰¹å®šè¯­è¨€æ¨¡å¼ã€è¯æ±‡å’Œä¸Šä¸‹æ–‡ï¼Œä»Žè€Œæé«˜åœ¨è¯¥é¢†åŸŸä»»åŠ¡ä¸Šçš„æ€§èƒ½ æ¨¡åž‹ä¸ªæ€§åŒ–ï¼šå¾®è°ƒè¿˜å¯ä»¥ç”¨äºŽä¸ªæ€§åŒ–æ¨¡åž‹ï¼Œä»¥é€‚åº”ç‰¹å®šç”¨æˆ·æˆ–ç‰¹å®šåº”ç”¨åœºæ™¯çš„éœ€æ±‚ã€‚é€šè¿‡å¾®è°ƒæ¨¡åž‹ï¼Œå¯ä»¥æ ¹æ®ä¸ªä½“ç”¨æˆ·çš„åå¥½ã€è¡Œä¸ºæˆ–æ•°æ®ç‰¹ç‚¹è¿›è¡Œå®šåˆ¶ï¼Œæä¾›æ›´å‡†ç¡®å’Œä¸ªæ€§åŒ–çš„é¢„æµ‹å’ŒæŽ¨è å¾®è°ƒè¯­è¨€æ¨¡åž‹æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡è¿ç§»å­¦ä¹ ã€å°‘æ ·æœ¬å­¦ä¹ ã€é¢†åŸŸè‡ªé€‚åº”å’Œæ¨¡åž‹ä¸ªæ€§åŒ–ç­‰æ–¹å¼ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„ä¼˜åŠ¿å’Œæ³›åŒ–èƒ½åŠ›ï¼Œæé«˜æ¨¡åž‹åœ¨ç‰¹å®šä»»åŠ¡æˆ–é¢†åŸŸä¸Šçš„æ€§èƒ½å’Œé€‚åº”æ€§ ä¸ºä»€ä¹ˆéœ€è¦å¾®è°ƒ é«˜æ•ˆè®­ç»ƒï¼Œå‡å°‘è®­ç»ƒæˆæœ¬ å…±äº«åŸºç¡€å¤§æ¨¡åž‹ï¼Œåœ¨ä¸Šé¢å åŠ è‡ªå·±çš„æ–°æ¨¡åž‹ å‘å±•è„‰ç»œ Adapterç³»åˆ— AdapterFusion: Non-Destructive Task Composition for Transfer Learning 2021 Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter 2021 LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention 2023 LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model 2023 github LLaMA-Adapter: Efficient Fine-tuning of LLaMA p-tunningç³»åˆ— Prefix-Tuning: Optimizing Continuous Prompts for Generation 2021 The Power of Scale for Parameter-Efficient Prompt Tuning 2021 P-Tuning - GPT Understands, Too 2021 P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks 2022 loraç³»åˆ— LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS 2021 AdaLoRA Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning 2023 QLORA: Efficient Finetuning of Quantized LLM 2023 å¦å¤–huggingfaceå¾ˆè´´å¿ƒçš„æŠŠå¸¸è§çš„fine-Tuningæ–¹æ³•éƒ½åšäº†é›†æˆï¼Œåªç”¨å‡ è¡Œä»£ç å°±å¯æ·»åŠ å’Œä¿®æ”¹ï¼Œååˆ†æ–¹ä¾¿ï¼Œè¿˜æœ‰å¾®è½¯æä¾›çš„åŠ é€Ÿåº“ huggingfaceå®˜ç½‘å®žçŽ°çš„fine-Tuningæ–¹æ³• microsoft/DeepSpeed åŠ é€Ÿ è§£å¯†Promptç³»åˆ—3. å†»ç»“LMå¾®è°ƒPrompt: Prefix-Tuning & Prompt-Tuning & P-Tuning å¾®è°ƒLMå’Œå…¨éƒ¨å†»ç»“çš„promptæ¨¡æ¿ç›¸æ¯”ï¼Œå¾®è°ƒPromptèŒƒå¼æœ€å¤§çš„åŒºåˆ«å°±æ˜¯promptæ¨¡æ¿éƒ½æ˜¯è¿žç»­åž‹(Embedding)ï¼Œè€Œéžå’ŒTokenå¯¹åº”çš„ç¦»æ•£åž‹æ¨¡æ¿ æ ¸å¿ƒåœ¨äºŽæˆ‘ä»¬å¹¶ä¸å…³å¿ƒpromptæœ¬èº«æ˜¯å¦æ˜¯è‡ªç„¶è¯­è¨€ï¼Œåªå…³å¿ƒpromptä½œä¸ºæŽ¢é’ˆèƒ½å¦å¼•å¯¼å‡ºé¢„è®­ç»ƒæ¨¡åž‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„ç‰¹å®šèƒ½åŠ› å›ºå®šLMå¾®è°ƒPromptçš„èŒƒå¼æœ‰ä»¥ä¸‹å‡ ä¸ªä¼˜ç‚¹ æ€§ä»·æ¯”é«˜: å¾®è°ƒå‚æ•°å°‘ï¼Œå†»ç»“LMåªå¾®è°ƒpromptéƒ¨åˆ†çš„å‚æ•° æ— äººå·¥å‚ä¸Ž: æ— éœ€äººå·¥è®¾è®¡promptæ¨¡æ¿ï¼Œä¾èµ–æ¨¡åž‹å¾®è°ƒå³å¯ å¤šä»»åŠ¡å…±äº«æ¨¡åž‹: å› ä¸ºLMè¢«å†»ç»“ï¼Œåªéœ€è®­ç»ƒé’ˆå¯¹ä¸åŒä»»åŠ¡çš„promptå³å¯ã€‚å› æ­¤å¯ä»¥å›ºå®šé¢„è®­ç»ƒæ¨¡åž‹ï¼Œæ‹”æ’å¼åŠ å…¥Promptç”¨äºŽä¸åŒä¸‹æ¸¸ä»»åŠ¡ Prefix/Prompt-Tuning Prefix-Tuning ç­‰å¾…... Prefix-Tuningå¯ä»¥ç†è§£æ˜¯CTRL[1]æ¨¡åž‹çš„è¿žç»­åŒ–å‡çº§ç‰ˆï¼Œä¸ºäº†ç”Ÿæˆä¸åŒé¢†åŸŸå’Œè¯é¢˜çš„æ–‡æœ¬ï¼ŒCTRLæ˜¯åœ¨é¢„è®­ç»ƒé˜¶æ®µåœ¨è¾“å…¥æ–‡æœ¬å‰åŠ å…¥äº†control codeï¼Œä¾‹å¦‚å¥½è¯„å‰é¢åŠ 'Reviews Rating:5.0',å·®è¯„å‰é¢åŠ 'Reviews Rating:1.0', æ”¿æ²»è¯„è®ºå‰é¢åŠ â€˜Politics Title:â€™ï¼ŒæŠŠè¯­è¨€æ¨¡åž‹çš„ç”Ÿæˆæ¦‚çŽ‡ï¼Œä¼˜åŒ–æˆäº†åŸºäºŽæ–‡æœ¬ä¸»é¢˜çš„æ¡ä»¶æ¦‚çŽ‡ Prefix-Tuningè¿›ä¸€æ­¥æŠŠcontrol codeä¼˜åŒ–æˆäº†è™šæ‹ŸTokenï¼Œæ¯ä¸ªNLPä»»åŠ¡å¯¹åº”å¤šä¸ªè™šæ‹ŸTokençš„Embeddingï¼ˆprefixï¼‰ï¼Œå¯¹äºŽDecoder-Onlyçš„GPTï¼ŒprefixåªåŠ åœ¨å¥é¦–ï¼Œå¯¹äºŽEncoder-Decoderçš„BARTï¼Œä¸åŒçš„prefixåŒæ—¶åŠ åœ¨ç¼–ç å™¨å’Œè§£ç å™¨çš„å¼€å¤´ã€‚åœ¨ä¸‹æ¸¸å¾®è°ƒæ—¶ï¼ŒLMçš„å‚æ•°è¢«å†»ç»“ï¼Œåªæœ‰prefixéƒ¨åˆ†çš„å‚æ•°è¿›è¡Œæ›´æ–°ã€‚ä¸è¿‡è¿™é‡Œçš„prefixå‚æ•°ä¸åªåŒ…æ‹¬embeddingå±‚è€Œæ˜¯è™šæ‹Ÿtokenä½ç½®å¯¹åº”çš„æ¯ä¸€å±‚çš„activationéƒ½è¿›è¡Œæ›´æ–° Prompt-Tuning https://github.com/google-research/prompt-tuning ç­‰å¾…... Prompt-Tunningæ˜¯ä»¥ä¸Šprefix-Tunningçš„ç®€åŒ–ç‰ˆæœ¬ï¼Œé¢å‘NLUä»»åŠ¡ï¼Œè¿›è¡Œäº†æ›´å…¨é¢çš„æ•ˆæžœå¯¹æ¯”ï¼Œå¹¶ä¸”åœ¨å¤§æ¨¡åž‹ä¸ŠæˆåŠŸæ‰“å¹³äº†LMå¾®è°ƒçš„æ•ˆæžœ å¯¹æ¯”Prefix-Tunningï¼Œprompt-tuningçš„ä¸»è¦å·®å¼‚å¦‚ä¸‹: è®ºæ–‡ä½¿ç”¨100ä¸ªprefix tokenä½œä¸ºé»˜è®¤å‚æ•°ï¼Œå¤§äºŽä»¥ä¸Šprefix-tuningé»˜è®¤çš„10ä¸ªtokenï¼Œä¸è¿‡å·®å¼‚åœ¨äºŽprompt-Tunningåªå¯¹è¾“å…¥å±‚(Embedding)è¿›è¡Œå¾®è°ƒï¼Œè€ŒPrefixæ˜¯å¯¹è™šæ‹ŸTokenå¯¹åº”çš„ä¸Šæ¸¸layerå…¨éƒ¨è¿›è¡Œå¾®è°ƒã€‚å› æ­¤Prompt-Tunningçš„å¾®è°ƒå‚æ•°é‡çº§è¦æ›´å°ï¼Œä¸”ä¸éœ€è¦ä¿®æ”¹åŽŸå§‹æ¨¡åž‹ç»“æž„ï¼Œè¿™æ˜¯â€œç®€åŒ–â€çš„æ¥æºã€‚ç›¸åŒçš„prefixé•¿åº¦ï¼ŒPrompt-Tunning( P-Tuning P-Tuning V1 github THUDM/P-tuning æ‰‹åŠ¨å°è¯•æœ€ä¼˜çš„æç¤ºæ— å¼‚äºŽå¤§æµ·æžé’ˆï¼ŒäºŽæ˜¯ä¾¿æœ‰äº†è‡ªåŠ¨ç¦»æ•£æç¤ºæœç´¢çš„æ–¹æ³•(å·¦å›¾)ï¼Œä½†æç¤ºæ˜¯ç¦»æ•£çš„ï¼Œç¥žç»ç½‘ç»œæ˜¯è¿žç»­çš„ï¼Œæ‰€ä»¥å¯»æ‰¾çš„æœ€ä¼˜æç¤ºå¯èƒ½æ˜¯æ¬¡ä¼˜çš„ã€‚p-tuningä¾ç„¶æ˜¯å›ºå®šLLMå‚æ•°ï¼Œåˆ©ç”¨å¤šå±‚æ„ŸçŸ¥æœºå’ŒLSTMå¯¹promptè¿›è¡Œç¼–ç ï¼Œç¼–ç ä¹‹åŽä¸Žå…¶ä»–å‘é‡è¿›è¡Œæ‹¼æŽ¥ä¹‹åŽæ­£å¸¸è¾“å…¥LLMã€‚æ³¨æ„ï¼Œè®­ç»ƒä¹‹åŽåªä¿ç•™promptç¼–ç ä¹‹åŽçš„å‘é‡å³å¯ï¼Œæ— éœ€ä¿ç•™ç¼–ç å™¨ åŠ¨æœº ä¸€ä¸ªåˆ»æ¿å°è±¡æ˜¯GPTä¸é€‚åˆç†è§£ç±»ä»»åŠ¡ï¼Œè¿™ç¯‡å°±æ˜¯åŽ»æ€è€ƒè¿™ç§åˆ»æ¿å°è±¡æ˜¯å¦æ­£ç¡® GPT-3é‡‡ç”¨äººå·¥æž„é€ çš„æ¨¡ç‰ˆæ¥åšin context learningï¼Œäººå·¥è®¾è®¡çš„æ¨¡ç‰ˆçš„å˜åŒ–ç‰¹åˆ«æ•æ„Ÿï¼ŒåŠ ä¸€ä¸ªè¯æˆ–è€…å°‘ä¸€ä¸ªè¯ï¼Œæˆ–è€…å˜åŠ¨ä½ç½®å•¥çš„éƒ½ä¼šé€ æˆæ¯”è¾ƒå¤§çš„å˜åŒ–ï¼ˆè¿™é‡Œä½œè€…åšäº†ä¸€ä¸ªç®€å•çš„éªŒè¯å®žéªŒï¼Œå…·ä½“çœ‹è®ºæ–‡ï¼‰ã€‚è¿‘æ¥çš„è‡ªåŠ¨åŒ–æœç´¢æ¨¡ç‰ˆå·¥ä½œæˆæœ¬ä¹Ÿæ¯”è¾ƒé«˜ï¼ŒåŒæ—¶ä»¥å‰è¿™ç§ç¦»æ•£åŒ–çš„tokençš„æœç´¢å‡ºæ¥çš„ç»“æžœå¯èƒ½å¹¶ä¸æ˜¯æœ€ä¼˜çš„ å’Œprefix-tuningå·®ä¸å¤šï¼Œåæ­£æ˜¯åŸºäºŽè¿™ä¸¤ç‚¹åŽ»è®¾è®¡äº†ä¸€ç§è¿žç»­å¯å¾®çš„æ¨¡ç‰ˆ ç›¸æ¯”prefix-tuningï¼Œè¿™é‡ŒåŠ äº†å¯å¾®çš„virtual tokenï¼Œä½†æ˜¯ä»…é™äºŽè¾“å…¥ï¼Œæ²¡æœ‰åœ¨æ¯å±‚åŠ ï¼›å¦å¤–virtual tokençš„ä½ç½®ä¹Ÿä¸ä¸€å®šæ˜¯å‰ç¼€ï¼Œæ’å…¥çš„ä½ç½®æ˜¯å¯é€‰çš„ã€‚è¿™é‡Œçš„å‡ºå‘ç‚¹å®žé™…æ˜¯æŠŠä¼ ç»Ÿäººå·¥è®¾è®¡æ¨¡ç‰ˆä¸­çš„çœŸå®žtokenæ›¿æ¢æˆå¯å¾®çš„virtual token P-Tuning V2 github THUDM/P-tuning-v2 P-tuning V2è®ºæ–‡å’Œä»£ç å®žçŽ°è¯¦è§£ æ¦‚è¿° ä»£ç ç¤ºä¾‹ PrefixEncoderç±»ï¼Œä¸ºäº†èŽ·å¾—è¿žç»­promptï¼Œè®¾è®¡çš„æ¨¡å— import torch class PrefixEncoder(torch.nn.Module): r''' The torch.nn model to encode the prefix Input shape: (batch-size, prefix-length) Output shape: (batch-size, prefix-length, 2*layers*hidden) ''' def __init__(self, config): super().__init__() self.prefix_projection = config.prefix_projection if self.prefix_projection: # Use a two-layer MLP to encode the prefix self.embedding = torch.nn.Embedding(config.pre_seq_len, config.hidden_size) self.trans = torch.nn.Sequential( torch.nn.Linear(config.hidden_size, config.prefix_hidden_size), torch.nn.Tanh(), torch.nn.Linear(config.prefix_hidden_size, config.num_hidden_layers * 2 * config.hidden_size) ) else: self.embedding = torch.nn.Embedding(config.pre_seq_len, config.num_hidden_layers * 2 * config.hidden_size) def forward(self, prefix: torch.Tensor): if self.prefix_projection: prefix_tokens = self.embedding(prefix) past_key_values = self.trans(prefix_tokens) else: past_key_values = self.embedding(prefix) return past_key_values > class BertPrefixForTokenClassification(BertPreTrainedModel): def __init__(self, config): super().__init__(config) self.num_labels = config.num_labels self.bert = BertModel(config, add_pooling_layer=False) self.dropout = torch.nn.Dropout(config.hidden_dropout_prob) self.classifier = torch.nn.Linear(config.hidden_size, config.num_labels) from_pretrained = False if from_pretrained: self.classifier.load_state_dict(torch.load('model/checkpoint.pkl')) for param in self.bert.parameters(): param.requires_grad = False self.pre_seq_len = config.pre_seq_len self.n_layer = config.num_hidden_layers self.n_head = config.num_attention_heads self.n_embd = config.hidden_size // config.num_attention_heads self.prefix_tokens = torch.arange(self.pre_seq_len).long() self.prefix_encoder = PrefixEncoder(config) bert_param = 0 for name, param in self.bert.named_parameters(): bert_param += param.numel() all_param = 0 for name, param in self.named_parameters(): all_param += param.numel() total_param = all_param - bert_param print('total param is {}'.format(total_param)) # 9860105 def get_prompt(self, batch_size): prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1).to(self.bert.device) # å¾—åˆ°è¿žç»­Prompt past_key_values = self.prefix_encoder(prefix_tokens) # bsz, seqlen, _ = past_key_values.shape # æ”¹å˜å½¢çŠ¶ past_key_values = past_key_values.view( batch_size, self.pre_seq_len, self.n_layer * 2, self.n_head, self.n_embd ) past_key_values = self.dropout(past_key_values) # æ”¹å˜å½¢çŠ¶ï¼Œåˆ’åˆ†æˆæ•°ç»„ã€‚æ¯ä¸€ä¸ªæ•°ç»„å…ƒç´ å½¢çŠ¶ä¸ºï¼š(2,batch_size,n_head,seq_len,head_dim) past_key_values = past_key_values.permute([2, 0, 3, 1, 4]).split(2) return past_key_values def forward( self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None, output_attentions=None, output_hidden_states=None, return_dict=None, ): return_dict = return_dict if return_dict is not None else self.config.use_return_dict batch_size = input_ids.shape[0] past_key_values = self.get_prompt(batch_size=batch_size) prefix_attention_mask = torch.ones(batch_size, self.pre_seq_len).to(self.bert.device) attention_mask = torch.cat((prefix_attention_mask, attention_mask), dim=1) # å¼€å§‹ä¼ é€’past_key_values outputs = self.bert( input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask, inputs_embeds=inputs_embeds, output_attentions=output_attentions, output_hidden_states=output_hidden_states, return_dict=return_dict, past_key_values=past_key_values, ) ... return TokenClassifierOutput( loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions, ) ä¸€æ¬¡å‰å‘è®¡ç®—ä¸­ï¼ŒP-tuning v2ä¼šé€šè¿‡self.get_prompt(batch_size=batch_size)å¾—åˆ°è¦è¿žç»­Prompt BertEncoderä¼šæ‰§è¡Œforå¾ªçŽ¯ï¼ŒæŠŠpast_key_valuesæ‹†åˆ†åˆ°ä¸€ä¸ªä¸ªBertLayer self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)]) ... for i, layer_module in enumerate(self.layer): if output_hidden_states: all_hidden_states = all_hidden_states + (hidden_states,) layer_head_mask = head_mask[i] if head_mask is not None else None past_key_value = past_key_values[i] if past_key_values is not None else None ... # BertLayer layer_module(..., past_key_value, ...) å·§å¦™çš„åˆ©ç”¨past_key_valueså‚æ•°ï¼Œå°†past_key_valuesæ•°ç»„ä¸­æ¯ä¸€ä¸ªå…ƒç´ ï¼Œæ‹¼æŽ¥åˆ°BertSelfAttentionä¸­Keyå’ŒValue ä»£ç è·Ÿè¸ªé“¾è·¯BertModel -> BertEncoder -> BertLayer -> BertAttention -> BertSelfAttention class BertSelfAttention(nn.Module): ... def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor: # å°†å¼ é‡è½¬æ¢å½¢çŠ¶ï¼Œè°ƒæ¢ç»´åº¦ã€‚è¿™ä¸ªä»£ç ä¼šåœ¨seq_lengthç»´åº¦è¿›è¡Œæ‹¼æŽ¥ï¼Œå…¶ä»–ç»´åº¦ä¸å¯åŠ¨ new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size) x = x.view(new_x_shape) return x.permute(0, 2, 1, 3) def forward( self, hidden_states: torch.Tensor, attention_mask: Optional[torch.FloatTensor] = None, head_mask: Optional[torch.FloatTensor] = None, encoder_hidden_states: Optional[torch.FloatTensor] = None, encoder_attention_mask: Optional[torch.FloatTensor] = None, past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = None, output_attentions: Optional[bool] = False, ) -> Tuple[torch.Tensor]: mixed_query_layer = self.query(hidden_states) # If this is instantiated as a cross-attention module, the keys # and values come from an encoder; the attention mask needs to be # such that the encoder's padding tokens are not attended to. is_cross_attention = encoder_hidden_states is not None if is_cross_attention and past_key_value is not None: # reuse k,v, cross_attentions key_layer = past_key_value[0] value_layer = past_key_value[1] attention_mask = encoder_attention_mask elif is_cross_attention: key_layer = self.transpose_for_scores(self.key(encoder_hidden_states)) value_layer = self.transpose_for_scores(self.value(encoder_hidden_states)) attention_mask = encoder_attention_mask elif past_key_value is not None: key_layer = self.transpose_for_scores(self.key(hidden_states)) value_layer = self.transpose_for_scores(self.value(hidden_states)) key_layer = torch.cat([past_key_value[0], key_layer], dim=2) value_layer = torch.cat([past_key_value[1], value_layer], dim=2) else: key_layer = self.transpose_for_scores(self.key(hidden_states)) value_layer = self.transpose_for_scores(self.value(hidden_states)) query_layer = self.transpose_for_scores(mixed_query_layer) ... è¿™é‡Œå°±ä¼šæŠŠpast_key_valueæ‹¼æŽ¥åˆ°äº†åŽŸå§‹çš„kã€vä¸Šé¢ï¼Œè¿™æ ·å­å°±ç›¸å½“äºŽç»™kã€væ·»åŠ äº†é¢å¤–éœ€è¦å­¦ä¹ çš„å‚æ•°äº†ï¼Œå†å¾®è°ƒæ—¶åªæ›´æ–°è¿™éƒ¨åˆ†æ–°çš„å‚æ•°å³å¯ P-tuning V2è¿žç»­Promptä»£ç å®žçŽ°ä»¿çœŸä»£ç  #!/usr/bin/env Python # -- coding: utf-8 -- \"\"\" @version: v1.0 @author: huangyc @file: p_tuning_test.py @Description: @time: 2023/6/6 15:31 \"\"\" import torch from torch import nn def run(): def transpose_for_scores(x: torch.Tensor) -> torch.Tensor: new_x_shape = x.size()[:-1] + (12, 64) x = x.view(new_x_shape) return x.permute(0, 2, 1, 3) prompt = torch.rand(32, 128, 48, 12, 64) # batch_size, seq_len, num_layer*2, num_head, head_size prompt = prompt.permute([2, 0, 3, 1, 4]) print(f\"P-tuningV2æž„é€ çš„trainable continuous embeddingså½¢çŠ¶ï¼š{prompt.shape}\") past_key_values = prompt.split(2) num_layers = 24 hidden_dim = 768 n_head = 12 head_dim = hidden_dim // n_head all_head_size = n_head * head_dim hidden_states = torch.randn(32, 128, 768) # batch_size, seq_len, hidden_size print(f\"è¾“å…¥çš„å‘é‡å½¢çŠ¶ï¼š{hidden_states.shape}\") for i in range(num_layers): past_key_value = past_key_values[i] print(f\"æ¯ä¸€å±‚BertLayeréœ€è¦åŠ å…¥çš„promptå½¢çŠ¶: {past_key_value.shape}\") self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None # BertSelfAttention query = nn.Linear(hidden_dim, all_head_size) key = nn.Linear(hidden_dim, all_head_size) value = nn.Linear(hidden_dim, all_head_size) # åŽŸå§‹kvçš„å¤§å° key_layer = transpose_for_scores(key(hidden_states)) old_key_layer_shape = key_layer.shape print(f\"ç»è¿‡transpose_for_scoresåŽçš„keyå½¢çŠ¶ï¼š{old_key_layer_shape}\") value_layer = transpose_for_scores(value(hidden_states)) old_value_layer_shape = value_layer.shape print(f\"ç»è¿‡transpose_for_scoresåŽçš„valueå½¢çŠ¶ï¼š{old_value_layer_shape}\\n\") # æ‹¼æŽ¥åŽkvçš„å¤§å° key_layer = torch.cat([past_key_value[0], key_layer], dim=2) print( f\"past_key_value[0]çš„å½¢çŠ¶ï¼š{past_key_value[0].shape} åŽŸå§‹key_layerçš„å½¢çŠ¶ï¼š{old_key_layer_shape} ç»è¿‡catåŽçš„key_layerå½¢çŠ¶ï¼š{key_layer.shape}\") value_layer = torch.cat([past_key_value[1], value_layer], dim=2) print( f\"past_key_value[1]çš„å½¢çŠ¶ï¼š{past_key_value[1].shape} åŽŸå§‹value_layerçš„å½¢çŠ¶ï¼š{old_value_layer_shape} ç»è¿‡catåŽçš„value_layerå½¢çŠ¶ï¼š{value_layer.shape}\\n\") mixed_query_layer = query(hidden_states) print(f\"hidden_statesç»è¿‡queryå±‚åŽè¾“å‡ºçš„å½¢çŠ¶ï¼š{mixed_query_layer.size()}\") # batch seq len embed query_layer = transpose_for_scores(mixed_query_layer) print(f\"ç»è¿‡transpose_for_scoresåŽçš„queryå½¢çŠ¶{query_layer.size()}\") # batch print(\"æ³¨æ„åŠ›åˆ†æ•°å¼€å§‹è®¡ç®—\") attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2)) print(f\"attention_scoresçš„å½¢çŠ¶ï¼š{attention_scores.size()}\") # batch head seq_len seq_len print(\"å¼€å§‹æ³¨æ„åŠ›æ±‡èšè®¡ç®—\") context_layer = torch.matmul(attention_scores, value_layer) print(f\"æ³¨æ„åŠ›æ±‡èšåŽè¾“å‡ºçŸ©é˜µcontext_layerçš„å½¢çŠ¶ï¼š{context_layer.size()}\") # batch head seq_len embed/12 print(\"æœ€åŽï¼Œå°†context_layerçš„å½¢çŠ¶æ¢å¤æˆè¾“å…¥hidden_statesçš„å½¢çŠ¶\") context_layer = context_layer.permute(0, 2, 1, 3).contiguous() new_context_layer_shape = context_layer.size()[:-2] + (768,) context_layer = context_layer.view(new_context_layer_shape) print(f\"context_layerçš„å½¢çŠ¶æ¢å¤å®Œæˆï¼Œå…¶å½¢çŠ¶ä¸ºï¼š{context_layer.size()}\") print(\"ä¸€æ¬¡P-tuningV2çš„BertLayerè®¡ç®—ä»¿çœŸç»“æŸ\") break if __name__ == '__main__': run() æµ‹è¯•è¾“å‡º S:\\Anaconda3\\envs\\torch38\\python.exe Q:\\pyCharmWS\\chatgpts\\P-tuning-v2\\tests\\p_tuning_test.py P-tuningV2æž„é€ çš„trainable continuous embeddingså½¢çŠ¶ï¼štorch.Size([48, 32, 12, 128, 64]) è¾“å…¥çš„å‘é‡å½¢çŠ¶ï¼štorch.Size([32, 128, 768]) æ¯ä¸€å±‚BertLayeréœ€è¦åŠ å…¥çš„promptå½¢çŠ¶: torch.Size([2, 32, 12, 128, 64]) ç»è¿‡transpose_for_scoresåŽçš„keyå½¢çŠ¶ï¼štorch.Size([32, 12, 128, 64]) ç»è¿‡transpose_for_scoresåŽçš„valueå½¢çŠ¶ï¼štorch.Size([32, 12, 128, 64]) ====================> æ ¸å¿ƒ past_key_value[0]çš„å½¢çŠ¶ï¼štorch.Size([32, 12, 128, 64]) åŽŸå§‹key_layerçš„å½¢çŠ¶ï¼štorch.Size([32, 12, 128, 64]) ç»è¿‡catåŽçš„key_layerå½¢çŠ¶ï¼štorch.Size([32, 12, 256, 64]) past_key_value[1]çš„å½¢çŠ¶ï¼štorch.Size([32, 12, 128, 64]) åŽŸå§‹value_layerçš„å½¢çŠ¶ï¼štorch.Size([32, 12, 128, 64]) ç»è¿‡catåŽçš„value_layerå½¢çŠ¶ï¼štorch.Size([32, 12, 256, 64]) ====================> æ ¸å¿ƒ hidden_statesç»è¿‡queryå±‚åŽè¾“å‡ºçš„å½¢çŠ¶ï¼štorch.Size([32, 128, 768]) ç»è¿‡transpose_for_scoresåŽçš„queryå½¢çŠ¶torch.Size([32, 12, 128, 64]) æ³¨æ„åŠ›åˆ†æ•°å¼€å§‹è®¡ç®— attention_scoresçš„å½¢çŠ¶ï¼štorch.Size([32, 12, 128, 256]) å¼€å§‹æ³¨æ„åŠ›æ±‡èšè®¡ç®— æ³¨æ„åŠ›æ±‡èšåŽè¾“å‡ºçŸ©é˜µcontext_layerçš„å½¢çŠ¶ï¼štorch.Size([32, 12, 128, 64]) æœ€åŽï¼Œå°†context_layerçš„å½¢çŠ¶æ¢å¤æˆè¾“å…¥hidden_statesçš„å½¢çŠ¶ context_layerçš„å½¢çŠ¶æ¢å¤å®Œæˆï¼Œå…¶å½¢çŠ¶ä¸ºï¼štorch.Size([32, 128, 768]) ä¸€æ¬¡P-tuningV2çš„BertLayerè®¡ç®—ä»¿çœŸç»“æŸ LORAç³»åˆ— ç‚¹èµž&#x1F44D;Bç«™åšä¸» å°æ¨ä¸åŠªåŠ›0v0 + åšä¸»ç›¸å…³çš„æ–‡ç« é“¾æŽ¥ LORA(è½¬) LoRAï¼šè®­ç»ƒä½ çš„GPTã€è®ºæ–‡ç²—è¯»Â·1ã€‘ ä¸€ç§é€šè¿‡ä½Žç§©è¿‘ä¼¼å¢žé‡çŸ©é˜µçš„ï¼Œç»è¿‡å¹¿æ³›éªŒè¯è¶³å¤ŸRobustçš„å¾®è°ƒæ–¹æ³• æ‘˜è¦ éšç€è‡ªç„¶è¯­è¨€å¤„ç†(NLP)æ¨¡åž‹è§„æ¨¡çš„ä¸æ–­å¢žé•¿ï¼Œç”±äºŽæˆæœ¬å’Œèµ„æºé™åˆ¶ï¼Œå¯¹å…¶è¿›è¡Œå®Œå…¨å¾®è°ƒä»¥ç”¨äºŽä¸‹æ¸¸ä»»åŠ¡çš„æŒ‘æˆ˜æ—¥ç›Šå¢žåŠ  ä»‹ç»ä½Žç§©é€‚åº”(Low-Rank Adaptation)ã€‚LoRAé€šè¿‡å¼•å…¥å‚æ•°çŸ©é˜µæ¥å‡å°‘å‚æ•°ï¼Œå¹¶å°†GPUå†…å­˜éœ€æ±‚é™ä½Žäº†3å€ã€‚ç›¸æ¯”äºŽä½¿ç”¨GPT-3è¿›è¡Œå¾®è°ƒï¼Œå®ƒå°†å‚æ•°å‡å°‘äº†10,000å€ å°½ç®¡å¯è®­ç»ƒå‚æ•°æ›´å°‘ï¼Œä½†LoRAåœ¨å¤§å¤šæ•°è¯­è¨€æ¨¡åž‹ä¸Šè¡¨çŽ°ä¼˜äºŽå¾®è°ƒï¼Œå…·æœ‰æ›´é«˜çš„è®­ç»ƒåžåé‡å’Œæ— æŽ¨ç†å»¶è¿Ÿ å¯¹è¯­è¨€æ¨¡åž‹é€‚åº”ä¸­çš„ç§©ç¼ºå¤±è¿›è¡Œçš„å®žè¯ç ”ç©¶ä¸ºLoRAçš„æœ‰æ•ˆæ€§æä¾›äº†è¯æ®ï¼ŒLoRAæ˜¯å¼€æºçš„ ä»‹ç» å¯¹äºŽä¸‹æ¸¸ä»»åŠ¡è€Œè¨€ï¼Œå®Œå…¨å¾®è°ƒå¤§åž‹è¯­è¨€æ¨¡åž‹æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚ å—åˆ°[å†…åœ¨ç»´åº¦]çš„ç ”ç©¶å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†LoRAï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š ä½Žä»»åŠ¡åˆ‡æ¢å¼€é”€: ä¸€ä¸ªé¢„è®­ç»ƒæ¨¡åž‹å¯ä»¥è¢«å…±äº«å¹¶ç”¨äºŽæž„å»ºå¤šä¸ªé’ˆå¯¹ä¸åŒä»»åŠ¡çš„å°åž‹LoRAæ¨¡å— å‚æ•°é«˜æ•ˆ: LoRAé€šè¿‡ä½¿ç”¨è‡ªé€‚åº”ä¼˜åŒ–å™¨ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿å¾—è®­ç»ƒæ›´é«˜æ•ˆï¼Œå¹¶å°†ç¡¬ä»¶é—¨æ§›é™ä½Žäº†æœ€å¤š3å€ æ— æŽ¨ç†å»¶è¿Ÿ: LoRAçš„ç®€å•çº¿æ€§è®¾è®¡ä½¿å¾—å¯è®­ç»ƒçŸ©é˜µåœ¨éƒ¨ç½²æ—¶å¯ä»¥ä¸Žå†»ç»“æƒé‡åˆå¹¶ æ­£äº¤æ€§: LoRAä¸Žè®¸å¤šå…ˆå‰çš„æ–¹æ³•æ˜¯æ­£äº¤çš„ï¼Œå¹¶ä¸”å¯ä»¥ä¸Žå®ƒä»¬ç»“åˆä½¿ç”¨ï¼Œæ¯”å¦‚å‰ç¼€å¾®è°ƒ(prefix-tuning) é—®é¢˜æè¿° æ¨¡åž‹è®­ç»ƒæ—¶å‚æ•°é‡è¯„ä¼°ï¼Œå¯¹äºŽLLMï¼Œå¦‚æžœæ¨¡åž‹çš„å‚æ•°æ—¶\\Phiçš„è¯ å…¨é‡å¾®è°ƒ \\max _{\\Phi} \\sum_{(x, y) \\in \\mathcal{Z}} \\sum_{t=1}^{|y|} \\log \\left(P_{\\Phi}\\left(y_{t} \\mid x, y_{ ä½¿ç”¨Adamä¼˜åŒ–å™¨ä¸‹çš„ï¼Œ\\mathrm{n}=8ï¼Œå¹¶ä¸”ä½¿ç”¨æ··åˆç²¾åº¦ï¼Œä¸€ä¸ªå‚æ•°éœ€è¦16ä¸ªbytesæ¥å­˜å‚¨ï¼Œè¿™16ä¸ªbytesåˆ†åˆ«ä¸º æƒé‡Wéœ€è¦fp16æ¥å­˜å‚¨ï¼Œæ¿€æ´»å€¼Aéœ€è¦fp16ï¼Œä¸ºäº†æ›´æ–°æƒé‡è¿˜éœ€å­˜ä¸€ä¸ªå¤åˆ¶W_céœ€è¦fp32ï¼Œä¼˜åŒ–å™¨éœ€è¦å­˜ä¸¤ä¸ªå€¼ï¼Œåˆ†åˆ«æ˜¯Må’ŒV(æ–¹å·®)ï¼Œåˆ†åˆ«éœ€è¦fp32 å…¶ä¸­fp16å 2bytesï¼Œfp32å bytesï¼Œæ€»å…±ä¸º2+2+4+4+4 = 16bytes å› æ­¤ï¼Œ\\Phiä¸ªå‚æ•°å°±éœ€è¦ \\Phi * 2nbytes Lora \\max _{\\Theta} \\sum_{(x, y) \\in \\mathcal{Z}} \\sum_{t=1}^{|y|} \\log \\left(p_{\\Phi_{0}+\\Delta \\Phi(\\Theta)}\\left(y_{t} \\mid x, y_{ Loraåœ¨è®­ç»ƒæ—¶ï¼Œå°†åŽŸæ¥çš„å‚æ•°å›ºå®šä¸‹æ¥ï¼Œåªæ›´æ–°æ–°å¢žåŠ çš„å‚æ•°ï¼Œå› æ­¤Mem Required: (4 \\Phi+\\theta * 2 n) bytes åœ¨GPT-3çš„175Bå‚æ•°ä¸‹ï¼Œè¿™é‡Œçš„\\Thetaå¯ä»¥è¾¾åˆ°åŽŸæ¥çš„0.01 \\% ä¸ºä»€ä¹ˆä¼šæå‡ºLoraå‘¢ åŽŸæ¥çš„Adapteræ–¹æ³•ä¹Ÿæ˜¯å›ºå®šæ¨¡åž‹çš„å‚æ•°ï¼Œåªè®­ç»ƒMLPå‚æ•°ï¼Œä½†æ˜¯è¿™æ ·å­æœ‰å‡ ä¸ªå¼Šç«¯ å¢žåŠ äº†ç½‘ç»œæ·±åº¦ï¼Œå¢žåŠ äº†æŽ¨ç†çš„æ—¶é—´ æ·»åŠ MLPä¹‹åŽï¼Œè®­ç»ƒå‡ºæ¥çš„æœ€ä¼˜æ–¹æ¡ˆä¹Ÿåªèƒ½æ”¶æ•›åˆ°MLPå±‚ï¼Œä¸ä¸€å®šæ˜¯å…¨å±€æœ€å¥½çš„ ç›´æŽ¥åŽ»ä¼˜åŒ–è¿™ä¸ªPromoteå¹¶ä¸èƒ½ä¿è¯ä¼˜åŒ–æ˜¯å•è°ƒçš„ï¼Œä¹Ÿå°±æ˜¯ä¸æ˜¯å…¨å±€æœ€ä¼˜ï¼Œå¾ˆéš¾ä¼˜åŒ–å¥½ å‡å°‘äº†å¯ç”¨äºŽå¤„ç†ä¸‹æ¸¸ä»»åŠ¡çš„åºåˆ—é•¿åº¦ï¼Œå› ä¸ºæ–°åŠ å…¥çš„Promoteä¼šå ç”¨è¾“å…¥çš„tokené•¿åº¦ å…·ä½“æ–¹æ³• æœ€æ ¸å¿ƒçš„æ€è·¯å¦‚ä¸‹å…¬å¼æ‰€ç¤ºï¼Œç ”ç©¶è¡¨æ˜Ž\\Delta Wé€šå¸¸æ˜¯ä¸€ä¸ªæ¬ ç§©çš„çŸ©é˜µ W \\Leftarrow W_{0}+\\Delta W \\\\ W_{0}+\\Delta W=W_{0}+B A \\\\ h=W_{0} x+\\Delta W x=W_{0} x+B A x å› æ­¤ï¼Œ\\Delta Wå¯ä»¥è¿›è¡Œä½Žç§©åˆ†è§£ è®­ç»ƒæ—¶ï¼ŒBåˆå§‹åŒ–ä¸ºå…¨é›¶çŸ©é˜µï¼Œè¿™æ ·å­å‚æ•°é‡å°±ä»Žd*då˜æˆäº†d*2*rï¼Œè¿™é‡Œçš„rä¸€èˆ¬æ˜¯è¿œå°äºŽdçš„ ä¼˜ç‚¹ LoRAæ˜¯å¯¹å®Œå…¨å¾®è°ƒçš„ä¸€ç§æŽ¨å¹¿æ–¹æ³• åœ¨é€‚åº”è¿‡ç¨‹ä¸­ï¼ŒLoRAä¸éœ€è¦å¯¹æƒé‡çŸ©é˜µè¿›è¡Œå®Œå…¨ç§©çš„ç´¯ç§¯æ¢¯åº¦æ›´æ–°ï¼Œè€Œæ˜¯å¯ä»¥åŸºäºŽé¢„è®­ç»ƒçš„æƒé‡çŸ©é˜µè®¾ç½®ç§© å½“LoRAåº”ç”¨äºŽæ‰€æœ‰æƒé‡çŸ©é˜µå¹¶ä¸”åç½®è¿›è¡Œè®­ç»ƒæ—¶ï¼Œè¿™ç§æ–¹æ³•æä¾›äº†ç±»ä¼¼äºŽå®Œå…¨å¾®è°ƒçš„è¡¨çŽ°èƒ½åŠ› æ²¡æœ‰é¢å¤–çš„æŽ¨ç†å»¶è¿Ÿ åœ¨ç”Ÿäº§éƒ¨ç½²ä¸­ï¼ŒLoRAå¯ä»¥è®¡ç®—å’Œå­˜å‚¨W=W_0+BAï¼Œå…¶ä¸­W_0å’Œðµð´å±žäºŽâ„^{ð‘‘Ã—ð‘˜}ï¼Œå½“åˆ‡æ¢åˆ°å¦ä¸€ä¸ªä¸‹æ¸¸ä»»åŠ¡æ—¶ï¼Œå¯ä»¥é€šè¿‡å‡åŽ»ðµð´å¹¶åŠ ä¸Šä¸åŒçš„ðµ'ð´'æ¥æ¢å¤ð‘Š_0ï¼Œè¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿæ“ä½œï¼Œå‡ ä¹Žæ²¡æœ‰é¢å¤–çš„å†…å­˜å¼€é”€(æ½®æ±GPU) ä¸ºä»€ä¹ˆä½Žç§©çŸ©é˜µæœ‰æ•ˆ å½“ç»™å®šå‚æ•°æ•°é‡æ—¶ï¼Œåº”è¯¥è°ƒæ•´é¢„è®­ç»ƒTransformerä¸­çš„å“ªäº›å…·ä½“æƒé‡çŸ©é˜µå­é›†ä»¥å®žçŽ°æœ€ä½³çš„ä¸‹æ¸¸æ€§èƒ½ï¼Ÿ åœ¨ç»™å®šå‚æ•°é¢„ç®—çš„æƒ…å†µä¸‹ï¼Œç¡®å®šè¦è°ƒæ•´çš„æƒé‡çŸ©é˜µå­é›†ä»¥å®žçŽ°æœ€ä½³ä¸‹æ¸¸æ€§èƒ½æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼Œå¹¶ä¸”æ²¡æœ‰å›ºå®šçš„ç­”æ¡ˆ é€šå¸¸ï¼Œå¯ä»¥è€ƒè™‘æ ¹æ®ä¸‹æ¸¸ä»»åŠ¡çš„ç‰¹ç‚¹å’Œéœ€æ±‚è¿›è¡Œæƒè¡¡å’Œé€‰æ‹© ä¸€ç§å¸¸è§çš„æ–¹æ³•æ˜¯é€šè¿‡å¯¹ä¸åŒæƒé‡çŸ©é˜µè¿›è¡Œå®žéªŒæ€§å¾®è°ƒï¼Œå¹¶æ ¹æ®æ€§èƒ½è¯„ä¼°æ¥ç¡®å®šé€‚åˆç‰¹å®šä»»åŠ¡çš„æƒé‡çŸ©é˜µå­é›† æœ€ä¼˜çš„é€‚åº”çŸ©é˜µ\\Delta Wæ˜¯å¦çœŸçš„æ˜¯æ¬ ç§©çš„å—ï¼Ÿå¦‚æžœæ˜¯ï¼Œé‚£ä¹ˆåœ¨å®žé™…æƒ…å†µä¸‹æŽ¨èçš„ç§©æ˜¯å¤šå°‘ï¼Ÿ æœ€ä¼˜çš„é€‚åº”çŸ©é˜µ\\Delta Wæ˜¯å¦çœŸçš„æ˜¯æ¬ ç§©çš„ï¼Œè¿™å–å†³äºŽå…·ä½“æƒ…å†µã€‚ç§©ç¼ºå¤±æ„å‘³ç€çŸ©é˜µçš„ç§©(çŸ©é˜µçš„çº¿æ€§ç‹¬ç«‹åˆ—æ•°æˆ–è¡Œæ•°çš„æœ€å¤§æ•°é‡)è¾ƒä½Ž å¯¹äºŽå®žé™…ç›®çš„ï¼Œå»ºè®®é€‰æ‹©é€‚å½“çš„ç§©ä»¥å¹³è¡¡æ¨¡åž‹æ€§èƒ½å’Œè®¡ç®—æˆæœ¬ã€‚å…·ä½“æŽ¨èçš„ç§©å–å†³äºŽä»»åŠ¡çš„å¤æ‚æ€§ã€æ•°æ®é›†çš„è§„æ¨¡ä»¥åŠå¯ç”¨çš„è®¡ç®—èµ„æºç­‰å› ç´  \\Delta Wå’ŒWä¹‹é—´çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ\\Delta Wå’ŒWä¹‹é—´æ˜¯å¦å­˜åœ¨é«˜ç›¸å…³æ€§ï¼Ÿ\\Delta Wçš„å¤§å°ä¸ŽWç›¸æ¯”å¦‚ä½•ï¼Ÿ \\Delta Wè¡¨ç¤ºé€‚åº”çŸ©é˜µï¼Œç”¨äºŽè°ƒæ•´é¢„è®­ç»ƒæƒé‡çŸ©é˜µWï¼Œ\\Delta Wå’ŒWä¹‹é—´çš„å…³ç³»å–å†³äºŽå…·ä½“çš„é€‚åº”æ–¹æ³•å’Œä¼˜åŒ–ç®—æ³•ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œ\\Delta Wå¯ä»¥é€šè¿‡å¯¹Wçš„å¾®å°è°ƒæ•´æ¥èŽ·å¾—ï¼Œè€Œåœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œ\\Delta Wå¯èƒ½åŒ…å«æ›´å¤§çš„å˜åŒ– \\Delta Wå’ŒWä¹‹é—´çš„ç›¸å…³æ€§å–å†³äºŽé€‚åº”æ–¹æ³•çš„è®¾è®¡å’Œä¼˜åŒ–è¿‡ç¨‹çš„ç»†èŠ‚ã€‚å®ƒä»¬å¯ä»¥å­˜åœ¨ä¸€å®šçš„ç›¸å…³æ€§ï¼Œä½†å…·ä½“æƒ…å†µå¯èƒ½å› æ¨¡åž‹æž¶æž„ã€ä»»åŠ¡è¦æ±‚å’Œæ•°æ®é›†ç‰¹å¾è€Œå¼‚ \\Delta Wçš„å¤§å°ä¸ŽWçš„å¤§å°ä¹‹é—´æ²¡æœ‰å›ºå®šçš„æ¯”è¾ƒå…³ç³»ï¼Œå› ä¸ºå®ƒä»¬çš„å°ºåº¦å–å†³äºŽå…·ä½“çš„æ•°å€¼èŒƒå›´å’Œè°ƒæ•´æ–¹æ³• å¯¹äºŽattentionå‚æ•°é™„åŠ åˆ°å“ªä¸ªä¸Šæ›´æœ‰æ•ˆ å®žéªŒåœ¨GPT-3 175Bæ¨¡åž‹ä¸Šè®¾ç½®äº†ä¸€ä¸ªå‚æ•°é¢„ç®—ä¸º18M(å¦‚æžœä»¥FP16å­˜å‚¨ï¼Œå¤§çº¦ä¸º35MB)ã€‚è¿™å¯¹åº”äºŽå½“æˆ‘ä»¬é€‚åº”ä¸€ç§æ³¨æ„åŠ›æƒé‡æ—¶r=8ï¼Œæˆ–è€…å½“æˆ‘ä»¬é€‚åº”ä¸¤ç§ç±»åž‹æ—¶r=4ï¼Œé€‚ç”¨äºŽæ‰€æœ‰96å±‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå°†æ‰€æœ‰å‚æ•°æ”¾åœ¨\\Delta ð‘Š_ð‘žæˆ–\\Delta ð‘Š_kä¸­ä¼šå¯¼è‡´æ˜¾è‘—é™ä½Žæ€§èƒ½ï¼Œè€Œæ³¨å…¥åˆ°ð‘Š_ð‘žå’Œð‘Š_våˆ™äº§ç”Ÿæœ€ä½³ç»“æžœã€‚è¿™è¡¨æ˜Žï¼Œå³ä½¿ç§©ä¸º4ï¼Œ\\Delta ð‘Šä¸­åŒ…å«äº†è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä½¿å¾—ä¸Žä½¿ç”¨å…·æœ‰è¾ƒå¤§ç§©çš„å•ä¸€ç±»åž‹çš„æƒé‡ç›¸æ¯”ï¼Œä½¿ç”¨æ›´å¤šçš„æƒé‡çŸ©é˜µæ›´å¯å– å›žç­”ï¼šå°†å‚æ•°è®¾ç½®åˆ°qã€vä¸Šæ—¶ï¼Œrå–å¤šå°‘åˆé€‚ LoRAåœ¨éžå¸¸å°çš„ç§©(ç‰¹åˆ«æ˜¯å¯¹äºŽð‘Š_ð‘žï¼Œð‘Š_ð‘£è€Œè¨€)ä¸‹å·²ç»å–å¾—äº†ç›¸å½“çš„ç«žäº‰åŠ›ï¼Œè¿™è¡¨æ˜Žæ›´æ–°çŸ©é˜µ\\Delta Wå¯èƒ½å…·æœ‰éžå¸¸å°çš„å†…åœ¨ç§©ï¼Œä½¿ç”¨ä½Žç§©çŸ©é˜µå¯¹LLMè¿›è¡Œfine tuneçš„æ—¶å€™ï¼Œå¯ä»¥ç”¨ä¸€ä¸ªéžå¸¸å°çš„ä½Žç§©çŸ©é˜µï¼Œå°±å¯ä»¥æ•æ‰åˆ°å¯¹ä¸‹æ¸¸ä»»åŠ¡çš„ä¸€äº›ç‰¹å¾ä¿¡æ¯ï¼Œè¿™ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªéžå¸¸é«˜æ•ˆçš„LLMçš„fine tuneçš„æ–¹å¼ï¼ŒåŒæ—¶æé«˜äº†ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ å›žç­”ï¼š\\Delta Wå’ŒWä¹‹é—´çš„å…³ç³»æ˜¯ä»€ä¹ˆ é¦–å…ˆå¯¹\\Delta Wè¿›è¡Œå¥‡å¼‚å€¼åˆ†è§£ï¼Œå¹¶ä¸”æŠŠå®ƒå·¦å¥‡å¼‚å€¼å‘é‡å’Œå³å¥‡å¼‚å€¼å‘é‡ä¹˜åˆ°W_qä¸Šï¼ŒæŠŠW_qæ˜ å°„åˆ°\\Delta W_qçš„å­ç©ºé—´ï¼Œå¹¶è®¡ç®—FèŒƒæ•°ï¼ŒåŒæ—¶è¿˜æŠŠW_qæ˜ å°„åˆ°æ˜ å°„åˆ°éšæœºçŸ©é˜µä¸Š ä»¥æ­¤æ¥è¯æ˜Ž\\Delta W_qä¸ŽW_qæœ‰æ›´å¼ºçš„ç›¸å…³æ€§ é¦–å…ˆï¼Œä¸ŽéšæœºçŸ©é˜µç›¸æ¯”ï¼Œ\\Delta W_qä¸ŽW_qå…·æœ‰æ›´å¼ºçš„ç›¸å…³æ€§ï¼Œè¡¨æ˜Ž\\Delta Wæ”¾å¤§äº†é¢„è®­ç»ƒæ¨¡åž‹ä¸­çš„Wä¸­å·²ç»å­˜åœ¨çš„æŸäº›ç‰¹å¾ å…¶æ¬¡ï¼Œ\\Delta Wä¸æ˜¯é‡å¤Wçš„å¥‡å¼‚å€¼æ–¹å‘ï¼Œè€Œæ˜¯åªæ”¾å¤§åœ¨Wä¸­æ²¡æœ‰å¼ºè°ƒçš„æ–¹å‘ ç¬¬ä¸‰ï¼Œæ”¾å¤§å› å­ç›¸å½“å·¨å¤§ï¼šå½“r=4æ—¶ï¼Œ21.5â‰ˆ6.91/0.32ï¼Œè¡¨æ˜Ž\\Delta Wåªæ˜¯æ”¾å¤§äº†Wä¸­çš„ä¸€äº›ç‰¹å¾ï¼Œä¸”æ”¾å¤§å€æ•°æ˜¯å¾ˆå¤§çš„ï¼Œç›¸å½“äºŽæ˜¯æŠŠä¸‹æ¸¸ä»»åŠ¡éœ€è¦çš„ç‰¹å¾æå–å‡ºæ¥å¹¶è¿›è¡Œæ”¾å¤§ AdaLoRA(è½¬) AdaLoRAï¼šæ›´å¼ºå¤§çš„LoRA github cauyxy/YourGPT Loraä¸­çš„ræ˜¯ä¸€ä¸ªç¡®å®šå€¼ï¼Œä½†ä¸æ˜¯å¯¹äºŽæ‰€æœ‰çš„å±‚ï¼Œåƒqã€kè¿™æ ·çš„å±‚ï¼Œqå†…åœ¨ç§©æ¯”è¾ƒå¤§ï¼Œvå†…åœ¨ç§©æ¯”è¾ƒå°ï¼Œå¯¹äºŽä¸åŒçš„çŸ©é˜µåº”è¯¥ä½¿ç”¨ä¸åŒçš„å†…åœ¨ç§© AdaLoRAæ˜¯åœ¨å¯¹åŒæ ·çš„å‚æ•°é‡ä¸‹ï¼Œå¯¹ä¸åŒçš„çŸ©é˜µä½¿ç”¨ä¸åŒçš„rï¼Œé€šè¿‡å¥‡å¼‚å€¼åˆ†è§£ï¼Œåˆ¤æ–­rçš„å¤§å°ï¼Œæ¥å–å¾—æ›´å¥½çš„æ•ˆæžœ æå‡ºé—®é¢˜ åœ¨NLPé¢†åŸŸï¼Œå¯¹äºŽä¸‹æ¸¸ä»»åŠ¡è¿›è¡Œå¤§åž‹é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹çš„å¾®è°ƒå·²ç»æˆä¸ºä¸€ç§é‡è¦çš„åšæ³•ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œæˆ‘ä»¬ä¼šé‡‡ç”¨å¯¹åŽŸæœ‰çš„é¢„è®­ç»ƒæ¨¡åž‹è¿›è¡Œå…¨é‡å¾®è°ƒçš„æ–¹æ³•æ¥é€‚é…ä¸‹æ¸¸ä»»åŠ¡ï¼Œä½†è¿™ç§æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ è®­ç»ƒé˜¶æ®µ: å¯¹äºŽé¢„è®­ç»ƒæ¨¡åž‹è¿›è¡Œå¾®è°ƒçš„æ—¶å€™ï¼Œä¸ºäº†æ›´æ–°æƒé‡å‚æ•°ï¼Œéœ€è¦å¤§é‡çš„æ˜¾å­˜æ¥å­˜å‚¨å‚æ•°çš„æ¢¯åº¦å’Œä¼˜åŒ–å™¨ä¿¡æ¯ï¼Œåœ¨å½“ä»Šé¢„è®­ç»ƒæ¨¡åž‹çš„å‚æ•°å˜å¾—è¶Šæ¥è¶Šå¤§çš„æƒ…å†µä¸‹ï¼Œé’ˆå¯¹ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒé—¨æ§›å˜å¾—è¶Šæ¥è¶Šé«˜ æŽ¨ç†é˜¶æ®µ: ç”±äºŽæˆ‘ä»¬è®­ç»ƒçš„æ—¶å€™æ˜¯å¯¹äºŽæ¨¡åž‹å‚æ•°è¿›è¡Œå…¨é‡çš„æ›´æ–°ï¼Œæ‰€ä»¥å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡éœ€è¦ä¸ºæ¯ä¸ªä»»åŠ¡ç»´æŠ¤ä¸€ä¸ªå¤§åž‹æ¨¡åž‹çš„ç‹¬ç«‹å‰¯æœ¬ï¼Œè¿™æ ·å°±å¯¼è‡´æˆ‘ä»¬åœ¨å®žé™…åº”ç”¨çš„æ—¶å€™æµªè´¹äº†ä¸å¿…è¦çš„å­˜å‚¨ çŽ°æœ‰æ–¹æ³•: ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œç ”ç©¶è€…æå‡ºäº†ä¸¤ä¸ªä¸»è¦ç ”ç©¶æ–¹å‘ï¼Œä»¥å‡å°‘å¾®è°ƒå‚æ•°çš„æ•°é‡ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æé«˜é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹çš„æ€§èƒ½ æ·»åŠ å°åž‹ç½‘ç»œæ¨¡å— å°†å°åž‹ç½‘ç»œæ¨¡å—æ·»åŠ åˆ°PLMsä¸­ï¼Œä¿æŒåŸºç¡€æ¨¡åž‹ä¿æŒä¸å˜çš„æƒ…å†µä¸‹ä»…é’ˆå¯¹æ¯ä¸ªä»»åŠ¡å¾®è°ƒè¿™äº›æ¨¡å—ï¼Œå¯ä»¥ç”¨äºŽæ‰€æœ‰ä»»åŠ¡ã€‚è¿™æ ·ï¼Œåªéœ€å¼•å…¥å’Œæ›´æ–°å°‘é‡ä»»åŠ¡ç‰¹å®šçš„å‚æ•°ï¼Œå°±å¯ä»¥é€‚é…ä¸‹æ¸¸çš„ä»»åŠ¡ï¼Œå¤§å¤§æé«˜äº†é¢„è®­ç»ƒæ¨¡åž‹çš„å®žç”¨æ€§ï¼Œæ–¹æ³•ç¤ºä¾‹ Adapter tuningï¼šæ˜¯åœ¨åŸºç¡€æ¨¡åž‹çš„å„å±‚ä¹‹é—´æ’å…¥å°åž‹ç¥žç»æ¨¡å— Prefix tuningï¼šå°†å¯è®­ç»ƒçš„å‰ç¼€æ ‡è®°é™„åŠ åˆ°åŸºç¡€æ¨¡åž‹çš„è¾“å…¥æˆ–éšè—å±‚ä¸Š Prompt Tuning: ä¿®æ”¹æ¨¡åž‹çš„è¾“å…¥ï¼Œåœ¨æ¨¡åž‹è¾“å…¥çš„å‰é¢åŠ ä¸€äº›ç‰¹å®šçš„å‰ç¼€ å¯è¡Œä¹‹å¤„ï¼šå¯ä»¥è¾¾åˆ°ä¸Žå®Œå…¨å¾®è°ƒå‡ ä¹Žç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶ä»…æ›´æ–°ä¸åˆ°åŽŸå§‹æ¨¡åž‹å‚æ•°çš„1ï¼…ï¼Œå¤§å¤§å‡å°‘äº†å†…å­˜æ¶ˆè€—ã€‚ å­˜åœ¨é—®é¢˜ï¼š Adapter tuningï¼šå¼•å…¥äº†æŽ¨ç†å»¶è¿Ÿï¼Œæœ€ç»ˆæ”¶æ•›åˆ°é€‚é…å™¨å±‚ Prefix or Prompt tuningï¼šç›´æŽ¥ä¼˜åŒ–Prefixå’ŒPromptæ˜¯éžå•è°ƒçš„ï¼Œæ¯”è¾ƒéš¾æ”¶æ•›ï¼Œå¹¶ä¸”æ¶ˆè€—äº†è¾“å…¥çš„token ä¸‹æ¸¸ä»»åŠ¡å¢žé‡æ›´æ–° å¯¹é¢„è®­ç»ƒæƒé‡çš„å¢žé‡æ›´æ–°è¿›è¡Œå»ºæ¨¡ï¼Œè€Œæ— éœ€ä¿®æ”¹æ¨¡åž‹æž¶æž„ W=W^{(0)}+\\Delta æ–¹æ³•ç¤ºä¾‹ï¼š Diff pruningï¼šå°†\\Deltaåˆå§‹åŒ–ä¸ºä¸ŽWç›¸åŒçš„ç»´åº¦ï¼Œç„¶åŽæ ¹æ®å‚æ•°çš„å¤§å°æŒ‰å…ƒç´ å¯¹\\Deltaè¿›è¡Œå‰ªæž LoRAï¼šé€šè¿‡ä¸¤ä¸ªå°å¾—å¤šçš„çŸ©é˜µçš„ä¹˜ç§¯å°†\\Deltaå‚æ•°åŒ–ä¸ºä½Žé˜¶çŸ©é˜µ W=W^{(0)}+\\Delta=W^{(0)}+B A å¯è¡Œä¹‹å¤„ï¼šå¯ä»¥è¾¾åˆ°ä¸Žå®Œå…¨å¾®è°ƒå‡ ä¹Žç›¸å½“çš„æ€§èƒ½ å­˜åœ¨é—®é¢˜: Diff pruningï¼š éœ€è¦åº•å±‚å®žçŽ°æ¥åŠ é€Ÿéžç»“æž„åŒ–ç¨€ç–çŸ©é˜µçš„è®¡ç®—ï¼Œä¸èƒ½ç›´æŽ¥ä½¿ç”¨çŽ°æœ‰çš„æ¡†æž¶ è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦å­˜å‚¨å®Œæ•´çš„\\DeltaçŸ©é˜µï¼Œç›¸æ¯”äºŽFull finetuneå¹¶æ²¡æœ‰é™ä½Žè®¡ç®—æˆæœ¬ LoRAï¼š é¢„å…ˆæŒ‡å®šæ¯ä¸ªå¢žé‡çŸ©é˜µçš„å†…åœ¨ç§©rç›¸åŒï¼Œå¿½ç•¥äº†åœ¨å¾®è°ƒé¢„è®­ç»ƒæ¨¡åž‹æ—¶ï¼Œæƒé‡çŸ©é˜µçš„é‡è¦æ€§åœ¨ä¸åŒæ¨¡å—å’Œå±‚ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ åªè®­ç»ƒäº†self-attentionï¼Œæ²¡æœ‰è®­ç»ƒfeed-forward networksï¼Œäº‹å®žä¸ŠFFNæ›´é‡è¦ é—®é¢˜æ€»ç»“ ä¸èƒ½é¢„å…ˆæŒ‡å®šçŸ©é˜µçš„ç§©ï¼Œéœ€è¦åŠ¨æ€æ›´æ–°å¢žé‡çŸ©é˜µçš„R æƒé‡çŸ©é˜µçš„é‡è¦æ€§åœ¨ä¸åŒæ¨¡å—å’Œå±‚ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ éœ€è¦æ‰¾åˆ°æ›´åŠ é‡è¦çš„çŸ©é˜µï¼Œåˆ†é…æ›´å¤šçš„å‚æ•°ï¼Œè£å‰ªä¸é‡è¦çš„çŸ©é˜µ æ‰¾åˆ°é‡è¦çš„çŸ©é˜µï¼Œæå‡æ¨¡åž‹æ•ˆæžœ è£å‰ªä¸é‡è¦çš„çŸ©é˜µï¼Œé™ä½Žå‚æ•°è®¡ç®—é‡ï¼Œé™ä½Žæ¨¡åž‹æ•ˆæžœå·®çš„é£Žé™© è§£å†³æ–¹æ¡ˆ ç›®æ ‡ï¼šåœ¨ç±»ä¼¼LoRAçš„å¾®è°ƒè¿‡ç¨‹ä¸­åŠ¨æ€åˆ†é…å‚æ•°é¢„ç®—ç»™æƒé‡çŸ©é˜µ è°ƒæ•´å¢žé‡çŸ©é˜µçš„ç§©æ¥æŽ§åˆ¶é¢„ç®—åˆ†é…ã€‚AdaLoRAå°†å…³é”®çš„å¢žé‡çŸ©é˜µåˆ†é…é«˜ç§©ä»¥æ•æ‰æ›´ç²¾ç»†å’Œä»»åŠ¡ç‰¹å®šçš„ä¿¡æ¯ï¼Œè€Œå°†è¾ƒä¸é‡è¦çš„çŸ©é˜µçš„ç§©é™ä½Žä»¥é˜²æ­¢è¿‡æ‹Ÿåˆå¹¶èŠ‚çœè®¡ç®—é¢„ç®— é‡‡ç”¨å‚æ•°åŒ–çŸ©é˜µæ¥æ¨¡æ‹ŸSVDï¼Œå¹¶èˆå¼ƒä¸é‡è¦çš„å¥‡å¼‚å€¼ï¼ŒåŒæ—¶ä¿ç•™å¥‡å¼‚å‘é‡ã€‚ç”±äºŽå¯¹ä¸€ä¸ªå¤§çŸ©é˜µè¿›è¡Œç²¾ç¡®SVDåˆ†è§£çš„è®¡ç®—æ¶ˆè€—éžå¸¸å¤§ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥åŠ é€Ÿè®¡ç®—ï¼ŒåŒæ—¶ä¿ç•™æœªæ¥æ¢å¤çš„å¯èƒ½æ€§å¹¶ç¨³å®šè®­ç»ƒ åœ¨è®­ç»ƒæŸå¤±ä¸­æ·»åŠ äº†é¢å¤–çš„æƒ©ç½šé¡¹ï¼Œä»¥è§„èŒƒå¥‡å¼‚çŸ©é˜µPå’ŒQçš„æ­£äº¤æ€§ï¼Œä»Žè€Œé¿å…SVDçš„å¤§é‡è®¡ç®—å¹¶ç¨³å®šè®­ç»ƒ SVD-BASED ADAPTATION å¦‚ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬æŠŠå¢žé‡çŸ©é˜µ\\Deltaåšä¸€ä¸ªå¥‡å¼‚å€¼åˆ†è§£çš„è¿‘ä¼¼ï¼Œå³\\Delta=P \\Lambda Qï¼Œå¯¹çŸ©é˜µæ›´æ–°çš„æè¿°åˆ™æœ‰å¦‚ä¸‹è¡¨ç¤º W=W^{(0)}+\\Delta=W^{(0)}+P \\Lambda Q ä¸ºäº†ä¿è¯\\mathrm{P}å’Œ\\mathrm{Q}çš„æ­£äº¤æ€§ï¼Œå³P^{\\top} P=Q Q^{\\top}=Iï¼Œæˆ‘ä»¬æå‡ºå¦‚ä¸‹æ‰€ç¤ºçš„æ­£åˆ™æŸå¤± R(P, Q)=\\left\\|P^{\\top} P-I\\right\\|_{\\mathrm{F}}^{2}+\\left\\|Q Q^{\\top}-I\\right\\|_{\\mathrm{F}}^{2} ä¸ºä»€ä¹ˆä¸ç›´æŽ¥åœ¨åŽŸæ¥çš„BAä¸Šè¿›è¡Œä¿®å‰ªï¼Ÿ å½“ä¸€å¯¹å¥‡å¼‚å‘é‡è¢«è®¤ä¸ºä¸ºä¸é‡è¦æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»ä¿®å‰ªå®ƒçš„æ‰€æœ‰å…ƒç´ ã€‚è¿™å°±å¯¼è‡´å‡ ä¹Žä¸å¯èƒ½é‡æ–°æ¿€æ´»ä¿®å‰ªè¿‡çš„å¥‡å¼‚å‘é‡ï¼Œå› ä¸ºå®ƒä»¬çš„å…ƒç´ éƒ½è¢«æ¸…é›¶å¹¶ä¸”ä¸å†è®­ç»ƒ ä¸Žä¹‹å¯¹æ¯”ï¼ŒAdaLoRAåªæ˜¯Maskäº†å¥‡å¼‚å€¼ LoRAçš„Aå’ŒBä¸æ˜¯æ­£äº¤çš„ï¼Œè¿™æ„å‘³ç€å¥‡å¼‚å‘é‡å¯ä»¥ç›¸äº’ä¾èµ–ã€‚ ä¸Žæˆªæ–­æœ€å°çš„å¥‡å¼‚å€¼ç›¸æ¯”ï¼Œä¸¢å¼ƒå¥‡å¼‚å‘é‡å¯èƒ½ä¼šå¯¼è‡´åŽŸå§‹çŸ©é˜µå‘ç”Ÿæ›´å¤§çš„å˜åŒ–ã€‚ å› æ­¤ï¼Œåœ¨åˆ†é…å®Œç§©çš„æ¯ä¸€æ­¥ä¹‹åŽï¼Œå¢žé‡çŸ©é˜µé€šå¸¸ä¼šå‘ç”Ÿæ›´å¤šä¸å¯é¢„æµ‹çš„æ˜¾è‘—å˜åŒ–ï¼Œè¿™å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œç”šè‡³æŸå®³æ¨¡åž‹çš„æ•ˆæžœ IMPORTANCE-AWARE RANK ALLOCATION æˆ‘ä»¬å°†åŸºäºŽSVDçš„ç§©è°ƒæ•´åº”ç”¨äºŽæ¯ä¸ªæƒé‡çŸ©é˜µï¼ŒåŒ…æ‹¬æ¯ä¸ªtransformerå±‚çš„W_{q}, W_{k}, W_{v}, W_{f 1}å’ŒW_{f 2}ã€‚ä¸ºäº†æŽ§åˆ¶å‚æ•°é¢„ç®—ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒæœŸé—´æ ¹æ®é‡è¦æ€§å¾—åˆ†è¿­ä»£ä¿®å‰ªå¥‡å¼‚å€¼ ä¸ºäº†æ›´å¥½åœ°è¡¨ç¤ºï¼Œæˆ‘ä»¬ç”¨kæ¥ç´¢å¼•å¢žé‡çŸ©é˜µ\\Delta_{k}=P_{k} \\Lambda_{k} Q_{k} for k=1, \\ldots, nï¼Œç”¨\\mathcal{G}_{k, i}=\\left\\{P_{k, * i}, \\lambda_{k, i}, Q_{k, i *}\\right\\}æ¥è¡¨ç¤ºç¬¬kä¸ªçŸ©é˜µçš„å¥‡å¼‚å€¼ï¼Œå¥‡å¼‚å‘é‡ä¸‰å…ƒç»„ï¼Œ\\mathcal{S}_{k, i} æ¥è¡¨ç¤ºè¿™ä¸ªä¸‰å…ƒç»„çš„é‡è¦æ€§ \\mathcal{C}(\\mathcal{P}, \\mathcal{E}, \\mathcal{Q})ä½œä¸ºå‚æ•°è®­ç»ƒçš„ä»£ä»·ï¼ŒåŒæ—¶åŠ ä¸Šæ­£åˆ™åŒ–é¡¹ï¼Œå°±å¾—å‡ºäº†å¦‚ä¸‹çš„ç›®æ ‡å‡½æ•°: (\\gammaæ˜¯æ­£åˆ™åŒ–ç³»æ•°) \\mathcal{L}(\\mathcal{P}, \\mathcal{E}, \\mathcal{Q})=\\mathcal{C}(\\mathcal{P}, \\mathcal{E}, \\mathcal{Q})+\\gamma \\sum_{k=1}^{n} R\\left(P_{k}, Q_{k}\\right) æˆ‘ä»¬åœ¨è®­ç»ƒçš„æ—¶å€™å°±å¯ä»¥é€šè¿‡æ¢¯åº¦ä¸‹é™çš„æ–¹å¼å¯¹P, \\Lambda, Qè¿›è¡Œæ›´æ–°ï¼Œä¸‹é¢æ˜¯\\Lambdaçš„ä¾‹å­ \\tilde{\\Lambda}_{k}^{(t)}=\\Lambda_{k}^{(t)}-\\eta \\nabla_{\\Lambda_{k}} \\mathcal{L}\\left(\\mathcal{P}^{(t)}, \\mathcal{E}^{(t)}, \\mathcal{Q}^{(t)}\\right) ç„¶åŽæˆ‘ä»¬å†åŸºäºŽ\\mathcal{S}_{k, i}å¯¹\\Lambdaè¿›è¡Œè£å‰ª \\Lambda_{k}^{(t+1)}=\\mathcal{T}\\left(\\tilde{\\Lambda}_{k}^{(t)}, S_{k}^{(t)}\\right), \\text { with } \\mathcal{T}\\left(\\tilde{\\Lambda}_{k}^{(t)}, S_{k}^{(t)}\\right)_{i i}=\\left\\{\\begin{array}{ll} \\tilde{\\Lambda}_{k, i i}^{(t)} & S_{k, i}^{(t)} \\text { is in the top- } b^{(t)} \\text { of } S^{(t)} \\\\ 0 & \\text { otherwise } \\end{array}\\right. å…¶ä¸­S^{(t)}=\\left\\{S_{k, i}^{(t)}\\right\\}_{1 \\leq k \\leq n, 1 \\leq i \\leq r}åŒ…å«æ‰€æœ‰ä¸‰å…ƒç»„çš„é‡è¦æ€§åˆ†æ•°ã€‚b^{(t)}æ˜¯ç¬¬\\mathrm{t}æ­¥å‰©ä½™å¥‡å¼‚å€¼çš„é¢„ç®— é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬é€šè¿‡ä¿®å‰ªä¸å¤ªé‡è¦çš„å¥‡å¼‚å€¼ï¼Œå°†æ›´å¤šé¢„ç®—ç•™ç»™ä¼˜å…ˆçº§è¾ƒé«˜çš„å¢žé‡çŸ©é˜µ Magnitude of singular values è¿™æ ·çš„è¯åªæœ‰æœ€å°çš„å¥‡å¼‚å€¼ä»¥åŠæœ€ä¸é‡è¦çš„å¥‡å¼‚å‘é‡è¢«åŽ»å¼ƒã€‚å®ƒæœ€å¤§é™åº¦åœ°å‡å°äº†ä¸ŽåŽŸå§‹çŸ©é˜µçš„åå·®ï¼Œè¿›ä¸€æ­¥ç¨³å®šäº†è®­ç»ƒã€‚ä½†æ˜¯è¿™ä¸ªåº¦é‡ä¸èƒ½æ­£ç¡®é‡åŒ–å‚æ•°(ä¸‰å…ƒç»„)å¯¹æ¨¡åž‹æ€§èƒ½çš„è´¡çŒ® S_{k, i}=\\left|\\lambda_{k, i}\\right| Sensitivity-based importance ä¹‹å‰çš„å·¥ä½œåˆ©ç”¨çµæ•åº¦æ¥é‡åŒ–å•ä¸ªå‚æ•°çš„é‡è¦æ€§ï¼Œå¹¶æ®æ­¤å¯¹å‚æ•°è¿›è¡Œéžç»“æž„åŒ–ä¿®å‰ªã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸Šï¼Œæˆ‘ä»¬å¿…é¡»è®¾è®¡ä¸€ä¸ªæ–°çš„åº¦é‡æ ‡å‡†ï¼Œå› ä¸ºä¸‰å…ƒç»„è¦è¢«æŒ‰ç»„ä¸¢å¼ƒäº†ï¼Œæ‰€ä»¥æ¯ä¸€é¡¹çš„æ•æ„Ÿæ€§éƒ½åº”è¯¥è¢«è€ƒè™‘ï¼Œå¹¶é€‚å½“åœ°ç»„åˆèµ·æ¥ï¼Œä»¥é‡åŒ–ä¸‰å…ƒç»„å¯¹æ¨¡åž‹æ€§èƒ½çš„æ•´ä½“è´¡çŒ® æˆ‘ä»¬è®¾è®¡äº†å¦‚ä¸‹æ‰€ç¤ºçš„å‡½æ•°æ¥è®¡ç®—importance score S_{k, i}=s\\left(\\lambda_{k, i}\\right)+\\frac{1}{d_{1}} \\sum_{j=1}^{d_{1}} s\\left(P_{k, j i}\\right)+\\frac{1}{d_{2}} \\sum_{j=1}^{d_{2}} s\\left(Q_{k, i j}\\right) æˆ‘ä»¬å¯ä»¥é‡‡ç”¨s(\\cdot)çš„çµæ•åº¦ï¼Œs(\\cdot)å®šä¹‰ä¸ºæ¢¯åº¦æƒé‡ä¹˜ç§¯çš„å¤§å°: I\\left(w_{i j}\\right)=\\left|w_{i j} \\nabla_{w_{i j}} \\mathcal{L}\\right| æœ¬è´¨ä¸Šè¿‘ä¼¼äºŽå‚æ•°å½’é›¶æ—¶çš„æŸå¤±å˜åŒ–ã€‚å¦‚æžœåŽ»é™¤ä¸€ä¸ªå‚æ•°å½±å“è¾ƒå¤§ï¼Œåˆ™æ¨¡åž‹å¯¹è¯¥å‚æ•°æ•æ„Ÿï¼Œæˆ‘ä»¬åº”è¯¥ä¿ç•™å®ƒ ä½†ä¹‹å‰çš„å·¥ä½œæŒ‡å‡ºï¼Œç›´æŽ¥è®¡ç®—çš„æ•æ„Ÿæ€§è¿˜ä¸æ˜¯ä¸€ä¸ªå¯é çš„é‡è¦æŒ‡æ ‡ã€‚è¿™æ ·çš„åˆ†æ•°æ˜¯åœ¨æŠ½æ ·çš„minibatchä¸Šä¼°è®¡çš„ã€‚éšæœºé‡‡æ ·å’Œå¤æ‚çš„è®­ç»ƒåŠ¨æ€å¯¼è‡´çµæ•åº¦ä¼°è®¡çš„å˜å¼‚æ€§å¤§ï¼Œä¸ç¡®å®šæ€§å¤§ï¼Œè¿™æ ·å¯èƒ½ä¼šå¯¼è‡´å¯¹äºŽå‚æ•°çš„é‡è¦æ€§çš„é”™è¯¯ä¼°è®¡ã€‚æå‡ºé€šè¿‡çµæ•åº¦å¹³æ»‘å’Œä¸ç¡®å®šæ€§é‡åŒ–ï¼ŒåŠ å…¥ç´¯è®¡çµæ•åº¦çš„å½±å“æ¥è§£å†³è¿™ä¸€é—®é¢˜: \\begin{array}{l} \\bar{I}^{(t)}\\left(w_{i j}\\right)=\\beta_{1} \\bar{I}^{(t-1)}\\left(w_{i j}\\right)+\\left(1-\\beta_{1}\\right) I^{(t)}\\left(w_{i j}\\right) \\\\ \\bar{U}^{(t)}\\left(w_{i j}\\right)=\\beta_{2} \\bar{U}^{(t-1)}\\left(w_{i j}\\right)+\\left(1-\\beta_{2}\\right)\\left|I^{(t)}\\left(w_{i j}\\right)-\\bar{I}^{(t)}\\left(w_{i j}\\right)\\right| \\end{array} æŽ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æŠŠs(\\cdot)å®šä¹‰ä¸º\\bar{I}^{(t)}å’Œ\\bar{U}^{(t)}çš„ä¹˜ç§¯ s^{(t)}\\left(w_{i j}\\right)=\\bar{I}^{(t)}\\left(w_{i j}\\right) \\cdot \\bar{U}^{(t)}\\left(w_{i j}\\right) è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†ä¸€ä¸ªæ—¢è€ƒè™‘äº†ä¸‰å…ƒç»„æ‰€æœ‰å…ƒç´ ï¼Œåˆè€ƒè™‘äº†ç´¯è®¡çµæ•åº¦è¶³å¤Ÿå¹³æ»‘çš„ä¸€ä¸ªé‡è¦æ€§å‡½æ•° GLOBAL BUDGET SCHEDULER åœ¨ä½Žç§©è‡ªé€‚åº”çš„æƒ…å†µä¸‹ï¼Œè°ƒæ•´ç§©è‡ªç„¶æ˜¯ä¸ºäº†æŽ§åˆ¶å‚æ•°é¢„ç®—ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°†é¢„ç®—b^{(t)}å®šä¹‰ä¸ºæ‰€æœ‰å¢žé‡çŸ©é˜µçš„æ€»ç§©ï¼Œå³æ€»å¥‡å¼‚å€¼çš„æ•°é‡ å›žæƒ³ä¸€ä¸‹ï¼Œé¢„ç®—åˆ†é…æ˜¯åœ¨å¾®è°ƒæœŸé—´è¿­ä»£æ‰§è¡Œçš„ã€‚ä¸ºäº†ä¾¿äºŽè®­ç»ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå…¨å±€é¢„ç®—è°ƒåº¦å™¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä»Žç•¥é«˜äºŽç›®æ ‡é¢„ç®—b^{(T)}çš„åˆå§‹é¢„ç®—ç®—b^{(0)}å¼€å§‹(ä¾‹å¦‚ï¼Œb^{(T)}çš„1.5å€) æˆ‘ä»¬å°†æ¯ä¸ªå¢žé‡çŸ©é˜µçš„åˆå§‹ç§©è®¾ä¸ºr=\\frac{b^{(0)}}{n}ã€‚æˆ‘ä»¬å¯¹t_{\\text {init }}æ­¥è¿›è¡Œwarmupï¼Œç„¶åŽæŒ‰ç…§ä¸‰æ¬¡è®¡åˆ’å‡å°‘é¢„ç®—b^{(t)}ï¼Œç›´åˆ°è¾¾åˆ°b^{(t)} æœ€åŽï¼Œæˆ‘ä»¬å¾—åˆ°çš„ä¿®æ­£å®Œé¢„ç®—åˆ†å¸ƒï¼Œå¹¶å¯¹t_{\\text {final }}æ­¥éª¤çš„æ¨¡åž‹è¿›è¡Œäº†å¾®è°ƒ è¿™ä½¿å¾—AdaLoRAå¯ä»¥å…ˆæŽ¢ç´¢å‚æ•°ç©ºé—´ï¼Œç„¶åŽå†å…³æ³¨æœ€é‡è¦çš„æƒé‡ å®žéªŒéªŒè¯ QLORA FineTune -> P_tuning -> P_tuning V2 -> LoRA -> QLoRA BERT Adapter RLHF å…¥é—¨ã€‘å¤§è¯­è¨€æ¨¡åž‹å¸¸ç”¨å¾®è°ƒæ¡†æž¶ä»‹ç»ï½œLoRA&Prefix-Tuning&Prompt-Tuning&P-Tuning v2&RLHFå¾®è°ƒåŽŸç†ç®€ä»‹ RLHF: Reinforcement Learning from Humanã€‚Feedbackï¼Œå³åŸºäºŽäººå·¥åé¦ˆæœºåˆ¶çš„å¼ºåŒ–å­¦ä¹ ã€‚æœ€æ—©ä¸Ž2022å¹´4æœˆï¼Œç”±OpenAIç ”ç©¶å›¢é˜Ÿç³»ç»Ÿæ€»ç»“å¹¶æå‡º.å¹¶åœ¨GPTæ¨¡åž‹çš„å¯¹è¯ç±»ä»»åŠ¡å¾®è°ƒä¸­å¤§æ”¾å¼‚å½©ï¼Œè¢«ç§°ä¸ºChatGPTèƒŒåŽçš„åŠŸè‡£ RLHFä¹Ÿæ˜¯ç›®å‰ä¸ºæ­¢å¸¸ç”¨çš„ã€æœ€ä¸ºå¤æ‚çš„åŸºäºŽå¼ºåŒ–å­¦ä¹ çš„å¤§è¯­è¨€æ¨¡åž‹å¾®è°ƒæ–¹æ³•ï¼Œç›®å‰æœ€å¥½çš„ç«¯åˆ°ç«¯RLHFå®žçŽ°æ˜¯DeepSpeedChatåº“ï¼Œç”±å¾®è½¯å¼€æºå¹¶ç»´æŠ¤ åŸºäºŽå¼ºåŒ–å­¦ä¹ çš„è¿›é˜¶å¾®è°ƒæ–¹æ³•RLHFæ–¹æ³• è®ºæ–‡åœ°å€: https://arxiv.org/abs/2203.02155 æ­¥éª¤1: ç›‘ç£å¾®è°ƒ (SFT)-ä¸€ ä½¿ç”¨ç²¾é€‰çš„äººç±»å›žç­”æ¥å¾®è°ƒé¢„è®­ç»ƒçš„è¯­è¨€æ¨¡åž‹ä»¥åº”å¯¹å„ç§æŸ¥è¯¢ æ­¥éª¤2:å¥–åŠ±æ¨¡åž‹å¾®è°ƒ -- ä½¿ç”¨ä¸€ä¸ªåŒ…å«äººç±»å¯¹åŒä¸€æŸ¥è¯¢çš„å¤šä¸ªç­”æ¡ˆæ‰“åˆ†çš„æ•°æ®é›†æ¥è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„ (é€šå¸¸æ¯” SFT å°çš„) å¥–åŠ±æ¨¡åž‹ (RW) æ­¥éª¤3: RLHF è®­ç»ƒ --åˆ©ç”¨ Proximal Policy Optimization (PPO) ç®—æ³•æ ¹æ® RW æ¨¡åž‹çš„å¥–åŠ±Dä¹å¤©Hectoråé¦ˆè¿›ä¸€æ­¥å¾®è°ƒ SFT æ¨¡åž‹ã€‚ Flash_Atten(è½¬) å‰ç½®çŸ¥è¯† GPU Arch:è‡ªé¡¶å‘ä¸‹åˆ†æž + Bç«™ GPU Archï¼šè‡ªé¡¶å‘ä¸‹åˆ†æžã€æµ…è°ˆåº•å±‚Â·1ã€‘ éšç€äººå·¥æ™ºèƒ½ç‰¹åˆ«æ˜¯ä»¥GPTä¸ºä»£è¡¨çš„ç”Ÿæˆå¼AIçš„è¿…çŒ›å‘å±•ï¼ŒGPUå·²ç»æˆä¸ºäº†ä¸€ç§ä¸å¯æˆ–ç¼ºçš„å·¥å…·ï¼Œç”šè‡³ä¼ä¸šéƒ½ä»¥æ‹¥æœ‰å¤šå°‘é«˜ç«¯GPUä½œä¸ºæŠ“ä½é£Žå£èƒ½åŠ›çš„è¡¡é‡æ ‡å‡†ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒCPUè™½ç„¶åœ¨ä¼ ç»Ÿè®¡ç®—é¢†åŸŸå æ®ä¸»å¯¼åœ°ä½ï¼Œä½†åœ¨å¤„ç†AIä»»åŠ¡æ—¶å´ä¸åŠGPUå‡ºè‰² ä¸ºä»€ä¹ˆAIè®¡ç®—é€šå¸¸é€‰æ‹©GPUè€Œä¸æ˜¯CPUï¼Œåˆ†æžGPUåœ¨AIè®¡ç®—ä¸­çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶ï¼Œä»Žåº•å±‚åŽŸç†æŽ¢è®¨ä»ŽVoltaåˆ°æœ€æ–°çš„Hopperå››ä»£NVIDIA GPUæž¶æž„çš„æ¼”è¿›ï¼Œå±•ç¤ºå…¶ä¸æ–­æå‡çš„æ€§èƒ½å’ŒåŠŸèƒ½ GPUä¸»è¦ç”±è®¡ç®—å•å…ƒALUç»„æˆã€‚CPUä¸ä»…è¢«Cacheå æ®äº†å¤§é‡ç©ºé—´ï¼Œè€Œä¸”è¿˜æœ‰æœ‰å¤æ‚çš„æŽ§åˆ¶é€»è¾‘å’Œè¯¸å¤šä¼˜åŒ–ç”µè·¯ï¼Œç›¸æ¯”ä¹‹ä¸‹ï¼Œè®¡ç®—èƒ½åŠ›åªæ˜¯CPUå¾ˆå°çš„ä¸€éƒ¨åˆ† é€šè¿‡ä¸Šé¢è‡ªé¡¶å‘ä¸‹çš„åˆ†æžï¼Œæˆ‘ä»¬çŸ¥é“ï¼Œå¯¹äºŽGPUä¸­çš„å­˜å‚¨éƒ¨åˆ†è®¿é—®é€Ÿåº¦ç”±å¿«åˆ°æ…¢ï¼Œè®¡ç®—éƒ¨åˆ†ä»Žå¤§åˆ°å°æŽ’åˆ—ä¸º \\begin{array}{c} \\text{Mem Speed:(L1 Cache/SMEM)>L2 Cache>HBM} \\\\ \\text{Compute Unit:GPC>TPC>SM>(TensorCore, SFU, INT32, FP32..)} \\end{array} NVLinkæ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆéœ€è¦ä»–ï¼Ÿ å¤§æ¨¡åž‹é€šå¸¸å…·æœ‰å·¨å¤§çš„å‚æ•°æ•°é‡å’Œå¤æ‚çš„ç»“æž„ï¼Œéœ€è¦å¤„ç†å¤§é‡çš„æ•°æ®ã€‚åˆ†å¸ƒå¼è®­ç»ƒå°†è¿™äº›å¤§åž‹æ¨¡åž‹åˆ†å‰²æˆå¤šä¸ªéƒ¨åˆ†ï¼Œç”±å¤šä¸ªGPUæˆ–è®¡ç®—èŠ‚ç‚¹å¹¶è¡Œå¤„ç†ï¼Œæ¯ä¸ªéƒ¨åˆ†å¤„ç†è‡ªå·±çš„æ•°æ®å­é›†ã€‚ç„¶åŽé€šè¿‡å…¨å±€é€šä¿¡ï¼Œå‚æ•°åŒæ­¥ç­‰æ–¹å¼è¿›è¡Œæ¢¯åº¦ä¼ æ’­ï¼Œæ­¤æ—¶GPUä¹‹é—´çš„é€šä¿¡å¸¦å®½å°±å˜çš„è¶Šæ¥è¶Šé‡è¦ åœ¨NVLinkå‡ºçŽ°ä¹‹å‰ï¼ŒGPUä¸ŽGPUä¹‹é—´çš„æ•°æ®äº¤äº’é€šè¿‡PCIeï¼ˆPeripheral Component Interconnect Expressï¼‰æ€»çº¿è¿›è¡Œã€‚ä½†PCIeå­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼Œä¸€æ˜¯PCIeæ€»çº¿çš„å¸¦å®½ç›¸å¯¹æœ‰é™ï¼Œå…¶ä¸­PCIe 4.0x16çš„æœ€å¤§å¸¦å®½ä¹Ÿå°±64GB/sï¼ŒäºŒæ˜¯PCIeæ€»çº¿çš„å»¶è¿Ÿç›¸å¯¹è¾ƒé«˜ï¼Œåœ¨GPUä¹‹é—´ä¼ è¾“æ•°æ®æ—¶ï¼Œæ¯æ¬¡æ•°æ®ä¼ è¾“éƒ½éœ€è¦é€šè¿‡CPUå’Œä¸»æœºå†…å­˜æ¥å®Œæˆã€‚è¿™ç§ä¼ è¾“è·¯å¾„ä¼šå¯¼è‡´é¢å¤–çš„å»¶è¿Ÿï¼Œå¹¶é™ä½Žæ•°æ®ä¼ è¾“çš„æ•ˆçŽ‡ã€‚ç„¶è€Œï¼Œæ·±åº¦å­¦ä¹ åº”ç”¨ä¸­éœ€è¦æ›´é«˜çš„å¸¦å®½å’Œæ›´ä½Žçš„å»¶è¿Ÿï¼ŒPCIeæ˜¾ç„¶æ˜¯æ— æ³•æ»¡è¶³å½“ä¸‹çš„ç¥žç»ç½‘ç»œè®­ç»ƒéœ€æ±‚ NVLinkåˆ©ç”¨é«˜å¸¦å®½ã€ä½Žå»¶è¿Ÿçš„é€šä¿¡é€šé“ï¼Œç›´æŽ¥å°†å¤šä¸ªGPUè¿žæŽ¥åœ¨ä¸€èµ·ï¼Œå®žçŽ°å¿«é€Ÿã€é«˜æ•ˆçš„æ•°æ®ä¼ è¾“å’Œå…±äº«ã€‚é€šè¿‡NVLinkï¼ŒGPUä¹‹é—´çš„æ•°æ®äº¤äº’å¯ä»¥ç›´æŽ¥åœ¨GPUä¹‹é—´è¿›è¡Œï¼Œè€Œæ— éœ€é€šè¿‡CPUå’Œä¸»æœºå†…å­˜ã€‚è¿™ç§ç›´æŽ¥å†…å­˜è®¿é—®ï¼ˆDMAï¼‰çš„æ–¹å¼å¤§å¤§å‡å°‘äº†æ•°æ®ä¼ è¾“çš„å¤åˆ¶å’Œå»¶è¿Ÿï¼Œæé«˜äº†æ•°æ®å…±äº«çš„æ•ˆçŽ‡ã€‚æ­¤å¤–ï¼ŒNVLinkè¿˜æä¾›äº†ä¸€è‡´çš„å†…å­˜ç©ºé—´ï¼Œä½¿å¾—å¤šä¸ªGPUèƒ½å¤Ÿå…±äº«åŒä¸€ä»½å†…å­˜ï¼Œç®€åŒ–äº†ç¨‹åºè®¾è®¡å’Œæ•°æ®ç®¡ç†çš„å¤æ‚æ€§ æ¦‚è¿° FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness Paper 2022 FlashAttention: æ›´å¿«è®­ç»ƒæ›´é•¿ä¸Šä¸‹æ–‡çš„GPT Transformerä½œä¸ºGPTç±»æ¨¡åž‹çš„åŸºç¡€æž¶æž„æä¾›äº†å¼ºå¤§çš„ç‰¹å¾å¤„ç†èƒ½åŠ›ï¼Œä½†æ˜¯å¤„ç†æ›´é•¿ä¸Šä¸‹æ–‡ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºæ ¸å¿ƒçš„è‡ªæ³¨æ„åŠ›æ¨¡å—åœ¨åºåˆ—é•¿åº¦ä¸Šå…·æœ‰O(N^2)çš„æ—¶é—´å’Œå†…å­˜å¤æ‚åº¦&#x1F613; è¿™ç¯‡Flash Attentionçš„å·¥ä½œæ·±å…¥ç¡¬ä»¶ï¼Œæ–°æå‡ºäº†ä¸€ç§å…·æœ‰IOæ„ŸçŸ¥çš„ï¼Œå¿«é€Ÿçš„âš¡ï¸ï¼ŒèŠ‚çœå†…å­˜çš„&#x1F9E0;ï¼Œç²¾ç¡®çš„&#x1F3AF;æ³¨æ„åŠ›ç®—æ³•ã€‚ç›®å‰ï¼ŒFlash Attentionå·²ç»é›†æˆè‡³torch2.0ï¼Œå¹¶ä¸”ç¤¾åŒºä¹Ÿæä¾›äº†å¤šç§å®žçŽ° 78sçœ‹æ‡‚FlashAttentionã€æœ‰ç‚¹æ„æ€Â·1ã€‘ æ ¸å¿ƒè¦ç‚¹ âš¡ï¸ä¸ºä»€ä¹ˆåŠ å¿«äº†è®¡ç®—ï¼ŸFast é™ä½Žäº†è€—æ—¶çš„HBMè®¿é—®æ¬¡æ•°ã€‚é‡‡ç”¨TilingæŠ€æœ¯åˆ†å—ä»ŽHBMåŠ è½½æ•°æ®åˆ°SRAMè¿›è¡Œèžåˆè®¡ç®— &#x1F9E0;ä¸ºä»€ä¹ˆèŠ‚çœäº†å†…å­˜ï¼ŸMemory-Efficient ä¸å†å¯¹ä¸­é—´çŸ©é˜µSï¼ŒPè¿›è¡Œå­˜å‚¨ã€‚åœ¨åå‘çš„æ—¶å€™é€šè¿‡Recomputationé‡æ–°è®¡ç®—æ¥è®¡ç®—æ¢¯åº¦ &#x1F3AF;ä¸ºä»€ä¹ˆæ˜¯ç²¾å‡†æ³¨æ„åŠ›ï¼ŸExact Attention ç®—æ³•æµç¨‹åªæ˜¯åˆ†å—è®¡ç®—ï¼Œæ— è¿‘ä¼¼æ“ä½œ æå‡ºé—®é¢˜ Transformerç»“æž„å·²æˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†å’Œå›¾åƒåˆ†ç±»ç­‰åº”ç”¨ä¸­æœ€å¸¸ç”¨çš„æž¶æž„ã€‚å°½ç®¡Transformeråœ¨è§„æ¨¡ä¸Šä¸æ–­å¢žå¤§å’ŒåŠ æ·±ï¼Œä½†å¤„ç†æ›´é•¿ä¸Šä¸‹æ–‡ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºæ ¸å¿ƒçš„è‡ªæ³¨æ„åŠ›æ¨¡å—åœ¨åºåˆ—é•¿åº¦ä¸Šå…·æœ‰äºŒæ¬¡æ–¹çš„æ—¶é—´å’Œå†…å­˜å¤æ‚åº¦ã€‚è¿™å¯¼è‡´åœ¨å¤„ç†é•¿åºåˆ—æ—¶é€Ÿåº¦å˜æ…¢ä¸”å†…å­˜éœ€æ±‚å·¨å¤§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›ä¼˜åŒ–ç®—æ³•æ¥æé«˜æ³¨æ„åŠ›æ¨¡å—çš„è®¡ç®—é€Ÿåº¦å’Œå†…å­˜åˆ©ç”¨çŽ‡ è§£å†³æ–¹æ¡ˆ Forward Standard Attention åœ¨æ³¨æ„åŠ›çš„ä¸€èˆ¬å®žçŽ°ä¸­ï¼Œå¯¹\\mathbf{Q}, \\mathbf{K}, \\mathbf{V} \\in \\mathbb{R}^{N \\times d} ä¸‰ä¸ªè¾“å…¥æ‰§è¡Œä»¥ä¸‹ç®—æ³•å¾—åˆ°è¾“å‡º\\mathbf{O}ï¼Œå…¶ä¸­softmaxè¡Œçº§åˆ«æ‰§è¡Œ \\mathbf{S}=\\mathbf{Q} \\mathbf{K}^{\\top} \\in \\mathbb{R}^{N \\times N}, \\quad \\mathbf{P}=\\operatorname{softmax}(\\mathbf{S}) \\in \\mathbb{R}^{N \\times N}, \\quad \\mathbf{O}=\\mathbf{P V} \\in \\mathbb{R}^{N \\times d} åœ¨è¿™ä¸ªç®—æ³•ä¸­ï¼Œ\\mathbf{S}ï¼Œ\\mathbf{P}çŸ©é˜µéƒ½æ˜¯å¾ˆå¤§ï¼Œéœ€è¦åœ¨HBMä¸­å®žä¾‹åŒ–æ¥è¿›è¡Œå­˜å‚¨ï¼Œè¿™æ ·å°±ä¼šå¸¦æ¥å¾ˆå¤šHBMçš„è®¿é—®æ¬¡æ•°ï¼Œ æœ€ç»ˆä½“çŽ°åˆ°ç®—æ³•æ—¶é—´ç«¯åˆ°ç«¯è¾ƒé•¿çš„å»¶è¿Ÿ FlashAttention(Tiling) ç†è®ºåŸºç¡€ åœ¨ä¼ ç»Ÿç®—æ³•ä¸­ï¼Œä¸€ç§æ–¹å¼æ˜¯å°†Maskå’ŒSoftMaxéƒ¨åˆ†èžåˆï¼Œä»¥å‡å°‘è®¿å­˜æ¬¡æ•°ã€‚ç„¶è€Œï¼ŒFlashAttentionåˆ™æ›´åŠ æ¿€è¿›ï¼Œå®ƒå°†ä»Žè¾“å…¥\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}åˆ°è¾“å‡º\\mathbf{O}çš„æ•´ä¸ªè¿‡ç¨‹è¿›è¡Œèžåˆï¼Œä»¥é¿å…\\mathbf{S}ï¼Œ \\mathbf{P}çŸ©é˜µçš„å­˜å‚¨å¼€é”€ï¼Œå®žçŽ°ç«¯åˆ°ç«¯çš„å»¶è¿Ÿç¼©å‡ã€‚ç„¶è€Œï¼Œç”±äºŽè¾“å…¥çš„é•¿åº¦Né€šå¸¸å¾ˆé•¿ï¼Œæ— æ³•å®Œå…¨å°†å®Œæ•´çš„\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}, \\mathbf{O}åŠä¸­é—´è®¡ç®—ç»“æžœå­˜å‚¨åœ¨SRAMä¸­ã€‚å› æ­¤ï¼Œéœ€è¦ä¾ èµ–HBMè¿›è¡Œè®¿å­˜æ“ä½œï¼Œä¸ŽåŽŸå§‹è®¡ç®—å»¶è¿Ÿç›¸æ¯”æ²¡æœ‰å¤ªå¤§å·®å¼‚ï¼Œç”šè‡³ä¼šå˜æ…¢(æ²¡å…·ä½“æµ‹) ä¸ºäº†è®©è®¡ç®—è¿‡ç¨‹çš„ç»“æžœå®Œå…¨åœ¨SRAMä¸­ï¼Œæ‘†è„±å¯¹HBMçš„ä¾èµ–ï¼Œå¯ä»¥é‡‡ç”¨åˆ†ç‰‡æ“ä½œï¼Œæ¯æ¬¡è¿›è¡Œéƒ¨åˆ†è®¡ç®—ï¼Œç¡®ä¿è¿™äº›è®¡ç®—ç»“æžœèƒ½åœ¨SRAMå†…è¿›è¡Œäº¤äº’ï¼Œå¾…å¾—åˆ°å¯¹åº”çš„ç»“æžœåŽå†è¿›è¡Œè¾“å‡º è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæœ‰ä¸€ç‚¹éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¹‹å‰å¯¹äºŽsoftmaxçš„è®¡ç®—æ˜¯ä»¥è¡Œä¸ºå•ä½çš„ï¼Œå¦‚ä¸‹æ‰€ç¤º: m(x):=\\max _{i} x_{i}, \\quad f(x):=\\left[\\begin{array}{lll} e^{x_{1}-m(x)} & \\ldots & e^{x_{B}-m(x)} \\end{array}\\right], \\quad \\ell(x):=\\sum_{i} f(x)_{i}, \\quad \\operatorname{softmax}(x):=\\frac{f(x)}{\\ell(x)} å½“æˆ‘ä»¬å°†è¾“å…¥è¿›è¡Œåˆ†ç‰‡åŽï¼Œæ— æ³•å¯¹å®Œæ•´çš„è¡Œæ•°æ®æ‰§è¡ŒSoftmaxæ“ä½œã€‚è¿™æ˜¯å› ä¸ºSoftmaxå‡½æ•°åœ¨è®¡ç®—æ—¶éœ€è¦è€ƒè™‘æ•´ä¸ªè¡Œçš„æ•°æ® ç„¶è€Œï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¦‚ä¸‹æ‰€ç¤ºæ–¹æ³•æ¥èŽ·å¾—ä¸Žå®Œæ•´è¡ŒSoftmaxç›¸åŒçš„ç»“æžœï¼Œè€Œæ— éœ€ä½¿ç”¨è¿‘ä¼¼æ“ä½œ \\begin{array}{l} m(x)=m\\left(\\left[x^{(1)} x^{(2)}\\right]\\right)=\\max \\left(m\\left(x^{(1)}\\right), m\\left(x^{(2)}\\right)\\right), \\quad f(x)=\\left[\\begin{array}{ll} e^{m\\left(x^{(1)}\\right)-m(x)} f\\left(x^{(1)}\\right) & \\left.e^{m\\left(x^{(2)}\\right)-m(x)} f\\left(x^{(2)}\\right)\\right] \\end{array}\\right. \\\\ \\ell(x)=\\ell\\left(\\left[x^{(1)} x^{(2)}\\right]\\right)=e^{m\\left(x^{(1)}\\right)-m(x)} \\ell\\left(x^{(1)}\\right)+e^{m\\left(x^{(2)}\\right)-m(x)} \\ell\\left(x^{(2)}\\right), \\quad \\operatorname{softmax}(x)=\\frac{f(x)}{\\ell(x)} \\end{array} å…·ä½“çš„åˆ†å—softmaxä»£ç æ¼”ç¤º import torch q = torch.tensor([1,2]).float() v = torch.tensor([1,2]).float() q_sm = torch.softmax(q, 0) print(q_sm) # tensor([0.2689, 0.7311]) torch.dot(q_sm, v) # tensor(1.7311) m_pre = float(\"-inf\") l_pre = 0 cur_sum = 0 block1 = torch.tensor([1]).float() # get cur max value m_cur = max(torch.max(block1), m_pre) # scale pre log value by max exp l_pre *= torch.exp(m_pre - m_cur) # calculate current log sum p = torch.exp(block1 - m_cur) l_cur = torch.sum(p) + l_pre # scale pre result by log sum cur_sum = cur_sum * l_pre / l_cur p = p / l_cur cur_sum = 1 * p[0] l_pre = l_cur m_pre = m_cur print(cur_sum) # tensor(1.) block2 = torch.tensor([2]).float() m_cur = max(torch.max(block2), m_pre) l_pre *= torch.exp(m_pre - m_cur) p = torch.exp(block2 - m_cur) l_cur = torch.sum(p) + l_pre cur_sum = cur_sum * l_pre / l_cur p = p / l_cur cur_sum += 2 * p[0] print(cur_sum) # tensor(1.7311) ä»£ç å®žçŽ° @triton.jit def _fwd_kernel( Q, K, V, sm_scale, L, M, Out, stride_qz, stride_qh, stride_qm, stride_qk, stride_kz, stride_kh, stride_kn, stride_kk, stride_vz, stride_vh, stride_vk, stride_vn, stride_oz, stride_oh, stride_om, stride_on, Z, H, N_CTX, BLOCK_M: tl.constexpr, BLOCK_DMODEL: tl.constexpr, BLOCK_N: tl.constexpr, ): start_m = tl.program_id(0) off_hz = tl.program_id(1) # initialize offsets offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M) offs_n = tl.arange(0, BLOCK_N) offs_d = tl.arange(0, BLOCK_DMODEL) off_q = off_hz * stride_qh + offs_m[:, None] * stride_qm + offs_d[None, :] * stride_qk off_k = off_hz * stride_qh + offs_n[None, :] * stride_kn + offs_d[:, None] * stride_kk off_v = off_hz * stride_qh + offs_n[:, None] * stride_qm + offs_d[None, :] * stride_qk # Initialize pointers to Q, K, V q_ptrs = Q + off_q k_ptrs = K + off_k v_ptrs = V + off_v # initialize pointer to m and l m_prev = tl.zeros([BLOCK_M], dtype=tl.float32) - float(\"inf\") l_prev = tl.zeros([BLOCK_M], dtype=tl.float32) acc = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32) # load q: it will stay in SRAM throughout q = tl.load(q_ptrs) # loop over k, v and update accumulator for start_n in range(0, (start_m + 1) * BLOCK_M, BLOCK_N): # -- compute qk ---- k = tl.load(k_ptrs) qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32) qk += tl.dot(q, k) qk *= sm_scale qk = tl.where(offs_m[:, None] >= (start_n + offs_n[None, :]), qk, float(\"-inf\")) # compute new m m_curr = tl.maximum(tl.max(qk, 1), m_prev) # correct old l l_prev *= tl.exp(m_prev - m_curr) # attention weights p = tl.exp(qk - m_curr[:, None]) l_curr = tl.sum(p, 1) + l_prev # rescale operands of matmuls l_rcp = 1. / l_curr p *= l_rcp[:, None] acc *= (l_prev * l_rcp)[:, None] # update acc p = p.to(Q.dtype.element_ty) v = tl.load(v_ptrs) acc += tl.dot(p, v) # update m_i and l_i l_prev = l_curr m_prev = m_curr # update pointers k_ptrs += BLOCK_N * stride_kn v_ptrs += BLOCK_N * stride_vk # rematerialize offsets to save registers start_m = tl.program_id(0) offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M) # write back l and m l_ptrs = L + off_hz * N_CTX + offs_m m_ptrs = M + off_hz * N_CTX + offs_m tl.store(l_ptrs, l_prev) tl.store(m_ptrs, m_prev) # initialize pointers to output offs_n = tl.arange(0, BLOCK_DMODEL) off_o = off_hz * stride_oh + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on out_ptrs = Out + off_o tl.store(out_ptrs, acc) IOå¤æ‚åº¦åˆ†æž Standard Attention å¯¹äºŽæ ‡å‡†æ³¨æ„åŠ›å®žçŽ°ï¼ŒåˆæœŸæˆ‘ä»¬éœ€è¦æŠŠè¾“å…¥ \\mathbf{Q}, \\mathbf{K}, \\mathbf{V}ä»ŽHBMä¸­è¯»å–ï¼Œå¹¶è®¡ç®—å®Œæ¯•åŽæŠŠè¾“å‡º\\mathbf{O}å†™å…¥åˆ°HBMä¸­ ç¬¬ä¸€æ­¥æŠŠ\\mathbf{Q}, \\mathbf{K}è¯»å–å‡ºæ¥è®¡ç®—å‡º\\mathbf{S}=\\mathbf{Q} \\mathbf{K}^{\\top}ï¼Œç„¶åŽæŠŠ\\mathbf{S}å­˜å›žåŽ»ï¼Œå†…å­˜è®¿é—®å¤æ‚åº¦\\Theta\\left(N d+N^{2}\\right) ç¬¬äºŒæ­¥æŠŠ\\mathbf{S}è¯»å–å‡ºæ¥è®¡ç®—å‡º\\mathbf{P}=\\operatorname{softmax}(\\mathbf{S})ï¼Œç„¶åŽæŠŠ\\mathbf{P}å­˜å›žåŽ»ï¼Œå†…å­˜è®¿é—®å¤æ‚åº¦\\Theta\\left(N^{2}\\right) ç¬¬ä¸‰æ­¥æŠŠ\\mathbf{V}, \\mathbf{P}è¯»å–å‡ºæ¥è®¡ç®—å‡º\\mathbf{O}=\\mathbf{P V}ï¼Œç„¶åŽè®¡ç®—å‡ºç»“æžœ\\mathbf{O}ï¼Œå†…å­˜è®¿é—®å¤æ‚åº¦\\Theta\\left(N d+N^{2}\\right) ç»¼ä¸Šæ‰€è¿°ï¼Œæ•´ä½“çš„å†…å­˜è®¿é—®å¤æ‚åº¦ä¸º\\Theta\\left(N d+N^{2}\\right) FlashAttention å¯¹äºŽFlashAttentionï¼Œæˆ‘ä»¬è®¾ç½®ä¸€ä¸ªåˆ†å—å¤§å°B_{c}æ¥æŠŠ\\mathbf{K}, \\mathbf{V}åˆ†æˆT_{c}å—ï¼Œå¯¹äºŽ\\mathbf{Q}, \\mathbf{O}çš„æ¯ä¸€å—éƒ½è¦æŠŠ\\mathbf{K}, \\mathbf{V}éƒ¨åˆ†çš„å…¨éƒ¨å…ƒç´ Loadä¸€éï¼Œè¿™æ ·åˆ™æœ‰FlashAttentionçš„å†…å­˜è®¿é—®å¤æ‚åº¦ä¸º\\Theta\\left(N d+N d T_{c}\\right)=\\Theta\\left(N d T_{c}\\right) åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦ä¸¤ä¸ªåˆ†å—å¤§å°ï¼Œ\\mathbf{Q}, \\mathbf{O}çš„åˆ†å—å¤§å°B_{r}ï¼Œ\\mathbf{K}, \\mathbf{V}çš„åˆ†å—å¤§å°B_{c}ï¼Œæˆ‘ä»¬è®¾å®šSRAMçš„å¤§å°ä¸ºMï¼Œä¸ºäº†èƒ½æŠŠåˆ†å—åŽçš„\\mathbf{K}, \\mathbf{V} \\in \\mathbb{R}^{B_{c} \\times d}æ”¾è¿›SRAMï¼Œé‚£ä¹ˆåˆ™æœ‰ä¸€ä¸‹é™åˆ¶: B_{c} d=O(M) \\Leftrightarrow B_{c}=O\\left(\\frac{M}{d}\\right) ç›¸åº”çš„ï¼Œ\\mathbf{Q}, \\mathbf{O} \\in \\mathbb{R}^{B_{r} \\times d}æœ‰å¦‚ä¸‹é™åˆ¶: B_{r} d=O(M) \\Leftrightarrow B_{r}=O\\left(\\frac{M}{d}\\right) æœ€ç»ˆï¼Œè¿˜æœ‰ä¸€ä¸ªä¸­é—´æ€\\mathbf{S}=\\mathbf{Q K}^{\\top} \\in \\mathbb{R}^{B_{r} \\times B_{c}}éœ€è¦å­˜å‚¨ï¼Œåˆ™æœ‰å¦‚ä¸‹é™åˆ¶: B_{r} B_{c}=O(M) ç»¼ä¸Šï¼Œé™åˆ¶å¦‚ä¸‹ B_{c}=\\Theta\\left(\\frac{M}{d}\\right), \\quad B_{r}=\\Theta\\left(\\min \\left(\\frac{M}{d}, \\frac{M}{B_{c}}\\right)\\right)=\\Theta\\left(\\min \\left(\\frac{M}{d}, d\\right)\\right) è¿›è€ŒæŽ¨å‡º T_{c}=\\frac{N}{B_{c}}=\\Theta\\left(\\frac{N d}{M}\\right) é‚£ä¹ˆåœ¨M=\\Theta(N d) çš„å‰æä¸‹ï¼Œåˆ™æœ‰FlashAttentionçš„HBMå†…å­˜è®¿é—®å¤æ‚åº¦ä¸ºï¼š \\Theta\\left(N d T_{c}\\right)=\\Theta\\left(\\frac{N^{2} d^{2}}{M}\\right)=\\Theta(N d) åœ¨è¯­è¨€å»ºæ¨¡ä¸­ï¼Œé€šå¸¸æœ‰d \\lll Nï¼Œåˆ™æœ‰\\Theta_{\\text {stand }}\\left(N d+N^{2}\\right)>\\Theta_{f l a s h}(N d)ã€‚è¿™æ ·ï¼Œåœ¨å‰å‘çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨åˆ†å—è®¡ç®—çš„æ–¹å¼ï¼Œé¿å…äº†\\mathbf{S}, \\mathbf{P}çŸ©é˜µçš„å­˜å‚¨å¼€é”€ï¼Œæ•´ä½“çš„è¿ç®—éƒ½åœ¨SRAMå†…è¿›è¡Œï¼Œé™ä½Žäº†HBMè®¿é—®æ¬¡æ•°ï¼Œå¤§å¤§æå‡äº†è®¡ç®—çš„é€Ÿåº¦ï¼Œå‡å°‘äº†å¯¹å­˜å‚¨çš„æ¶ˆè€— Backward ç†è®ºåŸºç¡€ åœ¨ä¸Šé¢å‰å‘çš„æ—¶å€™æˆ‘ä»¬ä¸ºäº†å‡å°‘HBMè®¿å­˜æ¬¡æ•°ï¼Œé™ä½Žå†…å­˜æ¶ˆè€—é‡ï¼Œæˆ‘ä»¬å¹¶æ²¡æœ‰å¯¹\\mathbf{S}, \\mathbf{P}çŸ©é˜µè¿›è¡Œå­˜å‚¨ï¼Œè€Œè¿™ä¸ªåœ¨åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦çš„æ—¶å€™ç¡®å®žéœ€è¦çš„ä¸€ä¸ªä¿¡æ¯ ä¹‹å‰æœ‰é€šè¿‡Gradient checkpointingçš„æ–¹å¼æ¥å®žçŽ°æ¢¯åº¦å®žçŽ°åœ¨å‰å‘çš„æ—¶å€™æ›´åŠ èŠ‚çœå†…å­˜ æˆ‘ä»¬è¿™é‡Œåˆ™é‡‡ç”¨é‡æ–°è®¡ç®—çš„æ–¹å¼æ¥è®¡ç®—å¯¹åº”çš„æ¢¯åº¦ã€‚åœ¨ä¸Šé¢å‰å‘è®¡ç®—çš„æ—¶å€™æˆ‘ä»¬ä¸ä¼šå­˜å‚¨\\mathbf{S}, \\mathbf{P}çŸ©é˜µï¼Œä½†æ˜¯æˆ‘ä»¬ä¼šå­˜å‚¨å¯¹åº”çš„æŒ‡æ•°é¡¹ä¹‹å’ŒLæ¥è¿›è¡Œæ¢¯åº¦çš„è®¡ç®— æˆ‘ä»¬åœ¨åå‘çš„è¿‡ç¨‹ä¸­æœ€é‡è¦çš„äº‹æƒ…å°±æ˜¯å°±æ˜¯Losså‡½æ•°\\phiå¯¹\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}, \\mathbf{O}å¯¹åº”çš„æ¢¯åº¦ \\mathbf{O}å¯¹åº”çš„æ¢¯åº¦æœ€å¥½è®¡ç®—\\mathbf{d} \\mathbf{O}=\\frac{\\partial \\phi}{\\partial \\mathbf{O}}ï¼Œå…¶ä¸­\\mathbf{O}æ˜¯çŽ°æˆçš„ \\mathbf{V}å¯¹åº”çš„æ¢¯åº¦ä¹Ÿå¾ˆå¥½è®¡ç®—ï¼Œç”±äºŽ\\mathbf{O}=\\mathbf{P V}ï¼Œæ ¹æ®é“¾å¼æ±‚å¯¼æ³•åˆ™å’ŒçŸ©é˜µæ±‚å¯¼æ³•åˆ™åˆ™æœ‰\\mathbf{d V}=\\mathbf{P}^{T} \\mathbf{d} \\mathbf{O}ï¼Œæ›´è¯¦ç»†å¦‚ä¸‹æ‰€ç¤º: d v_{j}=\\sum_{i} P_{i j} d o_{i}=\\sum_{i} \\frac{e^{q_{i}^{T}} k_{j}}{L_{i}} d o_{i} \\mathbf{Q}, \\mathbf{K}å¯¹åº”çš„æ¢¯åº¦ç®—èµ·æ¥å°±æ¯”è¾ƒå¤æ‚ä¸€ç‚¹ã€‚è¿™ä¸¤ä¸ªç»è¿‡çš„è®¡ç®—é€»è¾‘æ­¥éª¤æ›´å¤šï¼Œæˆ‘ä»¬å¯ä»¥ä¸€æ­¥ä¸€æ­¥çš„æ¥è¿›è¡Œè®¡ç®—ã€‚æˆ‘ä»¬å¯ä»¥å…ˆè®¡ç®—\\mathbf{d P}ï¼Œ\\mathbf{d S}ã€‚ç”±äºŽ\\mathbf{O}=\\mathbf{P V} ï¼Œåˆ™æœ‰\\mathbf{d P}å¦‚ä¸‹è¡¨ç¤º d P_{i j}=d o_{i}^{T} v_{j} Fact: y=\\operatorname{softmax}(x)çš„é›…å„æ¯”çŸ©é˜µä¸º\\operatorname{diag}(y)-y y^{T}ï¼Œå…·ä½“æŽ¨å¯¼è§ Derivative of the Softmax Function and the Categorical Cross-Entropy Loss ç”±äºŽP_{i:}=\\operatorname{softmax}\\left(S_{i:}\\right)ï¼Œ æ ¹æ®ä¸Šè¿°å®šç†åˆ™æœ‰: d S_{i:}=\\left(\\operatorname{diag}\\left(P_{i:}\\right)-P_{i:} P_{i:}^{T}\\right) d P_{i:}=P_{i:} \\circ d P_{i:}-\\left(P_{i:}^{T} d P_{i:}\\right) P_{i:} æŽ¥ä¸‹æ¥æˆ‘ä»¬å®šä¹‰å¦‚ä¸‹è¡¨ç¤º: D_{i}=P_{i:}^{T} d P_{i:}=\\sum \\frac{e^{q_{i} \\kappa_{j}}}{L_{i}} d o_{i}^{T} v_{j}=d o_{i}^{T} \\sum \\frac{e^{q_{i} \\kappa_{j}}}{L_{i}} v_{j}=d o_{i}^{T} o_{i} æ ¹æ®ä¸Šè¿°å®šä¹‰ç®€åŒ–ä¸Šä¸Šå¼åˆ™æœ‰å¦‚ä¸‹è¡¨ç¤º: d S_{i:}=P_{i:} \\circ d P_{i:}-D_{i} P_{i:} ç›¸åº”çš„d \\mathbf{S}å¯è¡¨ç¤ºä¸ºå¦‚ä¸‹å½¢å¼: d S_{i j}=P_{i j} d P_{i j}-D_{i} P_{i j}=P_{i j}\\left(d P_{i j}-D_{i}\\right) åˆå› ä¸ºS_{i j}=q_{i}^{T} k_{j}ï¼Œç»“åˆä¸Šè¿°æŽ¨å¯¼åˆ©ç”¨é“¾å¼æ±‚å¯¼æ³•åˆ™\\mathbf{Q}, \\mathbf{K}å¯¹åº”çš„æ¢¯åº¦æœ‰å¦‚ä¸‹è¡¨ç¤ºï¼š \\begin{array}{l} d q_{i}=\\sum_{j} d S_{i j} k_{j}=\\sum_{j} P_{i j}\\left(d P_{i j}-D_{i}\\right) k_{j}=\\sum_{j} \\frac{e^{q_{i}^{T} k_{j}}}{L_{i}}\\left(d o_{i}^{T} v_{j}-D_{i}\\right) k_{j} \\\\ d k_{j}=\\sum_{i} d S_{i j} q_{i}=\\sum_{i} P_{i j}\\left(d P_{i j}-D_{i}\\right) q_{i}=\\sum_{i} \\frac{e^{q_{i}^{T} k_{j}}}{L_{i}}\\left(d o_{i}^{T} v_{j}-D_{i}\\right) q_{i} \\end{array} è‡³æ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªå®Œæ•´çš„åŒ…å«å‰å‘å’Œåå‘çš„ï¼Œé™ä½Žäº†HBMè®¿é—®æ¬¡æ•°çš„ï¼Œæ–°çš„Attentionç®—å­ ä»£ç å®žçŽ° @triton.jit def _bwd_kernel( Q, K, V, sm_scale, Out, DO, DQ, DK, DV, L, M, D, stride_qz, stride_qh, stride_qm, stride_qk, stride_kz, stride_kh, stride_kn, stride_kk, stride_vz, stride_vh, stride_vk, stride_vn, Z, H, N_CTX, num_block, BLOCK_M: tl.constexpr, BLOCK_DMODEL: tl.constexpr, BLOCK_N: tl.constexpr, ): off_hz = tl.program_id(0) off_z = off_hz // H off_h = off_hz % H # offset pointers for batch/head Q += off_z * stride_qz + off_h * stride_qh K += off_z * stride_qz + off_h * stride_qh V += off_z * stride_qz + off_h * stride_qh DO += off_z * stride_qz + off_h * stride_qh DQ += off_z * stride_qz + off_h * stride_qh DK += off_z * stride_qz + off_h * stride_qh DV += off_z * stride_qz + off_h * stride_qh for start_n in range(0, num_block): lo = start_n * BLOCK_M # initialize row/col offsets offs_qm = lo + tl.arange(0, BLOCK_M) offs_n = start_n * BLOCK_M + tl.arange(0, BLOCK_M) offs_m = tl.arange(0, BLOCK_N) offs_k = tl.arange(0, BLOCK_DMODEL) # initialize pointers to value-like data q_ptrs = Q + (offs_qm[:, None] * stride_qm + offs_k[None, :] * stride_qk) k_ptrs = K + (offs_n[:, None] * stride_kn + offs_k[None, :] * stride_kk) v_ptrs = V + (offs_n[:, None] * stride_qm + offs_k[None, :] * stride_qk) do_ptrs = DO + (offs_qm[:, None] * stride_qm + offs_k[None, :] * stride_qk) dq_ptrs = DQ + (offs_qm[:, None] * stride_qm + offs_k[None, :] * stride_qk) # pointer to row-wise quantities in value-like data D_ptrs = D + off_hz * N_CTX m_ptrs = M + off_hz * N_CTX # initialize dv amd dk dv = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32) dk = tl.zeros([BLOCK_M, BLOCK_DMODEL], dtype=tl.float32) # k and v stay in SRAM throughout k = tl.load(k_ptrs) v = tl.load(v_ptrs) # loop over rows for start_m in range(lo, num_block * BLOCK_M, BLOCK_M): offs_m_curr = start_m + offs_m # load q, k, v, do on-chip q = tl.load(q_ptrs) # recompute p = softmax(qk, dim=-1).T # NOTE: `do` is pre-divided by `l`; no normalization here qk = tl.dot(q, tl.trans(k)) qk = tl.where(offs_m_curr[:, None] >= (offs_n[None, :]), qk, float(\"-inf\")) m = tl.load(m_ptrs + offs_m_curr) p = tl.exp(qk * sm_scale - m[:, None]) # compute dv do = tl.load(do_ptrs) dv += tl.dot(tl.trans(p.to(Q.dtype.element_ty)), do) # compute dp = dot(v, do) Di = tl.load(D_ptrs + offs_m_curr) dp = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32) - Di[:, None] dp += tl.dot(do, tl.trans(v)) # compute ds = p * (dp - delta[:, None]) ds = p * dp * sm_scale # compute dk = dot(ds.T, q) dk += tl.dot(tl.trans(ds.to(Q.dtype.element_ty)), q) # compute dq dq = tl.load(dq_ptrs) dq += tl.dot(ds.to(Q.dtype.element_ty), k) tl.store(dq_ptrs, dq) # increment pointers dq_ptrs += BLOCK_M * stride_qm q_ptrs += BLOCK_M * stride_qm do_ptrs += BLOCK_M * stride_qm # write-back dv_ptrs = DV + (offs_n[:, None] * stride_qm + offs_k[None, :] * stride_qk) dk_ptrs = DK + (offs_n[:, None] * stride_kn + offs_k[None, :] * stride_kk) tl.store(dv_ptrs, dv) tl.store(dk_ptrs, dk) Block-Sparse ç›¸æ¯”äºŽä¸Šé¢çš„å…¨é‡è®¡ç®—ï¼Œå—ç¨€ç–çš„FlashAttentionéœ€è¦é¢å¤–æä¾›ä¸€ä¸ªMaskçŸ©é˜µ\\tilde{\\mathbf{M}} \\in\\{0,1\\}^{N \\times N}ç”¨äºŽå°†ä¸€äº›å…ƒ ç´ ç½®é›¶æ¥ä¿è¯å—ç¨€ç–åŠ é€Ÿè®¡ç®— æœ¬ç« å¯¹äºŽå—ç¨€ç–çš„ä¸€ä¸ªè®¡ç®—åªæ˜¯ä¸€ä¸ªç®€å•çš„å°è¯•ï¼Œæ²¡æœ‰è¿›è¡Œå¤ªæ·±å…¥çš„æŽ¢ç´¢ï¼Œæ‰€ä»¥è¿™é‡Œæˆ‘ä»¬å…ˆä¸€ç¬”å¸¦è¿‡ï¼ŒåŽé¢æˆ‘ä»¬å¯ä»¥è®²ä¸€ç¯‡å¯¹FlashAttentionè¿›è¡Œå—ç¨€ç–ä¼˜åŒ–çš„å·¥ä½œSCFA \\mathbf{S}=\\mathbf{Q K} \\mathbf{K}^{\\top} \\in \\mathbb{R}^{N \\times N}, \\quad \\mathbf{P}=\\operatorname{softmax}\\left(\\mathbf{S} \\odot 1_{\\overline{\\mathbf{M}}}\\right) \\in \\mathbb{R}^{N \\times N}, \\quad \\mathbf{O}=\\mathbf{P V} \\in \\mathbb{R}^{N \\times d} å®žéªŒéªŒè¯ é€šè¿‡å®žéªŒéªŒè¯å‘çŽ°ï¼ŒFlashAttentionåœ¨é€Ÿåº¦å’Œå†…å­˜å ç”¨æ–¹é¢éƒ½è¡¨çŽ°å‡ºæ˜Žæ˜¾çš„ä¼˜åŠ¿ï¼Œå¹¶å–å¾—äº†è‰¯å¥½çš„æ•ˆæžœ ç›®å‰ï¼ŒFlashAttentionå·²ç»ç»è¿‡å¹¿æ³›éªŒè¯, torch2.0ä¸­å·²æä¾›flashattentionçš„å®žçŽ° æ­£å¦‚æ ‡é¢˜ã€ŠFast and Memory-Efficient Exact Attention with IO-Awarenessã€‹æ‰€ç¤ºï¼ŒFlashAttentionçš„ä¼˜ç‚¹åœ¨äºŽå……åˆ†è€ƒè™‘äº†åœ¨è®¡ç®—ä»»åŠ¡ä¸­IOçš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡åˆ†å—è®¡ç®—çš„æ–¹å¼å¼€å‘äº†ä¸€ç§å¿«é€Ÿã€èŠ‚çœæ˜¾å­˜ã€ç²¾ç¡®æ— è¿‘ä¼¼çš„æ³¨æ„åŠ›å®žçŽ°æ–¹æ³•ã€‚è¿™ä½¿å¾—æˆ‘ä»¬æ›´ä¾¿äºŽè®­ç»ƒå…·æœ‰æ›´é•¿ä¸Šä¸‹æ–‡çš„Transformeræ¨¡åž‹ï¼Œå¹¶ä¸”ä¸ºåŽç»­æ³¨æ„åŠ›ç®—æ³•çš„ä¼˜åŒ–æä¾›äº†ä¸€ä¸ªåŸºå‡† Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/LLMæ¨¡åž‹éƒ¨ç½²è°ƒè¯•æŽ¨ç†.html":{"url":"chapters/LLMæ¨¡åž‹éƒ¨ç½²è°ƒè¯•æŽ¨ç†.html","title":"LLMæ¨¡åž‹éƒ¨ç½²è°ƒè¯•æŽ¨ç†.md","summary":"LLMæ¨¡åž‹éƒ¨ç½²è°ƒè¯•æŽ¨ç†","keywords":"","body":"LLMæ¨¡åž‹æ¦‚è¿°ä¸»è¦åº”ç”¨GPUçŽ¯å¢ƒé˜¿é‡Œäº‘AutoDLæœ¬åœ°Langchain-ChatGLMå‡†å¤‡å·¥ä½œæŽ¨ç†ä¿®æ”¹é…ç½®å¯åŠ¨webæœåŠ¡pycharmè¿œç¨‹é…ç½®ç›¸å…³æŠ€æœ¯localGPT LLMæ¨¡åž‹ ä»€ä¹ˆæ˜¯LLMï¼ˆå¤§è¯­éŸ³æ¨¡åž‹ï¼‰ æ¦‚è¿° Large Language Model(LLM)ï¼Œä¹Ÿç§°ä¸ºå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼Œæ˜¯ä¸€ç§åŸºäºŽæœºå™¨å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯çš„æ¨¡åž‹ï¼Œå®ƒé€šè¿‡å¯¹å¤§é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæ¥å­¦ä¹ æœåŠ¡äººç±»è¯­è¨€ç†è§£å’Œç”Ÿæˆçš„èƒ½åŠ› LLMçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¤§è§„æ¨¡çš„æ— ç›‘ç£è®­ç»ƒæ¥å­¦ä¹ è‡ªç„¶è¯­è¨€çš„æ¨¡å¼å’Œè¯­è¨€ç»“æž„ï¼Œè¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»çš„è¯­è¨€è®¤çŸ¥å’Œç”Ÿæˆè¿‡ç¨‹ ä¸Žä¼ ç»Ÿçš„NLPæ¨¡åž‹ç›¸æ¯”ï¼ŒLLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆè‡ªç„¶æ–‡æœ¬ï¼ŒåŒæ—¶è¿˜èƒ½å¤Ÿè¡¨çŽ°å‡ºä¸€å®šçš„é€»è¾‘æ€ç»´å’ŒæŽ¨ç†èƒ½åŠ› è¿‘å¹´æ¥ï¼ŒLLMå¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ï¼Œå…¶ä¸­æœ€å…·ä»£è¡¨æ€§çš„æ˜¯è°·æ­Œçš„BERTå’ŒOpenAIçš„GPTç³»åˆ—ã€‚è¿™äº›æ¨¡åž‹åœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå·²ç»å–å¾—äº†æ˜¾è‘—çš„æˆæžœï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€å‘½åå®žä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æžã€æœºå™¨ç¿»è¯‘ã€è‡ªåŠ¨é—®ç­”ç­‰ ç„¶è€Œï¼Œåœ¨å®žé™…åº”ç”¨ä¸­ï¼ŒLLMé¢ä¸´ç€æ›´å¤šçš„æŒ‘æˆ˜ é¦–å…ˆï¼ŒLLMéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œå¤§è§„æ¨¡çš„æ•°æ®é›†æ¥è®­ç»ƒï¼Œè¿™å¯¹äºŽä¸€èˆ¬çš„ä¼ä¸šå’Œä¸ªäººæ¥è¯´ååˆ†å›°éš¾ å…¶æ¬¡ï¼Œç”±äºŽLLMæ¨¡åž‹çš„å¤æ‚æ€§å’Œè®¡ç®—é‡è¾ƒå¤§ï¼Œå¯¹äºŽå®žæ—¶çš„è¯­è¨€å¤„ç†åº”ç”¨æ¥è¯´ï¼ŒLLMåœ¨åº”ç”¨æ•ˆçŽ‡å’Œå“åº”é€Ÿåº¦ä¸Šè¿˜å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ å› æ­¤ï¼Œå¦‚ä½•è§£å†³æ¨¡åž‹è®­ç»ƒå’Œåº”ç”¨è¿‡ç¨‹ä¸­çš„è®¡ç®—æ€§èƒ½å’Œæ•ˆçŽ‡é—®é¢˜ï¼Œæ˜¯LLMé¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ ä¸»è¦åº”ç”¨ LLMåœ¨å®žé™…åº”ç”¨ä¸­æœ‰å¤šç§å½¢å¼ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å…·ä½“çš„ç¤ºä¾‹ï¼š è‡ªç„¶è¯­è¨€ç†è§£ï¼šé€šè¿‡è¯­æ³•è¯æ±‡ã€å¥æ³•è¯­ä¹‰ã€è¯­å¢ƒç­‰ç›¸äº’ä½œç”¨ï¼Œä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£äººç±»è¯­è¨€ã€‚å¦‚é€šè¿‡è¯­éŸ³åˆæˆåŠŸèƒ½ï¼Œå®žçŽ°æ–‡å­—è½¬è¯­éŸ³çš„æŠ€æœ¯ã€‚å¦å¤–ï¼ŒåŸºäºŽLLMæŠ€æœ¯çš„è‹±è¯­å­¦ä¹ Appå¯ä»¥é’ˆå¯¹ä¸åŒçš„ç”¨æˆ·è®©æœºå™¨è¿›è¡Œè‡ªé€‚åº”æ•™å­¦ï¼Œå¸®åŠ©ç”¨æˆ·æ›´åŠ é«˜æ•ˆåœ°å­¦ä¹ è‹±è¯­ æœºå™¨ç¿»è¯‘ï¼šLLMå¯ä»¥åˆ©ç”¨å¤§é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œç¿»è¯‘å­¦ä¹ ï¼Œæé«˜ç¿»è¯‘å‡†ç¡®åº¦å’Œè¯­éŸ³ç¿»è¯‘åº¦ï¼ŒåŒæ—¶åŠ é€Ÿç¿»è¯‘é€Ÿåº¦ï¼Œä¾‹å¦‚è°·æ­Œç¿»è¯‘ç­‰ä½“éªŒéƒ½æœ‰æ˜Žæ˜¾æå‡ æƒ…æ„Ÿåˆ†æžï¼šLLMæŠ€æœ¯å¯ä»¥é€šè¿‡å¯¹å¤§é‡æ•°æ®è¿›è¡Œåˆ†æžï¼Œå®žçŽ°å¯¹äººä»¬åœ¨ç¤¾äº¤åª’ä½“ä¸Šå¯¹å•†å“ã€æœåŠ¡å’Œå“ç‰Œç­‰çš„è¯„ä»·ï¼Œä»Žè€Œå¸®åŠ©ä¼ä¸šäº†è§£æ¶ˆè´¹è€…çš„å¿ƒæ€ï¼Œå¹¶æ ¹æ®æƒ…æ„Ÿä¿¡æ¯æ¥ä¼˜åŒ–å…¶è¥é”€ç­–ç•¥ æœºå™¨å­¦ä¹ è¯­éŸ³è¯†åˆ«ï¼šåœ¨è¯­éŸ³è¯†åˆ«é¢†åŸŸï¼ŒLLMæŠ€æœ¯å¯ä»¥é€šè¿‡æ·±åº¦å­¦ä¹ ç®—æ³•ç­‰æŠ€æœ¯æ”¹è¿›ï¼Œä»Žè€Œåœ¨åˆ†è¾¨çŽ‡ã€å£°éŸ³é‡å ã€å™ªéŸ³å’Œå¤æ‚è¯­éŸ³è¯­è¨€ä¸­å®žçŽ°æ›´å¥½çš„è¯­éŸ³è¯†åˆ«æ•ˆæžœã€‚åŒæ—¶ï¼Œåœ¨è¯­éŸ³äº¤äº’ä¸Šï¼Œä¹Ÿå¯ä»¥è¿›è¡Œä¸€äº›åŸºäºŽLLMçš„å®šåˆ¶ï¼Œä¾‹å¦‚æ™ºèƒ½éŸ³ç®±ã€è¯­éŸ³æŽ¥å¾…å‘˜å’Œå®¢æˆ·æœåŠ¡æœºå™¨äººç­‰ æ–‡æœ¬ç”Ÿæˆï¼šLLMæŠ€æœ¯åœ¨æ–‡æœ¬ç”Ÿæˆæ–¹é¢çš„åº”ç”¨å¯ä»¥åœ¨æ–‡æœ¬æ‘˜è¦ã€ç¿»è¯‘å’Œè‡ªåŠ¨åŒ–å†™ä½œç­‰æ–¹é¢è¿›è¡Œé€‚ç”¨ã€‚ä¾‹å¦‚ï¼ŒLLMæ¨¡åž‹å¯ä»¥ä»ŽçŸ­ç¯‡å°è¯´çš„èƒŒæ™¯ä¿¡æ¯ä¸­è‡ªåŠ¨ç”Ÿæˆæè¿°ã€å¯¹è¯ç­‰å†…å®¹ï¼ŒåŒæ—¶è¿˜å¯ä»¥é€šè¿‡å¯¹ä¸åŒé£Žæ ¼çš„æ–‡æœ¬è¿›è¡Œå­¦ä¹ ï¼Œå¹¶ä»Žä¸­å­¦ä¹ åˆ›é€ æ€§çš„æ–‡æœ¬ç”Ÿæˆ GPUçŽ¯å¢ƒ é˜¿é‡Œäº‘ è´­ä¹°ä¸€å°è‡ªå·±çš„GPUæœæœåŠ¡å™¨ è´­ä¹°é˜¿é‡Œäº‘æœåŠ¡å™¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š è®¿é—®é˜¿é‡Œäº‘å®˜ç½‘å¹¶æ³¨å†Œä¸€ä¸ªè´¦æˆ· ç™»å½•æ‚¨çš„é˜¿é‡Œäº‘è´¦æˆ·ï¼Œé€‰æ‹©\"äº§å“ä¸ŽæœåŠ¡\"ï¼Œç„¶åŽé€‰æ‹©\"äº‘æœåŠ¡å™¨ ECS\" åœ¨äº‘æœåŠ¡å™¨ECSé¡µé¢ä¸Šï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä¸åŒçš„å®žä¾‹ç±»åž‹å’Œé…ç½®ï¼Œæ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©é€‚åˆçš„æœåŠ¡å™¨è§„æ ¼ã€‚è¿™äº›è§„æ ¼åŒ…æ‹¬CPUã€å†…å­˜ã€å­˜å‚¨ç©ºé—´ç­‰ é…ç½®ç½‘ç»œå’Œå®‰å…¨ç»„ï¼Œæ‚¨å¯ä»¥è®¾ç½®ç½‘ç»œç±»åž‹ã€å…¬ç½‘å¸¦å®½ã€IPåœ°å€ç­‰ æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©è´­ä¹°æ—¶é•¿ï¼Œå¯ä»¥é€‰æ‹©åŒ…å¹´åŒ…æœˆæˆ–æŒ‰å°æ—¶è®¡è´¹ï¼Œè¿™é‡Œå¦‚æžœåªæ˜¯ä¸ºäº†æµ‹è¯•æˆ–çŽ©ä¸€çŽ©ï¼Œå¯ä»¥é€‰æ‹©æœ€ä¾¿å®œçš„æ–¹å¼ é…ç½®ç³»ç»Ÿå’Œè½¯ä»¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©æ“ä½œç³»ç»Ÿå’Œå…¶ä»–è½¯ä»¶é¢„è£…é€‰é¡¹ æŸ¥çœ‹è®¢å•å’Œä»·æ ¼ï¼Œç¡®è®¤æ— è¯¯åŽï¼Œç‚¹å‡»\"ç«‹å³è´­ä¹°\" åœ¨æ”¯ä»˜é¡µé¢é€‰æ‹©åˆé€‚çš„æ”¯ä»˜æ–¹å¼å®Œæˆè´­ä¹° å®Œæˆæ”¯ä»˜åŽï¼Œæ‚¨å°†æ”¶åˆ°è´­ä¹°æœåŠ¡å™¨çš„ç¡®è®¤ä¿¡æ¯å’ŒæœåŠ¡å™¨ç™»å½•å‡­è¯ ç«¯å£å¼€æ”¾ å®‰è£…åŸºç¡€çš„pythonçŽ¯å¢ƒ é¦–å…ˆå¤åˆ¶å…¬ç½‘ipï¼Œä½¿ç”¨sshå·¥å…·è¿žæŽ¥è‡ªå·±çš„æœåŠ¡å™¨ï¼Œç”¨æˆ·åé»˜è®¤æ˜¯rootï¼Œå¯†ç ä¸ºè‡ªå®šä¹‰å¯†ç ï¼Œç™»é™†è¿›æ¥é¦–å…ˆä¼šç³»ç»Ÿåˆå§‹åŒ–GPUçŽ¯å¢ƒï¼Œç­‰å¾…å®ŒæˆåŽä¼šè‡ªåŠ¨é‡å¯ è‡ªåŠ¨é‡å¯åŽï¼Œå¯ä»¥ç”¨nvidia-smiæŸ¥çœ‹nvidiaé©±åŠ¨é…ç½® å®‰è£…gitï¼ŒåŽé¢å¾ˆå¤šé¡¹ç›®æˆ–è€…æ¨¡åž‹ä¸‹è½½ä¼šç”¨åˆ°ï¼ŒåŒ…æ‹¬git lfs # å®‰è£…git yum install git -y # å®‰è£…git lfsï¼ˆå¤§æ–‡ä»¶ä¸‹è½½ï¼‰ curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash yum install git-lfs git lfs install å®‰è£…anacondaï¼Œå¹¶åˆ›å»ºè‡ªå·±çš„pythonçŽ¯å¢ƒ # å®‰è£…anacondaçŽ¯å¢ƒ wget https://repo.anaconda.com/archive/Anaconda3-2023.03-1-Linux-x86_64.sh chmod +x Anaconda3-2023.03-1-Linux-x86_64.sh ./Anaconda3-2023.03-1-Linux-x86_64.sh # åˆ›å»ºè‡ªå·±çš„pythonçŽ¯å¢ƒ conda create -n gpt310 python=3.10 anaconda å®‰è£…pytorchï¼Œè¿™é‡Œçš„cudaé€‰cu117ï¼Œå› ä¸ºä¸Šé¢çš„æœåŠ¡å™¨çš„cudaæ˜¯11.4çš„ï¼Œè¿™é‡Œçš„cu117æ˜¯å¯ä»¥å‘ä¸‹å…¼å®¹çš„ # åˆ‡æ¢åˆ°gpt310 source activate gpt310 # å®‰è£…gpuç‰ˆçš„pytorch, éœ€è¦åœ¨GPUçŽ¯å¢ƒä¸‹å®‰è£…ï¼Œå¦åˆ™å®‰è£…æ˜¯cpuç‰ˆæœ¬ pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu117 åœ¨Pythonä¸­å¯¼å…¥PyTorchå¹¶æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨ import torch # æ£€æŸ¥PyTorchæ˜¯å¦ä½¿ç”¨äº†CUDA if torch.cuda.is_available(): print(\"CUDAå¯ç”¨\") else: print(\"CUDAä¸å¯ç”¨\") è¿˜å¯ä»¥ä½¿ç”¨torch.cuda.get_device_capability()å‡½æ•°æ¥èŽ·å–è®¡ç®—æœºä¸Šæ”¯æŒçš„CUDAè®¾å¤‡çš„è®¡ç®—èƒ½åŠ›ã€‚è¿™å¯ä»¥å¸®åŠ©æ‚¨ç¡®å®šæ‰€å®‰è£…çš„CUDAç‰ˆæœ¬æ˜¯å¦ä¸Žæ‚¨çš„æ˜¾å¡å…¼å®¹ ç”¨å®Œæœºå™¨è®°å¾—å…³æœºï¼Œä¸ç„¶ä¼šä¸€ç›´æ‰£è´¹ AutoDL AutoDLå¹³å°ç®€ä»‹ AutoDLç®—åŠ›å¹³å°æ˜¯æŒ‡ä¸ºè‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ (AutoDL)ä»»åŠ¡æä¾›è®¡ç®—èµ„æºå’ŒåŸºç¡€è®¾æ–½çš„å¹³å°ã€‚ç”±äºŽæ·±åº¦å­¦ä¹ ä»»åŠ¡é€šå¸¸éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œå­˜å‚¨ç©ºé—´ï¼Œä¸ºäº†æœ‰æ•ˆåœ°æ‰§è¡ŒAutoDLä»»åŠ¡ï¼Œéœ€è¦å…·å¤‡ç›¸åº”çš„ç®—åŠ›å¹³å° ä¸€ä¸ªä¼˜ç§€çš„AutoDLç®—åŠ›å¹³å°é€šå¸¸å…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š é«˜æ€§èƒ½è®¡ç®—ï¼šæä¾›å¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ï¼ŒåŒ…æ‹¬é«˜æ€§èƒ½çš„CPUã€GPUæˆ–ä¸“ç”¨çš„AIèŠ¯ç‰‡ç­‰ã€‚è¿™äº›è®¡ç®—èµ„æºå¯ä»¥æ”¯æŒAutoDLä»»åŠ¡çš„æ¨¡åž‹è®­ç»ƒã€è¶…å‚æ•°æœç´¢å’Œæž¶æž„æœç´¢ç­‰è®¡ç®—å¯†é›†åž‹ä»»åŠ¡ åˆ†å¸ƒå¼è®¡ç®—ï¼šæ”¯æŒåˆ†å¸ƒå¼è®¡ç®—å’Œè®­ç»ƒï¼Œä½¿å¾—AutoDLä»»åŠ¡å¯ä»¥åœ¨å¤šä¸ªè®¡ç®—èŠ‚ç‚¹ä¸Šå¹¶è¡Œæ‰§è¡Œï¼Œä»Žè€ŒåŠ å¿«ä»»åŠ¡çš„å®Œæˆæ—¶é—´ã€‚è¿™å¯¹äºŽå¤§è§„æ¨¡æ•°æ®å’Œå¤æ‚æ¨¡åž‹çš„AutoDLä»»åŠ¡å°¤ä¸ºé‡è¦ æ•°æ®å­˜å‚¨å’Œç®¡ç†ï¼šæä¾›é«˜æ•ˆçš„æ•°æ®å­˜å‚¨å’Œç®¡ç†ç³»ç»Ÿï¼Œä»¥æ”¯æŒå¤§è§„æ¨¡æ•°æ®é›†çš„å­˜å‚¨å’Œè®¿é—®ã€‚è¿™å¯ä»¥ç¡®ä¿AutoDLä»»åŠ¡èƒ½å¤Ÿå¿«é€Ÿã€å¯é åœ°è®¿é—®æ‰€éœ€çš„è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ® ä»»åŠ¡è°ƒåº¦å’Œèµ„æºç®¡ç†ï¼šå…·å¤‡ä»»åŠ¡è°ƒåº¦å’Œèµ„æºç®¡ç†åŠŸèƒ½ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ç®¡ç†å¤šä¸ªAutoDLä»»åŠ¡çš„æ‰§è¡Œï¼ŒåŒ…æ‹¬èµ„æºåˆ†é…ã€ä¼˜å…ˆçº§ç®¡ç†å’Œä»»åŠ¡è°ƒåº¦ç­‰ï¼Œä»¥ä¿è¯ä»»åŠ¡çš„é¡ºåˆ©è¿›è¡Œ æ˜“ç”¨æ€§å’Œçµæ´»æ€§ï¼šæä¾›å‹å¥½çš„ç”¨æˆ·ç•Œé¢å’Œå·¥å…·ï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥æ–¹ä¾¿åœ°é…ç½®å’Œç®¡ç†AutoDLä»»åŠ¡ã€‚åŒæ—¶ï¼Œæä¾›çµæ´»çš„é…ç½®é€‰é¡¹ï¼Œä»¥æ»¡è¶³ä¸åŒä»»åŠ¡å’Œéœ€æ±‚çš„å®šåˆ¶åŒ–è¦æ±‚ AutoDLç®—åŠ›å¹³å°çš„è®¾è®¡å’ŒåŠŸèƒ½æ—¨åœ¨æä¾›é«˜æ•ˆã€å¯æ‰©å±•å’Œæ˜“ç”¨çš„è®¡ç®—èµ„æºï¼Œä»¥æ”¯æŒAutoDLä»»åŠ¡çš„å¿«é€Ÿè¿­ä»£å’Œå¤§è§„æ¨¡åº”ç”¨ã€‚å®ƒä»¬å¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æ›´åŠ ä¾¿æ·åœ°è¿›è¡ŒAutoDLå®žéªŒå’Œæ¨¡åž‹ä¼˜åŒ–ï¼Œä»Žè€ŒæŽ¨åŠ¨è‡ªåŠ¨åŒ–æ·±åº¦å­¦ä¹ é¢†åŸŸçš„å‘å±• è´­ä¹°ç®—åŠ› é€‰æ‹©è®¡è´¹æ–¹å¼å’Œæ˜¾å¡ é€‰æ‹©æ˜¯å¦éœ€è¦æ‰©å±•æ•°æ®ç›˜ï¼Œä»¥åŠåŸºç¡€é•œåƒï¼Œè¿™é‡Œé€‰MinicondaçŽ¯å¢ƒ å¯åŠ¨æœºå™¨ï¼Œè¿›å…¥ç»ˆç«¯å¯ä»¥çœ‹åˆ° +--------------------------------------------------AutoDL--------------------------------------------------------+ ç›®å½•è¯´æ˜Ž: â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•— â•‘ç›®å½• â•‘åç§° â•‘é€Ÿåº¦â•‘è¯´æ˜Ž â•‘ â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•¬â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£ â•‘/ â•‘ç³» ç»Ÿ ç›˜â•‘ä¸€èˆ¬â•‘å®žä¾‹å…³æœºæ•°æ®ä¸ä¼šä¸¢å¤±ï¼Œå¯å­˜æ”¾ä»£ç ç­‰ã€‚ä¼šéšä¿å­˜é•œåƒä¸€èµ·ä¿å­˜ã€‚ â•‘ â•‘/root/autodl-tmp â•‘æ•° æ® ç›˜â•‘ å¿« â•‘å®žä¾‹å…³æœºæ•°æ®ä¸ä¼šä¸¢å¤±ï¼Œå¯å­˜æ”¾è¯»å†™IOè¦æ±‚é«˜çš„æ•°æ®ã€‚ä½†ä¸ä¼šéšä¿å­˜é•œåƒä¸€èµ·ä¿å­˜ â•‘ â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•©â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CPU ï¼š0.5 æ ¸å¿ƒ å†…å­˜ï¼š2 GB GPU ï¼šNo devices were found å­˜å‚¨ï¼š ç³» ç»Ÿ ç›˜/ ï¼š46% 12G/25G æ•° æ® ç›˜/root/autodl-tmpï¼š65% 33G/50G +----------------------------------------------------------------------------------------------------------------+ *æ³¨æ„: 1.ç³»ç»Ÿç›˜è¾ƒå°è¯·å°†å¤§çš„æ•°æ®å­˜æ”¾äºŽæ•°æ®ç›˜æˆ–ç½‘ç›˜ä¸­ï¼Œé‡ç½®ç³»ç»Ÿæ—¶æ•°æ®ç›˜å’Œç½‘ç›˜ä¸­çš„æ•°æ®ä¸å—å½±å“ 2.æ¸…ç†ç³»ç»Ÿç›˜è¯·å‚è€ƒï¼šhttps://www.autodl.com/docs/qa/ å®‰è£…git-lfsä»¥åŠsslç­‰ä¾èµ– curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash sudo apt-get install git-lfs git lfs install sudo apt-get install openssl sudo apt-get install libssl-dev å®‰è£…pytorchçŽ¯å¢ƒ # åˆ›å»ºè‡ªå·±çš„pythonçŽ¯å¢ƒ conda create -n gpt310 python=3.10 anaconda # åˆ‡æ¢åˆ°gpt310 source activate gpt310 # å®‰è£…gpuç‰ˆçš„pytorch, éœ€è¦åœ¨GPUçŽ¯å¢ƒä¸‹å®‰è£…ï¼Œå¦åˆ™å®‰è£…æ˜¯cpuç‰ˆæœ¬ pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu117 åœ¨Pythonä¸­å¯¼å…¥PyTorchå¹¶æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨ import torch # æ£€æŸ¥PyTorchæ˜¯å¦ä½¿ç”¨äº†CUDA if torch.cuda.is_available(): print(\"CUDAå¯ç”¨\") else: print(\"CUDAä¸å¯ç”¨\") å…¶å®ƒäº‹é¡¹ æŽ§åˆ¶å°ä¸‹å®¹å™¨å®žä¾‹å°±æ˜¯ç§Ÿç”¨çš„æœºå™¨ï¼Œè‡ªå®šä¹‰æœåŠ¡æ˜¯å°†å®¹å™¨å†…çš„6006ç«¯å£æ˜ å°„åˆ°å…¬ç½‘ /root/autodl-tmpå¯ä»¥æ”¾ä¸€äº›æ•°æ®æˆ–æ¨¡åž‹ï¼Œå¼€å…³æœºä¸ä¼šä¸¢å¤±ï¼Œä½†ä¸éšé•œåƒä¸€èµ·ä¿å­˜ æ— å¡å¼€æœºæ¨¡åž‹ä¸å¸¦GPUï¼Œå¾ˆä¾¿å®œï¼Œä¸€å°æ—¶0.01å…ƒ æœ¬åœ° &#x1F47B;æ²¡æœ‰æ˜¾å¡ï¼Œ&#x1F915;ä¼¤ä¸èµ·&#x1F915; Langchain-ChatGLM github imClumsyPanda/langchain-ChatGLM &#x1F916;ï¸ ä¸€ç§åˆ©ç”¨ langchain æ€æƒ³å®žçŽ°çš„åŸºäºŽæœ¬åœ°çŸ¥è¯†åº“çš„é—®ç­”åº”ç”¨ï¼Œç›®æ ‡æœŸæœ›å»ºç«‹ä¸€å¥—å¯¹ä¸­æ–‡åœºæ™¯ä¸Žå¼€æºæ¨¡åž‹æ”¯æŒå‹å¥½ã€å¯ç¦»çº¿è¿è¡Œçš„çŸ¥è¯†åº“é—®ç­”è§£å†³æ–¹æ¡ˆ &#x1F4A1; å— GanymedeNil çš„é¡¹ç›® document.ai å’Œ AlexZhangji åˆ›å»ºçš„ ChatGLM-6B Pull Request å¯å‘ï¼Œå»ºç«‹äº†å…¨æµç¨‹å¯ä½¿ç”¨å¼€æºæ¨¡åž‹å®žçŽ°çš„æœ¬åœ°çŸ¥è¯†åº“é—®ç­”åº”ç”¨ã€‚çŽ°å·²æ”¯æŒä½¿ç”¨ ChatGLM-6B ç­‰å¤§è¯­è¨€æ¨¡åž‹ç›´æŽ¥æŽ¥å…¥ï¼Œæˆ–é€šè¿‡ fastchat api å½¢å¼æŽ¥å…¥ Vicuna, Alpaca, LLaMA, Koala, RWKV ç­‰æ¨¡åž‹ âœ… æœ¬é¡¹ç›®ä¸­ Embedding é»˜è®¤é€‰ç”¨çš„æ˜¯ GanymedeNil/text2vec-large-chineseï¼ŒLLM é»˜è®¤é€‰ç”¨çš„æ˜¯ ChatGLM-6Bã€‚ä¾æ‰˜ä¸Šè¿°æ¨¡åž‹ï¼Œæœ¬é¡¹ç›®å¯å®žçŽ°å…¨éƒ¨ä½¿ç”¨å¼€æºæ¨¡åž‹ç¦»çº¿ç§æœ‰éƒ¨ç½² â›“ï¸ æœ¬é¡¹ç›®å®žçŽ°åŽŸç†å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¿‡ç¨‹åŒ…æ‹¬åŠ è½½æ–‡ä»¶ -> è¯»å–æ–‡æœ¬ -> æ–‡æœ¬åˆ†å‰² -> æ–‡æœ¬å‘é‡åŒ– -> é—®å¥å‘é‡åŒ– -> åœ¨æ–‡æœ¬å‘é‡ä¸­åŒ¹é…å‡ºä¸Žé—®å¥å‘é‡æœ€ç›¸ä¼¼çš„top kä¸ª -> åŒ¹é…å‡ºçš„æ–‡æœ¬ä½œä¸ºä¸Šä¸‹æ–‡å’Œé—®é¢˜ä¸€èµ·æ·»åŠ åˆ°promptä¸­ -> æäº¤ç»™LLMç”Ÿæˆå›žç­” ä»Žæ–‡æ¡£å¤„ç†è§’åº¦æ¥çœ‹ï¼Œå®žçŽ°æµç¨‹å¦‚ä¸‹ï¼š ChatGLM-6Bæ¨¡åž‹ç¡¬ä»¶éœ€æ±‚ æ³¨ï¼šå¦‚æœªå°†æ¨¡åž‹ä¸‹è½½è‡³æœ¬åœ°ï¼Œè¯·æ‰§è¡Œå‰æ£€æŸ¥$HOME/.cache/huggingface/æ–‡ä»¶å¤¹å‰©ä½™ç©ºé—´ï¼Œæ¨¡åž‹æ–‡ä»¶ä¸‹è½½è‡³æœ¬åœ°éœ€è¦15GBå­˜å‚¨ç©ºé—´ã€‚æ³¨ï¼šä¸€äº›å…¶å®ƒçš„å¯é€‰å¯åŠ¨é¡¹è§é¡¹ç›®å¯åŠ¨é€‰é¡¹æ¨¡åž‹ä¸‹è½½æ–¹æ³•å¯å‚è€ƒå¸¸è§é—®é¢˜ä¸­Q8 é‡åŒ–ç­‰çº§ æœ€ä½Ž GPU æ˜¾å­˜ï¼ˆæŽ¨ç†ï¼‰ æœ€ä½Ž GPU æ˜¾å­˜ï¼ˆé«˜æ•ˆå‚æ•°å¾®è°ƒï¼‰ FP16ï¼ˆæ— é‡åŒ–ï¼‰ 13 GB 14 GB INT8 8 GB 9 GB INT4 6 GB 7 GB å‡†å¤‡å·¥ä½œ é¡¹ç›®çŽ¯å¢ƒå‡†å¤‡ å…ˆåœ¨/homeç›®å½•ä¸‹åˆ›å»ºhuangycæ–‡ä»¶å¤¹ï¼Œè¿›å…¥huangycç›®å½•ä¸‹åŽï¼Œæ‹‰å–é¡¹ç›®ä»£ç  git clone https://github.com/imClumsyPanda/langchain-ChatGLM.git å®‰è£…å¿…è¦åº“ # centosç³»ç»Ÿä¸‹ yum install libX11 -y yum install libXext -y pip uninstall detectron2 # ubuntuç³»ç»Ÿä¸éœ€è¦ è¿›å…¥langchain-ChatGLMæ–‡ä»¶å¤¹ï¼Œå®‰è£…ä¾èµ–åº“ï¼ŒAutoDlå¹³å°ä¸‹å¥½åƒéœ€è¦åŠ -iå‚æ•° pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple æ¨¡åž‹å‡†å¤‡ ä»Žhuggingfaceå¼€æ”¾æ¨¡åž‹ä¸‹æ‰¾åˆ°è‡ªå·±çš„éœ€è¦çš„æ¨¡åž‹ï¼Œç”¨git lfsä¸‹è½½ï¼Œå¦‚æžœåœ¨AutoDlå¹³å°ï¼Œå¯ä»¥æŠŠæ¨¡åž‹ä¸‹è½½åˆ°/root/autodl-tmp git clone https://huggingface.co/THUDM/chatglm-6b-int4.git å¯ä»¥ç”¨ls -lh .å‘½ä»¤æŸ¥çœ‹ä¸‹è½½çš„æ–‡ä»¶å¤§å°æ˜¯å¦æ­£å¸¸ ä¸‹è½½å®Œçš„chatglm-6b-int4æ¨¡åž‹æ–‡ä»¶å¤¹ï¼Œæ”¾åˆ°langchain-ChatGLMé¡¹ç›®çš„modelæ–‡ä»¶å¤¹ä¸‹ï¼Œæ²¡æœ‰modelæ–‡ä»¶å¤¹çš„è¯ï¼Œè‡ªå·±åˆ›å»ºä¸‹ å¦‚æžœä¸‹è½½å¤±è´¥çš„è¯ï¼Œå¯ä»¥è¯•ä¸‹ç”¨wgetä¸‹è½½ï¼Œä¾‹å¦‚ wget --no-check-certificate https://huggingface.co/THUDM/chatglm-6b-int4/resolve/main/pytorch_model.bin æŽ¨ç† ä¿®æ”¹é…ç½® æ‰“å¼€langchain-ChatGLM/config/model_config.pyï¼Œä¿®æ”¹å¦‚ä¸‹é…ç½® # supported LLM models # llm_model_dict å¤„ç†äº†loaderçš„ä¸€äº›é¢„è®¾è¡Œä¸ºï¼Œå¦‚åŠ è½½ä½ç½®ï¼Œæ¨¡åž‹åç§°ï¼Œæ¨¡åž‹å¤„ç†å™¨å®žä¾‹ llm_model_dict = { ...... \"chatglm-6b-int4\": { \"name\": \"chatglm-6b-int4\", - \"pretrained_model_name\": \"THUDM/chatglm-6b-int4\", + \"pretrained_model_name\": \"model/chatglm-6b-int4\", \"local_model_path\": None, \"provides\": \"ChatGLM\" } ...... } # LLM åç§° LLM_MODEL = \"chatglm-6b-int4\" # å¦‚æžœä½ éœ€è¦åŠ è½½æœ¬åœ°çš„modelï¼ŒæŒ‡å®šè¿™ä¸ªå‚æ•° ` --no-remote-model`ï¼Œæˆ–è€…ä¸‹æ–¹å‚æ•°ä¿®æ”¹ä¸º `True` NO_REMOTE_MODEL = False è¿™æ ·æ¨¡åž‹ä¼šä»Žæœ¬åœ°åŠ è½½ ä¿®æ”¹webui.pyï¼Œç”¨äºŽå¯åŠ¨Web äº¤äº’ (demo .queue(concurrency_count=3) - .launch(server_name='0.0.0.0', + .launch(server_name='localhost', server_port=7860, # AutoDlå¹³å°ç”¨çš„æ˜¯6006 show_api=False, - share=False, + share=True, inbrowser=False)) é˜¿é‡Œäº‘æœåŠ¡å™¨é‚£è¾¹éœ€è¦å¼€æ”¾7860ç«¯å£ å¯åŠ¨webæœåŠ¡ è¿›å…¥åˆ°langchain-ChatGLMé¡¹ç›®ä¸‹ï¼Œæ‰§è¡Œwebui.py python webui.py å¦‚æžœå‘çŽ°ç«¯å£è¢«å ç”¨äº†ï¼Œå¯ä»¥ç”¨netstat -atunlp | grep 7860å‘½ä»¤æŸ¥çœ‹å¹¶æ€æ­»å ç”¨è¯¥ç«¯å£çš„è¿›ç¨‹(è‡ªå·±åˆ¤æ–­) æ‰“å¼€ç½‘é¡µï¼Œä½ çš„ip:7860ï¼Œå°±å¯ä»¥çœ‹åˆ°å¦‚ä¸‹ç•Œé¢ï¼Œé»˜è®¤æ˜¯å¯¹è¯ç•Œé¢ å¯ä»¥åˆ‡æ¢åˆ°çŸ¥è¯†åº“æµ‹è¯•ï¼Œåœ¨è¿™é‡Œå¯ä»¥ä¸Šä¼ è‡ªå·±çš„æ–‡æ¡£åˆ°çŸ¥è¯†åº“ åŽå°çœ‹ä¸‹å½“å‰æ˜¾å­˜å ç”¨ï¼Œæ¨¡åž‹ç”¨çš„æ˜¯chatglm-6b-int4æ¨¡åž‹ ä¹‹åŽæµ‹è¯•ä¸Šä¼ äº†ã€Šæµç•…çš„Pythonã€‹é«˜æ¸…å®˜æ–¹ä¸­æ–‡ç‰ˆ.pdfï¼ŒåŽå°ä¸€ç›´åœ¨æ›´æ–°çŸ¥è¯†åº“ï¼Œç­‰äº†åå‡ åˆ†é’Ÿï¼Œè¿˜æ²¡ç»“æŸï¼Œæˆ‘å°±åˆ‡æ¢åˆ°æ™®é€šå¯¹è¯äº†ï¼Œåˆæµ‹äº†åå‡ è½®å¯¹è¯ï¼Œçªç„¶çˆ†äº†æ˜¾å­˜ä¸å¤Ÿï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯ä¸Šä¼ çŸ¥è¯†åº“å¼•èµ·çš„ï¼Œè¿˜æ˜¯éšç€å¯¹è¯å¢žåŠ ï¼Œæ˜¾å­˜ä¸€ç›´æ²¡é‡Šæ”¾ pycharmè¿œç¨‹é…ç½® PyCharmè¿œç¨‹é…ç½®è§£é‡Šå™¨å’Œé¡¹ç›®æä¾›äº†ä»¥ä¸‹å‡ ä¸ªé‡è¦çš„ç”¨é€”å’Œä¼˜åŠ¿ï¼š è¿œç¨‹å¼€å‘ï¼šæ‚¨å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨PyCharmç¼–å†™ä»£ç ï¼Œå¹¶å°†ä»£ç éƒ¨ç½²å’Œè¿è¡Œåœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šã€‚è¿™æ„å‘³ç€æ‚¨ä¸éœ€è¦åœ¨æœ¬åœ°é…ç½®å’Œå®‰è£…ä¸Žè¿œç¨‹æœåŠ¡å™¨çŽ¯å¢ƒç›¸åŒçš„è½¯ä»¶å’Œä¾èµ–é¡¹ã€‚æ‚¨å¯ä»¥åˆ©ç”¨æœåŠ¡å™¨ä¸Šçš„è®¡ç®—èµ„æºå’ŒçŽ¯å¢ƒæ¥è¿›è¡Œå¼€å‘å’Œæµ‹è¯•ï¼Œå‡è½»äº†æœ¬åœ°æœºå™¨çš„è´Ÿæ‹… ç»Ÿä¸€å¼€å‘çŽ¯å¢ƒï¼šé€šè¿‡è¿œç¨‹é…ç½®è§£é‡Šå™¨å’Œé¡¹ç›®ï¼Œæ‚¨å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨PyCharmçš„åŠŸèƒ½å’Œå·¥å…·æ¥å¼€å‘å’Œè°ƒè¯•ä»£ç ã€‚æ‚¨å¯ä»¥äº«å—PyCharmæä¾›çš„æ™ºèƒ½ä»£ç è¡¥å…¨ã€è°ƒè¯•å™¨ã€ç‰ˆæœ¬æŽ§åˆ¶é›†æˆç­‰åŠŸèƒ½ï¼Œæ— éœ€åˆ‡æ¢åˆ°å…¶ä»–ç¼–è¾‘å™¨æˆ–è¿œç¨‹ç»ˆç«¯ åä½œä¸Žå›¢é˜Ÿå¼€å‘ï¼šè¿œç¨‹é…ç½®è§£é‡Šå™¨å’Œé¡¹ç›®ä½¿å›¢é˜Ÿæˆå‘˜å¯ä»¥å…±äº«ç›¸åŒçš„å¼€å‘çŽ¯å¢ƒã€‚æ— è®ºæ˜¯åœ¨æœ¬åœ°è¿˜æ˜¯è¿œç¨‹æœåŠ¡å™¨ä¸Šï¼Œå›¢é˜Ÿæˆå‘˜å¯ä»¥ä½¿ç”¨ç›¸åŒçš„é…ç½®å’Œä¾èµ–é¡¹æ¥å¼€å‘å’Œæµ‹è¯•ä»£ç ã€‚è¿™æœ‰åŠ©äºŽç¡®ä¿ä»£ç åœ¨ä¸åŒçŽ¯å¢ƒä¸‹çš„ä¸€è‡´æ€§ï¼Œå¹¶ä¿ƒè¿›å›¢é˜Ÿåä½œå’Œå¼€å‘æ•ˆçŽ‡ è¿œç¨‹è°ƒè¯•å’Œé”™è¯¯æŽ’æŸ¥ï¼šé€šè¿‡é…ç½®è¿œç¨‹è§£é‡Šå™¨ï¼Œæ‚¨å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨PyCharmçš„è°ƒè¯•å™¨æ¥è°ƒè¯•è¿œç¨‹æœåŠ¡å™¨ä¸Šçš„ä»£ç ã€‚è¿™æ ·ï¼Œæ‚¨å¯ä»¥é€æ­¥æ‰§è¡Œä»£ç ã€è§‚å¯Ÿå˜é‡å’Œç›‘æŽ§ç¨‹åºçŠ¶æ€ï¼Œä»¥ä¾¿æ›´è½»æ¾åœ°è¿›è¡Œé”™è¯¯æŽ’æŸ¥å’Œä¿®å¤ è¿œç¨‹éƒ¨ç½²å’Œç®¡ç†ï¼šé€šè¿‡è¿œç¨‹é…ç½®é¡¹ç›®ï¼Œæ‚¨å¯ä»¥å°†æœ¬åœ°çš„ä»£ç åŒæ­¥åˆ°è¿œç¨‹æœåŠ¡å™¨ä¸Šï¼Œå¹¶åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œå’Œç®¡ç†é¡¹ç›®ã€‚è¿™ç®€åŒ–äº†éƒ¨ç½²è¿‡ç¨‹ï¼Œå¹¶ä½¿æ‚¨èƒ½å¤Ÿç›´æŽ¥åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šæ“ä½œé¡¹ç›®æ–‡ä»¶å’Œèµ„æº PyCharmè¿œç¨‹é…ç½®è§£é‡Šå™¨å’Œé¡¹ç›®æä¾›äº†ä¸€ç§æ–¹ä¾¿è€Œé«˜æ•ˆçš„æ–¹å¼ï¼Œè®©æ‚¨å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨PyCharmè¿›è¡Œå¼€å‘å’Œè°ƒè¯•ï¼ŒåŒæ—¶åˆ©ç”¨è¿œç¨‹æœåŠ¡å™¨çš„ä¼˜åŠ¿æ¥è¿è¡Œå’Œéƒ¨ç½²ä»£ç ã€‚è¿™å¯¹äºŽéœ€è¦åœ¨è¿œç¨‹çŽ¯å¢ƒä¸‹è¿›è¡Œå¼€å‘å’Œåä½œçš„åœºæ™¯éžå¸¸æœ‰ç”¨ï¼Œå¦‚è¿œç¨‹æœåŠ¡å™¨ä¸Šçš„Webå¼€å‘ã€æ•°æ®å¤„ç†å’Œäº‘è®¡ç®—ç­‰ä»»åŠ¡ pycharmè¿œç¨‹é…ç½®å‚è€ƒæœ¬ç«™çš„Sparké›†ç¾¤æ­å»ºç« èŠ‚ä¸‹çš„é…ç½®è¿œç¨‹è§£é‡Šå™¨ ç›¸å…³æŠ€æœ¯ langchain: langchainã€LangChainï¼šä¸ºä½ å®šåˆ¶ä¸€ä¸ªä¸“å±žçš„GPT LangChainæ˜¯ä¸€ä¸ªç”¨äºŽå¼€å‘åŸºäºŽè¯­è¨€æ¨¡åž‹çš„åº”ç”¨ç¨‹åºå¼€å‘æ¡†æž¶ï¼Œç”¨æˆ·å¯ä»¥åˆ©ç”¨LangChainçš„æ¨¡å—æ¥æ”¹å–„å¤§è¯­è¨€æ¨¡åž‹çš„ä½¿ç”¨ï¼Œé€šè¿‡è¾“å…¥è‡ªå·±çš„çŸ¥è¯†åº“æ¥å®šåˆ¶åŒ–è‡ªå·±çš„å¤§è¯­è¨€æ¨¡åž‹ faiss: Faiss Documentationã€[python] å‘é‡æ£€ç´¢åº“Faissä½¿ç”¨æŒ‡åŒ— æ‰€è°“ç›¸ä¼¼æ€§æœç´¢æ˜¯æŒ‡é€šè¿‡æ¯”è¾ƒå¤šç»´ç©ºé—´ä¸­æ•°æ®ä¹‹é—´çš„ç›¸ä¼¼æ€§æ¥æœç´¢ä¸Žè¾“å…¥æ•°æ®æœ€ç›¸ä¼¼çš„ç›®æ ‡æ•°æ®ã€‚ä¾‹å¦‚äººè„¸è¯†åˆ«ä¸­ï¼Œé€šè¿‡æ¯”è¾ƒäººè„¸å‘é‡ä¹‹å‰çš„è·ç¦»æ¥è¯†åˆ«å½“å‰äººè„¸ä¸Žå“ªå¼ äººè„¸ç›¸ä¼¼ã€‚å› æ­¤ï¼Œè¯¥æŠ€æœ¯è¢«å¹¿æ³›åº”ç”¨äºŽä¿¡æ¯æ£€ç´¢ã€è®¡ç®—æœºè§†è§‰ã€æ•°æ®åˆ†æžç­‰é¢†åŸŸã€‚å¦‚æžœè¦æ£€ç´¢çš„æ•°æ®å¾ˆå¤šæ—¶ï¼Œé‚£ä¹ˆå°±éœ€è¦ä¸€ä¸ªå‘é‡æ£€ç´¢åº“æ¥åŠ é€Ÿæ£€ç´¢ FaissåŒ…å«å¤šç§ç›¸ä¼¼æ€§æœç´¢æ–¹æ³•ï¼Œå¹¶æä¾›cpuå’Œgpuç‰ˆæœ¬æ”¯æŒã€‚Faissçš„ä¼˜åŠ¿åœ¨äºŽé€šè¿‡è¾ƒå°çš„ç²¾åº¦æŸå¤±æé«˜å‘é‡ç›¸ä¼¼åº¦çš„æ£€ç´¢é€Ÿåº¦å’Œå‡å°‘å†…å­˜ä½¿ç”¨é‡ ChatGLM-6B: chatglmã€github THUDM/ChatGLM-6B ChatGLM-6Bæ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡åž‹ï¼ŒåŸºäºŽGeneral Language Model (GLM)æž¶æž„ï¼Œå…·æœ‰62äº¿å‚æ•°ã€‚ç»“åˆæ¨¡åž‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²(INT4é‡åŒ–çº§åˆ«ä¸‹æœ€ä½Žåªéœ€6GBæ˜¾å­˜)ã€‚ ChatGLM-6Bä½¿ç”¨äº†å’ŒChatGPTç›¸ä¼¼çš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç»è¿‡çº¦1Tæ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62äº¿å‚æ•°çš„ChatGLM-6Bå·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›žç­” Hugging Face: Hugging Face Hugging Faceæ˜¯ä¸€ä¸ªçŸ¥åçš„å¼€æºç¤¾åŒºå’Œå…¬å¸ï¼Œä¸“æ³¨äºŽè‡ªç„¶è¯­è¨€å¤„ç†(NLP)å’Œæœºå™¨å­¦ä¹ (ML)é¢†åŸŸã€‚ä»–ä»¬å¼€å‘äº†è®¸å¤šæµè¡Œçš„å¼€æºå·¥å…·å’Œåº“ï¼Œä½¿å¾—æž„å»ºå’Œåº”ç”¨NLPæ¨¡åž‹æ›´åŠ ä¾¿æ· localGPT github PromtEngineer/localGPT ç­‰å¾… Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/dl_in_vision_field.html":{"url":"chapters/dl_in_vision_field.html","title":"dl_in_vision_field.md","summary":null,"keywords":"","body":"æ¨¡åž‹ä»‹ç»å›¾åƒåˆ†ç±»ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ªå›¾åƒåˆ†å‰²å›¾åƒå¤„ç†å›¾åƒç”ŸæˆåŠ¨ä½œè¯†åˆ«é£Žæ ¼è½¬æ¢äººè„¸è¯†åˆ«å›¾åƒæè¿°OCR å¿…è¯»ï¼è®¡ç®—æœºè§†è§‰å››å¤§åŸºæœ¬ä»»åŠ¡(åˆ†ç±»ã€å®šä½ã€æ£€æµ‹ã€åˆ†å‰²) æ¨¡åž‹ä»‹ç» æ¨¡åž‹å¯è§†åŒ–netronå·¥å…·åº“ pytorchæ¨¡åž‹è½¬onnxæ¨¡åž‹çš„æ–¹æ³•è¯¦è§£ å›¾åƒåˆ†ç±» Stable Diffusionæ€»å…±åŒ…å«ä¸‰ä¸ªä¸»è¦çš„ç»„ä»¶ äººå·¥æ™ºèƒ½Aiç”»ç”»â€”â€”stable diffusion åŽŸç†å’Œä½¿ç”¨æ–¹æ³•è¯¦è§£ï¼ 1ï¼‰Clip Textç”¨äºŽæ–‡æœ¬ç¼–ç ã€‚è¾“å…¥ï¼šæ–‡æœ¬è¾“å‡ºï¼š77ä¸ªtokenåµŒå…¥å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå‘é‡åŒ…å«768ä¸ªç»´åº¦ 2ï¼‰UNet + Scheduleråœ¨ä¿¡æ¯ï¼ˆæ½œï¼‰ç©ºé—´ä¸­é€æ­¥å¤„ç†/æ‰©æ•£ä¿¡æ¯ã€‚è¾“å…¥ï¼šæ–‡æœ¬åµŒå…¥å’Œä¸€ä¸ªç”±å™ªå£°ç»„æˆçš„åˆå§‹å¤šç»´æ•°ç»„ï¼ˆç»“æž„åŒ–çš„æ•°å­—åˆ—è¡¨ï¼Œä¹Ÿå«å¼ é‡tensorï¼‰ã€‚è¾“å‡ºï¼šä¸€ä¸ªç»è¿‡å¤„ç†çš„ä¿¡æ¯é˜µåˆ— 3ï¼‰è‡ªç¼–ç è§£ç å™¨ï¼ˆAutoencoder Decoderï¼‰ï¼Œä½¿ç”¨å¤„ç†è¿‡çš„ä¿¡æ¯çŸ©é˜µç»˜åˆ¶æœ€ç»ˆå›¾åƒçš„è§£ç å™¨ã€‚ Clip Text æ˜¯ä¸€ç§è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡åž‹ï¼Œç”± OpenAI å¼€å‘ã€‚å®ƒåŸºäºŽ CLIPï¼ˆContrastive Language-Image Pretrainingï¼‰æ¨¡åž‹ï¼Œæ—¨åœ¨å°†æ–‡æœ¬å’Œå›¾åƒè”ç³»èµ·æ¥ã€‚Clip Text æ¨¡åž‹å¯ä»¥ç†è§£å’Œå¤„ç†æ–‡æœ¬æ•°æ®ï¼Œä»¥ä¾¿è¿›è¡Œå„ç§ä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æžã€å‘½åå®žä½“è¯†åˆ«ç­‰ã€‚é€šè¿‡è®­ç»ƒ Clip Text æ¨¡åž‹ï¼Œå¯ä»¥ä½¿å…¶å…·å¤‡å¯¹æ–‡æœ¬çš„ç†è§£èƒ½åŠ›ï¼Œä»Žè€Œæ”¯æŒåœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸè¿›è¡Œå„ç§åº”ç”¨å’Œç ”ç©¶ã€‚ UNet æ˜¯ä¸€ç§ç”¨äºŽå›¾åƒåˆ†å‰²çš„å·ç§¯ç¥žç»ç½‘ç»œæ¨¡åž‹ã€‚å®ƒæœ€åˆç”± Olaf Ronneberger ç­‰äººåœ¨ 2015 å¹´æå‡ºï¼Œæ—¨åœ¨è§£å†³åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­çš„é—®é¢˜ã€‚UNet çš„è®¾è®¡çµæ„Ÿæ¥è‡ªäºŽç”Ÿç‰©å­¦ä¸­çš„ç¥žç»å…ƒç»“æž„ï¼Œå®ƒå…·æœ‰ä¸€ä¸ªç‰¹æ®Šçš„ U å½¢ç»“æž„ï¼Œå› æ­¤å¾—å UNetã€‚ UNet çš„ç‰¹ç‚¹æ˜¯å…·æœ‰å¯¹ç§°çš„ç¼–ç å™¨-è§£ç å™¨ç»“æž„ï¼Œå…¶ä¸­ç¼–ç å™¨éƒ¨åˆ†ç”±å¤šä¸ªå·ç§¯å’Œæ± åŒ–å±‚ç»„æˆï¼Œç”¨äºŽé€æ­¥æå–å›¾åƒçš„ç‰¹å¾ã€‚è§£ç å™¨éƒ¨åˆ†åˆ™é€šè¿‡ä¸Šé‡‡æ ·å’Œå·ç§¯æ“ä½œé€æ­¥å°†ç‰¹å¾æ˜ å°„æ¢å¤åˆ°åŽŸå§‹å›¾åƒçš„å°ºå¯¸ï¼Œç”¨äºŽç”Ÿæˆåˆ†å‰²ç»“æžœã€‚æ­¤å¤–ï¼ŒUNet è¿˜é€šè¿‡è·³è·ƒè¿žæŽ¥ï¼ˆskip connectionsï¼‰åœ¨ç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´å»ºç«‹äº†ç›´æŽ¥è¿žæŽ¥ï¼Œä»¥ä¾¿ä¿ç•™å’Œåˆ©ç”¨ä¸åŒå±‚çº§çš„ç‰¹å¾ä¿¡æ¯ã€‚ UNet åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­å–å¾—äº†å¾ˆå¥½çš„æ•ˆæžœï¼Œå¹¶ä¸”åœ¨å…¶ä»–é¢†åŸŸçš„å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ä¹Ÿå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚å®ƒçš„ç½‘ç»œç»“æž„ç®€å•ã€æ˜“äºŽå®žçŽ°å’Œè®­ç»ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿå¤„ç†ä¸åŒå°ºåº¦å’Œå½¢çŠ¶çš„ç›®æ ‡ç‰©ä½“ï¼Œå› æ­¤æˆä¸ºå›¾åƒåˆ†å‰²é¢†åŸŸçš„é‡è¦æ¨¡åž‹ä¹‹ä¸€ã€‚ ç›®æ ‡æ£€æµ‹å’Œè·Ÿè¸ª å›¾åƒåˆ†å‰² è¯­ä¹‰åˆ†å‰² å®žä¾‹åˆ†å‰² å›¾åƒå¤„ç† è¶…åˆ†è¾¨çŽ‡ é™¤é›¾ å›¾åƒç”Ÿæˆ åŠ¨ä½œè¯†åˆ« é£Žæ ¼è½¬æ¢ äººè„¸è¯†åˆ« å›¾åƒæè¿° OCR æ·±å…¥äº†è§£è§†è§‰è¯­è¨€æ¨¡åž‹ BEiT: BERT Pre-Training of Image Transformers 2022 ã€æ·±åº¦å­¦ä¹ ã€‘è¯¦è§£ BEiT ã€ŠBEITã€‹-åŸºäºŽå›¾åƒé‡å»ºè¿›è¡Œé¢„è®­ç»ƒï¼å¾®è½¯æå‡ºBEITï¼ŒTop-1å‡†ç¡®çŽ‡è¾¾86.3%ï¼ä»£ç å·²å¼€æºï¼ ä¸Žå…¶ä»–æ¨¡åž‹ä¸åŒï¼ŒVisionEncoderDecoderModel æ˜¯ä¸€ä¸ªæ ‡å‡†åŒ–çš„æ¨¡åž‹ï¼Œå¯ç”¨äºŽåˆå§‹åŒ–ä»»æ„å›¾åƒè½¬æ–‡æœ¬æ¨¡åž‹ï¼Œè¿™ç±»æ¨¡åž‹å¯ä»¥ä½¿ç”¨ä»»ä½•é¢„è®­ç»ƒçš„åŸºäºŽTransformerçš„è§†è§‰æ¨¡åž‹ä½œä¸ºç¼–ç å™¨(ä¾‹å¦‚ViT(å­ç›‘ç£è®­ç»ƒ)ã€BEiTã€DeiTã€Swin)ä»¥åŠä»»ä½•é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡åž‹ä½œä¸ºè§£ç å™¨(ä¾‹å¦‚RoBERTaã€GPT2ã€BERTã€DistilBERT)ã€‚äº‹å®žä¸Šï¼ŒTrOCRæ˜¯è¿™ä¸ªæ ‡å‡†ç±»çš„ä¸€ä¸ªå®žä¾‹ TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models 2022 å¾®è½¯äºšæ´²ç ”ç©¶é™¢çš„ç ”ç©¶å‘˜ä»¬å±•å¼€äº†æ·±å…¥ç ”ç©¶ï¼Œæå‡ºäº†é¦–ä¸ªåˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹çš„ç«¯åˆ°ç«¯åŸºäºŽTransformerçš„æ–‡æœ¬è¯†åˆ«OCRæ¨¡åž‹ï¼šTrOCRã€‚è¯¥æ¨¡åž‹ç®€å•æœ‰æ•ˆï¼Œå¯ä»¥ä½¿ç”¨å¤§è§„æ¨¡åˆæˆæ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨äººå·¥æ ‡æ³¨çš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚å®žéªŒè¯æ˜Žï¼ŒTrOCRåœ¨æ‰“å°æ•°æ®å’Œæ‰‹å†™æ•°æ®ä¸Šå‡è¶…è¿‡äº†å½“å‰æœ€å…ˆè¿›çš„æ¨¡åž‹ ä¸€èˆ¬çš„å…‰å­¦å­—ç¬¦è¯†åˆ«åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šæ–‡æœ¬æ£€æµ‹å’Œæ–‡æœ¬è¯†åˆ« æ–‡æœ¬æ£€æµ‹: ç”¨äºŽåœ¨æ–‡æœ¬å›¾åƒä¸­å®šä½æ–‡æœ¬å—ï¼Œç²’åº¦å¯ä»¥æ˜¯å•è¯çº§åˆ«æˆ–æ˜¯æ–‡æœ¬è¡Œçº§åˆ« ç›®å‰çš„è§£å†³æ–¹æ¡ˆå¤§å¤šæ˜¯å°†è¯¥ä»»åŠ¡è§†ä¸ºç‰©ä½“æ£€æµ‹é—®é¢˜ï¼Œå¹¶é‡‡ç”¨äº†å¦‚YoLOv5å’ŒDBNetçš„ä¼ ç»Ÿç‰©ä½“æ£€æµ‹æ¨¡åž‹ æ–‡æœ¬è¯†åˆ«: è‡´åŠ›äºŽç†è§£æ–‡æœ¬å›¾åƒå¹¶å°†è§†è§‰ä¿¡å·è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€ç¬¦å·ï¼Œè¯¥ä»»åŠ¡é€šå¸¸ä½¿ç”¨ç¼–ç å™¨-è§£ç å™¨æž¶æž„ çŽ°æœ‰æ–¹æ³•é‡‡ç”¨äº†åŸºäºŽCNNç½‘ç»œçš„ç¼–ç å™¨è¿›è¡Œå›¾åƒç†è§£ï¼Œä»¥åŠåŸºäºŽRNNç½‘ç»œçš„è§£ç å™¨è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ ä¸ºäº†æ›´æœ‰æ•ˆçš„è®­ç»ƒTrOCRæ¨¡åž‹ï¼Œç ”ç©¶å‘˜ä»¬ä½¿ç”¨äº†ViTæ¨¡å¼çš„é¢„è®­ç»ƒæ¨¡åž‹å’ŒBERTæ¨¡å¼çš„é¢„è®­ç»ƒæ¨¡åž‹ï¼Œæ¥åˆ†åˆ«åˆå§‹åŒ–ç¼–ç å™¨å’Œè§£ç å™¨ TrOCRForCausalLM huggingface TrOCRForCausalLM ç¿»è¯‘ï¼šThe ViTFeatureExtractor class is responsible for preprocessing the input image and RobertaTokenizer decodes the generated target tokens to the target string. The TrOCRProcessor wraps ViTFeatureExtractor and RobertaTokenizer into a single instance to both extract the input features and decode the predicted token ids. ViTFeatureExtractorç±»è´Ÿè´£é¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œè€ŒRobertaTokenizeråˆ™å°†ç”Ÿæˆçš„ç›®æ ‡æ ‡è®°è§£ç ä¸ºç›®æ ‡å­—ç¬¦ä¸²ã€‚TrOCRProcessorå°†ViTFeatureExtractorå’ŒRobertaTokenizerå°è£…ä¸ºå•ä¸ªå®žä¾‹ï¼Œæ—¢å¯ä»¥æå–è¾“å…¥ç‰¹å¾ï¼Œåˆå¯ä»¥è§£ç é¢„æµ‹çš„æ ‡è®°ID ç¿»è¯‘ï¼šThe VisionEncoderDecoderModel can be used to initialize an image-to-text-sequence model with any pretrained vision autoencoding model as the encoder (e.g. ViT, BEiT, DeiT) and any pretrained language model as the decoder (e.g. RoBERTa, GPT2, BERT). The effectiveness of initializing image-to-text-sequence models with pretrained checkpoints has been shown in (for example) TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models by Minghao Li, Tengchao Lv, Lei Cui, Yijuan Lu, Dinei Florencio, Cha Zhang, Zhoujun Li, Furu Wei. An example of how to use a VisionEncoderDecoderModel for inference can be seen in TrOCR. VisionEncoderDecoderModelå¯ä»¥ç”¨äºŽåˆå§‹åŒ–ä¸€ä¸ªå›¾åƒåˆ°æ–‡æœ¬åºåˆ—æ¨¡åž‹ï¼Œå…¶ä¸­ç¼–ç å™¨å¯ä»¥æ˜¯ä»»ä½•é¢„è®­ç»ƒçš„å›¾åƒè‡ªç¼–ç æ¨¡åž‹ï¼ˆä¾‹å¦‚ViTã€BEiTã€DeiTï¼‰ï¼Œè§£ç å™¨å¯ä»¥æ˜¯ä»»ä½•é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡åž‹ï¼ˆä¾‹å¦‚RoBERTaã€GPT2ã€BERTï¼‰ åˆå§‹åŒ–å›¾åƒåˆ°æ–‡æœ¬åºåˆ—æ¨¡åž‹æ—¶ä½¿ç”¨é¢„è®­ç»ƒçš„æ£€æŸ¥ç‚¹å·²ç»è¢«è¯æ˜Žæ˜¯æœ‰æ•ˆçš„ï¼Œä¾‹å¦‚åœ¨ã€ŠTrOCRï¼šåŸºäºŽé¢„è®­ç»ƒæ¨¡åž‹çš„åŸºäºŽTransformerçš„å…‰å­¦å­—ç¬¦è¯†åˆ«ã€‹ä¸€æ–‡ä¸­ï¼Œä½œè€…Minghao Liã€Tengchao Lvã€Lei Cuiã€Yijuan Luã€Dinei Florencioã€Cha Zhangã€Zhoujun Liã€Furu Weiå±•ç¤ºäº†è¿™ä¸€ç‚¹ å…³äºŽå¦‚ä½•ä½¿ç”¨VisionEncoderDecoderModelè¿›è¡ŒæŽ¨æ–­çš„ç¤ºä¾‹å¯ä»¥åœ¨TrOCRä¸­æ‰¾åˆ° å›¾åƒç‰¹å®šçš„å½’çº³åå·® å›¾åƒç‰¹å®šçš„å½’çº³åå·®æ˜¯æŒ‡åœ¨å¤„ç†å›¾åƒæ•°æ®æ—¶ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•æˆ–äººç±»å¤§è„‘å¯¹å›¾åƒçš„å¤„ç†å’Œç†è§£ä¸­å­˜åœ¨çš„åå¥½æˆ–å€¾å‘æ€§ã€‚è¿™ç§åå·®å¯èƒ½å¯¼è‡´ç®—æ³•æˆ–äººç±»åœ¨å¤„ç†å›¾åƒæ—¶å‡ºçŽ°ç³»ç»Ÿæ€§çš„é”™è¯¯æˆ–è¯¯è§£ã€‚ å›¾åƒç‰¹å®šçš„å½’çº³åå·®å¯èƒ½æºè‡ªä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š å½¢çŠ¶åå·®ï¼šäººç±»å’Œæœºå™¨å­¦ä¹ ç®—æ³•åœ¨å¤„ç†å›¾åƒæ—¶ï¼Œå¯èƒ½æ›´å®¹æ˜“å…³æ³¨ç‰©ä½“çš„å½¢çŠ¶å’Œè½®å»“ã€‚è¿™å¯èƒ½å¯¼è‡´å¯¹äºŽå½¢çŠ¶ç‰¹å¾è¾ƒå¼ºçš„ç‰©ä½“æ›´æ•æ„Ÿï¼Œè€Œå¯¹äºŽçº¹ç†ã€é¢œè‰²ç­‰å…¶ä»–ç‰¹å¾çš„é‡è¦æ€§è¾ƒä½Žã€‚ é¢œè‰²åå·®ï¼šé¢œè‰²æ˜¯å›¾åƒä¸­çš„é‡è¦ç‰¹å¾ä¹‹ä¸€ï¼Œä½†äººç±»å’Œæœºå™¨å­¦ä¹ ç®—æ³•å¯èƒ½å¯¹ä¸åŒé¢œè‰²çš„æ„ŸçŸ¥å’Œè¾¨åˆ«èƒ½åŠ›å­˜åœ¨å·®å¼‚ã€‚æŸäº›é¢œè‰²çš„è¾¨åˆ«å¯èƒ½æ›´å®¹æ˜“ï¼Œè€Œå¯¹äºŽå…¶ä»–é¢œè‰²çš„è¾¨åˆ«å¯èƒ½ç›¸å¯¹è¾ƒå·®ã€‚ å°ºåº¦åå·®ï¼šå›¾åƒä¸­çš„ç‰©ä½“å°ºåº¦å¯èƒ½å¯¹äºŽç®—æ³•æˆ–äººç±»çš„è§†è§‰å¤„ç†äº§ç”Ÿå½±å“ã€‚ä¾‹å¦‚ï¼Œè¾ƒå¤§å°ºåº¦çš„ç‰©ä½“å¯èƒ½æ›´å®¹æ˜“è¢«æ³¨æ„åˆ°å’Œç†è§£ï¼Œè€Œè¾ƒå°å°ºåº¦çš„ç‰©ä½“å¯èƒ½å®¹æ˜“è¢«å¿½ç•¥æˆ–è¯¯è§£ã€‚ è§†è§’åå·®ï¼šè§†è§’å¯¹äºŽç†è§£å›¾åƒä¸­çš„ç‰©ä½“å’Œåœºæ™¯ä¹Ÿå…·æœ‰é‡è¦ä½œç”¨ã€‚ä¸åŒçš„è§†è§’å¯èƒ½å¯¼è‡´ç‰©ä½“çš„å¤–è§‚å‘ç”Ÿå˜åŒ–ï¼Œä»Žè€Œå½±å“ç®—æ³•æˆ–äººç±»å¯¹ç‰©ä½“çš„è®¤çŸ¥å’Œè§£é‡Šã€‚ è¿™äº›å›¾åƒç‰¹å®šçš„å½’çº³åå·®å¯èƒ½ä¼šå¯¹è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼ˆå¦‚ç‰©ä½“æ£€æµ‹ã€å›¾åƒåˆ†ç±»ç­‰ï¼‰çš„æ€§èƒ½äº§ç”Ÿå½±å“ï¼Œå¹¶å¯¼è‡´ä¸€äº›å¸¸è§çš„è¯¯åˆ†ç±»æˆ–è¯¯è§£ã€‚ä¸ºäº†å‡å°‘è¿™äº›åå·®çš„å½±å“ï¼Œç ”ç©¶äººå‘˜å’Œå¼€å‘è€…é€šå¸¸ä¼šé‡‡å–ä¸€ç³»åˆ—çš„æ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨æ›´ä¸°å¯Œçš„ç‰¹å¾è¡¨ç¤ºã€è¿›è¡Œæ•°æ®å¢žå¼ºã€å¤šè§’åº¦è®­ç»ƒç­‰ï¼Œä»¥æé«˜ç®—æ³•åœ¨å¤„ç†å›¾åƒæ•°æ®æ—¶çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚ åŸºäºŽTrOCR æä¸€äº›é¢è¯•é¢˜ å½“æ¶‰åŠåˆ°TrOCRï¼ˆTransformer-based Optical Character Recognitionï¼‰çš„é¢è¯•é—®é¢˜æ—¶ï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹å‡ ä¸ªæ–¹é¢çš„é—®é¢˜ï¼š ä»€ä¹ˆæ˜¯TrOCRï¼Ÿå®ƒä¸Žä¼ ç»Ÿçš„OCRæ–¹æ³•æœ‰ä½•ä¸åŒï¼Ÿ TrOCRä¸­ä½¿ç”¨çš„æ˜¯å“ªç§Transformeræ¨¡åž‹ï¼Ÿè¯·æè¿°å…¶ç»“æž„å’Œä¸»è¦ç»„æˆéƒ¨åˆ†ã€‚ åœ¨TrOCRä¸­ï¼Œå›¾åƒæ˜¯å¦‚ä½•è¢«å¤„ç†å’Œè¾“å…¥åˆ°Transformeræ¨¡åž‹ä¸­çš„ï¼Ÿ TrOCRå¦‚ä½•å®žçŽ°å¯¹æ–‡æœ¬çš„è‡ªå›žå½’ç”Ÿæˆï¼Ÿå®ƒé‡‡ç”¨äº†å“ªäº›æŠ€æœ¯å’Œç­–ç•¥ï¼Ÿ TrOCRä¸­çš„é¢„è®­ç»ƒå’Œå¾®è°ƒæ˜¯å¦‚ä½•è¿›è¡Œçš„ï¼Ÿä½¿ç”¨äº†å“ªäº›æ•°æ®é›†å’Œè®­ç»ƒæ–¹æ³•ï¼Ÿ TrOCRåœ¨å“ªäº›ä»»åŠ¡å’Œæ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜ç§€çš„æ€§èƒ½ï¼Ÿå¯ä»¥è°ˆè°ˆå…¶åœ¨å°åˆ·ä½“å’Œæ‰‹å†™ä½“è¯†åˆ«ä»»åŠ¡ä¸Šçš„è¡¨çŽ°ã€‚ TrOCRçš„ä¼˜åŠ¿å’Œå±€é™æ€§æ˜¯ä»€ä¹ˆï¼Ÿç›¸å¯¹äºŽä¼ ç»Ÿçš„OCRæ–¹æ³•ï¼Œå®ƒæœ‰å“ªäº›æ½œåœ¨çš„åº”ç”¨å‰æ™¯å’ŒæŒ‘æˆ˜ï¼Ÿ åœ¨TrOCRä¸­ï¼Œæ˜¯å¦å­˜åœ¨ä¸€äº›å¸¸è§çš„é—®é¢˜æˆ–æŒ‘æˆ˜ï¼Ÿå¯ä»¥è°ˆè°ˆå¯¹åº”çš„è§£å†³æ–¹æ³•æˆ–æ”¹è¿›æ€è·¯ã€‚ TrOCRåœ¨å®žé™…åº”ç”¨ä¸­å¯èƒ½é¢ä¸´çš„è®¡ç®—èµ„æºå’Œæ•ˆçŽ‡æ–¹é¢çš„é—®é¢˜æœ‰å“ªäº›ï¼Ÿå¦‚ä½•è§£å†³æˆ–ä¼˜åŒ–è¿™äº›é—®é¢˜ï¼Ÿ é™¤äº†TrOCRï¼Œè¿˜æœ‰å“ªäº›åŸºäºŽTransformerçš„å›¾åƒå¤„ç†ä»»åŠ¡å’Œåº”ç”¨ï¼Ÿå¯ä»¥ä¸¾ä¾‹è¯´æ˜Žã€‚ è¿™äº›é—®é¢˜å°†æ¶µç›–TrOCRçš„åŸºæœ¬æ¦‚å¿µã€æ¨¡åž‹ç»“æž„ã€è®­ç»ƒå’Œåº”ç”¨ç­‰æ–¹é¢ï¼Œæœ‰åŠ©äºŽè¯„ä¼°é¢è¯•è€…å¯¹TrOCRçš„ç†è§£å’Œç†Ÿæ‚‰ç¨‹åº¦ã€‚æ ¹æ®å…·ä½“æƒ…å†µï¼Œä½ è¿˜å¯ä»¥è¿›ä¸€æ­¥å±•å¼€è®¨è®ºç›¸å…³çš„æ·±å…¥é—®é¢˜ã€‚ å›žç­”ä¸‹ä½ æçš„åä¸ªé—®é¢˜ å½“æ¶‰åŠåˆ°TrOCRï¼ˆTransformer-based Optical Character Recognitionï¼‰çš„é¢è¯•é—®é¢˜æ—¶ï¼Œä»¥ä¸‹æ˜¯å¯¹ä½ æå‡ºçš„åä¸ªé—®é¢˜çš„ç®€è¦å›žç­”ï¼š TrOCRæ˜¯ä¸€ç§åŸºäºŽTransformerçš„å…‰å­¦å­—ç¬¦è¯†åˆ«æ–¹æ³•ï¼Œä¸Žä¼ ç»Ÿçš„OCRæ–¹æ³•ç›¸æ¯”ï¼Œå®ƒåˆ©ç”¨Transformeræ¨¡åž‹å®žçŽ°äº†ç«¯åˆ°ç«¯çš„æ–‡æœ¬ç”Ÿæˆå’Œç†è§£ï¼Œå…·æœ‰æ›´å¥½çš„å»ºæ¨¡èƒ½åŠ›å’Œä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚ TrOCRä½¿ç”¨çš„æ˜¯Transformeræ¨¡åž‹ï¼Œå®ƒç”±ç¼–ç å™¨å’Œè§£ç å™¨ç»„æˆã€‚ç¼–ç å™¨é‡‡ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥å¤„ç†è¾“å…¥å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºï¼Œè§£ç å™¨é‡‡ç”¨è‡ªå›žå½’ç”Ÿæˆçš„æ–¹å¼é€æ­¥ç”Ÿæˆè¾“å‡ºæ–‡æœ¬ã€‚ åœ¨TrOCRä¸­ï¼Œå›¾åƒç»è¿‡é¢„å¤„ç†æ­¥éª¤ï¼Œå¦‚åˆ†å‰²ä¸ºå›ºå®šå¤§å°çš„å›¾åƒå—ï¼Œå¹¶è¿›è¡Œçº¿æ€§åµŒå…¥ï¼Œç„¶åŽæ·»åŠ ä½ç½®ç¼–ç ã€‚å¤„ç†åŽçš„å›¾åƒè¡¨ç¤ºè¢«è¾“å…¥åˆ°Transformerç¼–ç å™¨ä¸­è¿›è¡Œå¤„ç†ã€‚ TrOCRé‡‡ç”¨è‡ªå›žå½’ç”Ÿæˆçš„æ–¹å¼å¯¹æ–‡æœ¬è¿›è¡Œç”Ÿæˆï¼Œå³é€ä¸ªç”Ÿæˆæ¯ä¸ªå­—ç¬¦æˆ–è¯æ±‡ã€‚å®ƒä½¿ç”¨äº†ç±»ä¼¼äºŽè¯­è¨€å»ºæ¨¡çš„æŠ€æœ¯ï¼Œé€šè¿‡ä¸Šæ–‡çš„ä¿¡æ¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦æˆ–è¯æ±‡ã€‚ TrOCRçš„é¢„è®­ç»ƒé˜¶æ®µé€šå¸¸ä½¿ç”¨å¤§è§„æ¨¡çš„åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»¥å­¦ä¹ å›¾åƒå’Œæ–‡æœ¬ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚ç„¶åŽï¼Œå¯ä»¥é€šè¿‡å¾®è°ƒé˜¶æ®µä½¿ç”¨çœŸå®žæ ‡æ³¨çš„æ•°æ®æ¥ä¼˜åŒ–æ¨¡åž‹çš„æ€§èƒ½ã€‚ TrOCRåœ¨å°åˆ·ä½“å’Œæ‰‹å†™ä½“è¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜ç§€çš„æ€§èƒ½ã€‚å®ƒåœ¨å¤§è§„æ¨¡çš„OCRæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶åœ¨å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¶…è¿‡äº†ä¼ ç»Ÿçš„OCRæ–¹æ³•ã€‚ TrOCRçš„ä¼˜åŠ¿åŒ…æ‹¬èƒ½å¤Ÿå¯¹é•¿æ–‡æœ¬è¿›è¡Œå»ºæ¨¡ã€ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›å¼ºã€é€‚åº”ä¸åŒè¯­ç§å’Œå­—ä½“æ ·å¼ç­‰ã€‚ç„¶è€Œï¼ŒTrOCRå¯èƒ½å¯¹è®¡ç®—èµ„æºè¦æ±‚è¾ƒé«˜ï¼Œå¹¶ä¸”åœ¨å¤„ç†ä¸€äº›ç‰¹å®šçš„å¤æ‚åœºæ™¯ï¼ˆå¦‚ä½Žè´¨é‡å›¾åƒæˆ–ç‰¹æ®Šå­—ä½“ï¼‰æ—¶å¯èƒ½é¢ä¸´æŒ‘æˆ˜ã€‚ åœ¨TrOCRä¸­ï¼Œä¸€äº›å¸¸è§çš„é—®é¢˜åŒ…æ‹¬æ–‡æœ¬é‡å¤ç”Ÿæˆã€æ¨¡ç³Šå›¾åƒçš„å¤„ç†ã€é•¿æ–‡æœ¬çš„ç”Ÿæˆå’Œè®­ç»ƒæ•°æ®çš„æ ‡æ³¨è´¨é‡ã€‚è§£å†³è¿™äº›é—®é¢˜çš„æ–¹æ³•å¯èƒ½æ¶‰åŠä½¿ç”¨æ›´å¤æ‚çš„è§£ç ç­–ç•¥ã€æ”¹è¿›çš„å›¾åƒé¢„å¤„ç†å’Œå¢žå¼ºæŠ€æœ¯ä»¥åŠæ›´å¥½çš„æ•°æ®æ ‡æ³¨å’Œæ¸…æ´—æ–¹æ³•ã€‚ TrOCRåœ¨å®žé™…åº”ç”¨ä¸­å¯èƒ½é¢ä¸´çš„è®¡ç®—èµ„æºå’Œæ•ˆçŽ‡æ–¹é¢çš„é—®é¢˜åŒ…æ‹¬æ¨¡åž‹å¤§å°å’ŒæŽ¨ç†é€Ÿåº¦ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œå¯ä»¥é‡‡ç”¨æ¨¡åž‹åŽ‹ç¼©å’ŒåŠ é€ŸæŠ€æœ¯ï¼Œå¦‚å‰ªæžã€é‡åŒ–å’Œæ¨¡åž‹å¹¶è¡ŒåŒ–ç­‰ã€‚ é™¤äº†TrOCRï¼Œè¿˜æœ‰è®¸å¤šåŸºäºŽTransformerçš„å›¾åƒå¤„ç†ä»»åŠ¡å’Œåº”ç”¨ã€‚ä¾‹å¦‚ï¼Œå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ OCRè¯†åˆ«æ‰‹å†™æ–‡å­—(ä¸­æ–‡+è‹±æ–‡) å‚è€ƒæ–‡çŒ®ï¼š TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models 2022 è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºTrOCRçš„åŸºäºŽTransformerçš„å…‰å­¦å­—ç¬¦è¯†åˆ«(OCR)æ¨¡åž‹ï¼Œé€šè¿‡åˆ©ç”¨é¢„è®­ç»ƒæ¨¡åž‹è¿›è¡Œç‰¹å¾æå–å’Œæ–‡æœ¬ç”Ÿæˆï¼Œå®žçŽ°ç«¯åˆ°ç«¯çš„æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ TrOCRæ¨¡åž‹çš„å…³é”®åˆ›æ–°ç‚¹åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š åŸºäºŽTransformerçš„æž¶æž„ï¼šTrOCRé‡‡ç”¨äº†Transformeræž¶æž„ä½œä¸ºå…¶åŸºç¡€æ¨¡åž‹ï¼Œå…¶ä¸­åŒ…æ‹¬ç¼–ç å™¨å’Œè§£ç å™¨ã€‚ç¼–ç å™¨ç”¨äºŽæå–å›¾åƒç‰¹å¾ï¼Œè§£ç å™¨ç”¨äºŽç”Ÿæˆè¯†åˆ«çš„æ–‡æœ¬åºåˆ— é¢„è®­ç»ƒæ¨¡åž‹çš„åº”ç”¨ï¼šTrOCRåˆ©ç”¨é¢„è®­ç»ƒçš„å›¾åƒå’Œæ–‡æœ¬æ¨¡åž‹ä½œä¸ºç¼–ç å™¨å’Œè§£ç å™¨ï¼Œå¦‚ViTã€RoBERTaç­‰ã€‚è¿™äº›é¢„è®­ç»ƒæ¨¡åž‹èƒ½å¤Ÿæä¾›ä¸°å¯Œçš„è§†è§‰å’Œè¯­è¨€è¡¨ç¤ºèƒ½åŠ›ï¼Œæœ‰åŠ©äºŽæé«˜OCRçš„å‡†ç¡®æ€§ å¤§è§„æ¨¡åˆæˆæ•°æ®é›†ï¼šä¸ºäº†è¿›è¡Œé¢„è®­ç»ƒå’Œå¾®è°ƒï¼ŒTrOCRä½¿ç”¨äº†å¤§è§„æ¨¡çš„åˆæˆæ•°æ®é›†ï¼ŒåŒ…æ‹¬æ•°ç™¾ä¸‡å¼ æ‰“å°æ–‡æœ¬å›¾åƒå’Œæ‰‹å†™æ–‡æœ¬å›¾åƒã€‚è¿™æ ·å¯ä»¥å¢žåŠ æ¨¡åž‹åœ¨ä¸åŒé¢†åŸŸå’Œæ ·å¼çš„æ–‡æœ¬ä¸Šçš„æ³›åŒ–èƒ½åŠ› å®žéªŒè¯æ˜Žï¼ŒTrOCRæ¨¡åž‹åœ¨æ‰“å°æ–‡æœ¬ã€æ‰‹å†™æ–‡æœ¬å’Œåœºæ™¯æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½è¡¨çŽ°ï¼Œè¶…è¿‡äº†å½“å‰çš„state-of-the-artæ¨¡åž‹ã€‚è¯¥è®ºæ–‡çš„è´¡çŒ®åœ¨äºŽå°†Transformeråº”ç”¨äºŽOCRä»»åŠ¡ï¼Œå¹¶ä¸”é€šè¿‡é¢„è®­ç»ƒæ¨¡åž‹çš„åˆ©ç”¨æé«˜äº†OCRçš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ› æž¶æž„ï¼š model(VisionEncoderDecoderModel) = encoder(DeiT)+decoder(TrOCRForCausalLM) DeiTModel( (embeddings): DeiTEmbeddings( (patch_embeddings): DeiTPatchEmbeddings( (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16)) ) (dropout): Dropout(p=0.0, inplace=False) ) (encoder): DeiTEncoder( (layer): ModuleList( (0): DeiTLayer( (attention): DeiTAttention( (attention): DeiTSelfAttention( (query): Linear(in_features=384, out_features=384, bias=True) (key): Linear(in_features=384, out_features=384, bias=True) (value): Linear(in_features=384, out_features=384, bias=True) (dropout): Dropout(p=0.0, inplace=False) ) (output): DeiTSelfOutput( (dense): Linear(in_features=384, out_features=384, bias=True) (dropout): Dropout(p=0.0, inplace=False) ) ) (intermediate): DeiTIntermediate( (dense): Linear(in_features=384, out_features=1536, bias=True) (intermediate_act_fn): GELUActivation() ) (output): DeiTOutput( (dense): Linear(in_features=1536, out_features=384, bias=True) (dropout): Dropout(p=0.0, inplace=False) ) (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True) (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True) ) * 12 ) ) (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True) (pooler): DeiTPooler( (dense): Linear(in_features=384, out_features=384, bias=True) (activation): Tanh() ) ) # é€šè¿‡çº¿æ€§å±‚å°†ç¼–ç å™¨å’Œè§£ç å™¨è¿žæŽ¥åˆ°äº†ä¸€èµ· enc_to_dec_proj = nn.Linear(self.encoder.config.hidden_size, self.decoder.config.hidden_size) TrOCRForCausalLM( (model): TrOCRDecoderWrapper( (decoder): TrOCRDecoder( (embed_tokens): Embedding(11318, 256, padding_idx=1) (embed_positions): TrOCRLearnedPositionalEmbedding(514, 256) (layernorm_embedding): LayerNorm((256,), eps=1e-05, elementwise_affine=True) (layers): ModuleList( (0): TrOCRDecoderLayer( (self_attn): TrOCRAttention( (k_proj): Linear(in_features=256, out_features=256, bias=True) (v_proj): Linear(in_features=256, out_features=256, bias=True) (q_proj): Linear(in_features=256, out_features=256, bias=True) (out_proj): Linear(in_features=256, out_features=256, bias=True) ) (activation_fn): ReLU() (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True) (encoder_attn): TrOCRAttention( (k_proj): Linear(in_features=384, out_features=256, bias=True) (v_proj): Linear(in_features=384, out_features=256, bias=True) (q_proj): Linear(in_features=256, out_features=256, bias=True) (out_proj): Linear(in_features=256, out_features=256, bias=True) ) (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True) (fc1): Linear(in_features=256, out_features=1024, bias=True) (fc2): Linear(in_features=1024, out_features=256, bias=True) (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True) ) * 6 ) ) ) (output_projection): Linear(in_features=256, out_features=11318, bias=False) ) å®žçŽ°ç»†èŠ‚: æ•°æ®é›†: Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹.html":{"url":"chapters/huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹.html","title":"huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹.md","summary":"huggingfaceåŸºæœ¬ä½¿ç”¨æ•™ç¨‹","keywords":"","body":"huggingfaceæ¦‚è¿°å®‰è£…datasetså®‰è£…å¿«é€Ÿå¼€å§‹è§†è§‰nlpåŠ è½½æ•°æ®é›†è¿›é˜¶åŠ è½½æ•°æ®é›†æŽ¢ç´¢æ•°æ®é›†Preprocesså¤„ç†æž„å»ºæ•°æ®é›†åˆ†äº«æ•°æ®é›†è¯„ä¼°æŒ‡æ ‡å®‰è£…å¿«é€Ÿå¼€å§‹æŒ‡æ ‡ç§ç±»æŒ‡æ ‡åŠ è½½æŒ‡æ ‡è®¡ç®—ç»“æžœå­˜å‚¨å¯è§†åŒ–é€‰æ‹©åˆé€‚æŒ‡æ ‡transformersæ¦‚è¿°å®‰è£…å¿«é€Ÿå¼€å§‹PipelineAutoClassAutoConfigTraineræ•™ç¨‹æ¨¡åž‹è®­ç»ƒåˆ†å¸ƒå¼åŠ é€Ÿç¤ºä¾‹ä»£ç PEFTæ¨¡å—å…¶ä»–æ¨¡å—AutoTrainGradioDiffusersAccelerate huggingface æ¦‚è¿° Hugging Face å®˜ç½‘ä»»åŠ¡åˆ†ç±»å’Œç¤ºä¾‹ Hugging Faceæ˜¯ä¸€ä¸ªçŸ¥åçš„å¼€æºç¤¾åŒºå’Œå…¬å¸ï¼Œä¸“æ³¨äºŽè‡ªç„¶è¯­è¨€å¤„ç†(NLP)å’Œæœºå™¨å­¦ä¹ (ML)é¢†åŸŸã€‚ä»–ä»¬å¼€å‘äº†è®¸å¤šæµè¡Œçš„å¼€æºå·¥å…·å’Œåº“ï¼Œä½¿å¾—æž„å»ºå’Œåº”ç”¨NLPæ¨¡åž‹æ›´åŠ ä¾¿æ· Hugging faceèµ·åˆæ˜¯ä¸€å®¶æ€»éƒ¨ä½äºŽçº½çº¦çš„èŠå¤©æœºå™¨äººåˆåˆ›æœåŠ¡å•†ï¼Œä»–ä»¬æœ¬æ¥æ‰“ç®—åˆ›ä¸šåšèŠå¤©æœºå™¨äººï¼Œç„¶åŽåœ¨githubä¸Šå¼€æºäº†ä¸€ä¸ªTransformersåº“ï¼Œè™½ç„¶èŠå¤©æœºå™¨äººä¸šåŠ¡æ²¡æžèµ·æ¥ï¼Œä½†æ˜¯ä»–ä»¬çš„è¿™ä¸ªåº“åœ¨æœºå™¨å­¦ä¹ ç¤¾åŒºè¿…é€Ÿå¤§ç«èµ·æ¥ã€‚ç›®å‰å·²ç»å…±äº«äº†è¶…100,000ä¸ªé¢„è®­ç»ƒæ¨¡åž‹ï¼Œ10,000ä¸ªæ•°æ®é›†ï¼Œå˜æˆäº†æœºå™¨å­¦ä¹ ç•Œçš„github åœ¨è¿™é‡Œä¸»è¦æœ‰ä»¥ä¸‹å¤§å®¶éœ€è¦çš„èµ„æº Datasetsï¼šæ•°æ®é›†ï¼Œä»¥åŠæ•°æ®é›†çš„ä¸‹è½½åœ°å€ Modelsï¼šåŒ…æ‹¬å„ç§å¤„ç†CVå’ŒNLPç­‰ä»»åŠ¡çš„æ¨¡åž‹ï¼Œä¸Šé¢æ¨¡åž‹éƒ½æ˜¯å¯ä»¥å…è´¹èŽ·å¾— ä¸»è¦åŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³å¤„ç†ã€å¤šæ¨¡æ€ã€è¡¨æ ¼å¤„ç†ã€å¼ºåŒ–å­¦ä¹  courseï¼šå…è´¹çš„nlpè¯¾ç¨‹ docsï¼šæ–‡æ¡£ å±•å¼€ç»†èŠ‚ Computer Vision(è®¡ç®—æœºè§†è§‰ä»»åŠ¡)ï¼šåŒ…æ‹¬lmage Classification(å›¾åƒåˆ†ç±»)ï¼Œlmage Segmentation(å›¾åƒåˆ†å‰²)ã€zero-Shot lmage Classification(é›¶æ ·æœ¬å›¾åƒåˆ†ç±»)ã€lmage-to-Image(å›¾åƒåˆ°å›¾åƒçš„ä»»åŠ¡)ã€Unconditional lmage Generation(æ— æ¡ä»¶å›¾åƒç”Ÿæˆ)ã€Object Detection(ç›®æ ‡æ£€æµ‹)ã€Video Classification(è§†é¢‘åˆ†ç±»)ã€Depth Estimation(æ·±åº¦ä¼°è®¡ï¼Œä¼°è®¡æ‹æ‘„è€…è·ç¦»å›¾åƒå„å¤„çš„è·ç¦») Natural Language Processing(è‡ªç„¶è¯­è¨€å¤„ç†)ï¼šåŒ…æ‹¬Translation(æœºå™¨ç¿»è¯‘)ã€Fill-Mask(å¡«å……æŽ©ç ï¼Œé¢„æµ‹å¥å­ä¸­è¢«é®æŽ©çš„è¯)ã€Token Classification(è¯åˆ†ç±»)ã€Sentence Similarity(å¥å­ç›¸ä¼¼åº¦)ã€Question Answering(é—®ç­”ç³»ç»Ÿ)ï¼ŒSummarization(æ€»ç»“ï¼Œç¼©å¥)ã€Zero-Shot Classification (é›¶æ ·æœ¬åˆ†ç±»)ã€Text Classification(æ–‡æœ¬åˆ†ç±»)ã€Text2Text(æ–‡æœ¬åˆ°æ–‡æœ¬çš„ç”Ÿæˆ)ã€Text Generation(æ–‡æœ¬ç”Ÿæˆ)ã€Conversational(èŠå¤©)ã€Table Question Answer(è¡¨é—®ç­”ï¼Œ1.é¢„æµ‹è¡¨æ ¼ä¸­è¢«é®æŽ©å•è¯2.æ•°å­—æŽ¨ç†ï¼Œåˆ¤æ–­å¥å­æ˜¯å¦è¢«è¡¨æ ¼æ•°æ®æ”¯æŒ) Audio(è¯­éŸ³)ï¼šAutomatic Speech Recognition(è¯­éŸ³è¯†åˆ«)ã€Audio Classification(è¯­éŸ³åˆ†ç±»)ã€Text-to-Speech(æ–‡æœ¬åˆ°è¯­éŸ³çš„ç”Ÿæˆ)ã€Audio-to-Audio(è¯­éŸ³åˆ°è¯­éŸ³çš„ç”Ÿæˆ)ã€Voice Activity Detection(å£°éŸ³æ£€æµ‹ã€æ£€æµ‹è¯†åˆ«å‡ºéœ€è¦çš„å£°éŸ³éƒ¨åˆ†) Multimodal(å¤šæ¨¡æ€)ï¼šFeature Extraction(ç‰¹å¾æå–)ã€Text-to-Image(æ–‡æœ¬åˆ°å›¾åƒ)ã€Visual Question Answering(è§†è§‰é—®ç­”)ã€Image2Text(å›¾åƒåˆ°æ–‡æœ¬)ã€Document Question Answering(æ–‡æ¡£é—®ç­”) Tabular(è¡¨æ ¼)ï¼šTabular Classification(è¡¨åˆ†ç±»)ã€Tabular Regression(è¡¨å›žå½’) Reinforcement Learning(å¼ºåŒ–å­¦ä¹ )ï¼šReinforcement Learning(å¼ºåŒ–å­¦ä¹ )ã€Robotics(æœºå™¨äºº) å®‰è£… å®‰è£…transformersåº“ pip install transformers datasets HuggingFace datasetsåº“æ€»ç»“ å®‰è£… ä¸‹é¢ä¸‰ä¸ªå‘½ä»¤éƒ½ç”¨äºŽå®‰è£…Hugging Faceçš„datasetsåº“çš„ä¸åŒé…ç½® pip install datasetsï¼šè¿™ä¸ªå‘½ä»¤å®‰è£…çš„æ˜¯datasetsåº“çš„åŸºæœ¬é…ç½®ï¼Œå®ƒæä¾›äº†å¯¹å¸¸è§çš„è‡ªç„¶è¯­è¨€å¤„ç†(NLP)ä»»åŠ¡å’Œæ•°æ®é›†çš„æ”¯æŒï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»ã€å‘½åå®žä½“è¯†åˆ«ã€é—®ç­”ç³»ç»Ÿç­‰ã€‚å¦‚æžœæ‚¨åªéœ€è¦å¤„ç†æ–‡æœ¬æ•°æ®æˆ–è¿›è¡Œå¸¸è§çš„NLPä»»åŠ¡ï¼Œè¿™ä¸ªåŸºæœ¬é…ç½®å°±è¶³å¤Ÿäº† pip install datasets[audio]ï¼šè¿™ä¸ªå‘½ä»¤å®‰è£…çš„æ˜¯datasetsåº“çš„\"audio\"é…ç½®ã€‚å®ƒåŒ…å«äº†å¯¹å£°éŸ³å’ŒéŸ³é¢‘æ•°æ®é›†çš„æ”¯æŒï¼Œä¾‹å¦‚è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)å’ŒéŸ³é¢‘åˆ†ç±»ä»»åŠ¡ã€‚å¦‚æžœæ‚¨éœ€è¦å¤„ç†å£°éŸ³å’ŒéŸ³é¢‘æ•°æ®ï¼Œæ¯”å¦‚è¿›è¡Œè¯­éŸ³è¯†åˆ«æˆ–éŸ³é¢‘åˆ†ç±»ï¼Œå®‰è£…è¿™ä¸ªé…ç½®ä¼šæä¾›ç›¸åº”çš„åŠŸèƒ½å’Œæ•°æ®é›†æ”¯æŒ pip install datasets[vision]ï¼šè¿™ä¸ªå‘½ä»¤å®‰è£…çš„æ˜¯datasetsåº“çš„\"vision\"é…ç½®ã€‚å®ƒåŒ…å«äº†å¯¹å›¾åƒå’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„æ”¯æŒï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²ç­‰ã€‚å¦‚æžœæ‚¨éœ€è¦å¤„ç†å›¾åƒæ•°æ®æˆ–è¿›è¡Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œå®‰è£…è¿™ä¸ªé…ç½®ä¼šæä¾›ç›¸åº”çš„åŠŸèƒ½å’Œæ•°æ®é›†æ”¯æŒ é€šè¿‡å®‰è£…ä¸åŒçš„é…ç½®ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä»…å®‰è£…æ‚¨éœ€è¦çš„åŠŸèƒ½å’Œæ”¯æŒçš„ä»»åŠ¡ç±»åž‹ï¼Œä»¥å‡å°‘åº“çš„å®‰è£…å’Œå­˜å‚¨ç©ºé—´ã€‚æ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚ï¼Œé€‰æ‹©é€‚åˆçš„é…ç½®è¿›è¡Œå®‰è£…å³å¯ # å®‰è£…åŸºç¡€ç‰ˆ pip install datasets # å®‰è£…forå£°éŸ³ pip install datasets[audio] # å®‰è£…forå›¾åƒ pip install datasets[vision] å¿«é€Ÿå¼€å§‹ è§†è§‰ from datasets import load_dataset, Image from torch.utils.data import DataLoader from torchvision.transforms import Compose, ColorJitter, ToTensor # åŠ è½½æ•°æ®é›† dataset = load_dataset(\"beans\", split=\"train\") jitter = Compose( [ColorJitter(brightness=0.5, hue=0.5), ToTensor()] ) def transforms(examples): examples[\"pixel_values\"] = [jitter(image.convert(\"RGB\")) for image in examples[\"image\"]] return examples dataset = dataset.with_transform(transforms) def collate_fn(examples): images = [] labels = [] for example in examples: images.append((example[\"pixel_values\"])) labels.append(example[\"labels\"]) pixel_values = torch.stack(images) labels = torch.tensor(labels) return {\"pixel_values\": pixel_values, \"labels\": labels} # å®šä¹‰DataLoader dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=4) nlp ä½¿ç”¨ Hugging Face æä¾›çš„datasetsåº“åŠ è½½äº†GLUE(General Language Understanding Evaluation)æ•°æ®é›†ä¸­çš„MRPC(Microsoft Research Paraphrase Corpus)éƒ¨åˆ†çš„è®­ç»ƒé›†ã€‚è¿™ä¸ªæ•°æ®é›†ç”¨äºŽå¥å­å¯¹çš„ç›¸ä¼¼æ€§åˆ¤æ–­ä»»åŠ¡ from datasets import load_dataset from transformers import AutoModelForSequenceClassification, AutoTokenizer import torch dataset = load_dataset(\"glue\", \"mrpc\", split=\"test\") # load a pretrained BERT model and its corresponding tokenizer from the &#x1F917; Transformers library. model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\") tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") def encode(examples): return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, padding=\"max_length\") dataset = dataset.map(encode, batched=True) dataset[0] {'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0, 'input_ids': array([ 101, 7277, 2180, 5303, 4806, 1117, 1711, 117, 2292, 1119, 1270, 107, 1103, 7737, 107, 117, 1104, 9938, 4267, 12223, 21811, 1117, 2554, 119, 102, 11336, 6732, 3384, 1106, 1140, 1112, 1178, 107, 1103, 7737, 107, 117, 7277, 2180, 5303, 4806, 1117, 1711, 1104, 9938, 4267, 12223, 21811, 1117, 2554, 119, 102]), 'token_type_ids': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'attention_mask': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} # Rename the label column to labels, which is the expected input name in BertForSequenceClassification dataset = dataset.map(lambda examples: {\"labels\": examples[\"label\"]}, batched=True) dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]) dataloader = torch.utils.data.DataLoader(dataset, batch_size=32) åŠ è½½æ•°æ®é›† æŸ¥çœ‹æ•°æ®é›†æè¿° from datasets import load_dataset_builder ds_builder = load_dataset_builder(\"rotten_tomatoes\") ds_builder.info.description Movie Review Dataset. This is a dataset of containing 5,331 positive and 5,331 negative processed sentences from Rotten Tomatoes movie reviews. This data was first used in Bo Pang and Lillian Lee, ``Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.'', Proceedings of the ACL, 2005. ds_builder.info.features {'label': ClassLabel(num_classes=2, names=['neg', 'pos'], id=None), 'text': Value(dtype='string', id=None)} åŠ è½½æ•°æ®é›† from datasets import load_dataset dataset = load_dataset(\"rotten_tomatoes\", split=\"train\") å½“ä¸€ä¸ªæ•°æ®é›†ç”±å¤šä¸ªæ–‡ä»¶(æˆ‘ä»¬ç§°ä¹‹ä¸ºåˆ†ç‰‡)ç»„æˆæ—¶ï¼Œå¯ä»¥æ˜¾è‘—åŠ å¿«æ•°æ®é›†çš„ä¸‹è½½å’Œå‡†å¤‡æ­¥éª¤ æ‚¨å¯ä»¥ä½¿ç”¨num_procå‚æ•°é€‰æ‹©å¹¶è¡Œå‡†å¤‡æ•°æ®é›†æ—¶è¦ä½¿ç”¨çš„è¿›ç¨‹æ•°ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸ªè¿›ç¨‹è¢«åˆ†é…äº†ä¸€éƒ¨åˆ†åˆ†ç‰‡æ¥è¿›è¡Œå‡†å¤‡ from datasets import load_dataset oscar_afrikaans = load_dataset(\"oscar-corpus/OSCAR-2201\", \"af\", num_proc=8) imagenet = load_dataset(\"imagenet-1k\", num_proc=8) ml_librispeech_spanish = load_dataset(\"facebook/multilingual_librispeech\", \"spanish\", num_proc=8) æŸ¥çœ‹æ•°æ®é›†çš„åˆ†ç‰‡åç§°ï¼Œå¹¶åŠ è½½æŒ‡å®šçš„åˆ†ç‰‡åç§° from datasets import get_dataset_split_names from datasets import load_dataset get_dataset_split_names(\"rotten_tomatoes\") ['train', 'validation', 'test'] # åŠ è½½æŒ‡å®šåˆ†ç‰‡ dataset = load_dataset(\"rotten_tomatoes\", split=\"train\") Dataset({ features: ['text', 'label'], num_rows: 8530 }) # è¿˜å¯ä»¥è¿™ä¹ˆå†™ï¼š train_test_ds = datasets.load_dataset(\"bookcorpus\", split=\"train+test\") train_10_20_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[10:20]\") train_10pct_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[:10%]\") train_10_80pct_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[:10%]+train[-80%:]\") val_ds = datasets.load_dataset(\"bookcorpus\", split=[f\"train[{k}%:{k+10}%]\" for k in range(0, 100, 10)]) train_ds = datasets.load_dataset(\"bookcorpus\", split=[f\"train[:{k}%]+train[{k+10}%:]\" for k in range(0, 100, 10)]) train_50_52_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[50%:52%]\") train_52_54_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[52%:54%]\") # 18 records, from 450 (included) to 468 (excluded). train_50_52pct1_ds = datasets.load_dataset(\"bookcorpus\", split=datasets.ReadInstruction(\"train\", from_=50, to=52, unit=\"%\", rounding=\"pct1_dropremainder\")) # 18 records, from 468 (included) to 486 (excluded). train_52_54pct1_ds = datasets.load_dataset(\"bookcorpus\", split=datasets.ReadInstruction(\"train\",from_=52, to=54, unit=\"%\", rounding=\"pct1_dropremainder\")) # Or equivalently: train_50_52pct1_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[50%:52%](pct1_dropremainder)\") train_52_54pct1_ds = datasets.load_dataset(\"bookcorpus\", split=\"train[52%:54%](pct1_dropremainder)\") # åŠ è½½å…¨éƒ¨æ•°æ® dataset = load_dataset(\"rotten_tomatoes\") DatasetDict({ train: Dataset({ features: ['text', 'label'], num_rows: 8530 }) validation: Dataset({ features: ['text', 'label'], num_rows: 1066 }) test: Dataset({ features: ['text', 'label'], num_rows: 1066 }) }) æŸ¥çœ‹æ•°æ®é›†å­é›†ï¼Œä¸€ä¸ªæ•°æ®ä¸‹å¯èƒ½è¿˜æœ‰å¾ˆå¤šå­æ•°æ®é›† from datasets import get_dataset_config_names configs = get_dataset_config_names(\"PolyAI/minds14\") print(configs) ['cs-CZ', 'de-DE', 'en-AU', 'en-GB', 'en-US', 'es-ES', 'fr-FR', 'it-IT', 'ko-KR', 'nl-NL', 'pl-PL', 'pt-PT', 'ru-RU', 'zh-CN', 'all'] åŠ è½½æŒ‡å®šå­æ•°æ®é›† from datasets import load_dataset mindsFR = load_dataset(\"PolyAI/minds14\", \"fr-FR\", split=\"train\") # æŒ‡å®šå­æ•°æ®é›†æ˜¯fr-FR æŒ‡å®šæ•°æ®é›†çš„æ–‡ä»¶, é¿å…loadè¿‡å¤šçš„æ•°æ® data_files = {\"validation\": \"en/c4-validation.*.json.gz\"} c4_validation = load_dataset(\"allenai/c4\", data_files=data_files, split=\"validation\") loadæœ¬åœ°çš„jsonã€csvæ–‡ä»¶ç­‰ï¼Œå¯ä»¥loadè¿œç¨‹æ–‡ä»¶ã€sqlç­‰ #{\"version\": \"0.1.0\", # \"data\": [{\"a\": 1, \"b\": 2.0, \"c\": \"foo\", \"d\": false}, # {\"a\": 4, \"b\": -5.5, \"c\": null, \"d\": true}] #} from datasets import load_dataset dataset = load_dataset(\"json\", data_files=\"my_file.json\", field=\"data\") é€šè¿‡pythonå¯¹è±¡æ¥åˆ›å»ºdataset from datasets import Dataset import pandas as pd # å­—å…¸æ–¹å¼ my_dict = {\"a\": [1, 2, 3]} dataset = Dataset.from_dict(my_dict) # listæ–¹å¼ my_list = [{\"a\": 1}, {\"a\": 2}, {\"a\": 3}] dataset = Dataset.from_list(my_list) # pandasæ–¹å¼ df = pd.DataFrame({\"a\": [1, 2, 3]}) dataset = Dataset.from_pandas(df) loadå¤šä¸ªæ–‡æœ¬æ–‡ä»¶: æ–‡æœ¬å¿…é¡»ä¸€è¡Œå°±æ˜¯ä¸€æ¡æ ·æœ¬ from datasets import load_dataset dataset = load_dataset(\"text\", data_files={\"train\": [\"my_text_1.txt\", \"my_text_2.txt\"], \"test\": \"my_test_file.txt\"}) # Load from a directory dataset = load_dataset(\"text\", data_dir=\"path/to/text/dataset\") ç¦»çº¿load: å°†çŽ¯å¢ƒå˜é‡HF_DATASETS_OFFLINEè®¾ç½®ä¸º1ä»¥å¯ç”¨å®Œå…¨ç¦»çº¿æ¨¡å¼ è¿›é˜¶åŠ è½½æ•°æ®é›† ä»Žè„šæœ¬åŠ è½½æ•°æ®é›† æ‚¨å¯èƒ½åœ¨æœ¬åœ°è®¡ç®—æœºä¸Šæœ‰ä¸€ä¸ª&#x1F917;Datasetsçš„åŠ è½½è„šæœ¬ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šè¿‡å°†ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€ä¼ é€’ç»™load_dataset()æ¥åŠ è½½æ•°æ®é›†ï¼š åŠ è½½è„šæœ¬æ–‡ä»¶çš„æœ¬åœ°è·¯å¾„ã€‚ åŒ…å«åŠ è½½è„šæœ¬æ–‡ä»¶çš„ç›®å½•çš„æœ¬åœ°è·¯å¾„(ä»…å½“è„šæœ¬æ–‡ä»¶ä¸Žç›®å½•å…·æœ‰ç›¸åŒçš„åç§°æ—¶) dataset = load_dataset(\"path/to/local/loading_script/loading_script.py\", split=\"train\") # equivalent because the file has the same name as the directory dataset = load_dataset(\"path/to/local/loading_script\", split=\"train\") å¯ä»¥ä»ŽHubä¸Šä¸‹è½½åŠ è½½è„šæœ¬ï¼Œå¹¶å¯¹å…¶è¿›è¡Œç¼–è¾‘ä»¥æ·»åŠ è‡ªå·±çš„ä¿®æ”¹ã€‚å°†æ•°æ®é›†ä»“åº“ä¸‹è½½åˆ°æœ¬åœ°ï¼Œä»¥ä¾¿åŠ è½½è„šæœ¬ä¸­ç›¸å¯¹è·¯å¾„å¼•ç”¨çš„ä»»ä½•æ•°æ®æ–‡ä»¶éƒ½å¯ä»¥è¢«åŠ è½½ git clone https://huggingface.co/datasets/eli5 åœ¨åŠ è½½è„šæœ¬ä¸Šè¿›è¡Œç¼–è¾‘åŽï¼Œé€šè¿‡å°†å…¶æœ¬åœ°è·¯å¾„ä¼ é€’ç»™load_dataset()æ¥åŠ è½½å®ƒ from datasets import load_dataset eli5 = load_dataset(\"path/to/local/eli5\") csv+jsonæ–¹å¼ æ•°æ®é›†å¯ä»¥ä»Žå­˜å‚¨åœ¨è®¡ç®—æœºä¸Šçš„æœ¬åœ°æ–‡ä»¶å’Œè¿œç¨‹æ–‡ä»¶ä¸­åŠ è½½ã€‚è¿™äº›æ•°æ®é›†å¾ˆå¯èƒ½ä»¥csvã€jsonã€txtæˆ–parquetæ–‡ä»¶çš„å½¢å¼å­˜å‚¨ã€‚load_dataset()å‡½æ•°å¯ä»¥åŠ è½½è¿™äº›æ–‡ä»¶ç±»åž‹çš„æ•°æ®é›† from datasets import load_dataset # csvæ–¹å¼ dataset = load_dataset(\"csv\", data_files=\"my_file.csv\") # jsonæ–¹å¼ # {\"a\": 1, \"b\": 2.0, \"c\": \"foo\", \"d\": false} # {\"a\": 4, \"b\": -5.5, \"c\": null, \"d\": true} dataset = load_dataset(\"json\", data_files=\"my_file.json\") # {\"version\": \"0.1.0\", # \"data\": [{\"a\": 1, \"b\": 2.0, \"c\": \"foo\", \"d\": false}, # {\"a\": 4, \"b\": -5.5, \"c\": null, \"d\": true}] # } dataset = load_dataset(\"json\", data_files=\"my_file.json\", field=\"data\") # ä»Žhttpæ–¹å¼åŠ è½½csv base_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/\" dataset = load_dataset(\"json\", data_files={\"train\": base_url + \"train-v1.1.json\", \"validation\": base_url + \"dev-v1.1.json\"}, field=\"data\") # Parquetæ–¹å¼ dataset = load_dataset(\"parquet\", data_files={'train': 'train.parquet', 'test': 'test.parquet'}) base_url = \"https://storage.googleapis.com/huggingface-nlp/cache/datasets/wikipedia/20200501.en/1.0.0/\" data_files = {\"train\": base_url + \"wikipedia-train.parquet\"} wiki = load_dataset(\"parquet\", data_files=data_files, split=\"train\") sqlæ–¹å¼ ä½¿ç”¨from_sql()æ–¹æ³•å¯ä»¥é€šè¿‡æŒ‡å®šè¿žæŽ¥åˆ°æ•°æ®åº“çš„URIæ¥è¯»å–æ•°æ®åº“å†…å®¹ã€‚æ‚¨å¯ä»¥è¯»å–è¡¨åæˆ–æ‰§è¡ŒæŸ¥è¯¢æ“ä½œ from datasets import Dataset dataset = Dataset.from_sql(\"data_table_name\", con=\"sqlite:///sqlite_file.db\") dataset = Dataset.from_sql(\"SELECT text FROM table WHERE length(text) > 100 LIMIT 10\", con=\"sqlite:///sqlite_file.db\") For more details, check out the how to load tabular datasets from SQL databases guide. æŽ¢ç´¢æ•°æ®é›† ä¸‹æ ‡ # ç¬¬ä¸€ä¸ªæ ·æœ¬ dataset[0] #{'label': 1, # 'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .'} # æœ€åŽä¸€ä¸ªæ ·æœ¬ dataset[-1] # åªå–textåˆ— dataset[\"text\"] # è¿”å›ža list of æ ·æœ¬åˆ— # ç¬¬ä¸€ä¸ªæ ·æœ¬textåˆ— dataset[0][\"text\"] # æ€§èƒ½ï¼šdataset[0]['text']æ¯”dataset['text'][0]å¿«2å€ã€‚ æ•°æ®åˆ‡ç‰‡ # Get the first three rows dataset[:3] # Get rows between three and six dataset[3:6] è¿­ä»£æ–¹å¼ï¼Œstreaming=True from datasets import load_dataset iterable_dataset = load_dataset(\"food101\", split=\"train\", streaming=True) for example in iterable_dataset: print(example) break {'image': , 'label': 6} # Get first three examples list(iterable_dataset.take(3)) [{'image': , 'label': 6}, {'image': , 'label': 6}, {'image': , 'label': 6}] æŽ’åº+shuffle+é€‰æ‹©+filter+åˆ‡åˆ†æ•°æ®é›†+åˆ†ç‰‡ # sort: æŒ‰æŸä¸€åˆ—æŽ’åº dataset.sort(\"label\") # æ‰“ä¹± shuffled_dataset = sorted_dataset.shuffle(seed=42) # é€‰æ‹© small_dataset = dataset.select([0, 10, 20, 30, 40, 50]) # åŒ¹é…æŸ¥æ‰¾ start_with_ar = dataset.filter(lambda example: example[\"sentence1\"].startswith(\"Ar\")) len(start_with_ar) start_with_ar[\"sentence1\"] # åŒ¹é…æŸ¥æ‰¾ï¼šæ ¹æ®ä¸‹æ ‡ even_dataset = dataset.filter(lambda example, idx: idx % 2 == 0, with_indices=True) # åˆ‡åˆ† dataset.train_test_split(test_size=0.1) # åˆ†ç‰‡ # æ•°æ®é›†æ”¯æŒåˆ†ç‰‡ï¼Œå°†éžå¸¸å¤§çš„æ•°æ®é›†åˆ’åˆ†ä¸ºé¢„å®šä¹‰æ•°é‡çš„å—ã€‚ åœ¨ shard() ä¸­æŒ‡å®š num_shards å‚æ•°ä»¥ç¡®å®šè¦å°†æ•°æ®é›†æ‹†åˆ†æˆçš„åˆ†ç‰‡æ•°ã€‚ æ‚¨è¿˜éœ€è¦ä½¿ç”¨ index å‚æ•°æä¾›è¦è¿”å›žçš„åˆ†ç‰‡ã€‚ from datasets import load_dataset datasets = load_dataset(\"imdb\", split=\"train\") print(dataset) dataset.shard(num_shards=4, index=0) # å››åˆ†ä¹‹ä¸€ åˆ—é‡å‘½å+ç§»é™¤åˆ—+è½¬æ¢æ ¼å¼+flatten from datasets import ClassLabel, Value from datasets import load_dataset # åˆ—é‡å‘½å dataset = dataset.rename_column(\"sentence1\", \"sentenceA\") # åŽ»æŽ‰æŸä¸€åˆ— dataset = dataset.remove_columns([\"sentence1\", \"sentence2\"]) # è½¬æ¢æ ¼å¼ï¼šä¸€åˆ—æˆ–è€…å¤šåˆ— new_features = dataset.features.copy() new_features[\"label\"] = ClassLabel(names=[\"negative\", \"positive\"]) new_features[\"idx\"] = Value(\"int64\") dataset = dataset.cast(new_features) # è½¬æ¢æ ¼å¼ï¼šä¸€åˆ— dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000)) # å°†æŸä¸€åˆ—çš„key\\valueæ‹‰å¹³ dataset = load_dataset(\"squad\", split=\"train\") # ??? mapè½¬æ¢ from multiprocess import set_start_method from datasets import load_dataset import torch import os set_start_method(\"spawn\") # remove_columns è½¬æ¢çš„åŒæ—¶åŽ»æŽ‰æŸä¸€åˆ— updated_dataset = dataset.map(lambda example: {\"new_sentence\": example[\"sentence1\"]}, remove_columns=[\"sentence1\"]) updated_dataset.column_names # with_indices: å¯¹ä¸‹æ ‡å¤„ç† updated_dataset = dataset.map(lambda example, idx: {\"sentence2\": f\"{idx}: \" + example[\"sentence2\"]}, with_indices=True) updated_dataset[\"sentence2\"][:5] #å¦‚æžœæ‚¨è®¾ç½®with_rank=Trueï¼Œmap()ä¹Ÿé€‚ç”¨äºŽè¿›ç¨‹çš„ç­‰çº§ã€‚ è¿™ç±»ä¼¼äºŽwith_indiceså‚æ•°ã€‚ æ˜ å°„å‡½æ•°ä¸­çš„with_rankå‚æ•°ä½äºŽç´¢å¼•1ä¹‹åŽ(å¦‚æžœå®ƒå·²ç»å­˜åœ¨) def gpu_computation(example, rank): os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(rank % torch.cuda.device_count()) # Your big GPU call goes here return examples updated_dataset = dataset.map(gpu_computation, with_rank=True) # å¤šçº¿ç¨‹ updated_dataset = dataset.map(lambda example, idx: {\"sentence2\": f\"{idx}: \" + example[\"sentence2\"]}, num_proc=4) # batched chunked_dataset = dataset.map(chunk_examples, batched=True, remove_columns=dataset.column_names) # æ•°æ®å¢žå¼º def augment_data(examples): outputs = [] for sentence in examples[\"sentence1\"]: words = sentence.split(' ') K = randint(1, len(words)-1) masked_sentence = \" \".join(words[:K] + [mask_token] + words[K+1:]) predictions = fillmask(masked_sentence) augmented_sequences = [predictions[i][\"sequence\"] for i in range(3)] outputs += [sentence] + augmented_sequences return {\"data\": outputs} augmented_dataset = smaller_dataset.map(augment_data, batched=True, remove_columns=dataset.column_names, batch_size=8) augmented_dataset[:9][\"data\"] # å¤„ç†å¤šsplit dataset = load_dataset('glue', 'mrpc') encoded_dataset = dataset.map(lambda examples: tokenizer(examples[\"sentence1\"]), batched=True) encoded_dataset[\"train\"][0] åˆå¹¶+æ‹¼æŽ¥æ•°æ®é›† from datasets import concatenate_datasets, load_dataset from datasets import Dataset # åŠ è½½æ•°æ®é›† bookcorpus = load_dataset(\"bookcorpus\", split=\"train\") wiki = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train\") wiki = wiki.remove_columns([col for col in wiki.column_names if col != \"text\"]) # only keep the 'text' column assert bookcorpus.features.type == wiki.features.type bert_dataset = concatenate_datasets([bookcorpus, wiki]) # å¯ä»¥æ¢concateçš„æ–¹å‘ bookcorpus_ids = Dataset.from_dict({\"ids\": list(range(len(bookcorpus)))}) bookcorpus_with_ids = concatenate_datasets([bookcorpus, bookcorpus_ids], axis=1) ç›¸äº’ç©¿æ’ import torch # æŒ‰æ¦‚çŽ‡ç©¿æ’ seed = 42 probabilities = [0.3, 0.5, 0.2] d1 = Dataset.from_dict({\"a\": [0, 1, 2]}) d2 = Dataset.from_dict({\"a\": [10, 11, 12, 13]}) d3 = Dataset.from_dict({\"a\": [20, 21, 22]}) dataset = interleave_datasets([d1, d2, d3], probabilities=probabilities, seed=seed) dataset[\"a\"] # æŒ‰æ‰€æœ‰çš„æ ·æœ¬éƒ½å‡ºçŽ°è¿‡ä¸€æ¬¡åŽï¼Œé©¬ä¸Šåœæ­¢ d1 = Dataset.from_dict({\"a\": [0, 1, 2]}) d2 = Dataset.from_dict({\"a\": [10, 11, 12, 13]}) d3 = Dataset.from_dict({\"a\": [20, 21, 22]}) dataset = interleave_datasets([d1, d2, d3], stopping_strategy=\"all_exhausted\") dataset[\"a\"] format dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"]) # è¿”å›žä¸€ä¸ªæ–°dataset dataset = dataset.with_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"]) # æŸ¥çœ‹ dataset.format ä¿å­˜ from datasets import load_from_disk encoded_dataset.save_to_disk(\"path/of/my/dataset/directory\") # ä»Žæœ¬åœ°loadä¸Šæ¥ reloaded_dataset = load_from_disk(\"path/of/my/dataset/directory\") encoded_dataset.to_csv(\"path/of/my/dataset.csv\") Dataset.to_json() Preprocesså¤„ç† æ–‡æœ¬å¤„ç†ï¼šç”¨transformersçš„tokenizer from transformers import AutoTokenizer from datasets import load_dataset tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") dataset = load_dataset(\"rotten_tomatoes\", split=\"train\") tokenizer(dataset[0][\"text\"]) {'input_ids': [101, 1103, 2067, 1110, 17348, 1106, 1129, 1103, 6880, 1432, 112, 188, 1207, 107, 14255, 1389, 107, 1105, 1115, 1119, 112, 188, 1280, 1106, 1294, 170, 24194, 1256, 3407, 1190, 170, 11791, 5253, 188, 1732, 7200, 10947, 12606, 2895, 117, 179, 7766, 118, 172, 15554, 1181, 3498, 6961, 3263, 1137, 188, 1566, 7912, 14516, 6997, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} åˆ†è¯å™¨è¿”å›žä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé¡¹ç›®çš„å­—å…¸ï¼š input_idsï¼šè¡¨ç¤ºæ–‡æœ¬ä¸­å„ä¸ªæ ‡è®°çš„æ•°å­— token_type_idsï¼šå¦‚æžœæœ‰å¤šä¸ªåºåˆ—ï¼ŒæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°å±žäºŽå“ªä¸ªåºåˆ— attention_maskï¼šæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°æ˜¯å¦åº”è¯¥è¢«æŽ©ç›–(masked) dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"]) éŸ³é¢‘ä¿¡å·ï¼šé‡æ–°é‡‡æ ·éŸ³é¢‘ä¿¡å· from transformers import AutoFeatureExtractor from datasets import load_dataset, Audio feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base-960h\") dataset = load_dataset(\"PolyAI/minds14\", \"en-US\", split=\"train\") dataset[0][\"audio\"] {'array': array([ 0. , 0.00024414, -0.00024414, ..., -0.00024414, 0. , 0. ], dtype=float32), 'path': '/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav', 'sampling_rate': 8000} MInDS-14æ•°æ®é›†å¡ä¼šå‘Šè¯‰æ‚¨é‡‡æ ·çŽ‡ä¸º8kHz Wav2Vec2æ¨¡åž‹å¡è¯´å®ƒæ˜¯åœ¨16kHzè¯­éŸ³éŸ³é¢‘ä¸Šé‡‡æ ·çš„ã€‚ è¿™æ„å‘³ç€æ‚¨éœ€è¦å¯¹MInDS-14æ•°æ®é›†è¿›è¡Œä¸Šé‡‡æ ·ä»¥åŒ¹é…æ¨¡åž‹çš„é‡‡æ ·çŽ‡ ä½¿ç”¨cast_column()å‡½æ•°å¹¶åœ¨AudioåŠŸèƒ½ä¸­è®¾ç½®sampling_rateå‚æ•°ä»¥å¯¹éŸ³é¢‘ä¿¡å·è¿›è¡Œä¸Šé‡‡æ ·ã€‚ å½“æ‚¨çŽ°åœ¨è°ƒç”¨éŸ³é¢‘åˆ—æ—¶ï¼Œå®ƒä¼šè¢«è§£ç å¹¶é‡æ–°é‡‡æ ·åˆ°16kHzï¼š dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16_000)) dataset[0][\"audio\"] # åŠ é€Ÿï¼šä½¿ç”¨ map() å‡½æ•°å°†æ•´ä¸ªæ•°æ®é›†é‡æ–°é‡‡æ ·åˆ°16kHz def preprocess_function(examples): audio_arrays = [x[\"array\"] for x in examples[\"audio\"]] inputs = feature_extractor( audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True ) return inputs dataset = dataset.map(preprocess_function, batched=True) å›¾åƒå¢žå¼º åœ¨å›¾åƒæ•°æ®é›†ä¸­ï¼Œæœ€å¸¸è§çš„é¢„å¤„ç†æ“ä½œä¹‹ä¸€æ˜¯æ•°æ®å¢žå¼º(data augmentation)ï¼Œè¿™æ˜¯ä¸€ç§åœ¨ä¸æ”¹å˜æ•°æ®å«ä¹‰çš„æƒ…å†µä¸‹å¯¹å›¾åƒå¼•å…¥éšæœºå˜åŒ–çš„è¿‡ç¨‹ è¿™å¯ä»¥åŒ…æ‹¬æ”¹å˜å›¾åƒçš„é¢œè‰²å±žæ€§æˆ–éšæœºè£å‰ªå›¾åƒã€‚æ‚¨å¯ä»¥è‡ªç”±é€‰æ‹©ä»»ä½•æ•°æ®å¢žå¼ºåº“ï¼Œå¹¶ä¸”&#x1F917;Datasetså°†å¸®åŠ©æ‚¨å°†æ•°æ®å¢žå¼ºåº”ç”¨åˆ°æ‚¨çš„æ•°æ®é›†ä¸­ from transformers import AutoFeatureExtractor from datasets import load_dataset, Image from torchvision.transforms import RandomRotation feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\") dataset = load_dataset(\"beans\", split=\"train\") rotate = RandomRotation(degrees=(0, 90)) def transforms(examples): examples[\"pixel_values\"] = [rotate(image.convert(\"RGB\")) for image in examples[\"image\"]] return examples # åº”ç”¨å›¾åƒè½¬æ¢ dataset.set_transform(transforms) dataset[0][\"pixel_values\"] label idå¯¹é½ åœ¨Transformersåº“ä¸­ï¼Œlabel idå¯¹é½(label ID alignment)é€šå¸¸æŒ‡çš„æ˜¯å°†æ ‡ç­¾ä¸Žæ¨¡åž‹è¾“å‡ºçš„é¢„æµ‹ç»“æžœå¯¹é½ã€‚å½“ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹è¿›è¡Œåˆ†ç±»æˆ–å›žå½’ç­‰ä»»åŠ¡æ—¶ï¼Œé€šå¸¸éœ€è¦å°†æ ‡ç­¾æ˜ å°„ä¸ºæ¨¡åž‹æœŸæœ›çš„æ ‡ç­¾ID å…·ä½“æ¥è¯´ï¼Œå¯¹äºŽåˆ†ç±»ä»»åŠ¡ï¼Œå¸¸è§çš„åšæ³•æ˜¯å°†æ ‡ç­¾æ˜ å°„ä¸ºæ•´æ•°æ ‡ç­¾IDã€‚ä¾‹å¦‚ï¼Œå¦‚æžœæœ‰ä¸‰ä¸ªç±»åˆ«[\"cat\", \"dog\", \"bird\"]ï¼Œå¯ä»¥å°†å®ƒä»¬æ˜ å°„ä¸º[0, 1, 2]ï¼Œå¹¶å°†æ¨¡åž‹çš„è¾“å‡ºæ ‡ç­¾é¢„æµ‹ç»“æžœä¸Žè¿™äº›æ ‡ç­¾IDè¿›è¡Œå¯¹é½ å¯¹äºŽå›žå½’ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦å°†è¿žç»­å€¼çš„æ ‡ç­¾è¿›è¡Œç¦»æ•£åŒ–æˆ–å½’ä¸€åŒ–ï¼Œå¹¶å°†å…¶æ˜ å°„ä¸ºæ ‡ç­¾IDã€‚ä¾‹å¦‚ï¼Œå°†ä¸€ä¸ªè¿žç»­çš„ç›®æ ‡å€¼èŒƒå›´æ˜ å°„ä¸ºä¸€ç»„ç¦»æ•£çš„æ ‡ç­¾ID åœ¨ä½¿ç”¨Transformersåº“è¿›è¡Œè®­ç»ƒæˆ–è¯„ä¼°æ—¶ï¼Œæ‚¨éœ€è¦ç¡®ä¿æ ‡ç­¾ä¸Žæ¨¡åž‹çš„è¾“å‡ºç»“æžœå…·æœ‰ç›¸åŒçš„æ ‡ç­¾IDå¯¹é½ï¼Œä»¥ä¾¿æ­£ç¡®è®¡ç®—æŸå¤±ã€è¯„ä¼°æŒ‡æ ‡å’Œè§£ç é¢„æµ‹ç»“æžœ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ ‡ç­¾IDå¯¹é½çš„å…·ä½“å®žçŽ°æ–¹å¼å¯èƒ½å› ä»»åŠ¡å’Œåº“çš„ä½¿ç”¨è€Œæœ‰æ‰€ä¸åŒã€‚åœ¨å…·ä½“çš„ä»£ç å®žçŽ°ä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„æ•°æ®é›†å’Œæ¨¡åž‹è®¾ç½®è¿›è¡Œç›¸åº”çš„æ ‡ç­¾IDå¯¹é½æ“ä½œ from datasets import load_dataset label2id = {\"contradiction\": 0, \"neutral\": 1, \"entailment\": 2} mnli = load_dataset(\"glue\", \"mnli\", split=\"train\") mnli_aligned = mnli.align_labels_with_mapping(label2id, \"label\") æž„å»ºæ•°æ®é›† å¦‚æžœæ‚¨ä½¿ç”¨è‡ªå·±çš„æ•°æ®ï¼Œå¯èƒ½éœ€è¦åˆ›å»ºä¸€ä¸ªæ•°æ®é›†ã€‚ä½¿ç”¨&#x1F917;Datasetsåˆ›å»ºæ•°æ®é›†å¯ä»¥äº«å—åˆ°è¯¥åº“çš„æ‰€æœ‰ä¼˜åŠ¿ï¼šå¿«é€ŸåŠ è½½å’Œå¤„ç†æ•°æ®ã€æµå¼å¤„ç†å¤§åž‹æ•°æ®é›†ã€å†…å­˜æ˜ å°„ç­‰ç­‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨&#x1F917;Datasetsçš„ä½Žä»£ç æ–¹æ³•è½»æ¾å¿«é€Ÿåœ°åˆ›å»ºæ•°æ®é›†ï¼Œå‡å°‘å¯åŠ¨è®­ç»ƒæ¨¡åž‹æ‰€éœ€çš„æ—¶é—´ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œåªéœ€å°†æ•°æ®æ–‡ä»¶æ‹–æ”¾åˆ°Hubä¸Šçš„æ•°æ®é›†ä»“åº“ä¸­ï¼Œå°±å¯ä»¥è½»æ¾å®Œæˆ åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨&#x1F917;Datasetsçš„ä½Žä»£ç æ–¹æ³•åˆ›å»ºå„ç§ç±»åž‹çš„æ•°æ®é›†ï¼š åŸºäºŽæ–‡ä»¶å¤¹çš„æž„å»ºå™¨(Folder-based builders)ï¼Œç”¨äºŽå¿«é€Ÿåˆ›å»ºå›¾åƒæˆ–éŸ³é¢‘æ•°æ®é›† ä½¿ç”¨from_æ–¹æ³•ä»Žæœ¬åœ°æ–‡ä»¶åˆ›å»ºæ•°æ®é›† åŸºäºŽæ–‡ä»¶å¤¹çš„æž„å»ºå™¨ æœ‰ä¸¤ä¸ªåŸºäºŽæ–‡ä»¶å¤¹çš„æž„å»ºå™¨ï¼šImageFolder(å›¾åƒæ–‡ä»¶å¤¹æž„å»ºå™¨)å’ŒAudioFolder(éŸ³é¢‘æ–‡ä»¶å¤¹æž„å»ºå™¨) å®ƒä»¬æ˜¯ä½Žä»£ç æ–¹æ³•ï¼Œå¯ä»¥å¿«é€Ÿåˆ›å»ºåŒ…å«æ•°åƒä¸ªç¤ºä¾‹çš„å›¾åƒã€è¯­éŸ³å’ŒéŸ³é¢‘æ•°æ®é›†ã€‚å®ƒä»¬éžå¸¸é€‚ç”¨äºŽåœ¨æ‰©å±•åˆ°æ›´å¤§çš„æ•°æ®é›†ä¹‹å‰ï¼Œå¿«é€ŸåŽŸåž‹åŒ–è®¡ç®—æœºè§†è§‰å’Œè¯­éŸ³æ¨¡åž‹ åŸºäºŽæ–‡ä»¶å¤¹çš„æž„å»ºå™¨ä¼šä½¿ç”¨æ‚¨çš„æ•°æ®ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆæ•°æ®é›†çš„ç‰¹å¾ã€åˆ’åˆ†å’Œæ ‡ç­¾ã€‚å…·ä½“æ¥è¯´ï¼š ImageFolderä½¿ç”¨Imageç‰¹å¾æ¥è§£ç å›¾åƒæ–‡ä»¶ã€‚å®ƒæ”¯æŒè®¸å¤šå›¾åƒæ‰©å±•æ ¼å¼ï¼Œä¾‹å¦‚jpgå’Œpngï¼Œè¿˜æ”¯æŒå…¶ä»–æ ¼å¼ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹æ”¯æŒçš„å›¾åƒæ‰©å±•æ ¼å¼çš„å®Œæ•´åˆ—è¡¨ AudioFolderä½¿ç”¨Audioç‰¹å¾æ¥è§£ç éŸ³é¢‘æ–‡ä»¶ã€‚å®ƒæ”¯æŒéŸ³é¢‘æ‰©å±•æ ¼å¼ï¼Œå¦‚wavå’Œmp3ï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹æ”¯æŒçš„éŸ³é¢‘æ‰©å±•æ ¼å¼çš„å®Œæ•´åˆ—è¡¨ ä¾‹å¦‚ï¼Œå¦‚æžœæ‚¨çš„å›¾åƒæ•°æ®é›†(å¯¹äºŽéŸ³é¢‘æ•°æ®é›†ä¹Ÿæ˜¯ä¸€æ ·)å­˜å‚¨å¦‚ä¸‹æ‰€ç¤ºï¼š pokemon/train/grass/bulbasaur.png pokemon/train/fire/charmander.png pokemon/train/water/squirtle.png pokemon/test/grass/ivysaur.png pokemon/test/fire/charmeleon.png pokemon/test/water/wartortle.png from datasets import ImageFolder from datasets import AudioFolder dataset = load_dataset(\"imagefolder\", data_dir=\"/path/to/pokemon\") dataset = load_dataset(\"audiofolder\", data_dir=\"/path/to/folder\") æ•°æ®é›†ä¸­å¯ä»¥åŒ…å«æœ‰å…³æ•°æ®é›†çš„å…¶ä»–ä¿¡æ¯ï¼Œä¾‹å¦‚æ–‡æœ¬æ ‡é¢˜æˆ–è½¬å½•ï¼Œå¯ä»¥ä½¿ç”¨åŒ…å«åœ¨æ•°æ®é›†æ–‡ä»¶å¤¹ä¸­çš„metadata.csvæ–‡ä»¶æ¥è¿›è¡Œå­˜å‚¨ metadataæ–‡ä»¶éœ€è¦æœ‰ä¸€ä¸ªfile_nameåˆ—ï¼Œå°†å›¾åƒæˆ–éŸ³é¢‘æ–‡ä»¶ä¸Žå…¶ç›¸åº”çš„å…ƒæ•°æ®è¿›è¡Œå…³è” file_name, text bulbasaur.png, There is a plant seed on its back right from the day this PokÃ©mon is born. charmander.png, It has a preference for hot things. squirtle.png, When it retracts its long neck into its shell, it squirts out water with vigorous force. To learn more about each of these folder-based builders, check out the and ImageFolder or AudioFolder guides. åŸºäºŽæ–‡ä»¶çš„æž„å»ºå™¨ ä½¿ç”¨ from_generator() æ–¹æ³•æ˜¯ä»Žç”Ÿæˆå™¨åˆ›å»ºæ•°æ®é›†çš„æœ€èŠ‚çœå†…å­˜çš„æ–¹å¼ï¼Œè¿™æ˜¯ç”±äºŽç”Ÿæˆå™¨çš„è¿­ä»£è¡Œä¸ºã€‚è¿™åœ¨å¤„ç†éžå¸¸å¤§çš„æ•°æ®é›†æ—¶ç‰¹åˆ«æœ‰ç”¨ï¼Œå› ä¸ºæ•°æ®é›†æ˜¯é€æ­¥åœ¨ç£ç›˜ä¸Šç”Ÿæˆçš„ï¼Œç„¶åŽè¿›è¡Œå†…å­˜æ˜ å°„ï¼Œè¿™æ ·å¯ä»¥é¿å…å°†æ•´ä¸ªæ•°æ®é›†åŠ è½½åˆ°å†…å­˜ä¸­ from datasets import Dataset def gen(): yield {\"pokemon\": \"bulbasaur\", \"type\": \"grass\"} yield {\"pokemon\": \"squirtle\", \"type\": \"water\"} ds = Dataset.from_generator(gen) ds[0] {\"pokemon\": \"bulbasaur\", \"type\": \"grass\"} åŸºäºŽç”Ÿæˆå™¨çš„IterableDatasetéœ€è¦ä½¿ç”¨forå¾ªçŽ¯è¿›è¡Œè¿­ä»£ï¼Œä¾‹å¦‚ï¼š from datasets import IterableDataset ds = IterableDataset.from_generator(gen) for example in ds: print(example) {\"pokemon\": \"bulbasaur\", \"type\": \"grass\"} {\"pokemon\": \"squirtle\", \"type\": \"water\"} ä½¿ç”¨from_dict()æ–¹æ³•æ˜¯ä»Žå­—å…¸åˆ›å»ºæ•°æ®é›†çš„ç®€å•ç›´æŽ¥çš„æ–¹å¼ï¼š from datasets import Dataset ds = Dataset.from_dict({\"pokemon\": [\"bulbasaur\", \"squirtle\"], \"type\": [\"grass\", \"water\"]}) ds[0] {\"pokemon\": \"bulbasaur\", \"type\": \"grass\"} åˆ†äº«æ•°æ®é›† ç‚¹å‡»æ‚¨çš„ä¸ªäººèµ„æ–™å¹¶é€‰æ‹©æ–°çš„æ•°æ®é›†ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é›†ä»“åº“ã€‚ ä¸ºæ‚¨çš„æ•°æ®é›†é€‰æ‹©ä¸€ä¸ªåç§°ï¼Œå¹¶é€‰æ‹©å®ƒæ˜¯ä¸€ä¸ªå…¬å…±æ•°æ®é›†è¿˜æ˜¯ç§æœ‰æ•°æ®é›†ã€‚å…¬å…±æ•°æ®é›†å¯¹ä»»ä½•äººå¯è§ï¼Œè€Œç§æœ‰æ•°æ®é›†åªèƒ½ç”±æ‚¨æˆ–æ‚¨ç»„ç»‡çš„æˆå‘˜æŸ¥çœ‹ ä¸€æ—¦æ‚¨çš„æ•°æ®é›†å­˜å‚¨åœ¨Hubä¸Šï¼Œä»»ä½•äººéƒ½å¯ä»¥ä½¿ç”¨load_dataset()å‡½æ•°åŠ è½½å®ƒï¼š from datasets import load_dataset dataset = load_dataset(\"stevhliu/demo\") ä½¿ç”¨Pythonè¿›è¡Œä¸Šä¼  å–œæ¬¢ä»¥ç¼–ç¨‹æ–¹å¼ä¸Šä¼ æ•°æ®é›†çš„ç”¨æˆ·å¯ä»¥ä½¿ç”¨huggingface_hubåº“ã€‚è¯¥åº“å…è®¸ç”¨æˆ·ä»ŽPythonä¸­ä¸ŽHubè¿›è¡Œäº¤äº’ é¦–å…ˆå®‰è£…è¯¥åº“ï¼š pip install huggingface_hub è¦åœ¨Hubä¸Šä½¿ç”¨Pythonä¸Šä¼ æ•°æ®é›†ï¼Œæ‚¨éœ€è¦ç™»å½•åˆ°æ‚¨çš„Hugging Faceè´¦æˆ·ï¼š huggingface-cli login ä½¿ç”¨push_to_hub()å‡½æ•°å¸®åŠ©æ‚¨å°†æ–‡ä»¶æ·»åŠ ã€æäº¤å’ŒæŽ¨é€åˆ°æ‚¨çš„ä»“åº“ï¼š from datasets import load_dataset dataset = load_dataset(\"stevhliu/demo\") # dataset = dataset.map(...) # åœ¨è¿™é‡Œè¿›è¡Œæ‰€æœ‰çš„æ•°æ®å¤„ç† dataset.push_to_hub(\"stevhliu/processed_demo\") å¦‚æžœè¦å°†æ•°æ®é›†è®¾ç½®ä¸ºç§æœ‰ï¼Œè¯·å°†privateå‚æ•°è®¾ç½®ä¸ºTrueã€‚è¯¥å‚æ•°ä»…åœ¨é¦–æ¬¡åˆ›å»ºä»“åº“æ—¶æœ‰æ•ˆ dataset.push_to_hub(\"stevhliu/private_processed_demo\", private=True) è¯„ä¼°æŒ‡æ ‡ å®‰è£… ä¸€ç§ç”¨äºŽè½»æ¾è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡åž‹å’Œæ•°æ®é›†çš„åº“ åªéœ€ä¸€è¡Œä»£ç ï¼Œæ‚¨å°±å¯ä»¥è®¿é—®æ•°åç§ä¸åŒé¢†åŸŸ(è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€å¼ºåŒ–å­¦ä¹ ç­‰)çš„è¯„ä¼°æ–¹æ³• æ— è®ºæ˜¯åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿˜æ˜¯åœ¨åˆ†å¸ƒå¼è®­ç»ƒçŽ¯å¢ƒä¸­ï¼Œæ‚¨éƒ½å¯ä»¥ä»¥ä¸€ç§ä¸€è‡´ä¸”å¯é‡å¤çš„æ–¹å¼è¯„ä¼°æ‚¨çš„æ¨¡åž‹ å®‰è£… pip install evaluate æµ‹è¯• python -c \"import evaluate; print(evaluate.load('exact_match').compute(references=['hello'], predictions=['hello']))\" {'exact_match': 1.0} å¿«é€Ÿå¼€å§‹ æŒ‡æ ‡ç§ç±» Evaluate Metricå¡ç‰‡å®žä¾‹ &#x1F917;Evaluateæä¾›äº†å¹¿æ³›çš„è¯„ä¼°å·¥å…·ã€‚å®ƒæ¶µç›–äº†æ–‡æœ¬ã€è®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘ç­‰å¤šç§å½¢å¼ï¼Œå¹¶æä¾›äº†ç”¨äºŽè¯„ä¼°æ¨¡åž‹æˆ–æ•°æ®é›†çš„å·¥å…·ã€‚è¿™äº›å·¥å…·åˆ†ä¸ºä¸‰ä¸ªç±»åˆ« è¯„ä¼°ç±»åž‹ å…¸åž‹çš„æœºå™¨å­¦ä¹ æµç¨‹æ¶‰åŠåˆ°ä¸åŒæ–¹é¢çš„è¯„ä¼°ï¼Œå¯¹äºŽæ¯ä¸ªæ–¹é¢ï¼Œ&#x1F917; Evaluateéƒ½æä¾›äº†ç›¸åº”çš„å·¥å…·ï¼š æŒ‡æ ‡(Metric)ï¼šç”¨äºŽè¯„ä¼°æ¨¡åž‹çš„æ€§èƒ½ï¼Œé€šå¸¸æ¶‰åŠæ¨¡åž‹çš„é¢„æµ‹ç»“æžœå’Œä¸€äº›çœŸå®žæ ‡ç­¾ã€‚æ‚¨å¯ä»¥åœ¨evaluate-metricä¸­æ‰¾åˆ°æ‰€æœ‰é›†æˆçš„æŒ‡æ ‡ æ¯”è¾ƒ(Comparison)ï¼šç”¨äºŽæ¯”è¾ƒä¸¤ä¸ªæ¨¡åž‹ã€‚å¯ä»¥é€šè¿‡å°†å®ƒä»¬çš„é¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾è¿›è¡Œæ¯”è¾ƒå¹¶è®¡ç®—å®ƒä»¬çš„ä¸€è‡´æ€§æ¥è¿›è¡Œæ¯”è¾ƒã€‚æ‚¨å¯ä»¥åœ¨evaluate-comparisonä¸­æ‰¾åˆ°æ‰€æœ‰é›†æˆçš„æ¯”è¾ƒæ–¹æ³• æµ‹é‡(Measurement)ï¼šæ•°æ®é›†å’Œè®­ç»ƒåœ¨å…¶ä¸Šçš„æ¨¡åž‹åŒæ ·é‡è¦ã€‚é€šè¿‡æµ‹é‡å¯ä»¥ç ”ç©¶æ•°æ®é›†çš„ç‰¹æ€§ã€‚æ‚¨å¯ä»¥åœ¨evaluate-measurementä¸­æ‰¾åˆ°æ‰€æœ‰é›†æˆçš„æµ‹é‡æ–¹æ³• æ¯ä¸ªè¯„ä¼°æ¨¡å—éƒ½ä½œä¸ºä¸€ä¸ªSpaceå­˜å‚¨åœ¨Hugging Face Hubä¸Šã€‚å®ƒä»¬æä¾›äº†ä¸€ä¸ªäº¤äº’å¼å°éƒ¨ä»¶å’Œä¸€ä¸ªæ–‡æ¡£å¡ç‰‡ï¼Œç”¨äºŽè®°å½•å…¶ä½¿ç”¨æ–¹æ³•å’Œé™åˆ¶ è¯„ä¼°å·¥å…·ä¹‹é—´çš„å…³ç³»å’ŒåŒºåˆ« Evaluateåº“ä¸­çš„Metric(æŒ‡æ ‡)ã€Comparison(æ¯”è¾ƒ)å’ŒMeasurement(æµ‹é‡)æ˜¯ä¸‰ç§ä¸åŒçš„è¯„ä¼°å·¥å…·ï¼Œç”¨äºŽè¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡åž‹å’Œæ•°æ®é›†ã€‚å®ƒä»¬ä¹‹é—´çš„å…³ç³»å’ŒåŒºåˆ«å¦‚ä¸‹ï¼š Metric(æŒ‡æ ‡)ï¼š ç”¨é€”ï¼šç”¨äºŽè¯„ä¼°æ¨¡åž‹çš„æ€§èƒ½ å…·ä½“å«ä¹‰ï¼šæŒ‡æ ‡é€šè¿‡å°†æ¨¡åž‹çš„é¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾è¿›è¡Œæ¯”è¾ƒæ¥è¡¡é‡æ¨¡åž‹çš„è¡¨çŽ° ç¤ºä¾‹ï¼šå‡†ç¡®çŽ‡ã€ç²¾ç¡®çŽ‡ã€å¬å›žçŽ‡ã€F1åˆ†æ•°ç­‰ ç›®çš„ï¼šæä¾›äº†å¯¹æ¨¡åž‹æ€§èƒ½çš„å®šé‡è¯„ä¼°ï¼Œå¸®åŠ©è¡¡é‡æ¨¡åž‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨çŽ° Comparison(æ¯”è¾ƒ)ï¼š ç”¨é€”ï¼šç”¨äºŽæ¯”è¾ƒä¸¤ä¸ªæ¨¡åž‹ä¹‹é—´çš„å·®å¼‚ å…·ä½“å«ä¹‰ï¼šæ¯”è¾ƒå·¥å…·å°†ä¸¤ä¸ªæ¨¡åž‹çš„é¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾è¿›è¡Œå¯¹æ¯”ï¼Œè®¡ç®—å®ƒä»¬ä¹‹é—´çš„ä¸€è‡´æ€§æˆ–å·®å¼‚ç¨‹åº¦ ç¤ºä¾‹ï¼šä¸€è‡´æ€§æŒ‡æ ‡ã€ç›¸å¯¹è¯¯å·®ç­‰ ç›®çš„ï¼šå¸®åŠ©è¯„ä¼°ä¸åŒæ¨¡åž‹ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ï¼Œæ‰¾åˆ°æ›´å¥½çš„æ¨¡åž‹æˆ–è¿›è¡Œæ¨¡åž‹é€‰æ‹© Measurement(æµ‹é‡)ï¼š ç”¨é€”ï¼šç”¨äºŽç ”ç©¶æ•°æ®é›†çš„å±žæ€§å’Œç‰¹æ€§ å…·ä½“å«ä¹‰ï¼šæµ‹é‡å·¥å…·ç”¨äºŽå¯¹æ•°æ®é›†è¿›è¡Œåˆ†æžï¼ŒæŽ¢ç´¢æ•°æ®é›†çš„ç»“æž„ã€åˆ†å¸ƒã€åå·®ç­‰æ–¹é¢çš„ä¿¡æ¯ ç¤ºä¾‹ï¼šæ•°æ®é›†å¤§å°ã€æ ·æœ¬åˆ†å¸ƒã€ç±»åˆ«ä¸å¹³è¡¡åº¦ç­‰ ç›®çš„ï¼šæä¾›å¯¹æ•°æ®é›†çš„è¯¦ç»†äº†è§£ï¼Œå¸®åŠ©äº†è§£æ•°æ®é›†çš„ç‰¹ç‚¹å’Œæ½œåœ¨é—®é¢˜ è¿™ä¸‰ç§è¯„ä¼°å·¥å…·åœ¨Evaluateåº“ä¸­å„è‡ªç‹¬ç«‹ï¼Œç”¨äºŽä¸åŒçš„è¯„ä¼°ç›®çš„ã€‚Metricç”¨äºŽè¡¡é‡æ¨¡åž‹æ€§èƒ½ï¼ŒComparisonç”¨äºŽæ¯”è¾ƒä¸åŒæ¨¡åž‹ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ï¼ŒMeasurementç”¨äºŽç ”ç©¶å’Œäº†è§£æ•°æ®é›†çš„ç‰¹æ€§ã€‚é€šè¿‡ä½¿ç”¨è¿™äº›å·¥å…·ï¼Œå¯ä»¥å…¨é¢è¯„ä¼°å’Œç†è§£æœºå™¨å­¦ä¹ æ¨¡åž‹å’Œæ•°æ®é›†çš„è¡¨çŽ°å’Œç‰¹ç‚¹ æŒ‡æ ‡åŠ è½½ å®˜æ–¹+ç¤¾åŒº æŒ‡æ ‡ åœ¨ä½¿ç”¨Hugging Faceçš„Evaluateåº“åŠ è½½è¯„ä¼°å·¥å…·æ—¶ï¼Œå¯ä»¥é€šè¿‡æ˜¾å¼æŒ‡å®šè¯„ä¼°çš„ç±»åž‹æ¥ç¡®ä¿åŠ è½½æ­£ç¡®çš„å·¥å…·ã€‚è¿™å¯ä»¥é˜²æ­¢åç§°å†²çªæˆ–æ··æ·†ï¼Œç¡®ä¿æ‚¨ä½¿ç”¨çš„æ˜¯æœŸæœ›çš„è¯„ä¼°å·¥å…· import evaluate accuracy = evaluate.load(\"accuracy\") # æ˜¾å¼æŒ‡å®šè¯„ä¼°çš„ç±»åž‹ word_length = evaluate.load(\"word_length\", module_type=\"measurement\") # ç¤¾åŒºæŒ‡æ ‡ element_count = evaluate.load(\"lvwerra/element_count\", module_type=\"measurement\") æŸ¥çœ‹å¯ç”¨çš„æ¨¡å—æ–¹æ³• evaluate.list_evaluation_modules( module_type=\"comparison\", include_community=False, with_details=True) [{'name': 'mcnemar', 'type': 'comparison', 'community': False, 'likes': 1}, {'name': 'exact_match', 'type': 'comparison', 'community': False, 'likes': 0}] æŒ‡æ ‡è®¡ç®— è®¡ç®—æŒ‡æ ‡ å½“æ¶‰åŠåˆ°è®¡ç®—å®žé™…å¾—åˆ†æ—¶ï¼Œæœ‰ä¸¤ç§ä¸»è¦çš„æ–¹æ³•ï¼š ä¸€ä½“å¼è®¡ç®—(All-in-one)ï¼šé€šè¿‡ä¸€æ¬¡æ€§å°†æ‰€æœ‰å¿…è¦çš„è¾“å…¥ä¼ é€’ç»™compute()æ–¹æ³•æ¥è®¡ç®—å¾—åˆ† accuracy.compute(references=[0,1,0,1], predictions=[1,0,0,1]) {'accuracy': 0.5} é€æ­¥è®¡ç®—(Incremental)ï¼šé€šè¿‡ä½¿ç”¨EvaluationModule.add()æˆ–EvaluationModule.add_batch()å°†å¿…è¦çš„è¾“å…¥é€æ­¥æ·»åŠ åˆ°æ¨¡å—ä¸­ï¼Œç„¶åŽåœ¨æœ€åŽä½¿ç”¨ EvaluationModule.compute()è®¡ç®—å¾—åˆ† # addçš„æ–¹å¼ for ref, pred in zip([0,1,0,1], [1,0,0,1]): accuracy.add(references=ref, predictions=pred) accuracy.compute() {'accuracy': 0.5} # add_batchçš„æ–¹å¼ for refs, preds in zip([[0,1],[0,1]], [[1,0],[0,1]]): accuracy.add_batch(references=refs, predictions=preds) accuracy.compute() {'accuracy': 0.5} åœ¨ä½ éœ€è¦ä»¥æ‰¹é‡æ–¹å¼ä»Žæ¨¡åž‹ä¸­èŽ·å–é¢„æµ‹ç»“æžœæ—¶ç‰¹åˆ«æœ‰ç”¨ï¼š for model_inputs, gold_standards in evaluation_dataset: predictions = model(model_inputs) metric.add_batch(references=gold_standards, predictions=predictions) metric.compute() åˆ†å¸ƒå¼æŒ‡æ ‡ åœ¨åˆ†å¸ƒå¼çŽ¯å¢ƒä¸­è®¡ç®—æŒ‡æ ‡å¯èƒ½ä¼šæœ‰äº›æ£˜æ‰‹ã€‚æŒ‡æ ‡è¯„ä¼°æ˜¯åœ¨ä¸åŒçš„æ•°æ®å­é›†ä¸Šçš„å•ç‹¬Pythonè¿›ç¨‹æˆ–èŠ‚ç‚¹ä¸­æ‰§è¡Œçš„ é€šå¸¸æƒ…å†µä¸‹ï¼Œå½“ä¸€ä¸ªæŒ‡æ ‡å¾—åˆ†æ˜¯å¯åŠ çš„( f(A \\cup B) = f(A) + f(B))æ—¶ï¼Œä½ å¯ä»¥ä½¿ç”¨åˆ†å¸ƒå¼çš„reduceæ“ä½œæ¥æ”¶é›†æ¯ä¸ªæ•°æ®å­é›†çš„å¾—åˆ†ã€‚ä½†æ˜¯å½“æŒ‡æ ‡æ˜¯éžå¯åŠ çš„( f(A \\cup B) \\neq f(A) + f(B))æ—¶ï¼Œæƒ…å†µå°±ä¸é‚£ä¹ˆç®€å•äº†ã€‚ä¾‹å¦‚ï¼Œä½ ä¸èƒ½å°†æ¯ä¸ªæ•°æ®å­é›†çš„F1åˆ†æ•°ç›¸åŠ ä½œä¸ºæœ€ç»ˆçš„æŒ‡æ ‡ å…‹æœè¿™ä¸ªé—®é¢˜çš„å¸¸è§æ–¹æ³•æ˜¯å›žé€€åˆ°å•è¿›ç¨‹è¯„ä¼°ï¼Œä½†æŒ‡æ ‡åœ¨å•ä¸ªGPUä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¿™ä¼šå¯¼è‡´æ•ˆçŽ‡é™ä½Ž &#x1F917;Evaluateé€šè¿‡ä»…åœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸Šè®¡ç®—æœ€ç»ˆçš„æŒ‡æ ‡æ¥è§£å†³äº†è¿™ä¸ªé—®é¢˜ é¢„æµ‹ç»“æžœå’Œå‚è€ƒç»“æžœè¢«åˆ†åˆ«è®¡ç®—å¹¶æä¾›ç»™æ¯ä¸ªèŠ‚ç‚¹çš„æŒ‡æ ‡ï¼Œè¿™äº›ç»“æžœæš‚æ—¶å­˜å‚¨åœ¨Apache Arrowè¡¨ä¸­ï¼Œé¿å…äº†GPUæˆ–CPUå†…å­˜çš„æ··ä¹± å½“ä½ å‡†å¤‡ä½¿ç”¨compute()è®¡ç®—æœ€ç»ˆæŒ‡æ ‡æ—¶ï¼Œç¬¬ä¸€ä¸ªèŠ‚ç‚¹èƒ½å¤Ÿè®¿é—®æ‰€æœ‰å…¶ä»–èŠ‚ç‚¹ä¸Šå­˜å‚¨çš„é¢„æµ‹ç»“æžœå’Œå‚è€ƒç»“æžœã€‚ä¸€æ—¦å®ƒæ”¶é›†åˆ°æ‰€æœ‰çš„é¢„æµ‹ç»“æžœå’Œå‚è€ƒç»“æžœï¼Œcompute()å°†è¿›è¡Œæœ€ç»ˆçš„æŒ‡æ ‡è¯„ä¼° è¿™ä¸ªè§£å†³æ–¹æ¡ˆä½¿å¾—&#x1F917;Evaluateèƒ½å¤Ÿåœ¨åˆ†å¸ƒå¼è®¾ç½®ä¸­æ‰§è¡Œåˆ†å¸ƒå¼é¢„æµ‹ï¼Œè¿™å¯¹äºŽæé«˜è¯„ä¼°é€Ÿåº¦éžå¸¸é‡è¦ã€‚åŒæ—¶ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨å¤æ‚çš„éžå¯åŠ æŒ‡æ ‡ï¼Œè€Œä¸æµªè´¹å®è´µçš„GPUæˆ–CPUå†…å­˜ ç»„åˆè¯„ä¼° é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¸ä»…æƒ³è¯„ä¼°å•ä¸ªæŒ‡æ ‡ï¼Œè€Œæ˜¯æƒ³è¯„ä¼°ä¸€ç³»åˆ—ä¸åŒçš„æŒ‡æ ‡ï¼Œä»¥æ•æ‰æ¨¡åž‹æ€§èƒ½çš„ä¸åŒæ–¹é¢ ä¾‹å¦‚ï¼Œå¯¹äºŽåˆ†ç±»é—®é¢˜ï¼Œé™¤äº†å‡†ç¡®åº¦å¤–ï¼Œé€šå¸¸è¿˜ä¼šè®¡ç®—F1åˆ†æ•°ã€å¬å›žçŽ‡å’Œç²¾ç¡®åº¦ï¼Œä»¥ä¾¿æ›´å¥½åœ°äº†è§£æ¨¡åž‹çš„æ€§èƒ½ã€‚å½“ç„¶ï¼Œä½ å¯ä»¥åŠ è½½ä¸€ç³»åˆ—æŒ‡æ ‡å¹¶ä¾æ¬¡è°ƒç”¨å®ƒä»¬ã€‚ç„¶è€Œï¼Œä¸€ç§æ›´æ–¹ä¾¿çš„æ–¹æ³•æ˜¯ä½¿ç”¨combine()å‡½æ•°å°†å®ƒä»¬æ†ç»‘åœ¨ä¸€èµ·ï¼š clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"]) clf_metrics.compute(predictions=[0, 1, 0], references=[0, 1, 1]) { 'accuracy': 0.667, 'f1': 0.667, 'precision': 1.0, 'recall': 0.5 } è‡ªåŠ¨åŒ–è¯„ä¼° ä½¿ç”¨evaluate.evaluator()æä¾›äº†è‡ªåŠ¨åŒ–çš„è¯„ä¼°åŠŸèƒ½ï¼Œåªéœ€è¦ä¸€ä¸ªæ¨¡åž‹ã€æ•°æ®é›†å’Œåº¦é‡æŒ‡æ ‡ï¼Œä¸ŽEvaluationModulesä¸­çš„åº¦é‡æŒ‡æ ‡ç›¸æ¯”ï¼Œå®ƒä¸éœ€è¦æ¨¡åž‹çš„é¢„æµ‹ç»“æžœã€‚å› æ­¤ï¼Œä½¿ç”¨ç»™å®šçš„åº¦é‡æŒ‡æ ‡åœ¨æ•°æ®é›†ä¸Šè¯„ä¼°æ¨¡åž‹æ›´å®¹æ˜“ï¼Œå› ä¸ºæŽ¨ç†è¿‡ç¨‹æ˜¯åœ¨å†…éƒ¨å¤„ç†çš„ ä¸ºäº†å®žçŽ°è¿™ä¸€ç‚¹ï¼Œå®ƒä½¿ç”¨äº†transformersåº“ä¸­çš„pipelineæŠ½è±¡ã€‚ç„¶è€Œï¼Œåªè¦ç¬¦åˆpipelineæŽ¥å£ï¼Œä½ ä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±çš„æ¡†æž¶ from transformers import pipeline from datasets import load_dataset from evaluate import evaluator import evaluate ä¸ºäº†ä½¿ç”¨evaluatorè¿›è¡Œè¯„ä¼°ï¼Œè®©æˆ‘ä»¬åŠ è½½ä¸€ä¸ªåŸºäºŽIMDbè®­ç»ƒçš„transformers pipelineï¼ˆä½†ä½ ä¹Ÿå¯ä»¥ä¼ é€’è‡ªå·±çš„è‡ªå®šä¹‰æŽ¨ç†ç±»æ¥é€‚åº”ä»»ä½•éµå¾ªpipelineè°ƒç”¨APIçš„æ¡†æž¶ï¼‰ï¼Œå¹¶ä½¿ç”¨IMDbçš„æµ‹è¯•é›†å’Œå‡†ç¡®åº¦åº¦é‡æŒ‡æ ‡è¿›è¡Œè¯„ä¼° pipe = pipeline(\"text-classification\", model=\"lvwerra/distilbert-imdb\", device=0) data = load_dataset(\"imdb\", split=\"test\").shuffle().select(range(1000)) metric = evaluate.load(\"accuracy\") task_evaluator = evaluator(\"text-classification\") results = task_evaluator.compute(model_or_pipeline=pipe, data=data, metric=metric, label_mapping={\"NEGATIVE\": 0, \"POSITIVE\": 1},) {'accuracy': 0.934} ä»…ä»…è®¡ç®—åº¦é‡æŒ‡æ ‡çš„å€¼é€šå¸¸è¿˜ä¸è¶³ä»¥çŸ¥é“ä¸€ä¸ªæ¨¡åž‹æ˜¯å¦æ˜¾è‘—ä¼˜äºŽå¦ä¸€ä¸ªæ¨¡åž‹ã€‚é€šè¿‡ä½¿ç”¨è‡ªåŠ©æ³•(bootstrapping)ï¼Œevaluateè®¡ç®—ç½®ä¿¡åŒºé—´å’Œæ ‡å‡†è¯¯å·®ï¼Œè¿™æœ‰åŠ©äºŽä¼°è®¡åˆ†æ•°çš„ç¨³å®šæ€§ results = eval.compute(model_or_pipeline=pipe, data=data, metric=metric, label_mapping={\"NEGATIVE\": 0, \"POSITIVE\": 1}, strategy=\"bootstrap\", n_resamples=200) {'accuracy': { 'confidence_interval': (0.906, 0.9406749892841922), 'standard_error': 0.00865213251082787, 'score': 0.923 } } è¯„ä¼°å™¨æœŸæœ›æ•°æ®è¾“å…¥å…·æœ‰\"text\"å’Œ\"label\"åˆ—ã€‚å¦‚æžœæ‚¨çš„æ•°æ®é›†ä¸åŒï¼Œå¯ä»¥ä½¿ç”¨å…³é”®å­—å‚æ•°input_column=\"text\"å’Œlabel_column=\"label\"æ¥æä¾›åˆ—å ç›®å‰åªæ”¯æŒ\"text-classification\"ä»»åŠ¡ï¼Œå°†æ¥å¯èƒ½ä¼šæ·»åŠ æ›´å¤šçš„ä»»åŠ¡ç±»åž‹ ç»“æžœå­˜å‚¨ è¯„ä¼°ç»“æžœsaveå’Œpush ä¿å­˜å’Œåˆ†äº«è¯„ä¼°ç»“æžœæ˜¯ä¸€ä¸ªé‡è¦çš„æ­¥éª¤ã€‚æˆ‘ä»¬æä¾›evaluate.save()å‡½æ•°æ¥æ–¹ä¾¿åœ°ä¿å­˜æŒ‡æ ‡ç»“æžœã€‚ä½ å¯ä»¥ä¼ é€’ä¸€ä¸ªç‰¹å®šçš„æ–‡ä»¶åæˆ–ç›®å½•ã€‚åœ¨åŽä¸€ç§æƒ…å†µä¸‹ï¼Œç»“æžœå°†ä¿å­˜åœ¨ä¸€ä¸ªå¸¦æœ‰è‡ªåŠ¨åˆ›å»ºçš„æ–‡ä»¶åçš„æ–‡ä»¶ä¸­ é™¤äº†ç›®å½•æˆ–æ–‡ä»¶åï¼Œè¯¥å‡½æ•°è¿˜æŽ¥å—ä»»æ„çš„é”®å€¼å¯¹ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨ä¸€ä¸ªJSONæ–‡ä»¶ä¸­ result = accuracy.compute(references=[0,1,0,1], predictions=[1,0,0,1]) hyperparams = {\"model\": \"bert-base-uncased\"} evaluate.save(\"./results/\", experiment=\"run 42\", **result, **hyperparams) PosixPath('results/result-2022_05_30-22_09_11.json') # result-2022_05_30-22_09_11.json { \"experiment\": \"run 42\", \"accuracy\": 0.5, \"model\": \"bert-base-uncased\", \"_timestamp\": \"2022-05-30T22:09:11.959469\", \"_git_commit_hash\": \"123456789abcdefghijkl\", \"_evaluate_version\": \"0.1.0\", \"_python_version\": \"3.9.12 (main, Mar 26 2022, 15:51:15) \\n[Clang 13.1.6 (clang-1316.0.21.2)]\", \"_interpreter_path\": \"/Users/leandro/git/evaluate/env/bin/python\" } é™¤äº†æŒ‡å®šçš„å­—æ®µï¼Œå®ƒè¿˜åŒ…å«æœ‰ç”¨çš„ç³»ç»Ÿä¿¡æ¯ï¼Œç”¨äºŽé‡çŽ°ç»“æžœï¼Œä½ è¿˜åº”è¯¥å°†å®ƒä»¬æŠ¥å‘Šåˆ°æ¨¡åž‹åœ¨Hubä¸Šçš„å­˜å‚¨åº“ä¸­ evaluate.push_to_hub( model_id=\"huggingface/gpt2-wikitext2\", # model repository on hub metric_value=0.5, # metric value metric_type=\"bleu\", # metric name, e.g. accuracy.name metric_name=\"BLEU\", # pretty name which is displayed dataset_type=\"wikitext\", # dataset name on the hub dataset_name=\"WikiText\", # pretty name dataset_split=\"test\", # dataset split used task_type=\"text-generation\", # task id, see https://github.com/huggingface/datasets/blob/master/src/datasets/utils/resources/tasks.json task_name=\"Text Generation\" # pretty name for task ) ä¸Šä¼ è‡ªå·±çš„æŒ‡æ ‡Creating and sharing a new evaluation å¯è§†åŒ– å½“æ¯”è¾ƒå¤šä¸ªæ¨¡åž‹æ—¶ï¼Œä»…é€šè¿‡æŸ¥çœ‹å®ƒä»¬çš„å¾—åˆ†å¾€å¾€å¾ˆéš¾å‘çŽ°å®ƒä»¬ä¹‹é—´çš„å·®å¼‚ã€‚è€Œä¸”é€šå¸¸æƒ…å†µä¸‹ï¼Œå¹¶æ²¡æœ‰ä¸€ä¸ªå•ä¸€çš„æœ€ä½³æ¨¡åž‹ï¼Œè€Œæ˜¯åœ¨å‡†ç¡®æ€§å’Œå»¶è¿Ÿç­‰æ–¹é¢å­˜åœ¨ç€æƒè¡¡ï¼Œå› ä¸ºè¾ƒå¤§çš„æ¨¡åž‹å¯èƒ½å…·æœ‰æ›´å¥½çš„æ€§èƒ½ä½†ä¹Ÿæ›´æ…¢ã€‚æˆ‘ä»¬æ­£åœ¨é€æ­¥æ·»åŠ ä¸åŒçš„å¯è§†åŒ–æ–¹æ³•ï¼Œä¾‹å¦‚ç»˜å›¾ï¼Œä»¥ä¾¿æ›´è½»æ¾åœ°é€‰æ‹©é€‚åˆç‰¹å®šç”¨ä¾‹çš„æœ€ä½³æ¨¡åž‹ã€‚ ä¾‹å¦‚ï¼Œå¦‚æžœæ‚¨æœ‰å¤šä¸ªæ¨¡åž‹çš„ç»“æžœåˆ—è¡¨ï¼ˆä»¥å­—å…¸å½¢å¼ï¼‰ï¼Œæ‚¨å¯ä»¥å°†å®ƒä»¬ä¼ é€’ç»™radar_plot()å‡½æ•°è¿›è¡Œå¯è§†åŒ–ï¼š import evaluate from evaluate.visualization import radar_plot data = [ {\"accuracy\": 0.99, \"precision\": 0.8, \"f1\": 0.95, \"latency_in_seconds\": 33.6}, {\"accuracy\": 0.98, \"precision\": 0.87, \"f1\": 0.91, \"latency_in_seconds\": 11.2}, {\"accuracy\": 0.98, \"precision\": 0.78, \"f1\": 0.88, \"latency_in_seconds\": 87.6}, {\"accuracy\": 0.88, \"precision\": 0.78, \"f1\": 0.81, \"latency_in_seconds\": 101.6} ] model_names = [\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"] plot = radar_plot(data=data, model_names=model_names) plot.show() é€‰æ‹©åˆé€‚æŒ‡æ ‡ è¯„ä¼°æŒ‡æ ‡å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªé«˜çº§ç±»åˆ«ï¼š é€šç”¨æŒ‡æ ‡ï¼šé€‚ç”¨äºŽå„ç§æƒ…å†µå’Œæ•°æ®é›†çš„æŒ‡æ ‡ï¼Œä¾‹å¦‚ç²¾ç¡®åº¦å’Œå‡†ç¡®åº¦ precision_metric = evaluate.load(\"precision\") results = precision_metric.compute(references=[0, 1], predictions=[0, 1]) print(results) {'precision': 1.0} ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡ï¼šä»…é€‚ç”¨äºŽç‰¹å®šä»»åŠ¡çš„æŒ‡æ ‡ï¼Œä¾‹å¦‚æœºå™¨ç¿»è¯‘(é€šå¸¸ä½¿ç”¨BLEUæˆ–ROUGEæŒ‡æ ‡è¿›è¡Œè¯„ä¼°)æˆ–å‘½åå®žä½“è¯†åˆ«(é€šå¸¸ä½¿ç”¨seqevalè¿›è¡Œè¯„ä¼°) æ•°æ®é›†ç‰¹å®šæŒ‡æ ‡ï¼šæ—¨åœ¨è¡¡é‡æ¨¡åž‹åœ¨ç‰¹å®šåŸºå‡†æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œä¾‹å¦‚GLUEåŸºå‡†æµ‹è¯•å…·æœ‰ä¸“é—¨çš„è¯„ä¼°æŒ‡æ ‡ transformers æ¦‚è¿° What &#x1F917; Transformers can do &#x1F917; Transformersæä¾›äº†APIå’Œå·¥å…·ï¼Œå¯è½»æ¾ä¸‹è½½å’Œè®­ç»ƒæœ€å…ˆè¿›çš„é¢„è®­ç»ƒæ¨¡åž‹ã€‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹å¯ä»¥å‡å°‘è®¡ç®—æˆæœ¬ã€ç¢³è¶³è¿¹ï¼Œå¹¶èŠ‚çœä»Žå¤´å¼€å§‹è®­ç»ƒæ¨¡åž‹æ‰€éœ€çš„æ—¶é—´å’Œèµ„æºã€‚è¿™äº›æ¨¡åž‹æ”¯æŒä¸åŒé¢†åŸŸçš„å¸¸è§ä»»åŠ¡ï¼ŒåŒ…æ‹¬ï¼š &#x1F4DD; è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæ–‡æœ¬åˆ†ç±»ã€å‘½åå®žä½“è¯†åˆ«ã€é—®ç­”ç³»ç»Ÿã€è¯­è¨€å»ºæ¨¡ã€æ‘˜è¦ç”Ÿæˆã€ç¿»è¯‘ã€å¤šé¡¹é€‰æ‹©å’Œæ–‡æœ¬ç”Ÿæˆ &#x1F5BC;ï¸ è®¡ç®—æœºè§†è§‰ï¼šå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰² &#x1F5E3;ï¸ éŸ³é¢‘ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«å’ŒéŸ³é¢‘åˆ†ç±» &#x1F419; å¤šæ¨¡æ€ï¼šè¡¨æ ¼é—®ç­”ã€å…‰å­¦å­—ç¬¦è¯†åˆ«ã€ä»Žæ‰«ææ–‡æ¡£ä¸­æå–ä¿¡æ¯ã€è§†é¢‘åˆ†ç±»å’Œè§†è§‰é—®ç­” &#x1F917; Transformersæ”¯æŒåœ¨PyTorchã€TensorFlowå’ŒJAXä¹‹é—´è¿›è¡Œæ¡†æž¶äº’æ“ä½œã€‚è¿™æä¾›äº†åœ¨æ¨¡åž‹çš„ä¸åŒé˜¶æ®µä½¿ç”¨ä¸åŒæ¡†æž¶çš„çµæ´»æ€§ï¼›å¯ä»¥åœ¨ä¸€ä¸ªæ¡†æž¶ä¸­ç”¨ä¸‰è¡Œä»£ç è®­ç»ƒæ¨¡åž‹ï¼Œç„¶åŽåœ¨å¦ä¸€ä¸ªæ¡†æž¶ä¸­åŠ è½½æ¨¡åž‹è¿›è¡ŒæŽ¨ç†ã€‚æ¨¡åž‹è¿˜å¯ä»¥å¯¼å‡ºä¸ºONNXå’ŒTorchScriptç­‰æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­è¿›è¡Œéƒ¨ç½² å®‰è£… pip install transformers datasets å¿«é€Ÿå¼€å§‹ Pipeline pipeline()æ˜¯ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹è¿›è¡ŒæŽ¨ç†çš„æœ€ç®€å•å’Œæœ€å¿«æ·çš„æ–¹æ³•ã€‚æ‚¨å¯ä»¥ç›´æŽ¥ä½¿ç”¨pipeline()è¿›è¡Œè®¸å¤šä»»åŠ¡çš„æŽ¨ç†ï¼Œæ¶µç›–äº†ä¸åŒçš„æ¨¡æ€ï¼Œä¸‹è¡¨åˆ—å‡ºäº†å…¶ä¸­ä¸€äº›ä»»åŠ¡ Task Description Modality Pipeline identifier Text classification assign a label to a given sequence of text NLP pipeline(task=â€œsentiment-analysisâ€) Text generation generate text given a prompt NLP pipeline(task=â€œtext-generationâ€) Summarization generate a summary of a sequence of text or document NLP pipeline(task=â€œsummarizationâ€) Image classification assign a label to an image CV pipeline(task=â€œimage-classificationâ€) Image segmentation assign a label to each individual pixel of an image (supports semantic, panoptic, and instance segmentation) CV pipeline(task=â€œimage-segmentationâ€) Object detection predict the bounding boxes and classes of objects in an image CV pipeline(task=â€œobject-detectionâ€) Audio classification assign a label to some audio data Audio pipeline(task=â€œaudio-classificationâ€) Automatic speech recognition transcribe speech into text Audio pipeline(task=â€œautomatic-speech-recognitionâ€) Visual question answering answer a question about the image, given an image and a question Multimodal pipeline(task=â€œvqaâ€) Document question answering answer a question about a document, given an image and a question Multimodal pipeline(task=â€œdocument-question-answeringâ€) Image captioning generate a caption for a given image Multimodal pipeline(task=â€œimage-to-textâ€) åŸºæœ¬ä½¿ç”¨ é¦–å…ˆï¼Œé€šè¿‡åˆ›å»ºpipeline()çš„å®žä¾‹å¹¶æŒ‡å®šè¦ä½¿ç”¨çš„ä»»åŠ¡ï¼Œå¼€å§‹ä½¿ç”¨å®ƒã€‚åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä»¥æƒ…æ„Ÿåˆ†æžçš„pipeline()ä¸ºä¾‹ï¼š from transformers import pipeline classifier = pipeline(\"sentiment-analysis\") pipeline()ä¼šä¸‹è½½å¹¶ç¼“å­˜ç”¨äºŽæƒ…æ„Ÿåˆ†æžçš„é»˜è®¤é¢„è®­ç»ƒæ¨¡åž‹å’Œåˆ†è¯å™¨ã€‚çŽ°åœ¨ï¼Œæ‚¨å¯ä»¥åœ¨ç›®æ ‡æ–‡æœ¬ä¸Šä½¿ç”¨åˆ†ç±»å™¨äº†ï¼š classifier(\"We are very happy to show you the &#x1F917; Transformers library.\") [{'label': 'POSITIVE', 'score': 0.9998}] å¦‚æžœæ‚¨æœ‰å¤šä¸ªè¾“å…¥ï¼Œè¯·å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™pipeline()ï¼Œä»¥è¿”å›žä¸€ä¸ªå­—å…¸åˆ—è¡¨ results = classifier([\"We are very happy to show you the &#x1F917; Transformers library.\", \"We hope you don't hate it.\"]) for result in results: print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\") label: POSITIVE, with score: 0.9998 label: NEGATIVE, with score: 0.5309 pipeline()è¿˜å¯ä»¥å¯¹ä»»ä½•æ‚¨å–œæ¬¢çš„ä»»åŠ¡è¿­ä»£æ•´ä¸ªæ•°æ®é›†ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œè®©æˆ‘ä»¬é€‰æ‹©è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ä½œä¸ºæˆ‘ä»¬çš„ä»»åŠ¡ import torch from transformers import pipeline speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\") åŠ è½½æ‚¨æƒ³è¦è¿­ä»£çš„éŸ³é¢‘æ•°æ®é›†(æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…&#x1F917; Datasetså¿«é€Ÿå…¥é—¨)ã€‚ä¾‹å¦‚ï¼ŒåŠ è½½MInDS-14æ•°æ®é›†ï¼š from datasets import load_dataset, Audio dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\") æ‚¨éœ€è¦ç¡®ä¿æ•°æ®é›†çš„é‡‡æ ·çŽ‡ä¸Žfacebook/wav2vec2-base-960h è®­ç»ƒæ—¶ä½¿ç”¨çš„é‡‡æ ·çŽ‡ç›¸åŒ¹é… dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate)) è°ƒç”¨\"audio\"åˆ—æ—¶ï¼ŒéŸ³é¢‘æ–‡ä»¶ä¼šè‡ªåŠ¨åŠ è½½å’Œé‡æ–°é‡‡æ ·ã€‚ä»Žå‰å››ä¸ªæ ·æœ¬ä¸­æå–åŽŸå§‹æ³¢å½¢æ•°ç»„ï¼Œå¹¶å°†å…¶ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™pipelineï¼š result = speech_recognizer(dataset[:4][\"audio\"]) print([d[\"text\"] for d in result]) ['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT'] å¯¹äºŽè¾“å…¥è¾ƒå¤§çš„æ›´å¤§æ•°æ®é›†(å¦‚è¯­éŸ³æˆ–è§†è§‰æ•°æ®)ï¼Œæ‚¨å¯ä»¥å°†ç”Ÿæˆå™¨ä¼ é€’ç»™pipelineï¼Œè€Œä¸æ˜¯å°†å…¶ä½œä¸ºåˆ—è¡¨åŠ è½½åˆ°å†…å­˜ä¸­ åœ¨pipelineä¸­ä½¿ç”¨å…¶ä»–æ¨¡åž‹å’Œåˆ†è¯å™¨pipeline()å¯ä»¥é€‚åº”Hubä¸­çš„ä»»ä½•æ¨¡åž‹ï¼Œè¿™ä½¿å¾—å¯¹pipeline()è¿›è¡Œå…¶ä»–ç”¨é€”çš„è°ƒæ•´å˜å¾—å®¹æ˜“ ä¾‹å¦‚ï¼Œå¦‚æžœæ‚¨æƒ³è¦ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†æ³•è¯­æ–‡æœ¬çš„æ¨¡åž‹ï¼Œè¯·ä½¿ç”¨Hubä¸Šçš„æ ‡ç­¾æ¥è¿‡æ»¤åˆé€‚çš„æ¨¡åž‹ã€‚é€šè¿‡å¯¹è¿‡æ»¤ç»“æžœè¿›è¡ŒæŽ’åºï¼Œæ‚¨å¯ä»¥èŽ·å¾—ä¸€ä¸ªé’ˆå¯¹æ³•è¯­æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æžçš„å¤šè¯­è¨€BERTæ¨¡åž‹ åœ¨pipelineä¸­ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡åž‹å’Œåˆ†è¯å™¨ pipeline()å¯ä»¥é€‚åº”Hubä¸­çš„ä»»ä½•æ¨¡åž‹ï¼Œè¿™ä½¿å¾—å°†pipeline()é€‚åº”å…¶ä»–ç”¨ä¾‹å˜å¾—å®¹æ˜“ from transformers import AutoTokenizer, AutoModelForSequenceClassification model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\" model = AutoModelForSequenceClassification.from_pretrained(model_name) tokenizer = AutoTokenizer.from_pretrained(model_name) classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer) classifier(\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que &#x1F917; Transformers.\") AutoClass AutoClassæ˜¯ä¸€ç§å¿«æ·æ–¹å¼ï¼Œå®ƒå¯ä»¥æ ¹æ®æ¨¡åž‹çš„åç§°æˆ–è·¯å¾„è‡ªåŠ¨èŽ·å–é¢„è®­ç»ƒæ¨¡åž‹çš„æž¶æž„ã€‚æ‚¨åªéœ€è¦é€‰æ‹©ä¸Žæ‚¨çš„ä»»åŠ¡ç›¸åŒ¹é…çš„AutoClasså’Œç›¸åº”çš„é¢„å¤„ç†ç±» AutoTokenizer AutoTokenizeråˆ†è¯å™¨è´Ÿè´£å°†æ–‡æœ¬é¢„å¤„ç†ä¸ºæ¨¡åž‹è¾“å…¥çš„æ•°å­—æ•°ç»„ã€‚æœ‰å¤šä¸ªè§„åˆ™æ¥è§„å®šåˆ†è¯çš„è¿‡ç¨‹ï¼ŒåŒ…æ‹¬å¦‚ä½•æ‹†åˆ†ä¸€ä¸ªå•è¯ä»¥åŠä»¥ä½•ç§çº§åˆ«æ‹†åˆ†å•è¯ æœ€é‡è¦çš„æ˜¯ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ç›¸åŒçš„æ¨¡åž‹åç§°æ¥å®žä¾‹åŒ–ä¸€ä¸ªåˆ†è¯å™¨ï¼Œä»¥ç¡®ä¿æ‚¨ä½¿ç”¨äº†ä¸Žé¢„è®­ç»ƒæ¨¡åž‹ç›¸åŒçš„åˆ†è¯è§„åˆ™ ä½¿ç”¨AutoTokenizeråŠ è½½ä¸€ä¸ªåˆ†è¯å™¨ å°†return_tensorså‚æ•°è®¾ç½®ä¸ºptä»¥è¿”å›žé€‚ç”¨äºŽPyTorchçš„å¼ é‡ï¼Œæˆ–è€…è®¾ç½®ä¸ºtfä»¥è¿”å›žé€‚ç”¨äºŽTensorFlowçš„å¼ é‡ from transformers import AutoTokenizer model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\" tokenizer = AutoTokenizer.from_pretrained(model_name) encoding = tokenizer(\"We are very happy to show you the &#x1F917; Transformers library.\", return_tensors=\"pt\") {'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} tokenizer.decode(encoding[\"input_ids\"]) \"We are very happy to show you the &#x1F917; Transformers library.\" åˆ†è¯å™¨è¿”å›žä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé¡¹ç›®çš„å­—å…¸ï¼š input_idsï¼šè¡¨ç¤ºæ–‡æœ¬ä¸­å„ä¸ªæ ‡è®°çš„æ•°å­— token_type_idsï¼šå¦‚æžœæœ‰å¤šä¸ªåºåˆ—ï¼ŒæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°å±žäºŽå“ªä¸ªåºåˆ— attention_maskï¼šæŒ‡ç¤ºä¸€ä¸ªæ ‡è®°æ˜¯å¦åº”è¯¥è¢«æŽ©ç›–(masked) åˆ†è¯å™¨è¿˜å¯ä»¥æŽ¥å—ä¸€ä¸ªè¾“å…¥åˆ—è¡¨ï¼Œå¹¶å¯¹æ–‡æœ¬è¿›è¡Œå¡«å……å’Œæˆªæ–­ï¼Œä»¥è¿”å›žå…·æœ‰ç»Ÿä¸€é•¿åº¦çš„æ‰¹å¤„ç†æ•°æ® pt_batch = tokenizer( [\"We are very happy to show you the &#x1F917; Transformers library.\", \"We hope you don't hate it.\"], padding=True, truncation=True, max_length=512, return_tensors=\"pt\") pad + truncation # padding batch_sentences = [ \"But what about second breakfast?\", \"Don't think he knows about second breakfast, Pip.\", \"What about elevensies?\", ] encoded_input = tokenizer(batch_sentences, padding=True) {'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0], [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]} # truncation å°†truncationå‚æ•°è®¾ç½®ä¸ºTrueï¼Œå¯ä»¥å°†åºåˆ—æˆªæ–­ä¸ºæ¨¡åž‹æ‰€èƒ½æŽ¥å—çš„æœ€å¤§é•¿åº¦ batch_sentences = [ \"But what about second breakfast?\", \"Don't think he knows about second breakfast, Pip.\", \"What about elevensies?\", ] encoded_input = tokenizer(batch_sentences, padding=True, truncation=True) {'input_ids': [[101, 1252, 1184, 1164, 1248, 6462, 136, 102, 0, 0, 0, 0, 0, 0, 0], [101, 1790, 112, 189, 1341, 1119, 3520, 1164, 1248, 6462, 117, 21902, 1643, 119, 102], [101, 1327, 1164, 5450, 23434, 136, 102, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]} AutoModel &#x1F917;Transformersæä¾›äº†ä¸€ç§ç®€å•è€Œç»Ÿä¸€çš„æ–¹æ³•æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡åž‹å®žä¾‹ã€‚è¿™æ„å‘³ç€æ‚¨å¯ä»¥åƒåŠ è½½AutoTokenizerä¸€æ ·åŠ è½½AutoModel å”¯ä¸€çš„åŒºåˆ«æ˜¯é€‰æ‹©æ­£ç¡®çš„AutoModelæ¥é€‚åº”ä»»åŠ¡ã€‚å¯¹äºŽæ–‡æœ¬(æˆ–åºåˆ—)åˆ†ç±»ï¼Œæ‚¨åº”è¯¥åŠ è½½AutoModelForSequenceClassification from transformers import AutoModelForSequenceClassification model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\" pt_model = AutoModelForSequenceClassification.from_pretrained(model_name) pt_outputs = pt_model(**pt_batch) æ¨¡åž‹å°†æœ€ç»ˆçš„æ¿€æ´»å€¼å­˜å‚¨åœ¨logitså±žæ€§ä¸­ã€‚åº”ç”¨softmaxå‡½æ•°åˆ°logitsä¸Šä»¥èŽ·å–æ¦‚çŽ‡å€¼ from torch import nn pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1) tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725], [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=) åœ¨huggingfaceåº“ä¸­ï¼ŒAutoModelç±»å¯ä»¥æ ¹æ®ç»™å®šçš„checkpointè‡ªåŠ¨é€‰æ‹©å¹¶åŠ è½½é€‚åˆçš„æ¨¡åž‹ã€‚å®ƒæ”¯æŒå„ç§ä¸åŒçš„æ¨¡åž‹æž¶æž„ï¼ŒåŒ…æ‹¬ï¼š AutoModel: ç”¨äºŽé€šç”¨çš„æ¨¡åž‹åŠ è½½ï¼Œæ ¹æ®checkpointè‡ªåŠ¨é€‰æ‹©é€‚åˆçš„æ¨¡åž‹æž¶æž„ AutoModelForSequenceClassification: ç”¨äºŽåºåˆ—åˆ†ç±»ä»»åŠ¡çš„æ¨¡åž‹ï¼Œå¦‚æ–‡æœ¬åˆ†ç±» AutoModelForQuestionAnswering: ç”¨äºŽé—®ç­”ä»»åŠ¡çš„æ¨¡åž‹ï¼Œå¦‚é˜…è¯»ç†è§£ AutoModelForTokenClassification: ç”¨äºŽæ ‡è®°åˆ†ç±»ä»»åŠ¡çš„æ¨¡åž‹ï¼Œå¦‚å‘½åå®žä½“è¯†åˆ« AutoModelForMaskedLM: ç”¨äºŽé®è”½è¯­è¨€å»ºæ¨¡ä»»åŠ¡çš„æ¨¡åž‹ï¼Œå¦‚BERT AutoModelForCausalLM: ç”¨äºŽæœ‰å› æžœå…³ç³»çš„è¯­è¨€å»ºæ¨¡ä»»åŠ¡çš„æ¨¡åž‹ï¼Œå¦‚GPT AutoModelForImageClassification: ç”¨äºŽå›¾åƒåˆ†ç±»ä»»åŠ¡çš„æ¨¡åž‹ï¼Œå¦‚ResNet AutoModelForImageSegmentation: ç”¨äºŽå›¾åƒåˆ†å‰²ä»»åŠ¡çš„æ¨¡åž‹ï¼Œå¦‚Mask R-CNN è¿™äº›ä»…æ˜¯AutoModelç±»çš„ä¸€äº›ç¤ºä¾‹ï¼Œå®žé™…ä¸Šè¿˜æœ‰æ›´å¤šå¯ç”¨çš„æ¨¡åž‹æž¶æž„ã€‚æ‚¨å¯ä»¥æ ¹æ®å…·ä½“çš„ä»»åŠ¡éœ€æ±‚é€‰æ‹©é€‚åˆçš„AutoModelç±»è¿›è¡ŒåŠ è½½å’Œä½¿ç”¨ å…¶ä»–çš„Autoç±» AutoImageProcessor å¯¹äºŽè§†è§‰ä»»åŠ¡ï¼Œå›¾åƒå¤„ç†å™¨å°†å›¾åƒå¤„ç†ä¸ºæ­£ç¡®çš„è¾“å…¥æ ¼å¼ from transformers import AutoImageProcessor image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\") AutoFeatureExtractor å¯¹äºŽéŸ³é¢‘ä»»åŠ¡ï¼Œç‰¹å¾æå–å™¨å°†éŸ³é¢‘ä¿¡å·å¤„ç†ä¸ºæ­£ç¡®çš„è¾“å…¥æ ¼å¼ from transformers import AutoFeatureExtractor feature_extractor = AutoFeatureExtractor.from_pretrained( \"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition\" ) AutoProcessor å¤šæ¨¡æ€ä»»åŠ¡éœ€è¦ä¸€ä¸ªå¤„ç†å™¨æ¥ç»“åˆä¸¤ç§ç±»åž‹çš„é¢„å¤„ç†å·¥å…·ã€‚ä¾‹å¦‚ï¼ŒLayoutLMV2æ¨¡åž‹éœ€è¦ä¸€ä¸ªå›¾åƒå¤„ç†å™¨æ¥å¤„ç†å›¾åƒï¼Œè¿˜éœ€è¦ä¸€ä¸ªåˆ†è¯å™¨æ¥å¤„ç†æ–‡æœ¬ï¼›å¤„ç†å™¨å°†ä¸¤è€…ç»“åˆèµ·æ¥ from transformers import AutoProcessor processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\") æ¨¡åž‹ä¿å­˜ ä¸€æ—¦æ‚¨çš„æ¨¡åž‹ç»è¿‡å¾®è°ƒï¼Œæ‚¨å¯ä»¥ä½¿ç”¨PreTrainedModel.save_pretrained()å°†å…¶ä¸Žå…¶æ ‡è®°å™¨ä¸€èµ·ä¿å­˜èµ·æ¥ï¼š # æ¨¡åž‹+åˆ†è¯å™¨ ä¿å­˜ pt_save_directory = \"./pt_save_pretrained\" tokenizer.save_pretrained(pt_save_directory) pt_model.save_pretrained(pt_save_directory) # åŠ è½½ pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory) AutoConfig æ‚¨å¯ä»¥ä¿®æ”¹æ¨¡åž‹çš„é…ç½®ç±»æ¥æ›´æ”¹æ¨¡åž‹çš„æž„å»ºæ–¹å¼ã€‚é…ç½®ç±»æŒ‡å®šäº†æ¨¡åž‹çš„å±žæ€§ï¼Œä¾‹å¦‚éšè—å±‚çš„æ•°é‡æˆ–æ³¨æ„åŠ›å¤´æ•° å½“æ‚¨ä»Žè‡ªå®šä¹‰é…ç½®ç±»åˆå§‹åŒ–æ¨¡åž‹æ—¶ï¼Œæ‚¨å°†ä»Žå¤´å¼€å§‹ã€‚æ¨¡åž‹çš„å±žæ€§å°†è¢«éšæœºåˆå§‹åŒ–ï¼Œæ‚¨éœ€è¦åœ¨ä½¿ç”¨æ¨¡åž‹ä¹‹å‰å¯¹å…¶è¿›è¡Œè®­ç»ƒä»¥èŽ·å¾—æœ‰æ„ä¹‰çš„ç»“æžœ é¦–å…ˆå¯¼å…¥AutoConfigï¼Œç„¶åŽåŠ è½½è¦ä¿®æ”¹çš„é¢„è®­ç»ƒæ¨¡åž‹ã€‚åœ¨AutoConfig.from_pretrained()ä¸­ï¼Œæ‚¨å¯ä»¥æŒ‡å®šè¦æ›´æ”¹çš„å±žæ€§ï¼Œä¾‹å¦‚æ³¨æ„åŠ›å¤´çš„æ•°é‡ï¼š from transformers import AutoConfig from transformers import AutoModel my_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12) my_model = AutoModel.from_config(my_config) Trainer å¯¹äºŽPyTorchï¼Œæ‰€æœ‰æ¨¡åž‹éƒ½æ˜¯æ ‡å‡†çš„torch.nn.Moduleï¼Œå› æ­¤æ‚¨å¯ä»¥åœ¨ä»»ä½•å…¸åž‹çš„è®­ç»ƒå¾ªçŽ¯ä¸­ä½¿ç”¨å®ƒä»¬ã€‚è™½ç„¶æ‚¨å¯ä»¥ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªçŽ¯ï¼Œä½†&#x1F917;Transformersæä¾›äº†Trainerç±»ï¼Œå…¶ä¸­åŒ…å«åŸºæœ¬çš„è®­ç»ƒå¾ªçŽ¯ï¼Œå¹¶æ·»åŠ äº†å…¶ä»–åŠŸèƒ½ï¼Œå¦‚åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦ç­‰ æ ¹æ®æ‚¨çš„ä»»åŠ¡ï¼Œé€šå¸¸ä¼šå‘Trainerä¼ é€’ä»¥ä¸‹å‚æ•°ï¼š PreTrainedModelæˆ–torch.nn.Moduleå¯¹è±¡ from transformers import AutoModelForSequenceClassification model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\") TrainingArgumentsåŒ…å«äº†å¯ä»¥ä¿®æ”¹çš„æ¨¡åž‹è¶…å‚æ•°ï¼Œæ¯”å¦‚å­¦ä¹ çŽ‡ã€æ‰¹å¤§å°å’Œè®­ç»ƒçš„è½®æ•°ã€‚å¦‚æžœä½ ä¸æŒ‡å®šä»»ä½•è®­ç»ƒå‚æ•°ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ from transformers import TrainingArguments training_args = TrainingArguments( output_dir=\"path/to/save/folder/\", learning_rate=2e-5, per_device_train_batch_size=8, per_device_eval_batch_size=8, num_train_epochs=2, ) Preprocessingç±»ï¼Œä¾‹å¦‚tokenizer(æ ‡è®°å™¨)ã€image processor(å›¾åƒå¤„ç†å™¨)ã€feature extractor(ç‰¹å¾æå–å™¨)æˆ–processor(å¤„ç†å™¨) from transformers import AutoTokenizer tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") åŠ è½½æ•°æ®é›† from datasets import load_dataset dataset = load_dataset(\"rotten_tomatoes\") # doctest: +IGNORE_RESULT åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å¯¹æ•°æ®é›†è¿›è¡Œæ ‡è®°åŒ–å¤„ç†ï¼Œç„¶åŽä½¿ç”¨mapå‡½æ•°å°†å…¶åº”ç”¨äºŽæ•´ä¸ªæ•°æ®é›† def tokenize_dataset(dataset): return tokenizer(dataset[\"text\"]) dataset = dataset.map(tokenize_dataset, batched=True) ä½¿ç”¨DataCollatorWithPaddingæ¥ä»Žæ•°æ®é›†ä¸­åˆ›å»ºä¸€ä¸ªæ‰¹æ¬¡çš„ç¤ºä¾‹ from transformers import DataCollatorWithPadding data_collator = DataCollatorWithPadding(tokenizer=tokenizer) DataCollatorWithPaddingæ˜¯Hugging Faceçš„transformersåº“ä¸­çš„ä¸€ä¸ªç±»ï¼Œç”¨äºŽåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åˆ›å»ºæ‰¹æ¬¡æ•°æ®ã€‚å®ƒçš„ä½œç”¨æ˜¯å°†ä¸åŒé•¿åº¦çš„æ ·æœ¬å¡«å……åˆ°ç›¸åŒé•¿åº¦ï¼Œä»¥ä¾¿èƒ½å¤ŸåŒæ—¶è¿›è¡Œæ‰¹å¤„ç† å…·ä½“æ¥è¯´ï¼ŒDataCollatorWithPaddingä¼šæ ¹æ®ç»™å®šçš„æ•°æ®é›†ï¼Œæ‰¾åˆ°å…¶ä¸­æœ€é•¿çš„æ ·æœ¬ï¼Œå¹¶å°†å…¶ä»–æ ·æœ¬å¡«å……åˆ°ç›¸åŒçš„é•¿åº¦ã€‚å¡«å……é€šå¸¸ä½¿ç”¨ç‰¹å®šçš„å¡«å……ä»¤ç‰Œ(token)æ¥å®Œæˆï¼Œè¿™æ ·æ¨¡åž‹åœ¨å¤„ç†æ—¶å¯ä»¥è¯†åˆ«å‡ºå¡«å……éƒ¨åˆ†ï¼Œå¹¶è¿›è¡Œç›¸åº”çš„å¤„ç† ä½¿ç”¨DataCollatorWithPaddingå¯ä»¥ç¡®ä¿æ‰¹æ¬¡æ•°æ®çš„é•¿åº¦ä¸€è‡´ï¼Œä»Žè€Œæé«˜è®­ç»ƒæ•ˆçŽ‡ï¼Œå¹¶é¿å…ç”±äºŽä¸åŒé•¿åº¦æ ·æœ¬å¯¼è‡´çš„é”™è¯¯ çŽ°åœ¨å°†æ‰€æœ‰è¿™äº›ç±»ç»„åˆåœ¨Trainerä¸­ from transformers import Trainer trainer = Trainer( model=model, args=training_args, train_dataset=dataset[\"train\"], eval_dataset=dataset[\"test\"], tokenizer=tokenizer, data_collator=data_collator, ) # doctest: +SKIP trainer.train() Trainerç±»æä¾›äº†è‡ªå®šä¹‰è®­ç»ƒå¾ªçŽ¯è¡Œä¸ºçš„æ–¹æ³•ï¼Œä½ å¯ä»¥é€šè¿‡ç»§æ‰¿Trainerç±»å¹¶é‡å†™å…¶ä¸­çš„æ–¹æ³•æ¥å®žçŽ°è‡ªå®šä¹‰è¡Œä¸ºã€‚è¿™æ ·ä½ å°±å¯ä»¥å®šåˆ¶è¯¸å¦‚æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ çŽ‡è°ƒåº¦å™¨ç­‰åŠŸèƒ½ã€‚ä½ å¯ä»¥å‚è€ƒTrainerç±»çš„æ–‡æ¡£äº†è§£å¯ä»¥é‡å†™çš„æ–¹æ³• å¦ä¸€ç§å®šåˆ¶è®­ç»ƒå¾ªçŽ¯çš„æ–¹å¼æ˜¯ä½¿ç”¨å›žè°ƒå‡½æ•°(Callbacks)ã€‚ä½ å¯ä»¥ä½¿ç”¨å›žè°ƒå‡½æ•°ä¸Žå…¶ä»–åº“è¿›è¡Œé›†æˆï¼Œç›‘è§†è®­ç»ƒè¿‡ç¨‹å¹¶æŠ¥å‘Šè¿›å±•ï¼Œæˆ–åœ¨å¿…è¦æ—¶æå‰åœæ­¢è®­ç»ƒã€‚å›žè°ƒå‡½æ•°ä¸ä¼šä¿®æ”¹è®­ç»ƒå¾ªçŽ¯æœ¬èº«çš„è¡Œä¸ºã€‚å¦‚æžœä½ éœ€è¦å®šåˆ¶æŸå¤±å‡½æ•°ç­‰å†…å®¹ï¼Œä½ éœ€è¦ç»§æ‰¿Trainerç±»æ¥å®žçŽ° æ•™ç¨‹ æ¨¡åž‹è®­ç»ƒ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹æœ‰å¾ˆå¤šå¥½å¤„ã€‚å®ƒå¯ä»¥å‡å°‘è®¡ç®—æˆæœ¬å’Œç¢³è¶³è¿¹ï¼Œå¹¶ä¸”å¯ä»¥è®©æ‚¨ä½¿ç”¨æœ€å…ˆè¿›çš„æ¨¡åž‹ï¼Œè€Œæ— éœ€ä»Žå¤´å¼€å§‹è®­ç»ƒ &#x1F917;Transformersæä¾›äº†å¯¹å„ç§ä»»åŠ¡çš„æ•°åƒä¸ªé¢„è®­ç»ƒæ¨¡åž‹çš„è®¿é—®ã€‚å½“æ‚¨ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹æ—¶ï¼Œæ‚¨å¯ä»¥åœ¨ç‰¹å®šäºŽæ‚¨ä»»åŠ¡çš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒè®­ç»ƒã€‚è¿™è¢«ç§°ä¸ºå¾®è°ƒï¼Œæ˜¯ä¸€ç§éžå¸¸å¼ºå¤§çš„è®­ç»ƒæŠ€æœ¯ æ•°æ®å‡†å¤‡ from datasets import load_dataset from transformers import AutoTokenizer # 1. åŠ è½½æ•°æ®é›† dataset = load_dataset(\"yelp_review_full\") dataset[\"train\"][100] {'label': 0, 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'} # å¯ä»¥åˆ›å»ºä¸€ä¸ªè¾ƒå°çš„æ•°æ®é›†å­é›†ï¼Œç”¨äºŽå¾®è°ƒï¼Œä»¥å‡å°‘æ‰€éœ€çš„æ—¶é—´ small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000)) small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000)) # 2. åˆ†è¯å™¨ tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\") def tokenize_function(examples): return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True) tokenized_datasets = dataset.map(tokenize_function, batched=True) Train with PyTorch Trainer from transformers import AutoModelForSequenceClassification from transformers import TrainingArguments import numpy as np import evaluate # 1. åŠ è½½æ¨¡åž‹ model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5) # 2. å®šä¹‰è®­ç»ƒå‚æ•° åœ¨è®­ç»ƒå‚æ•°ä¸­æŒ‡å®ševaluation_strategyå‚æ•°ï¼Œä»¥åœ¨æ¯ä¸ªepochç»“æŸæ—¶æŠ¥å‘Šè¯„ä¼°æŒ‡æ ‡ training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\") # 3. åŠ è½½è¯„ä¼°å™¨ metric = evaluate.load(\"accuracy\") # åœ¨è®¡ç®—åº¦é‡æ ‡å‡†çš„æ—¶å€™è°ƒç”¨computeï¼Œä»¥è®¡ç®—æ‚¨çš„é¢„æµ‹çš„å‡†ç¡®çŽ‡ã€‚åœ¨å°†é¢„æµ‹ç»“æžœä¼ é€’ç»™computeä¹‹å‰ï¼Œæ‚¨éœ€è¦å°†é¢„æµ‹ç»“æžœè½¬æ¢ä¸ºlogits def compute_metrics(eval_pred): logits, labels = eval_pred predictions = np.argmax(logits, axis=-1) return metric.compute(predictions=predictions, references=labels) # 4. å®šä¹‰Trainer trainer = Trainer( model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset, compute_metrics=compute_metrics, ) # 5. å¼€å§‹è®­ç»ƒ trainer.train() Train in native PyTorch Trainerè´Ÿè´£è®­ç»ƒå¾ªçŽ¯ï¼Œå¹¶å…è®¸æ‚¨é€šè¿‡ä¸€è¡Œä»£ç å¯¹æ¨¡åž‹è¿›è¡Œå¾®è°ƒã€‚å¯¹äºŽå–œæ¬¢ç¼–å†™è‡ªå·±çš„è®­ç»ƒå¾ªçŽ¯çš„ç”¨æˆ·ï¼Œæ‚¨ä¹Ÿå¯ä»¥åœ¨åŽŸç”ŸPyTorchä¸­å¯¹&#x1F917;Transformersæ¨¡åž‹è¿›è¡Œå¾®è°ƒ from torch.utils.data import DataLoader from transformers import AutoModelForSequenceClassification from torch.optim import AdamW from transformers import get_scheduler import torch from tqdm.auto import tqdm import evaluate # 1. æ•°æ®é›†é¢„å¤„ç† tokenized_datasets = tokenized_datasets.remove_columns([\"text\"]) tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\") tokenized_datasets.set_format(\"torch\") # 2. å®šä¹‰DataLoader train_dataloader = DataLoader(small_train_dataset, shuffle=True, batch_size=8) eval_dataloader = DataLoader(small_eval_dataset, batch_size=8) # 3. åŠ è½½æ¨¡åž‹ model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5) # 4. å®šä¹‰ä¼˜åŒ–å™¨ optimizer = AdamW(model.parameters(), lr=5e-5) # 5. å®šä¹‰scheduler num_epochs = 3 num_training_steps = num_epochs * len(train_dataloader) lr_scheduler = get_scheduler( name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps ) # 6. ç§»åŠ¨æ¨¡åž‹åˆ°æŒ‡å®šè®¾å¤‡ device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") model.to(device) # 7. å¼€å§‹è®­ç»ƒ progress_bar = tqdm(range(num_training_steps)) model.train() for epoch in range(num_epochs): for batch in train_dataloader: batch = {k: v.to(device) for k, v in batch.items()} outputs = model(**batch) loss = outputs.loss loss.backward() optimizer.step() lr_scheduler.step() optimizer.zero_grad() progress_bar.update(1) # 8. éªŒè¯é›†è¯„ä¼° metric = evaluate.load(\"accuracy\") model.eval() for batch in eval_dataloader: batch = {k: v.to(device) for k, v in batch.items()} with torch.no_grad(): outputs = model(**batch) logits = outputs.logits predictions = torch.argmax(logits, dim=-1) metric.add_batch(predictions=predictions, references=batch[\"labels\"]) metric.compute() åˆ†å¸ƒå¼åŠ é€Ÿ huggingfaceçš„accelerateæ¨¡å— &#x1F917;Accelerateæ˜¯Hugging Faceæä¾›çš„ç”¨äºŽç®€åŒ–åˆ†å¸ƒå¼è®­ç»ƒçš„åº“ã€‚å®ƒæ—¨åœ¨ä½¿åˆ†å¸ƒå¼è®­ç»ƒæ›´åŠ å®¹æ˜“å’Œé«˜æ•ˆï¼Œæ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¡†æž¶ï¼ŒåŒ…æ‹¬PyTorchå’ŒTensorFlow Accelerateæä¾›äº†ä»¥ä¸‹åŠŸèƒ½ï¼š æ•°æ®å¹¶è¡Œï¼šAccelerateä½¿ç”¨accelerator.DataParallelç±»æ¥å®žçŽ°æ•°æ®å¹¶è¡Œï¼Œå¯ä»¥åœ¨å¤šä¸ªGPUä¸ŠåŒæ—¶è®­ç»ƒæ¨¡åž‹ æ··åˆç²¾åº¦è®­ç»ƒï¼šAccelerateæ”¯æŒè‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œé€šè¿‡å°†æ¨¡åž‹å‚æ•°å’Œæ¢¯åº¦è½¬æ¢ä¸ºåŠç²¾åº¦æµ®ç‚¹æ•°æ¥å‡å°‘å†…å­˜å ç”¨å’Œè®¡ç®—é‡ åˆ†å¸ƒå¼è®­ç»ƒï¼šAccelerateä½¿ç”¨accelerator.DistributedDataParallelç±»æ¥å®žçŽ°åˆ†å¸ƒå¼è®­ç»ƒï¼Œå¯ä»¥åœ¨å¤šä¸ªæœºå™¨ä¸Šå¹¶è¡Œè®­ç»ƒæ¨¡åž‹ è®­ç»ƒå¾ªçŽ¯çš„è‡ªåŠ¨ç®¡ç†ï¼šAccelerateæä¾›äº†ä¸€ä¸ªaccelerator.Trainerç±»ï¼Œå®ƒå°è£…äº†è®­ç»ƒå¾ªçŽ¯ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®åŠ è½½ã€å‰å‘ä¼ æ’­ã€åå‘ä¼ æ’­ã€ä¼˜åŒ–å™¨æ›´æ–°ç­‰è¿‡ç¨‹ ä½¿ç”¨Accelerateå¯ä»¥ç®€åŒ–åˆ†å¸ƒå¼è®­ç»ƒçš„é…ç½®å’Œç®¡ç†ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ›´è½»æ¾åœ°åˆ©ç”¨å¤šä¸ªGPUæˆ–å¤šå°æœºå™¨è¿›è¡Œè®­ç»ƒï¼Œå¹¶èŽ·å¾—æ›´é«˜çš„è®­ç»ƒæ•ˆçŽ‡ å®‰è£… pip install accelerate ç¤ºä¾‹ä»£ç ï¼Œä»¥ä¸‹ä»£ç åªåˆ—å‡ºæ”¹å˜çš„éƒ¨åˆ†ä»£ç  åªéœ€è¦åœ¨è®­ç»ƒå¾ªçŽ¯ä¸­æ·»åŠ å››è¡Œé¢å¤–çš„ä»£ç å³å¯å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ from accelerate import Accelerator # 1. å®šä¹‰åŠ é€Ÿå™¨ accelerator = Accelerator() # 2. dataloaderåŒ…è£… train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare( train_dataloader, eval_dataloader, model, optimizer ) # 3. åå‘ä¼ æ’­ for epoch in range(num_epochs): for batch in train_dataloader: outputs = model(**batch) loss = outputs.loss accelerator.backward(loss) optimizer.step() lr_scheduler.step() optimizer.zero_grad() progress_bar.update(1) å®Œæ•´ä»£ç å¦‚ä¸‹ + from accelerate import Accelerator from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler + accelerator = Accelerator() model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2) optimizer = AdamW(model.parameters(), lr=3e-5) - device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") - model.to(device) + train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare( + train_dataloader, eval_dataloader, model, optimizer + ) num_epochs = 3 num_training_steps = num_epochs * len(train_dataloader) lr_scheduler = get_scheduler( \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps ) progress_bar = tqdm(range(num_training_steps)) model.train() for epoch in range(num_epochs): for batch in train_dataloader: - batch = {k: v.to(device) for k, v in batch.items()} outputs = model(**batch) loss = outputs.loss - loss.backward() + accelerator.backward(loss) optimizer.step() lr_scheduler.step() optimizer.zero_grad() progress_bar.update(1) ç¤ºä¾‹ä»£ç  åŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³ã€è®¡ç®—æœºè§†è§‰å’Œå¤šæ¨¡æ€ PEFTæ¨¡å— huggingface PEFTæ¨¡å— &#x1F917;PEFTï¼Œå³Parameter-Efficient Fine-Tuning(å‚æ•°é«˜æ•ˆå¾®è°ƒ)ï¼Œæ˜¯ä¸€ä¸ªç”¨äºŽé«˜æ•ˆåœ°å°†é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹(PLM)é€‚åº”äºŽå„ç§ä¸‹æ¸¸åº”ç”¨çš„åº“ï¼Œè€Œæ— éœ€å¯¹æ‰€æœ‰æ¨¡åž‹å‚æ•°è¿›è¡Œå¾®è°ƒ PEFTæ–¹æ³•åªå¾®è°ƒå°‘é‡çš„(é¢å¤–çš„)æ¨¡åž‹å‚æ•°ï¼Œæ˜¾è‘—é™ä½Žäº†è®¡ç®—å’Œå­˜å‚¨æˆæœ¬ï¼Œå› ä¸ºå¯¹å¤§è§„æ¨¡PLMè¿›è¡Œå®Œæ•´å¾®è°ƒä»£ä»·è¿‡é«˜ã€‚æœ€è¿‘çš„æœ€å…ˆè¿›çš„PEFTæŠ€æœ¯è¾¾åˆ°äº†ä¸Žå®Œæ•´å¾®è°ƒç›¸å½“çš„æ€§èƒ½ PEFTä¸Ž&#x1F917;Accelerateåº“æ— ç¼é›†æˆï¼Œç”¨äºŽåˆ©ç”¨DeepSpeedå’ŒBig Model Inferenceè¿›è¡Œå¤§è§„æ¨¡æ¨¡åž‹å¾®è°ƒ Supported methods (æˆªè‡³23-06-15) LoRA: LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS Prefix Tuning: Prefix-Tuning: Optimizing Continuous Prompts for Generation, P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks P-Tuning: GPT Understands, Too Prompt Tuning: The Power of Scale for Parameter-Efficient Prompt Tuning AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention å…¶ä»–æ¨¡å— AutoTrain AutoTrainæ˜¯ä¸€ä¸ªç”¨äºŽè‡ªåŠ¨åŒ–è®­ç»ƒçš„åº“ï¼Œæ—¨åœ¨ç®€åŒ–æ¨¡åž‹è®­ç»ƒçš„è¿‡ç¨‹ã€‚å®ƒæä¾›äº†ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥å®šä¹‰å’Œè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡åž‹ï¼Œè‡ªåŠ¨å¤„ç†æ•°æ®åŠ è½½ã€æ‰¹å¤„ç†ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°ç­‰è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç»†èŠ‚ã€‚é€šè¿‡ä½¿ç”¨AutoTrainï¼Œä½ å¯ä»¥æ›´å¿«é€Ÿåœ°æ­å»ºå’Œè®­ç»ƒæ¨¡åž‹ï¼Œå‡å°‘æ ·æ¿ä»£ç çš„ç¼–å†™ï¼Œå¹¶ä¸”èƒ½å¤Ÿè½»æ¾åœ°è¿›è¡Œè¶…å‚æ•°æœç´¢å’Œæ¨¡åž‹é€‰æ‹© Gradio Gradioæ˜¯ä¸€ä¸ªç”¨äºŽæž„å»ºäº¤äº’å¼ç•Œé¢çš„åº“ï¼Œä½¿ä½ èƒ½å¤Ÿè½»æ¾åœ°ä¸ºä½ çš„æ·±åº¦å­¦ä¹ æ¨¡åž‹åˆ›å»ºWebåº”ç”¨ç¨‹åºã€‚Gradioæä¾›äº†ä¸€ä¸ªç®€å•è€Œå¼ºå¤§çš„APIï¼Œå¯ä»¥å°†æ¨¡åž‹ä¸Žç”¨æˆ·ç•Œé¢ç»„ä»¶(å¦‚æ–‡æœ¬æ¡†ã€æ»‘å—ã€å›¾åƒä¸Šä¼ å™¨ç­‰)ç›¸è¿žæŽ¥ï¼Œä»Žè€Œå®žçŽ°æ¨¡åž‹çš„å®žæ—¶æŽ¨ç†å’Œå¯è§†åŒ–ã€‚é€šè¿‡Gradioï¼Œä½ å¯ä»¥å¿«é€Ÿæž„å»ºä¸€ä¸ªäº¤äº’å¼çš„æ¼”ç¤ºæˆ–éƒ¨ç½²ä½ çš„æ¨¡åž‹åˆ°Webä¸Šï¼Œæ— éœ€ç¼–å†™å¤æ‚çš„å‰ç«¯ä»£ç  Diffusers Diffusersæ˜¯ä¸€ä¸ªç”¨äºŽç”Ÿæˆå›¾åƒã€éŸ³é¢‘ç”šè‡³åˆ†å­çš„ä¸‰ç»´ç»“æž„çš„æœ€æ–°é¢„è®­ç»ƒæ‰©æ•£æ¨¡åž‹çš„åº“ã€‚æ— è®ºæ‚¨æ˜¯å¯»æ‰¾ä¸€ä¸ªç®€å•çš„æŽ¨ç†è§£å†³æ–¹æ¡ˆï¼Œè¿˜æ˜¯æƒ³è¦è®­ç»ƒè‡ªå·±çš„æ‰©æ•£æ¨¡åž‹ï¼Œ&#x1F917;Diffuserséƒ½æ˜¯ä¸€ä¸ªæ”¯æŒä¸¤è€…çš„æ¨¡å—åŒ–å·¥å…·ç®±ã€‚æˆ‘ä»¬çš„åº“ç€é‡äºŽæ˜“ç”¨æ€§è€Œéžæ€§èƒ½ï¼Œç®€æ´è€Œéžå¤æ‚ï¼Œå¯å®šåˆ¶æ€§è€ŒéžæŠ½è±¡æ€§ï¼Œè¯¥åº“ä¸»è¦åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªç»„ä»¶ï¼š æœ€æ–°çš„æ‰©æ•£æŽ¨ç†æµç¨‹ï¼Œåªéœ€å‡ è¡Œä»£ç å³å¯å®žçŽ° å¯äº’æ¢çš„å™ªå£°è°ƒåº¦å™¨ï¼Œç”¨äºŽåœ¨ç”Ÿæˆé€Ÿåº¦å’Œè´¨é‡ä¹‹é—´å¹³è¡¡æƒè¡¡ å¯ç”¨ä½œæž„å»ºå—çš„é¢„è®­ç»ƒæ¨¡åž‹ï¼Œå¯ä»¥ä¸Žè°ƒåº¦å™¨ç»“åˆä½¿ç”¨ï¼Œåˆ›å»ºæ‚¨è‡ªå·±çš„ç«¯åˆ°ç«¯æ‰©æ•£ç³»ç»Ÿ Accelerate Hugging Faceçš„Accelerateæ˜¯ä¸€ä¸ªæ—¨åœ¨ç®€åŒ–å’ŒåŠ é€Ÿæ·±åº¦å­¦ä¹ æ¨¡åž‹è®­ç»ƒå’ŒæŽ¨ç†è¿‡ç¨‹çš„åº“ å®ƒæä¾›äº†ä¸€ä¸ªé«˜çº§APIï¼ŒæŠ½è±¡äº†åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦å’Œæ¢¯åº¦ç´¯ç§¯ç­‰å¤æ‚æ€§ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°å……åˆ†åˆ©ç”¨ç¡¬ä»¶èµ„æºçš„æ½œåŠ› Accelerateå…¼å®¹PyTorchå’ŒTensorFlowï¼Œå¹¶æä¾›äº†ä¸€å¥—å·¥å…·å’Œå®žç”¨ç¨‹åºï¼Œä»¥å®žçŽ°è·¨å¤šä¸ªGPUæˆ–å¤šå°æœºå™¨çš„é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒã€‚å®ƒåŒ…æ‹¬ä»¥ä¸‹åŠŸèƒ½ï¼š åˆ†å¸ƒå¼è®­ç»ƒï¼šAccelerateæä¾›äº†ç®€å•æ˜“ç”¨çš„æŽ¥å£ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿå°†è®­ç»ƒè¿‡ç¨‹åˆ†å¸ƒåˆ°å¤šä¸ªGPUæˆ–å¤šå°æœºå™¨ä¸Šã€‚å®ƒæ”¯æŒå¸¸è§çš„åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ï¼Œå¦‚æ•°æ®å¹¶è¡Œå’Œæ¨¡åž‹å¹¶è¡Œï¼Œå¹¶è‡ªåŠ¨å¤„ç†æ•°æ®çš„åˆ†å‘å’Œæ¢¯åº¦çš„èšåˆï¼Œä½¿ç”¨æˆ·æ— éœ€æ‰‹åŠ¨ç¼–å†™å¤æ‚çš„åˆ†å¸ƒå¼è®­ç»ƒä»£ç  æ··åˆç²¾åº¦è®­ç»ƒï¼šAccelerateæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼Œé€šè¿‡åŒæ—¶ä½¿ç”¨æµ®ç‚¹16ä½å’Œæµ®ç‚¹32ä½ç²¾åº¦æ¥åŠ å¿«æ¨¡åž‹çš„è®­ç»ƒé€Ÿåº¦ã€‚å®ƒè‡ªåŠ¨å¤„ç†æ•°æ®ç±»åž‹è½¬æ¢å’Œæ¢¯åº¦ç¼©æ”¾ï¼Œç”¨æˆ·åªéœ€ç®€å•åœ°æŒ‡å®šä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒå³å¯ æ¢¯åº¦ç´¯ç§¯ï¼šAccelerateæ”¯æŒæ¢¯åº¦ç´¯ç§¯ï¼Œè¿™åœ¨GPUæ˜¾å­˜æœ‰é™çš„æƒ…å†µä¸‹ç‰¹åˆ«æœ‰ç”¨ã€‚æ¢¯åº¦ç´¯ç§¯å…è®¸åœ¨å¤šä¸ªå°æ‰¹æ¬¡ä¸Šç´¯ç§¯æ¢¯åº¦ï¼Œç„¶åŽè¿›è¡Œä¸€æ¬¡å¤§æ‰¹æ¬¡çš„å‚æ•°æ›´æ–°ï¼Œä»Žè€Œå‡å°‘æ˜¾å­˜å ç”¨å¹¶æé«˜è®­ç»ƒæ•ˆçŽ‡ è‡ªåŠ¨è°ƒèŠ‚æ‰¹æ¬¡å¤§å°ï¼šAccelerateå¯ä»¥è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°ä»¥é€‚åº”å¯ç”¨çš„GPUå†…å­˜ã€‚å®ƒä¼šåŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„GPUåˆ©ç”¨çŽ‡å’Œè®­ç»ƒæ€§èƒ½ æ€»ä¹‹ï¼ŒHugging Faceçš„Accelerateæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„åº“ï¼Œæ—¨åœ¨ç®€åŒ–å’ŒåŠ é€Ÿæ·±åº¦å­¦ä¹ æ¨¡åž‹çš„è®­ç»ƒå’ŒæŽ¨ç†è¿‡ç¨‹ã€‚å®ƒæä¾›äº†é«˜çº§APIå’Œä¸€ç³»åˆ—å·¥å…·ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿè½»æ¾åœ°å®žçŽ°åˆ†å¸ƒå¼è®­ç»ƒã€æ··åˆç²¾åº¦è®­ç»ƒå’Œæ¢¯åº¦ç´¯ç§¯ç­‰é«˜æ•ˆè®­ç»ƒç­–ç•¥ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/nlpå…³é”®è¯å’Œæ‘˜è¦æå–æŠ€æœ¯æ•´ç†.html":{"url":"chapters/nlpå…³é”®è¯å’Œæ‘˜è¦æå–æŠ€æœ¯æ•´ç†.html","title":"nlpå…³é”®è¯å’Œæ‘˜è¦æå–æŠ€æœ¯æ•´ç†.md","summary":"nlpå…³é”®è¯å’Œæ‘˜è¦æå–æŠ€æœ¯æ•´ç†","keywords":"","body":"åˆ‡è¯å…³é”®è¯æå–æ¦‚è¿°åˆ†ç±»åŸºäºŽç»Ÿè®¡tf-idfYAKEæ¦‚è¿°åŸºäºŽå›¾æŠ€æœ¯TextRankPageRankå®žçŽ°RAKEåŸºäºŽæ·±åº¦å­¦ä¹ SIFRankSIFæ¨¡åž‹Bert-KPEKeyBertæ¦‚è¿°å¤šæ ·æ€§ç¤ºä¾‹æ‘˜è¦æå– åˆ‡è¯ ç­‰å¾…... å…³é”®è¯æå– è‡ªåŠ¨å…³é”®è¯æŠ½å–ç ”ç©¶ç»¼è¿°2017 ç‰¹å¾é©±åŠ¨çš„å…³é”®è¯æå–ç®—æ³•ç»¼è¿°2018 å…³é”®è¯æå–ç ”ç©¶ç»¼è¿°2021 æ¦‚è¿° æ¦‚å¿µ å…³é”®è¯æå–æŠ€æœ¯æ˜¯ä¸€ç§è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œæ—¨åœ¨ä»Žç»™å®šçš„æ–‡æœ¬ä¸­è‡ªåŠ¨è¯†åˆ«å‡ºæœ€å…·ä»£è¡¨æ€§å’Œé‡è¦æ€§çš„å…³é”®è¯æˆ–çŸ­è¯­ å…³é”®è¯é€šå¸¸æ˜¯æ–‡æœ¬ä¸­å…·æœ‰ç‰¹æ®Šå«ä¹‰ã€èƒ½å¤Ÿæ¦‚æ‹¬æ–‡æœ¬ä¸»é¢˜æˆ–å†…å®¹çš„è¯è¯­æˆ–çŸ­è¯­ ä½¿ç”¨åœºæ™¯ å…³é”®è¯æå–æŠ€æœ¯çš„ç›®æ ‡æ˜¯å¯¹æ–‡æœ¬è¿›è¡Œè¯­ä¹‰åˆ†æžå’Œå†…å®¹æŠ½å–ï¼Œä»Žè€Œæå–å‡ºæœ€èƒ½ä»£è¡¨æ–‡æœ¬ä¸»é¢˜å’Œå†…å®¹çš„å…³é”®è¯ è¿™äº›å…³é”®è¯å¯ä»¥ç”¨äºŽæ–‡æœ¬åˆ†ç±»ã€ä¿¡æ¯æ£€ç´¢ã€æ–‡æœ¬æ‘˜è¦ã€ä¸»é¢˜å»ºæ¨¡ã€ä¿¡æ¯è¿‡æ»¤ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ ç»å…¸æ–¹æ³• å…³é”®è¯æå–æŠ€æœ¯é€šå¸¸ç»“åˆäº†æ–‡æœ¬çš„è¯­è¨€ç»Ÿè®¡ç‰¹å¾ã€è¯é¢‘åˆ†å¸ƒã€è¯æ€§ã€ä¸Šä¸‹æ–‡å…³ç³»ã€è¯­ä¹‰ç›¸ä¼¼åº¦ç­‰å¤šç§ä¿¡æ¯æºï¼Œä»¥è¯†åˆ«å¹¶æå–å‡ºæœ€ç›¸å…³å’Œå…·æœ‰åŒºåˆ†åº¦çš„å…³é”®è¯ å¸¸è§çš„å…³é”®è¯æå–æ–¹æ³•åŒ…æ‹¬åŸºäºŽè¯é¢‘ã€TF-IDFã€æ–‡æœ¬å›¾ç»“æž„ã€è¯­è¨€æ¨¡åž‹ã€å›¾æ¨¡åž‹ã€æ·±åº¦å­¦ä¹ ç­‰å¤šç§æŠ€æœ¯æ‰‹æ®µ å…³é”®è¯æå–æŠ€æœ¯åœ¨ä¿¡æ¯å¤„ç†ã€æ–‡æœ¬æŒ–æŽ˜ã€è‡ªåŠ¨åŒ–æ–‡æ¡£å¤„ç†ç­‰é¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ï¼Œèƒ½å¤Ÿå¸®åŠ©äººä»¬æ›´å¿«é€Ÿã€å‡†ç¡®åœ°ç†è§£å’Œå¤„ç†å¤§é‡æ–‡æœ¬ä¿¡æ¯ åˆ†ç±» NLPä¸­å…³é”®å­—æå–æ–¹æ³•æ€»ç»“å’Œæ¦‚è¿° åŸºäºŽç»Ÿè®¡ ç»Ÿè®¡æ–¹æ³•æ˜¯æœ€ç®€å•çš„ã€‚ä»–ä»¬è®¡ç®—å…³é”®å­—çš„ç»Ÿè®¡æ•°æ®å¹¶ä½¿ç”¨è¿™äº›ç»Ÿè®¡æ•°æ®å¯¹å®ƒä»¬è¿›è¡Œè¯„åˆ†ã€‚ä¸€äº›æœ€ç®€å•çš„ç»Ÿè®¡æ–¹æ³•æ˜¯è¯é¢‘ã€è¯æ­é…å’Œå…±çŽ° ä¹Ÿæœ‰ä¸€äº›æ›´å¤æ‚çš„ï¼Œä¾‹å¦‚TF-IDFå’ŒYAKE! tf-idf æ¦‚è¿° TF-IDFæˆ–term frequencyâ€“inverse document frequencyï¼Œä¼šè®¡ç®—æ–‡æ¡£ä¸­å•è¯ç›¸å¯¹äºŽæ•´ä¸ªè¯­æ–™åº“(æ›´å¤šæ–‡æ¡£é›†)çš„é‡è¦æ€§ å®ƒè®¡ç®—æ–‡æ¡£ä¸­æ¯ä¸ªè¯çš„é¢‘çŽ‡ï¼Œå¹¶é€šè¿‡è¯åœ¨æ•´ä¸ªè¯­æ–™åº“ä¸­çš„é¢‘çŽ‡çš„å€’æ•°å¯¹å…¶è¿›è¡ŒåŠ æƒã€‚æœ€åŽï¼Œé€‰æ‹©å¾—åˆ†æœ€é«˜çš„è¯ä½œä¸ºå…³é”®è¯ï¼ŒTF-IDFæœ‰ä¸¤å±‚æ„æ€ è¯é¢‘: Term Frequencyï¼Œç¼©å†™ä¸ºTFï¼Œé€šå¸¸æ¥è¯´ï¼Œä¸€ä¸ªåˆ†è¯å‡ºçŽ°çš„æ¬¡æ•°è¶Šå¤šï¼Œä»£è¡¨è¶Šé‡è¦ é€†æ–‡æ¡£é¢‘çŽ‡: Inverse Document Frequencyï¼Œç¼©å†™ä¸ºIDFï¼Œåœ¨çŽ°å®žç”Ÿæ´»ä¸­ï¼Œå‡ºçŽ°æ¬¡æ•°æœ€å¤šçš„è¯æ˜¯ä¸€äº›æ— æ„ä¹‰çš„è¯ï¼Œæ¯”å¦‚åœç”¨è¯ï¼Œå¯¹æœç´¢ç»“æžœæ¯«æ— å¸®åŠ©ï¼Œå¿…é¡»é€šè¿‡åˆ†è¯å™¨æå‰è¿‡æ»¤æŽ‰çš„è¯ å…¬å¼ - TF-IDF from scratch in python on a real-world dataset. æœ¯è¯­ t d N corpus é‡Šä¹‰ term(word) document(set of words)ä¸€ç¯‡æ–‡æ¡£ä¸­çš„è¯é›†åˆ count of corpusè¯­æ–™æ•°é‡ the total document setæ€»ä½“æ–‡æ¡£é›†åˆ \\begin{array}{c} tf(t,d) = \\frac{count\\ of\\ t\\ in\\ d}{number\\ of\\ words\\ in\\ d} = \\frac {å•è¯tåœ¨æ–‡æ¡£dä¸­å‡ºçŽ°çš„é¢‘æ¬¡}{æ–‡æ¡£dçš„è¯é¢‘æ€»æ•°} \\\\\\\\ df(t) = occurrence\\ of\\ t\\ in\\ N\\ documents = å•è¯tåœ¨Nç¯‡æ–‡æ¡£ä¸­å¤šå°‘ç¯‡ä¸­å‡ºçŽ° \\\\\\\\ idf(t) = \\frac {N}{df} = log(\\frac {N}{df+1}) \\\\\\\\ tf\\_idf(t, d) = tf(t, d) * idf(t) \\end{array} ä¸€ä¸ªåˆ†è¯Termçš„ç›¸å…³æ€§ç”±tf*idfå…¬å¼ç®€åŒ–è¡¨è¾¾ã€‚tf-idfæ¨¡åž‹åŒ…å«äº†äºŒä¸ªç®€å•äº‹å®žï¼š æŸä¸ªtermåˆ†è¯åœ¨ä¸€ä¸ªæ–‡æ¡£ä¸­å‡ºçŽ°æ¬¡æ•°(tf)è¶Šå¤šï¼Œè¿™ä¸ªè¯ä¸Žæ–‡æ¡£è¶Šç›¸å…³ æŸä¸ªç´¢å¼•ä¸­åŒ…å«æŸä¸ªtermåˆ†è¯çš„æ–‡æ¡£æ•°é‡è¶Šå°‘(idf)ï¼Œè¿™ä¸ªtermåˆ†è¯è¶Šé‡è¦ ä¾‹å­ è€ƒè™‘ä¸€ä¸ªåŒ…å«100ä¸ªå•è¯çš„æ–‡æ¡£ï¼Œå…¶ä¸­Leonè¿™ä¸ªåˆ†è¯å‡ºçŽ°äº†10æ¬¡ã€‚è¿™ä¸ªæ—¶å€™TF=(10/100)=0.1 å¹¶ä¸”å‡è®¾Luceneç´¢å¼•ä¸­æœ‰1000Wä»½æ–‡æ¡£æ•°é‡ï¼Œå…¶ä¸­æœ‰1000ä»½æ–‡æ¡£ä¸­å‡ºçŽ°äº†Leonè¿™ä¸ªåˆ†è¯ï¼Œæ­¤æ—¶é€†æ–‡æ¡£é¢‘çŽ‡(IDF)è®¡ç®—ä¸ºIDF=log(10,000,000/1,000)=4 å› æ­¤ï¼ŒTD-IDFè®¡ç®—ä¸ºTF*IDF=0.1 * 4=0.4 import jieba import jieba.analyse sentence = 'ä¸­åŽèœœèœ‚åŽŸäº§äºŽä¸­å›½ï¼Œæ˜¯ä¸­å›½çš„åœŸè‘—èœ‚ï¼Œé€‚åº”ä¸­å›½å„åœ°çš„æ°”å€™å’Œèœœæºæ¡ä»¶ï¼Œé€‚äºŽå®šåœ°é¥²å…»ä¸”ç¨³äº§ï¼Œå°¤å…¶æ˜¯åœ¨å—æ–¹å±±åŒºï¼Œæœ‰ç€å…¶ä»–èœ‚ç§ä¸å¯æ›¿ä»£çš„åœ°ä½' seg_list = jieba.cut(sentence, cut_all=True) print(\", \".join(seg_list)) keywords = jieba.analyse.extract_tags(sentence, topK=20, withWeight=True, allowPOS=('n', 'nr', 'ns')) print(keywords) >>> ä¸­åŽ, èœœèœ‚, åŽŸäº§, äº§äºŽ, ä¸­å›½, ï¼Œ, æ˜¯, ä¸­å›½, çš„, åœŸè‘—, èœ‚, ï¼Œ, é€‚åº”, ä¸­å›½, å„åœ°, çš„, æ°”å€™, å’Œ, èœœæº, æ¡ä»¶, ï¼Œ, é€‚äºŽ, å®š, åœ°, é¥²å…», ä¸”, ç¨³äº§, ï¼Œ, å°¤å…¶, æ˜¯, åœ¨, å—æ–¹, æ–¹å±±, å±±åŒº, ï¼Œ, æœ‰ç€, å…¶ä»–, èœ‚, ç§, ä¸å¯, æ›¿ä»£, çš„, åœ°ä½ [('å®šåœ°', 0.7969), ('èœ‚ç§', 0.7969), ('ç¨³äº§', 0.7340), ('èœœæº', 0.66725), ('ä¸­å›½', 0.60546), ('èœœèœ‚', 0.5859), ('åœŸè‘—', 0.55968), ('åŽŸäº§', 0.544705), ('æ›¿ä»£', 0.484315), ('å±±åŒº', 0.44390), ('æ°”å€™', 0.38804), ('åœ°ä½', 0.34710), ('æ¡ä»¶', 0.32636)] ä¼˜ç¼ºç‚¹ é€Ÿåº¦å¿«: TF-IDFçš„ä¼˜ç‚¹æ˜¯é€Ÿåº¦å¿« è¯­è¨€æ— å…³: TF-IDFä¸Žè¯­è¨€æ— å…³ éœ€è¦è¯­æ–™: éœ€è¦è‡³å°‘å‡ åä¸ªæ–‡æ¡£çš„è¯­æ–™åº“ ä¸å¤Ÿå…¨é¢: ç¼ºç‚¹æ˜¯å•çº¯äºŽè¯é¢‘æ¥åˆ¤æ–­ä¸€ä¸ªåˆ†è¯çš„é‡è¦æ€§ï¼Œä¸å¤Ÿå…¨é¢ æ— æ³•æ•èŽ·è¯­ä¹‰: ç¼ºç‚¹æ˜¯ä¸èƒ½æ•æ‰åˆ†è¯Termåœ¨æ–‡æ¡£ä¸­çš„ä½ç½® å˜ç§ TF-IDF çš„4å¤§å¸¸è§å˜ç§ å˜ç§1: å¯¹æ•°å‡½æ•°å˜æ¢ TFï¼Œè§£å†³TFçŽ°è¡Œå¢žé•¿é—®é¢˜ å˜ç§2: å¯¹ TF è¿›è¡Œæ ‡å‡†åŒ–ï¼Œè§£å†³é•¿çŸ­æ–‡æ¡£é—®é¢˜ å˜ç§3: å¯¹æ•°å‡½æ•°å˜æ¢ IDFï¼Œè§£å†³IDF çŽ°è¡Œå¢žé•¿é—®é¢˜ å˜ç§4: æŸ¥è¯¢è¯åŠæ–‡æ¡£å‘é‡æ ‡å‡†åŒ–ï¼Œè§£å†³é•¿çŸ­æ–‡æ¡£é—®é¢˜ YAKE 2018ECIRçš„æœ€ä½³çŸ­è®ºæ–‡å¥– A Text Feature Based Automatic Keyword Extraction Method for Single Documents github Yet Another Keyword Extractor (Yake) æ¦‚è¿° YAKE(Yet Another Keyword Extractor)æ˜¯ä¸€ç§å…³é”®å­—æå–æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨å•ä¸ªæ–‡æ¡£çš„ç»Ÿè®¡ç‰¹å¾æ¥æå–å…³é”®å­— å®ƒé€šè¿‡äº”ä¸ªæ­¥éª¤æå–å…³é”®å­—ï¼Œæ—¨åœ¨ä»Žæ–‡æœ¬ä¸­è‡ªåŠ¨æå–æœ€ç›¸å…³çš„å…³é”®è¯å’Œå…³é”®çŸ­è¯­ YAKEç®—æ³•çš„å·¥ä½œåŽŸç†å¦‚ä¸‹ï¼š æ–‡æœ¬é¢„å¤„ç†ï¼šå°†è¾“å…¥æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬åˆ†è¯ã€åŽ»é™¤åœç”¨è¯ç­‰ ç‰¹å¾æå–ï¼šä½¿ç”¨è¯é¢‘ã€ä½ç½®æƒé‡ã€é•¿åº¦ç­‰ç‰¹å¾æ¥è¡¡é‡å•è¯å’ŒçŸ­è¯­çš„é‡è¦æ€§ å…³é”®è¯å€™é€‰ç”Ÿæˆï¼šæ ¹æ®ç‰¹å¾æƒé‡ï¼Œç”Ÿæˆå€™é€‰å…³é”®è¯å’Œå…³é”®çŸ­è¯­ å…³é”®è¯æƒé‡è®¡ç®—ï¼šæ ¹æ®å€™é€‰å…³é”®è¯çš„ç‰¹å¾æƒé‡ï¼Œè®¡ç®—å®ƒä»¬çš„æœ€ç»ˆæƒé‡ å…³é”®è¯ç­›é€‰ï¼šæ ¹æ®è®¾å®šçš„é˜ˆå€¼æˆ–æŽ’åºæ–¹æ³•ï¼Œç­›é€‰å‡ºå…·æœ‰é«˜æƒé‡çš„å…³é”®è¯å’Œå…³é”®çŸ­è¯­ä½œä¸ºæœ€ç»ˆç»“æžœ YAKEç®—æ³•ä¸Žä¼ ç»Ÿçš„åŸºäºŽç»Ÿè®¡å’Œè¯­è¨€æ¨¡åž‹çš„å…³é”®è¯æå–æ–¹æ³•ä¸åŒï¼Œå®ƒé‡‡ç”¨äº†åŸºäºŽç‰¹å¾æƒé‡çš„æ–¹æ³•ï¼Œä½¿å¾—ç®—æ³•æ›´åŠ çµæ´»å’Œå¯å®šåˆ¶ æ­¤å¤–ï¼ŒYAKEè¿˜æ”¯æŒå¤šè¯­è¨€å…³é”®è¯æå–ï¼Œå¹¶èƒ½å¤Ÿå¤„ç†é¢†åŸŸç‰¹å®šçš„æ–‡æœ¬ æ€»ä½“è€Œè¨€ï¼ŒYAKEç®—æ³•é€šè¿‡ç»¼åˆè€ƒè™‘å•è¯å’ŒçŸ­è¯­çš„ç‰¹å¾æƒé‡ï¼Œä»¥åŠå®ƒä»¬åœ¨æ–‡æœ¬ä¸­çš„é¢‘çŽ‡å’Œä½ç½®ç­‰ä¿¡æ¯ï¼Œæ¥æå–ä¸Žæ–‡æœ¬å†…å®¹ç›¸å…³çš„å…³é”®è¯å’Œå…³é”®çŸ­è¯­ å®˜æ–¹å®žçŽ°ä»…æ”¯æŒè‹±æ–‡ åŸºäºŽå›¾æŠ€æœ¯ TextRank TextRankç®—æ³•ä»‹ç»åŠå®žçŽ° TextRankæ˜¯ä¸€ç§åŸºäºŽå›¾çš„ç®—æ³•ï¼Œç”¨äºŽå…³é”®è¯æå–å’Œæ–‡æœ¬æ‘˜è¦ã€‚å®ƒåŸºäºŽPageRankç®—æ³•çš„æ€æƒ³ï¼Œå°†æ–‡æœ¬è¡¨ç¤ºä¸ºä¸€ä¸ªå›¾ï¼Œå…¶ä¸­èŠ‚ç‚¹è¡¨ç¤ºæ–‡æœ¬ä¸­çš„å•è¯æˆ–çŸ­è¯­ï¼Œè¾¹è¡¨ç¤ºå®ƒä»¬ä¹‹é—´çš„å…³ç³» é€šè¿‡è®¡ç®—èŠ‚ç‚¹ä¹‹é—´çš„æƒé‡å’Œè¿žæŽ¥å…³ç³»ï¼ŒTextRankå¯ä»¥ç¡®å®šæ–‡æœ¬ä¸­æœ€é‡è¦çš„å•è¯æˆ–çŸ­è¯­ã€‚ TextRankçš„æ­¥éª¤å¦‚ä¸‹ï¼š åˆ†å‰²æ–‡æœ¬ï¼šå°†æ–‡æœ¬åˆ†å‰²æˆå¥å­æˆ–å•è¯ æž„å»ºå›¾ï¼šæ ¹æ®æ–‡æœ¬ä¸­çš„å¥å­æˆ–å•è¯æž„å»ºä¸€ä¸ªå›¾ï¼Œå…¶ä¸­æ¯ä¸ªå¥å­æˆ–å•è¯ä½œä¸ºä¸€ä¸ªèŠ‚ç‚¹ï¼Œè¾¹è¡¨ç¤ºå®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚å¸¸è§çš„å…³ç³»å¯ä»¥æ˜¯å…±çŽ°å…³ç³»æˆ–è¯­ä¹‰å…³ç³» è®¡ç®—æƒé‡ï¼šä¸ºå›¾ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹è®¡ç®—æƒé‡ã€‚é€šå¸¸ä½¿ç”¨è¯é¢‘æˆ–TF-IDFä½œä¸ºåˆå§‹æƒé‡ è¿­ä»£è®¡ç®—ï¼šé€šè¿‡è¿­ä»£è®¡ç®—èŠ‚ç‚¹ä¹‹é—´çš„æƒé‡ï¼Œæ›´æ–°æ¯ä¸ªèŠ‚ç‚¹çš„æƒé‡å€¼ã€‚è¿­ä»£è¿‡ç¨‹ä¸­ï¼ŒèŠ‚ç‚¹çš„æƒé‡å°†è€ƒè™‘å…¶ç›¸é‚»èŠ‚ç‚¹çš„æƒé‡å€¼ æŽ’åºèŠ‚ç‚¹ï¼šæ ¹æ®èŠ‚ç‚¹çš„æƒé‡å€¼å¯¹èŠ‚ç‚¹è¿›è¡ŒæŽ’åºï¼Œå¾—åˆ°å…³é”®è¯æˆ–æ‘˜è¦ TextRankç®—æ³•åœ¨å…³é”®è¯æå–å’Œæ–‡æœ¬æ‘˜è¦ç­‰ä»»åŠ¡ä¸­è¡¨çŽ°è‰¯å¥½ï¼Œå®ƒä¸éœ€è¦ä¾èµ–é¢„è®­ç»ƒæ¨¡åž‹ï¼Œå¯ä»¥ç›´æŽ¥åº”ç”¨äºŽå„ç§é¢†åŸŸçš„æ–‡æœ¬å¤„ç†ä»»åŠ¡ PageRank The PageRank Citation Ranking: Bringing Order to the Web 1999 å…³é”®è¯æå–å’Œæ‘˜è¦ç®—æ³•TextRankè¯¦è§£ä¸Žå®žæˆ˜ PageRankç®—æ³•é€šè¿‡è®¡ç®—ç½‘é¡µé“¾æŽ¥çš„æ•°é‡å’Œè´¨é‡æ¥ç²—ç•¥ä¼°è®¡ç½‘é¡µçš„é‡è¦æ€§ï¼Œç®—æ³•åˆ›ç«‹ä¹‹åˆå³åº”ç”¨åœ¨è°·æ­Œçš„æœç´¢å¼•æ“Žä¸­ï¼Œå¯¹ç½‘é¡µè¿›è¡ŒæŽ’åã€‚ PageRankç®—æ³•çš„æ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š é“¾æŽ¥æ•°é‡ï¼šå¦‚æžœä¸€ä¸ªç½‘é¡µè¢«è¶Šå¤šçš„å…¶ä»–ç½‘é¡µé“¾æŽ¥ï¼Œè¯´æ˜Žè¿™ä¸ªç½‘é¡µè¶Šé‡è¦ï¼Œå³è¯¥ç½‘é¡µçš„PRå€¼(PageRankå€¼)ä¼šç›¸å¯¹è¾ƒé«˜ é“¾æŽ¥è´¨é‡ï¼šå¦‚æžœä¸€ä¸ªç½‘é¡µè¢«ä¸€ä¸ªè¶Šé«˜æƒå€¼çš„ç½‘é¡µé“¾æŽ¥ï¼Œä¹Ÿèƒ½è¡¨æ˜Žè¿™ä¸ªç½‘é¡µè¶Šé‡è¦ï¼Œå³ä¸€ä¸ªPRå€¼å¾ˆé«˜çš„ç½‘é¡µé“¾æŽ¥åˆ°ä¸€ä¸ªå…¶ä»–ç½‘é¡µï¼Œé‚£ä¹ˆè¢«é“¾æŽ¥åˆ°çš„ç½‘é¡µçš„PRå€¼ä¼šç›¸åº”åœ°å› æ­¤è€Œæé«˜ PageRankç®—æ³•è®¡ç®—å…¬å¼ S\\left(V_{i}\\right)=(1-\\mathrm{d})+\\mathrm{d} * \\sum_{j \\in \\operatorname{In}\\left(V_{i}\\right)} \\frac{1}{\\left|O u t\\left(V_{j}\\right)\\right|} S\\left(V_{j}\\right) å…¶ä¸­ï¼ŒS\\left(V_{i}\\right)æ˜¯ç½‘é¡µiçš„é‡è¦æ€§(PRå€¼)ï¼Œ\\mathrm{d}æ˜¯é˜»å°¼ç³»æ•°ï¼Œä¸€èˆ¬ä¸º0.85ï¼Œ\\operatorname{In}\\left(V_{i}\\right)æ˜¯æ•´ä¸ªäº’è”ç½‘ä¸­æ‰€å­˜åœ¨çš„æœ‰æŒ‡åŒç½‘é¡µiçš„é“¾æŽ¥çš„ç½‘é¡µé›†åˆï¼ŒOut\\left(V_{j}\\right)æ˜¯ç½‘é¡µjä¸­å­˜åœ¨çš„æŒ‡å‘æ‰€æœ‰å¤–éƒ¨ç½‘é¡µçš„é“¾è¾–çš„é›†åˆï¼Œ|Out \\left(V_{j}\\right) \\midæ˜¯è¯¥é›†åˆä¸­å…ƒç´ çš„ä¸ªæ•° ä¾‹å­ ç­‰å¾…... PageRankç®—æ³•ä¸ŽTextRankç®—æ³•çš„åŒºåˆ« PageRankç®—æ³•æ ¹æ®ç½‘é¡µä¹‹é—´çš„é“¾æŽ¥å…³ç³»æž„é€ ç½‘ç»œï¼ŒTextRankç®—æ³•æ ¹æ®è¯ä¹‹é—´çš„å…±çŽ°å…³ç³»æž„é€ ç½‘ç»œ PageRankç®—æ³•æž„é€ çš„ç½‘ç»œä¸­çš„è¾¹æ˜¯æœ‰å‘æ— æƒè¾¹ï¼ŒTextRankç®—æ³•æž„é€ çš„ç½‘ç»œä¸­çš„è¾¹æ˜¯æ— å‘æœ‰æƒè¾¹ å®žçŽ° åŸºäºŽTextrank4zhçš„TextRankç®—æ³•å®žçŽ° from textrank4zh import TextRank4Keyword, TextRank4Sentence import jieba.analyse from snownlp import SnowNLP import pandas as pd import numpy as np #å…³é”®è¯æŠ½å– def keywords_extraction(text): tr4w = TextRank4Keyword(allow_speech_tags=['n', 'nr', 'nrfg', 'ns', 'nt', 'nz']) # allow_speech_tags --è¯æ€§åˆ—è¡¨ï¼Œç”¨äºŽè¿‡æ»¤æŸäº›è¯æ€§çš„è¯ tr4w.analyze(text=text, window=2, lower=True, vertex_source='all_filters', edge_source='no_stop_words', pagerank_config={'alpha': 0.85, }) # text -- æ–‡æœ¬å†…å®¹ï¼Œå­—ç¬¦ä¸² # window -- çª—å£å¤§å°ï¼Œintï¼Œç”¨æ¥æž„é€ å•è¯ä¹‹é—´çš„è¾¹ã€‚é»˜è®¤å€¼ä¸º2 # lower -- æ˜¯å¦å°†è‹±æ–‡æ–‡æœ¬è½¬æ¢ä¸ºå°å†™ï¼Œé»˜è®¤å€¼ä¸ºFalse # vertex_source -- é€‰æ‹©ä½¿ç”¨words_no_filter, words_no_stop_words, words_all_filtersä¸­çš„å“ªä¸€ä¸ªæ¥æž„é€ pagerankå¯¹åº”çš„å›¾ä¸­çš„èŠ‚ç‚¹ # -- é»˜è®¤å€¼ä¸º`'all_filters'`ï¼Œå¯é€‰å€¼ä¸º`'no_filter', 'no_stop_words', 'all_filters' # edge_source -- é€‰æ‹©ä½¿ç”¨words_no_filter, words_no_stop_words, words_all_filtersä¸­çš„å“ªä¸€ä¸ªæ¥æž„é€ pagerankå¯¹åº”çš„å›¾ä¸­çš„èŠ‚ç‚¹ä¹‹é—´çš„è¾¹ # -- é»˜è®¤å€¼ä¸º`'no_stop_words'`ï¼Œå¯é€‰å€¼ä¸º`'no_filter', 'no_stop_words', 'all_filters'`ã€‚è¾¹çš„æž„é€ è¦ç»“åˆ`window`å‚æ•° # pagerank_config -- pagerankç®—æ³•å‚æ•°é…ç½®ï¼Œé˜»å°¼ç³»æ•°ä¸º0.85 keywords = tr4w.get_keywords(num=6, word_min_len=2) # num -- è¿”å›žå…³é”®è¯æ•°é‡ # word_min_len -- è¯çš„æœ€å°é•¿åº¦ï¼Œé»˜è®¤å€¼ä¸º1 return keywords #å…³é”®çŸ­è¯­æŠ½å– def keyphrases_extraction(text): tr4w = TextRank4Keyword() tr4w.analyze(text=text, window=2, lower=True, vertex_source='all_filters', edge_source='no_stop_words', pagerank_config={'alpha': 0.85, }) keyphrases = tr4w.get_keyphrases(keywords_num=6, min_occur_num=1) # keywords_num -- æŠ½å–çš„å…³é”®è¯æ•°é‡ # min_occur_num -- å…³é”®çŸ­è¯­åœ¨æ–‡ä¸­çš„æœ€å°‘å‡ºçŽ°æ¬¡æ•° return keyphrases #å…³é”®å¥æŠ½å– def keysentences_extraction(text): tr4s = TextRank4Sentence() tr4s.analyze(text, lower=True, source='all_filters') # text -- æ–‡æœ¬å†…å®¹ï¼Œå­—ç¬¦ä¸² # lower -- æ˜¯å¦å°†è‹±æ–‡æ–‡æœ¬è½¬æ¢ä¸ºå°å†™ï¼Œé»˜è®¤å€¼ä¸ºFalse # source -- é€‰æ‹©ä½¿ç”¨words_no_filter, words_no_stop_words, words_all_filtersä¸­çš„å“ªä¸€ä¸ªæ¥ç”Ÿæˆå¥å­ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚ # -- é»˜è®¤å€¼ä¸º`'all_filters'`ï¼Œå¯é€‰å€¼ä¸º`'no_filter', 'no_stop_words', 'all_filters' # sim_func -- æŒ‡å®šè®¡ç®—å¥å­ç›¸ä¼¼åº¦çš„å‡½æ•° # èŽ·å–æœ€é‡è¦çš„numä¸ªé•¿åº¦å¤§äºŽç­‰äºŽsentence_min_lençš„å¥å­ç”¨æ¥ç”Ÿæˆæ‘˜è¦ keysentences = tr4s.get_key_sentences(num=3, sentence_min_len=6) return keysentences def keywords_textrank(text): keywords = jieba.analyse.textrank(text, topK=6) return keywords if __name__ == \"__main__\": text = \"æ¥æºï¼šä¸­å›½ç§‘å­¦æŠ¥æœ¬æŠ¥è®¯ï¼ˆè®°è€…è‚–æ´ï¼‰åˆæœ‰ä¸€ä½ä¸­å›½ç§‘å­¦å®¶å–œèŽ·å°è¡Œæ˜Ÿå‘½åæ®Šè£ï¼4æœˆ19æ—¥ä¸‹åˆï¼Œä¸­å›½ç§‘å­¦é™¢å›½å®¶å¤©æ–‡å°åœ¨äº¬ä¸¾è¡Œâ€œå‘¨åˆå…ƒæ˜Ÿâ€é¢æŽˆä»ªå¼ï¼Œ\" \\ \"æˆ‘å›½å¤©æ–‡å­¦å®¶ã€ä¸­å›½ç§‘å­¦é™¢é™¢å£«å‘¨åˆå…ƒçš„å¼Ÿå­ä¸ŽåŽè¾ˆåœ¨æ¬¢å£°ç¬‘è¯­ä¸­æµŽæµŽä¸€å ‚ã€‚å›½å®¶å¤©æ–‡å°å…šå§”ä¹¦è®°ã€\" \\ \"å‰¯å°é•¿èµµåˆšåœ¨è‡´è¾žä¸€å¼€å§‹æ›´æ˜¯é€ä¸Šç™½å±…æ˜“çš„è¯—å¥ï¼šâ€œä»¤å…¬æ¡ƒæŽæ»¡å¤©ä¸‹ï¼Œä½•é¡»å ‚å‰æ›´ç§èŠ±ã€‚â€\" \\ \"æ®ä»‹ç»ï¼Œè¿™é¢—å°è¡Œæ˜Ÿç”±å›½å®¶å¤©æ–‡å°æ–½å¯†ç‰¹CCDå°è¡Œæ˜Ÿé¡¹ç›®ç»„äºŽ1997å¹´9æœˆ26æ—¥å‘çŽ°äºŽå…´éš†è§‚æµ‹ç«™ï¼Œ\" \\ \"èŽ·å¾—å›½é™…æ°¸ä¹…ç¼–å·ç¬¬120730å·ã€‚2018å¹´9æœˆ25æ—¥ï¼Œç»å›½å®¶å¤©æ–‡å°ç”³æŠ¥ï¼Œ\" \\ \"å›½é™…å¤©æ–‡å­¦è”åˆä¼šå°å¤©ä½“è”åˆä¼šå°å¤©ä½“å‘½åå§”å‘˜ä¼šæ‰¹å‡†ï¼Œå›½é™…å¤©æ–‡å­¦è”åˆä¼šã€Šå°è¡Œæ˜Ÿé€šæŠ¥ã€‹é€šçŸ¥å›½é™…ç¤¾ä¼šï¼Œ\" \\ \"æ­£å¼å°†è¯¥å°è¡Œæ˜Ÿå‘½åä¸ºâ€œå‘¨åˆå…ƒæ˜Ÿâ€ã€‚\" #å…³é”®è¯æŠ½å– keywords=keywords_extraction(text) print(keywords) #å…³é”®çŸ­è¯­æŠ½å– keyphrases=keyphrases_extraction(text) print(keyphrases) #å…³é”®å¥æŠ½å– keysentences=keysentences_extraction(text) print(keysentences) >>> [{'word': 'å°è¡Œæ˜Ÿ', 'weight': 0.05808}, {'word': 'å¤©æ–‡å°', 'weight': 0.05721}, {'word': 'å‘½å', 'weight': 0.048517}, {'word': 'ä¸­å›½', 'weight': 0.045716}, {'word': 'ä¸­å›½ç§‘å­¦é™¢', 'weight': 0.037818}, {'word': 'å›½å®¶', 'weight': 0.03438}] ['å°è¡Œæ˜Ÿå‘½å'] [{'index': 4, 'sentence': '2018å¹´9æœˆ25æ—¥ï¼Œç»å›½å®¶å¤©æ–‡å°ç”³æŠ¥ï¼Œå›½é™…å¤©æ–‡å­¦è”åˆä¼šå°å¤©ä½“è”åˆä¼šå°å¤©ä½“å‘½åå§”å‘˜ä¼šæ‰¹å‡†ï¼Œå›½é™…å¤©æ–‡å­¦è”åˆä¼šã€Šå°è¡Œæ˜Ÿé€šæŠ¥ã€‹é€šçŸ¥å›½é™…ç¤¾ä¼šï¼Œæ­£å¼å°†è¯¥å°è¡Œæ˜Ÿå‘½åä¸ºâ€œå‘¨åˆå…ƒæ˜Ÿâ€', 'weight': 0.2281}, {'index': 3, 'sentence': 'â€æ®ä»‹ç»ï¼Œè¿™é¢—å°è¡Œæ˜Ÿç”±å›½å®¶å¤©æ–‡å°æ–½å¯†ç‰¹CCDå°è¡Œæ˜Ÿé¡¹ç›®ç»„äºŽ1997å¹´9æœˆ26æ—¥å‘çŽ°äºŽå…´éš†è§‚æµ‹ç«™ï¼ŒèŽ·å¾—å›½é™…æ°¸ä¹…ç¼–å·ç¬¬120730å·', 'weight': 0.2106}, {'index': 1, 'sentence': '4æœˆ19æ—¥ä¸‹åˆï¼Œä¸­å›½ç§‘å­¦é™¢å›½å®¶å¤©æ–‡å°åœ¨äº¬ä¸¾è¡Œâ€œå‘¨åˆå…ƒæ˜Ÿâ€é¢æŽˆä»ªå¼ï¼Œæˆ‘å›½å¤©æ–‡å­¦å®¶ã€ä¸­å›½ç§‘å­¦é™¢é™¢å£«å‘¨åˆå…ƒçš„å¼Ÿå­ä¸ŽåŽè¾ˆåœ¨æ¬¢å£°ç¬‘è¯­ä¸­æµŽæµŽä¸€å ‚', 'weight': 0.20209}] åŸºäºŽjiebaçš„TextRankç®—æ³•å®žçŽ° if __name__ == \"__main__\": text = \"æ¥æºï¼šä¸­å›½ç§‘å­¦æŠ¥æœ¬æŠ¥è®¯ï¼ˆè®°è€…è‚–æ´ï¼‰åˆæœ‰ä¸€ä½ä¸­å›½ç§‘å­¦å®¶å–œèŽ·å°è¡Œæ˜Ÿå‘½åæ®Šè£ï¼4æœˆ19æ—¥ä¸‹åˆï¼Œä¸­å›½ç§‘å­¦é™¢å›½å®¶å¤©æ–‡å°åœ¨äº¬ä¸¾è¡Œâ€œå‘¨åˆå…ƒæ˜Ÿâ€é¢æŽˆä»ªå¼ï¼Œ\" \\ \"æˆ‘å›½å¤©æ–‡å­¦å®¶ã€ä¸­å›½ç§‘å­¦é™¢é™¢å£«å‘¨åˆå…ƒçš„å¼Ÿå­ä¸ŽåŽè¾ˆåœ¨æ¬¢å£°ç¬‘è¯­ä¸­æµŽæµŽä¸€å ‚ã€‚å›½å®¶å¤©æ–‡å°å…šå§”ä¹¦è®°ã€\" \\ \"å‰¯å°é•¿èµµåˆšåœ¨è‡´è¾žä¸€å¼€å§‹æ›´æ˜¯é€ä¸Šç™½å±…æ˜“çš„è¯—å¥ï¼šâ€œä»¤å…¬æ¡ƒæŽæ»¡å¤©ä¸‹ï¼Œä½•é¡»å ‚å‰æ›´ç§èŠ±ã€‚â€\" \\ \"æ®ä»‹ç»ï¼Œè¿™é¢—å°è¡Œæ˜Ÿç”±å›½å®¶å¤©æ–‡å°æ–½å¯†ç‰¹CCDå°è¡Œæ˜Ÿé¡¹ç›®ç»„äºŽ1997å¹´9æœˆ26æ—¥å‘çŽ°äºŽå…´éš†è§‚æµ‹ç«™ï¼Œ\" \\ \"èŽ·å¾—å›½é™…æ°¸ä¹…ç¼–å·ç¬¬120730å·ã€‚2018å¹´9æœˆ25æ—¥ï¼Œç»å›½å®¶å¤©æ–‡å°ç”³æŠ¥ï¼Œ\" \\ \"å›½é™…å¤©æ–‡å­¦è”åˆä¼šå°å¤©ä½“è”åˆä¼šå°å¤©ä½“å‘½åå§”å‘˜ä¼šæ‰¹å‡†ï¼Œå›½é™…å¤©æ–‡å­¦è”åˆä¼šã€Šå°è¡Œæ˜Ÿé€šæŠ¥ã€‹é€šçŸ¥å›½é™…ç¤¾ä¼šï¼Œ\" \\ \"æ­£å¼å°†è¯¥å°è¡Œæ˜Ÿå‘½åä¸ºâ€œå‘¨åˆå…ƒæ˜Ÿâ€ã€‚\" # åŸºäºŽjiebaçš„textrankç®—æ³•å®žçŽ° keywords=keywords_textrank(text) print(keywords) >>> ['å°è¡Œæ˜Ÿ', 'å‘½å', 'å›½é™…', 'ä¸­å›½', 'å›½å®¶', 'å¤©æ–‡å­¦å®¶'] RAKE RAKEå’ŒTextRankçš„ä¸»è¦åŒºåˆ«åœ¨äºŽRAKEè€ƒè™‘å€™é€‰å…³é”®å­—å†…çš„å…±çŽ°è€Œä¸æ˜¯å›ºå®šçª—å£ã€‚å®ƒä½¿ç”¨æ›´ç®€å•ã€æ›´å…·ç»Ÿè®¡æ€§çš„è¯„åˆ†ç¨‹åºã€‚è¯¥ç®—æ³•å¯¹æ¯ä¸ªæ–‡æ¡£åˆ†åˆ«è¿›è¡Œï¼Œå› æ­¤ä¸éœ€è¦æ–‡æ¡£è¯­æ–™åº“æ¥è¿›è¡Œå…³é”®è¯æå– åŸºäºŽæ·±åº¦å­¦ä¹  æ·±åº¦å­¦ä¹ çš„å‡ºçŽ°ä½¿åŸºäºŽåµŒå…¥çš„æ–¹æ³•æˆä¸ºå¯èƒ½ã€‚ç ”ç©¶äººå‘˜å¼€å‘äº†å‡ ç§ä½¿ç”¨æ–‡æ¡£åµŒå…¥çš„å…³é”®å­—æå–æ–¹æ³•(ä¾‹å¦‚Bennaniç­‰äºº) è¿™äº›æ–¹æ³•ä¸»è¦æŸ¥æ‰¾å€™é€‰å…³é”®å­—åˆ—è¡¨(ä¾‹å¦‚ï¼ŒBennaniç­‰äººåªè€ƒè™‘ç”±åè¯å’Œå½¢å®¹è¯ç»„æˆçš„å…³é”®å­—) ä»–ä»¬å°†æ–‡æ¡£å’Œå€™é€‰å…³é”®å­—åµŒå…¥åˆ°ç›¸åŒçš„åµŒå…¥ç©ºé—´ä¸­ï¼Œå¹¶æµ‹é‡æ–‡æ¡£å’Œå…³é”®å­—åµŒå…¥ä¹‹é—´çš„ç›¸ä¼¼åº¦(ä¾‹å¦‚ä½™å¼¦ç›¸ä¼¼åº¦)ã€‚ä»–ä»¬æ ¹æ®ç›¸ä¼¼åº¦åº¦é‡é€‰æ‹©ä¸Žæ–‡æ¡£æ–‡æœ¬æœ€ç›¸ä¼¼çš„å…³é”®å­— SIFRank SIFRank: A New Baseline for Unsupervised Keyphrase Extraction Based on Pre-Trained Language Model 2019 è®ºæ–‡é˜…è¯»ç¬”è®°ï¼š SIFRank and BERT-KPE github sunyilgdx/SIFRank_zh SIFRankæ¯”è¾ƒé€‚åˆçŸ­æ–‡æœ¬çš„å…³é”®è¯æŠ½å–ï¼Œè€ŒSIFRank+å¤§å¹…å¢žåŠ äº†é•¿æ–‡æœ¬çš„å…³é”®è¯æŠ½å–æ•ˆæžœ æ­¥éª¤ äººå·¥æ ‡æ³¨ï¼šåˆ†è¯+æ ‡è¯æ€§ èŽ·å–å€™é€‰å…³é”®è¯åˆ—è¡¨ï¼šåˆ©ç”¨æ­£åˆ™è¡¨è¾¾å¼ç¡®å®šåè¯çŸ­è¯­(ä¾‹å¦‚ï¼šå½¢å®¹è¯+åè¯)ï¼Œå°†åè¯çŸ­è¯­ä½œä¸ºå€™é€‰å…³é”®çŸ­è¯­ é€šè¿‡é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹ï¼Œå¾—åˆ°å…³é”®è¯çš„embedding åŒæ ·åœ°ï¼Œå¾—åˆ°å¥å­æˆ–æ–‡æ¡£çš„embedding è®¡ç®—3ä¸Ž4ç»“æžœçš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œé€‰å–topNä½œä¸ºå…¶æœ€ç»ˆæå–çš„å…³é”®è¯ NP chunker åœ¨SIFRankæ–¹æ³•ä¸­ï¼ŒNP chunkeræ˜¯ä¸€ç§ç”¨äºŽè¯†åˆ«å’Œæå–åè¯çŸ­è¯­(Noun Phrase)çš„å·¥å…·æˆ–ç»„ä»¶ã€‚NP chunkerçš„ç›®æ ‡æ˜¯ä»Žç»™å®šçš„æ–‡æœ¬ä¸­å®šä½å’Œæå–å‡ºåŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªåè¯çš„çŸ­è¯­ã€‚åè¯çŸ­è¯­é€šå¸¸ç”±ä¸€ä¸ªåè¯ä½œä¸ºæ ¸å¿ƒè¯ï¼Œå¹¶å¯èƒ½åŒ…å«å…¶ä»–ä¿®é¥°è¯æˆ–é™å®šè¯ NP chunkerä½¿ç”¨ä¸€ç³»åˆ—è¯­æ³•è§„åˆ™æˆ–æœºå™¨å­¦ä¹ æ¨¡åž‹æ¥è¯†åˆ«åè¯çŸ­è¯­çš„è¾¹ç•Œï¼Œå¹¶å°†å®ƒä»¬æ ‡è®°ä¸ºä¸€ä¸ªå•ç‹¬çš„çŸ­è¯­å•å…ƒ è¿™ä¸ªè¿‡ç¨‹æœ‰åŠ©äºŽæ›´å¥½åœ°ç†è§£æ–‡æœ¬çš„ç»“æž„å’Œè¯­ä¹‰ï¼Œç‰¹åˆ«æ˜¯åœ¨æ–‡æœ¬ä¸­æ¶‰åŠåˆ°åè¯çŸ­è¯­çš„å…³é”®çŸ­è¯­æå–ä»»åŠ¡ä¸­ã€‚åœ¨SIFRankæ–¹æ³•ä¸­ï¼ŒNP chunkerç”¨äºŽæå–å€™é€‰å…³é”®çŸ­è¯­ï¼Œå¹¶ä¸ºåŽç»­çš„å…³é”®çŸ­è¯­æŽ’åºå’Œè¯„åˆ†æä¾›åŸºç¡€ SIFæ¨¡åž‹ å¥å­åµŒå…¥æ¨¡åž‹SIF(Smooth Inverse Frequency)æ˜¯ä¸€ç§ç”¨äºŽå°†å¥å­è½¬æ¢ä¸ºè¿žç»­å‘é‡è¡¨ç¤ºçš„æ–¹æ³• å®ƒæ—¨åœ¨æ•æ‰å¥å­çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å°†å¥å­è¡¨ç¤ºä¸ºç¨ å¯†çš„ä½Žç»´å‘é‡ã€‚SIFæ¨¡åž‹çš„å…³é”®æ€æƒ³æ˜¯ç»“åˆè¯é¢‘ä¿¡æ¯æ¥è°ƒæ•´è¯å‘é‡çš„æƒé‡ï¼Œä»¥é™ä½Žé«˜é¢‘è¯çš„é‡è¦æ€§ï¼ŒåŒæ—¶æé«˜ä½Žé¢‘è¯çš„é‡è¦æ€§ã€‚è¿™æ ·å¯ä»¥å‡è½»ä¸€äº›å¸¸è§è¯å¯¹å¥å­è¡¨ç¤ºçš„å½±å“ï¼Œä½¿å¾—å¥å­è¡¨ç¤ºæ›´åŠ æ³¨é‡é‚£äº›åœ¨è¯­ä¹‰ä¸Šæ›´å…·åŒºåˆ†åº¦çš„è¯è¯­ã€‚SIFæ¨¡åž‹é€šè¿‡ç®€å•çš„æ•°å­¦è¿ç®—ï¼Œå¦‚å‡æ³•å’ŒåŠ æƒå¹³å‡ï¼Œæ¥è®¡ç®—å¥å­çš„åµŒå…¥è¡¨ç¤º å®ƒåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¢«å¹¿æ³›åº”ç”¨ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æžå’Œå¥å­ç›¸ä¼¼åº¦è®¡ç®—ç­‰ sentence embeddingçš„å‡è®¾æ˜¯ï¼šæ–‡ç« æ˜¯ç”±ä¸€ä¸ªtopicç”Ÿæˆçš„ï¼Œæ–‡ç« ä¸­çš„æ¯ä¸ªå¥å­äº¦æ˜¯å¦‚æ­¤ï¼Œå› æ­¤ï¼Œå¥å­çš„embeddingåº”è¯¥ä¸Žæ–‡ç« embeddingçš„æœŸæœ›å€¼(topic embedding)ç›¸è¿‘ Bert-KPE Capturing Global Informativeness in Open Domain Keyphrase Extraction 2021 BERT-KPEæ˜¯æœ€è¿‘ç”±thunlpæå‡ºçš„æ–¹æ³•ï¼Œåœ¨OpenKPå’ŒKP20Kä¸Šéƒ½è¾¾åˆ°äº†state-of-the-artå’Œè‰¯å¥½çš„é²æ£’æ€§ æœ‰ç›‘ç£çš„æ–¹å¼ KeyBert KeyBERT Keyword Extraction with BERT ã€Œå…³é”®è¯ã€æå–éƒ½æœ‰å“ªäº›æ–¹æ¡ˆï¼Ÿ å½“æˆ‘ä»¬æƒ³è¦ä»Žç‰¹å®šæ–‡æ¡£ä¸­äº†è§£å…³é”®ä¿¡æ¯æ—¶ï¼Œé€šå¸¸ä¼šä½¿ç”¨å…³é”®è¯æå–ã€‚å…³é”®è¯æå–æ˜¯ä¸€ç§è‡ªåŠ¨åŒ–çš„è¿‡ç¨‹ï¼Œç”¨äºŽæå–ä¸Žè¾“å…¥æ–‡æœ¬æœ€ç›¸å…³çš„å•è¯å’ŒçŸ­è¯­ é€šè¿‡ä½¿ç”¨Rakeå’ŒYAKE!ç­‰æ–¹æ³•ï¼Œæˆ‘ä»¬å·²ç»å¯ä»¥ä½¿ç”¨æ˜“äºŽä½¿ç”¨çš„è½¯ä»¶åŒ…æ¥æå–å…³é”®è¯å’Œå…³é”®çŸ­è¯­ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡åž‹é€šå¸¸åŸºäºŽæ–‡æœ¬çš„ç»Ÿè®¡ç‰¹æ€§è€Œä¸æ˜¯è¯­ä¹‰ç›¸ä¼¼æ€§è¿›è¡Œå·¥ä½œ äºŽæ˜¯BERTç™»åœºã€‚BERTæ˜¯ä¸€ä¸ªåŒå‘å˜æ¢å™¨æ¨¡åž‹ï¼Œå¯ä»¥å°†çŸ­è¯­å’Œæ–‡æ¡£è½¬åŒ–ä¸ºèƒ½å¤Ÿæ•æ‰å…¶æ„ä¹‰çš„å‘é‡ ä½¿ç”¨BERTæå–æ–‡æ¡£å‘é‡(åµŒå…¥)ä»¥èŽ·å–æ–‡æ¡£çº§è¡¨ç¤ºã€‚ç„¶åŽï¼Œé’ˆå¯¹Nå…ƒè¯­æ³•è¯/çŸ­è¯­æå–è¯å‘é‡ã€‚æœ€åŽï¼Œæˆ‘ä»¬ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ¥æŸ¥æ‰¾ä¸Žæ–‡æ¡£æœ€ç›¸ä¼¼çš„è¯/çŸ­è¯­ã€‚ç„¶åŽï¼Œå¯ä»¥å°†æœ€ç›¸ä¼¼çš„è¯è¯†å®šä¹‰ä¸ºæœ€èƒ½æè¿°æ•´ä¸ªæ–‡æ¡£çš„è¯ æ¦‚è¿° ä»€ä¹ˆæ˜¯Keybert Keybertæ˜¯ä¸€ç§åŸºäºŽæ— ç›‘ç£å­¦ä¹ çš„å…³é”®è¯æŠ½å–æŠ€æœ¯ï¼Œä¸ä»…æ•ˆæžœå¥½ï¼Œè€Œä¸”æ˜“äºŽä½¿ç”¨ Keybertä¸»è¦é€šè¿‡BertèŽ·å–æ–‡æ¡£å’Œå€™é€‰è¯çš„embeddingï¼Œç„¶åŽä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—å¾—åˆ°æ–‡æ¡£ä¸­æœ€ç›¸ä¼¼çš„å€™é€‰è¯ä½œä¸ºå…³é”®è¯ å¤šæ ·æ€§ åœ¨å…³é”®è¯æå–ä¸­ï¼Œå¤šæ ·æ€§é—®é¢˜æŒ‡çš„æ˜¯å…³é”®è¯åˆ—è¡¨ä¸­å­˜åœ¨å¤§é‡ç›¸ä¼¼æˆ–é‡å¤çš„å…³é”®è¯ï¼Œç¼ºä¹å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚è¿™å¯èƒ½å¯¼è‡´å…³é”®ä¿¡æ¯çš„ä¸¢å¤±æˆ–é‡å¤ï¼Œå¹¶é™ä½Žå…³é”®è¯æå–çš„æ•ˆæžœ MSS æœ€å¤§æ€»è·ç¦»(Max Sum Distance)ï¼šé€šè¿‡å°†æ–‡æ¡£ä¸­æœ€ç›¸ä¼¼çš„å…³é”®è¯/çŸ­è¯­ä¸Žå€™é€‰å…³é”®è¯/çŸ­è¯­è¿›è¡Œç»„åˆï¼Œæ‰¾åˆ°å½¼æ­¤ä¹‹é—´ç›¸ä¼¼æ€§æœ€ä½Žçš„ç»„åˆï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿å…³é”®è¯ä¹‹é—´çš„å·®å¼‚æ€§ MMR æœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼ˆMaximal Marginal Relevanceï¼ŒMMR)ï¼šé€šè¿‡ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ¥åˆ›å»ºå…³é”®è¯/çŸ­è¯­ï¼ŒåŸºäºŽç›¸ä¼¼æ€§çš„æŽ’åº ç„¶åŽï¼Œä»ŽæŽ’åºåŽçš„ç»“æžœä¸­é€‰æ‹©ä¸Žæ–‡æ¡£æœ€ç›¸å…³çš„å…³é”®è¯/çŸ­è¯­ï¼Œå¹¶é€‰æ‹©ä¸Žå·²é€‰æ‹©å…³é”®è¯/çŸ­è¯­æœ€ä¸ç›¸ä¼¼çš„å€™é€‰å…³é”®è¯/çŸ­è¯­ï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ç»“æžœå…·æœ‰é«˜åº¦çš„å¤šæ ·æ€§ ç¤ºä¾‹ KeyBert Quickstart å®‰è£… # é»˜è®¤hugging face pip install keybert # å…¶ä»–åŽç«¯ pip install keybert[flair] pip install keybert[gensim] pip install keybert[spacy] pip install keybert[use] åŸºç¡€KeyBERT åŸºç¡€ç”¨æ³• from keybert import KeyBERT doc = \"\"\" Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.[1] It infers a function from labeled training data consisting of a set of training examples.[2] In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a 'reasonable' way (see inductive bias). \"\"\" kw_model = KeyBERT() keywords = kw_model.extract_keywords(doc) # è®¾ç½®keyphrase_ngram_rangeæ¥ç¡®å®šç”Ÿæˆçš„å…³é”®è¯/å…³é”®çŸ­è¯­çš„é•¿åº¦èŒƒå›´ >>> kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 1), stop_words=None) [('learning', 0.4604), ('algorithm', 0.4556), ('training', 0.4487), ('class', 0.4086), ('mapping', 0.3700)] # è¦æå–å…³é”®çŸ­è¯­ï¼Œåªéœ€å°†keyphrase_ngram_rangeè®¾ç½®ä¸º(1, 2)æˆ–æ›´é«˜ï¼Œå…·ä½“å–å†³äºŽæ‚¨å¸Œæœ›åœ¨ç”Ÿæˆçš„å…³é”®çŸ­è¯­ä¸­åŒ…å«çš„å•è¯æ•°é‡ >>> kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 2), stop_words=None) [('learning algorithm', 0.6978), ('machine learning', 0.6305), ('supervised learning', 0.5985), ('algorithm analyzes', 0.5860), ('learning function', 0.5850)] # è®¾ç½®highlightæ¥åœ¨æ–‡æ¡£ä¸­çªå‡ºæ˜¾ç¤ºå…³é”®è¯ keywords = kw_model.extract_keywords(doc, highlight=True) å…³é”®è¯å¤šæ ·åŒ– é»˜è®¤æƒ…å†µä¸‹ï¼ŒKeyBERTä»…åŸºäºŽä½™å¼¦ç›¸ä¼¼åº¦æ¯”è¾ƒæ–‡æ¡£å’Œå€™é€‰å…³é”®è¯/å…³é”®çŸ­è¯­ã€‚ç„¶è€Œï¼Œè¿™å¯èƒ½å¯¼è‡´éžå¸¸ç›¸ä¼¼çš„å•è¯å‡ºçŽ°åœ¨æœ€å‡†ç¡®çš„å…³é”®è¯/å…³é”®çŸ­è¯­åˆ—è¡¨ä¸­ ä¸ºäº†ç¡®ä¿å®ƒä»¬æ›´åŠ å¤šæ ·åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡å–ä¸¤ç§æ–¹æ³•æ¥å¾®è°ƒè¾“å‡ºç»“æžœï¼Œå³æœ€å¤§æ€»è·ç¦»(Max Sum Distance)å’Œæœ€å¤§è¾¹é™…ç›¸å…³æ€§(Maximal Marginal Relevance) æœ€å¤§æ€»è·ç¦»: ä¸ºäº†ä½¿ç»“æžœå¤šæ ·åŒ–ï¼Œæˆ‘ä»¬é€‰å–æ–‡æ¡£ä¸­ä¸Žå‰top_nä¸ªæœ€ç›¸ä¼¼çš„å•è¯/çŸ­è¯­ã€‚ç„¶åŽï¼Œæˆ‘ä»¬ä»Žè¿™2 x top_nä¸ªå•è¯ä¸­é€‰å–æ‰€æœ‰top_nä¸ªç»„åˆï¼Œå¹¶æå–å½¼æ­¤ä¹‹é—´æœ€ä¸ç›¸ä¼¼çš„ç»„åˆï¼Œé€šè¿‡ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œæ¯”è¾ƒ >>> kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', use_maxsum=True, nr_candidates=20, top_n=5) [('set training examples', 0.7504), ('generalize training data', 0.7727), ('requires learning algorithm', 0.5050), ('supervised learning algorithm', 0.3779), ('learning machine learning', 0.2891)] æœ€å¤§è¾¹é™…ç›¸å…³æ€§: ä¸ºäº†ä½¿ç»“æžœå¤šæ ·åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ€å¤§è¾¹é™…ç›¸å…³æ€§ï¼ˆMaximal Marginal Relevanceï¼ŒMMRï¼‰æ¥åˆ›å»ºå…³é”®è¯/å…³é”®çŸ­è¯­ï¼Œå®ƒä¹ŸåŸºäºŽä½™å¼¦ç›¸ä¼¼åº¦ # å…·æœ‰é«˜å¤šæ ·æ€§çš„ç»“æžœ kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', use_mmr=True, diversity=0.7) [('algorithm generalize training', 0.7727), ('labels unseen instances', 0.1649), ('new examples optimal', 0.4185), ('determine class labels', 0.4774), ('supervised learning algorithm', 0.7502)] # å…·æœ‰ä½Žå¤šæ ·æ€§çš„ç»“æžœ >>> kw_model.extract_keywords(doc, keyphrase_ngram_range=(3, 3), stop_words='english', use_mmr=True, diversity=0.2) [('algorithm generalize training', 0.7727), ('supervised learning algorithm', 0.7502), ('learning machine learning', 0.7577), ('learning algorithm analyzes', 0.7587), ('learning algorithm generalize', 0.7514)] å…¶ä»–å…³é”®è¯ç®—æ³•ç”Ÿæˆçš„å€™é€‰å…³é”®è¯ åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½å¸Œæœ›ä½¿ç”¨å…¶ä»–å…³é”®è¯ç®—æ³•ç”Ÿæˆçš„å€™é€‰å…³é”®è¯æˆ–ä»Žå¯èƒ½çš„å…³é”®è¯/å…³é”®çŸ­è¯­åˆ—è¡¨ä¸­æ£€ç´¢çš„å€™é€‰å…³é”®è¯ åœ¨KeyBERTä¸­ï¼Œæ‚¨å¯ä»¥è½»æ¾ä½¿ç”¨è¿™äº›å€™é€‰å…³é”®è¯è¿›è¡Œå…³é”®è¯æå– import yake from keybert import KeyBERT # Create candidates kw_extractor = yake.KeywordExtractor(top=50) candidates = kw_extractor.extract_keywords(doc) candidates = [candidate[0] for candidate in candidates] # Pass candidates to KeyBERT kw_model = KeyBERT() keywords = kw_model.extract_keywords(doc, candidates=candidates) Guided KeyBERT Guided KeyBERT(å¼•å¯¼å¼KeyBERT)ä¸Žå¼•å¯¼å¼ä¸»é¢˜å»ºæ¨¡ç±»ä¼¼ï¼Œå®ƒè¯•å›¾å°†è®­ç»ƒå¼•å¯¼åˆ°ä¸€ç»„ç§å­æœ¯è¯­ä¸Šã€‚å½“åº”ç”¨KeyBERTæ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨æå–ä¸Žç‰¹å®šæ–‡æ¡£æœ€ç›¸å…³çš„å…³é”®è¯ã€‚ç„¶è€Œï¼Œæœ‰æ—¶åˆ©ç›Šç›¸å…³è€…å’Œç”¨æˆ·æ­£åœ¨å¯»æ‰¾ç‰¹å®šç±»åž‹çš„å…³é”®è¯ã€‚ä¾‹å¦‚ï¼Œå½“é€šè¿‡contentfulåœ¨æ‚¨çš„ç½‘ç«™ä¸Šå‘å¸ƒä¸€ç¯‡æ–‡ç« æ—¶ï¼Œæ‚¨é€šå¸¸å·²ç»äº†è§£ä¸Žè¯¥æ–‡ç« ç›¸å…³çš„å…¨å±€å…³é”®è¯ã€‚ä½†æ˜¯ï¼Œæ–‡ç« ä¸­å¯èƒ½å­˜åœ¨æ‚¨å¸Œæœ›é€šè¿‡å…³é”®è¯æå–å‡ºæ¥çš„ç‰¹å®šä¸»é¢˜ã€‚ä¸ºäº†å®žçŽ°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åªéœ€ç»™KeyBERTæä¾›ä¸€ç»„ç›¸å…³çš„ç§å­å…³é”®è¯(å¯ä»¥æ˜¯å•ä¸ªå…³é”®è¯)ï¼Œå¹¶æœç´¢ä¸Žæ–‡æ¡£å’Œç§å­å…³é”®è¯éƒ½ç›¸ä¼¼çš„å…³é”®è¯ ä½¿ç”¨è¿™ä¸ªåŠŸèƒ½éžå¸¸ç®€å•ï¼Œåªéœ€å®šä¹‰ä¸€ä¸ªç§å­å…³é”®è¯åˆ—è¡¨å¹¶å°†å…¶ä¼ é€’ç»™KeyBERTå³å¯ from keybert import KeyBERT kw_model = KeyBERT() # Define our seeded term seed_keywords = [\"information\"] keywords = kw_model.extract_keywords(doc, seed_keywords=seed_keywords) å½“ä½ æœ‰ä¸€ä¸ªå¤§åž‹æ•°æ®é›†ï¼Œå¹¶ä¸”æƒ³è¦å¾®è°ƒè¯¸å¦‚å¤šæ ·æ€§ä¹‹ç±»çš„å‚æ•°æ—¶ï¼Œæ¯æ¬¡æ›´æ”¹å‚æ•°æ—¶é‡æ–°è®¡ç®—æ–‡æ¡£å’Œå•è¯åµŒå…¥å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ã€‚ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥é¢„å…ˆè®¡ç®—è¿™äº›åµŒå…¥ï¼Œå¹¶å°†å®ƒä»¬ä¼ é€’ç»™.extract_keywordsï¼Œè¿™æ ·æˆ‘ä»¬åªéœ€è®¡ç®—ä¸€æ¬¡å³å¯ from keybert import KeyBERT kw_model = KeyBERT() doc_embeddings, word_embeddings = kw_model.extract_embeddings(docs) ç„¶åŽï¼Œä½ å¯ä»¥ä½¿ç”¨è¿™äº›åµŒå…¥å¹¶å°†å®ƒä»¬ä¼ é€’ç»™.extract_keywordsæ¥åŠ å¿«æ¨¡åž‹çš„è°ƒæ•´ keywords = kw_model.extract_keywords(docs, doc_embeddings=doc_embeddings, word_embeddings=word_embeddings) .extract_embeddingsä¸­æœ‰å‡ ä¸ªå‚æ•°å®šä¹‰äº†å¦‚ä½•ç”Ÿæˆå€™é€‰å…³é”®è¯/å…³é”®çŸ­è¯­çš„åˆ—è¡¨ï¼š candidates keyphrase_ngram_range stop_words min_df vectorizer è¿™äº›å‚æ•°çš„å€¼åœ¨.extract_embeddingså’Œ.extract_keywordsä¸­éœ€è¦å®Œå…¨ç›¸åŒï¼Œæ¢å¥è¯è¯´ï¼Œä»¥ä¸‹å†…å®¹å°†èµ·ä½œç”¨ï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨ç›¸åŒçš„å‚æ•°å­é›† from keybert import KeyBERT kw_model = KeyBERT() doc_embeddings, word_embeddings = kw_model.extract_embeddings(docs, min_df=1, stop_words=\"english\") keywords = kw_model.extract_keywords(docs, min_df=1, stop_words=\"english\", doc_embeddings=doc_embeddings, word_embeddings=word_embeddings) ç„¶è€Œï¼Œä»¥ä¸‹å†…å®¹å°†æŠ›å‡ºé”™è¯¯ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰ä¸ºmin_dfå’Œstop_wordsä½¿ç”¨ç›¸åŒçš„å€¼ from keybert import KeyBERT kw_model = KeyBERT() doc_embeddings, word_embeddings = kw_model.extract_embeddings(docs, min_df=3, stop_words=\"dutch\") keywords = kw_model.extract_keywords(docs, min_df=1, stop_words=\"english\", doc_embeddings=doc_embeddings, word_embeddings=word_embeddings) æ‘˜è¦æå– ç­‰å¾…... ç”Ÿæˆå¼ + æŠ½å–å¼ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/pytorchå­¦ä¹ .html":{"url":"chapters/pytorchå­¦ä¹ .html","title":"pytorchå­¦ä¹ .md","summary":"pytorchå­¦ä¹ è®°å½•","keywords":"","body":"torchåŸºæœ¬æ“ä½œåˆ›å»ºæ“ä½œ Creation Opsç´¢å¼•|åˆ‡ç‰‡|è¿žæŽ¥|æ¢ä½éšæœºæŠ½æ ·åºåˆ—åŒ–Serializationå¹¶è¡ŒåŒ– Parallelismæ•°å­¦æ“ä½œMath operationsReduction Opsæ¯”è¾ƒæ“ä½œ Comparison Opså…¶å®ƒæ“ä½œ Other OperationsBLAS and LAPACK OperationsTensorstorageå®žä¾‹PytorchåŠ è½½æ•°æ®TensorboardTransformstorchvisionæ•°æ®é›†æŸå¤±å‡½æ•°ä¼˜åŒ–å™¨ç½‘ç»œæ¨¡åž‹ä½¿ç”¨åŠä¿®æ”¹ç½‘ç»œæ¨¡åž‹ä¿å­˜ä¸Žè¯»å–å›ºå®šæ¨¡åž‹å‚æ•°è®­ç»ƒæµç¨‹ pytorchä¸­æ–‡æ–‡æ¡£ torch åŸºæœ¬æ“ä½œ torch.is_tensor: å¦‚æžœobjæ˜¯ä¸€ä¸ªpytorchå¼ é‡ï¼Œåˆ™è¿”å›žTrue x=torch.tensor([1,2,3]) torch.is_tensor(x) Out[0]: True torch.is_storage: å¦‚ä½•objæ˜¯ä¸€ä¸ªpytorch storageå¯¹è±¡ï¼Œåˆ™è¿”å›žTrue x=torch.tensor([1,2,3]) torch.is_storage(x) Out[0]: False torch.numel: è¿”å›žinput å¼ é‡ä¸­çš„å…ƒç´ ä¸ªæ•° a = torch.randn(1,2,3,4,5) torch.numel(a) Out[0]: 120 a = torch.zeros(4,4) torch.numel(a) Out[1]: 16 torch.set_printoptions: è®¾ç½®æ‰“å°é€‰é¡¹ å‚æ•°: precision â€“ æµ®ç‚¹æ•°è¾“å‡ºçš„ç²¾åº¦ä½æ•° (é»˜è®¤ä¸º8 ) threshold â€“ é˜ˆå€¼ï¼Œè§¦å‘æ±‡æ€»æ˜¾ç¤ºè€Œä¸æ˜¯å®Œå…¨æ˜¾ç¤º(repr)çš„æ•°ç»„å…ƒç´ çš„æ€»æ•° ï¼ˆé»˜è®¤ä¸º1000ï¼‰ edgeitems â€“ æ±‡æ€»æ˜¾ç¤ºä¸­ï¼Œæ¯ç»´ï¼ˆè½´ï¼‰ä¸¤ç«¯æ˜¾ç¤ºçš„é¡¹æ•°ï¼ˆé»˜è®¤å€¼ä¸º3ï¼‰ linewidth â€“ ç”¨äºŽæ’å…¥è¡Œé—´éš”çš„æ¯è¡Œå­—ç¬¦æ•°ï¼ˆé»˜è®¤ä¸º80ï¼‰ã€‚Thresholded matricies will ignore this parameter. profile â€“ prettyæ‰“å°çš„å®Œå…¨é»˜è®¤å€¼ã€‚ å¯ä»¥è¦†ç›–ä¸Šè¿°æ‰€æœ‰é€‰é¡¹ (é»˜è®¤ä¸ºshort, full) åˆ›å»ºæ“ä½œ Creation Ops torch.eye: è¿”å›žä¸€ä¸ª2ç»´å¼ é‡ï¼Œå¯¹è§’çº¿ä½ç½®å…¨1ï¼Œå…¶å®ƒä½ç½®å…¨0 å‚æ•°: n (int ) â€“ è¡Œæ•° m (int, optional) â€“ åˆ—æ•°.å¦‚æžœä¸ºNone,åˆ™é»˜è®¤ä¸ºn out (Tensor, optinal) - Output tensor torch.eye(3) Out[0]: 1 0 0 0 1 0 0 0 1 [torch.FloatTensor of size 3x3] from_numpy: å°†numpy.ndarray è½¬æ¢ä¸ºpytorchçš„ Tensorã€‚ è¿”å›žçš„å¼ é‡tensorå’Œnumpyçš„ndarrayå…±äº«åŒä¸€å†…å­˜ç©ºé—´ã€‚ä¿®æ”¹ä¸€ä¸ªä¼šå¯¼è‡´å¦å¤–ä¸€ä¸ªä¹Ÿè¢«ä¿®æ”¹ã€‚è¿”å›žçš„å¼ é‡ä¸èƒ½æ”¹å˜å¤§å° a = numpy.array([1, 2, 3]) t = torch.from_numpy(a) Out[0]: torch.LongTensor([1, 2, 3]) t[0] = -1 a Out[1]: array([-1, 2, 3]) torch.linspace: è¿”å›žä¸€ä¸ª1ç»´å¼ é‡ï¼ŒåŒ…å«åœ¨åŒºé—´start å’Œ end ä¸Šå‡åŒ€é—´éš”çš„stepsä¸ªç‚¹ã€‚ è¾“å‡º1ç»´å¼ é‡çš„é•¿åº¦ä¸ºsteps å‚æ•°: start (float) â€“ åºåˆ—çš„èµ·å§‹ç‚¹ end (float) â€“ åºåˆ—çš„æœ€ç»ˆå€¼ steps (int) â€“ åœ¨start å’Œ endé—´ç”Ÿæˆçš„æ ·æœ¬æ•° out (Tensor, optional) â€“ ç»“æžœå¼ é‡ torch.linspace(3, 10, steps=5) Out[0]: 3.0000 4.7500 6.5000 8.2500 10.0000 [torch.FloatTensor of size 5] torch.logspace: å‚æ•°: start (float) â€“ åºåˆ—çš„èµ·å§‹ç‚¹ end (float) â€“ åºåˆ—çš„æœ€ç»ˆå€¼ steps (int) â€“ åœ¨å¼€å§‹å’Œç»“æŸä¹‹é—´è¦é‡‡æ ·çš„ç‚¹æ•°ã€‚é»˜è®¤å€¼ï¼š100 out (Tensor, optional) â€“ ç»“æžœå¼ é‡ torch.logspace(start=0.1, end=1.0, steps=5) Out[0]: 1.2589 2.1135 3.5481 5.9566 10.0000 [torch.FloatTensor of size 5] torch.ones: è¿”å›žä¸€ä¸ªå…¨ä¸º1 çš„å¼ é‡ï¼Œå½¢çŠ¶ç”±å¯å˜å‚æ•°sizeså®šä¹‰ torch.ones(2, 3) Out[0]: 1 1 1 1 1 1 [torch.FloatTensor of size 2x3] torch.rand: è¿”å›žä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«äº†ä»ŽåŒºé—´[0,1)çš„å‡åŒ€åˆ†å¸ƒä¸­æŠ½å–çš„ä¸€ç»„éšæœºæ•°ï¼Œå½¢çŠ¶ç”±å¯å˜å‚æ•°sizes å®šä¹‰ torch.rand(2, 3) Out[0]: 0.5010 0.5140 0.0719 0.1435 0.5636 0.0538 [torch.FloatTensor of size 2x3] torch.randn: è¿”å›žä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«äº†ä»Žæ ‡å‡†æ­£æ€åˆ†å¸ƒ(å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º 1ï¼Œå³é«˜æ–¯ç™½å™ªå£°)ä¸­æŠ½å–ä¸€ç»„éšæœºæ•° torch.randn(2, 3) Out[0]: 1.4339 0.3351 -1.0999 1.5458 -0.9643 -0.3558 [torch.FloatTensor of size 2x3] torch.randperm: ç»™å®šå‚æ•°nï¼Œè¿”å›žä¸€ä¸ªä»Ž0 åˆ°n -1 çš„éšæœºæ•´æ•°æŽ’åˆ— torch.randperm(4) Out[0]: tensor([1, 0, 2, 3]) torch.randperm(6) Out[1]: tensor([1, 0, 3, 2, 5, 4]) torch.arange: torch.arange(start, end, step=1, out=None) â†’ Tensor å‚æ•°: start (float) â€“ åºåˆ—çš„èµ·å§‹ç‚¹ end (float) â€“ åºåˆ—çš„ç»ˆæ­¢ç‚¹ step (float) â€“ ç›¸é‚»ç‚¹çš„é—´éš”å¤§å° out (Tensor, optional) â€“ ç»“æžœå¼ é‡ torch.arange(1, 2.5, 0.5) Out[0]: tensor([1.0000, 1.5000, 2.0000]) torch.zeros: è¿”å›žä¸€ä¸ªå…¨ä¸ºæ ‡é‡ 0 çš„å¼ é‡ torch.zeros(2, 3) Out[0]: tensor([[0., 0., 0.], [0., 0., 0.]]) ç´¢å¼•|åˆ‡ç‰‡|è¿žæŽ¥|æ¢ä½ torch.cat: ç»™å®šç»´åº¦ä¸Šå¯¹è¾“å…¥çš„å¼ é‡åºåˆ—seq è¿›è¡Œè¿žæŽ¥æ“ä½œ torch.cat()å¯ä»¥çœ‹åš torch.split() å’Œ torch.chunk()çš„åæ“ä½œ å‚æ•°: inputs (sequence of Tensors) â€“ å¯ä»¥æ˜¯ä»»æ„ç›¸åŒTensor ç±»åž‹çš„python åºåˆ— dimension (int, optional) â€“ æ²¿ç€æ­¤ç»´è¿žæŽ¥å¼ é‡åºåˆ— x = torch.randn(1, 2) torch.cat((x, x, x), 0) Out[0]: tensor([[ 0.6030, -0.0292], [ 0.6030, -0.0292], [ 0.6030, -0.0292]]) torch.cat((x, x, x), 1) Out[1]: tensor([[ 0.6030, -0.0292, 0.6030, -0.0292, 0.6030, -0.0292]]) torch.chunk: torch.chunk(tensor, chunks, dim=0) åœ¨ç»™å®šç»´åº¦(è½´)ä¸Šå°†è¾“å…¥å¼ é‡è¿›è¡Œåˆ†å—å„¿ å‚æ•°: tensor (Tensor) â€“ å¾…åˆ†å—çš„è¾“å…¥å¼ é‡ chunks (int) â€“ åˆ†å—çš„ä¸ªæ•° dim (int) â€“ æ²¿ç€æ­¤ç»´åº¦è¿›è¡Œåˆ†å— torch.arange(11).chunk(4) Out[0]: (tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([ 9, 10])) torch.rand((3,2)).chunk(3,dim=0) Out[1]: (tensor([[0.4479, 0.8420]]), tensor([[0.2951, 0.9858]]), tensor([[0.2795, 0.7413]])) torch.gather: torch.gather(input, dim, index, out=None) â†’ Tensor æ²¿ç»™å®šè½´dimï¼Œå°†è¾“å…¥ç´¢å¼•å¼ é‡indexæŒ‡å®šä½ç½®çš„å€¼è¿›è¡Œèšåˆ å‚æ•°: input (Tensor) â€“ æºå¼ é‡ dim (int) â€“ ç´¢å¼•çš„è½´ index (LongTensor) â€“ èšåˆå…ƒç´ çš„ä¸‹æ ‡ out (Tensor, optional) â€“ ç›®æ ‡å¼ é‡ t = torch.Tensor([[1,2],[3,4]]) torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]])) Out[0]: tensor([[1., 1.], [4., 3.]]) t = torch.Tensor([[1, 2], [3, 4], [5, 6]]) torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]])) Out[1]: tensor([[1., 1.], [4., 3.]]) torch.index_select: torch.index_select(input, dim, index, out=None) â†’ Tensor æ²¿ç€æŒ‡å®šç»´åº¦å¯¹è¾“å…¥è¿›è¡Œåˆ‡ç‰‡ï¼Œå–indexä¸­æŒ‡å®šçš„ç›¸åº”é¡¹(indexä¸ºä¸€ä¸ªLongTensor)ï¼Œç„¶åŽè¿”å›žåˆ°ä¸€ä¸ªæ–°çš„å¼ é‡ï¼Œ è¿”å›žçš„å¼ é‡ä¸ŽåŽŸå§‹å¼ é‡Tensoræœ‰ç›¸åŒçš„ç»´åº¦(åœ¨æŒ‡å®šè½´ä¸Š) å‚æ•°: input (Tensor) â€“ è¾“å…¥å¼ é‡ dim (int) â€“ ç´¢å¼•çš„è½´ index (LongTensor) â€“ åŒ…å«ç´¢å¼•ä¸‹æ ‡çš„ä¸€ç»´å¼ é‡ out (Tensor, optional) â€“ ç›®æ ‡å¼ é‡ x = torch.randn(3, 4) Out[0]: tensor([[-0.8335, 1.2611, 0.6569, -0.1598], [-0.1019, 1.5010, -1.4486, -2.2269], [-0.6087, -0.6940, -0.2556, -1.1843]]) indices = torch.LongTensor([0, 2]) torch.index_select(x, 0, indices) Out[1]: tensor([[-0.8335, 1.2611, 0.6569, -0.1598], [-0.6087, -0.6940, -0.2556, -1.1843]]) torch.index_select(x, 1, indices) Out[2]: tensor([[-0.8335, 0.6569], [-0.1019, -1.4486], [-0.6087, -0.2556]]) torch.masked_select: torch.masked_select(input, mask, out=None) â†’ Tensor æ ¹æ®æŽ©ç å¼ é‡maskä¸­çš„äºŒå…ƒå€¼ï¼Œå–è¾“å…¥å¼ é‡ä¸­çš„æŒ‡å®šé¡¹( maskä¸ºä¸€ä¸ª ByteTensor)ï¼Œå°†å–å€¼è¿”å›žåˆ°ä¸€ä¸ªæ–°çš„1Då¼ é‡ å¼ é‡ maské¡»è·Ÿinputå¼ é‡æœ‰ç›¸åŒæ•°é‡çš„å…ƒç´ æ•°ç›®ï¼Œä½†å½¢çŠ¶æˆ–ç»´åº¦ä¸éœ€è¦ç›¸åŒ x = torch.randn(3, 4) Out[0]: tensor([[-0.8335, 1.2611, 0.6569, -0.1598], [-0.1019, 1.5010, -1.4486, -2.2269], [-0.6087, -0.6940, -0.2556, -1.1843]]) mask = x.ge(0.5) Out[1]: tensor([[ True, True, True, True], [False, False, False, True], [False, False, False, False]]) torch.masked_select(x, mask) Out[2]: tensor([1.2394, 0.5152, 0.5170, 1.8193, 0.7352]) torch.nonzero: ç”¨äºŽè¾“å‡ºæ•°ç»„çš„éžé›¶å€¼çš„ç´¢å¼•ï¼Œå³ç”¨æ¥å®šä½æ•°ç»„ä¸­éžé›¶çš„å…ƒç´  as_tupleï¼šå¦‚æžœè®¾ä¸ºFalseï¼Œåˆ™è¿”å›žä¸€ä¸ªäºŒç»´å¼ é‡ï¼Œå…¶ä¸­æ¯ä¸€è¡Œéƒ½æ˜¯éžé›¶å€¼çš„ç´¢å¼• torch.nonzero(torch.Tensor([1, 1, 1, 0, 1])) Out[0]: tensor([[0], [1], [2], [4]]) torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0], [0.0, 0.4, 0.0, 0.0], [0.0, 0.0, 1.2, 0.0], [0.0, 0.0, 1, -0.4]])) Out[1]: tensor([[0, 0], [1, 1], [2, 2], [3, 2], [3, 3]]) torch.split: torch.split(tensor, split_size, dim=0) å°†è¾“å…¥å¼ é‡åˆ†å‰²æˆç›¸ç­‰å½¢çŠ¶çš„chunks(å¦‚æžœå¯åˆ†) å¦‚æžœæ²¿æŒ‡å®šç»´çš„å¼ é‡å½¢çŠ¶å¤§å°ä¸èƒ½è¢«split_size æ•´åˆ†ï¼Œ åˆ™æœ€åŽä¸€ä¸ªåˆ†å—ä¼šå°äºŽå…¶å®ƒåˆ†å— å‚æ•°: tensor (Tensor) â€“ å¾…åˆ†å‰²å¼ é‡ split_size (int) â€“ å•ä¸ªåˆ†å—çš„å½¢çŠ¶å¤§å° dim (int) â€“ æ²¿ç€æ­¤ç»´è¿›è¡Œåˆ†å‰² a = torch.arange(10).reshape(5,2) Out[0]: tensor([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]) torch.split(a, 2) Out[1]: (tensor([[0, 1], [2, 3]]), tensor([[4, 5], [6, 7]]), tensor([[8, 9]])) torch.split(a, [1,4]) Out[2]: (tensor([[0, 1]]), tensor([[2, 3], [4, 5], [6, 7], [8, 9]])) torch.squeeze: torch.squeeze(input, dim=None, out=None) å°†è¾“å…¥å¼ é‡å½¢çŠ¶ä¸­çš„1 åŽ»é™¤å¹¶è¿”å›žã€‚ å¦‚æžœè¾“å…¥æ˜¯å½¢å¦‚(AÃ—1Ã—BÃ—1Ã—CÃ—1Ã—D)(AÃ—1Ã—BÃ—1Ã—CÃ—1Ã—D)ï¼Œé‚£ä¹ˆè¾“å‡ºå½¢çŠ¶å°±ä¸ºï¼š (AÃ—BÃ—CÃ—D) å½“ç»™å®šdimæ—¶ï¼Œé‚£ä¹ˆæŒ¤åŽ‹æ“ä½œåªåœ¨ç»™å®šç»´åº¦ä¸Šã€‚ä¾‹å¦‚ï¼Œè¾“å…¥å½¢çŠ¶ä¸º: (AÃ—1Ã—B)(AÃ—1Ã—B), squeeze(input, 0) å°†ä¼šä¿æŒå¼ é‡ä¸å˜ï¼Œåªæœ‰ç”¨ squeeze(input, 1)ï¼Œå½¢çŠ¶ä¼šå˜æˆ (AÃ—B)(AÃ—B)ã€‚ æ³¨æ„ï¼š è¿”å›žå¼ é‡ä¸Žè¾“å…¥å¼ é‡å…±äº«å†…å­˜ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€ä¸ªçš„å†…å®¹ä¼šæ”¹å˜å¦ä¸€ä¸ªã€‚ å‚æ•°: input (Tensor) â€“ è¾“å…¥å¼ é‡ dim (int, optional) â€“ å¦‚æžœç»™å®šï¼Œåˆ™inputåªä¼šåœ¨ç»™å®šç»´åº¦æŒ¤åŽ‹ out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡ x = torch.zeros(2, 1, 2, 1, 2) x.size() Out[0]: torch.Size([2, 1, 2, 1, 2]) y = torch.squeeze(x) y.size() Out[1]: torch.Size([2, 2, 2]) y = torch.squeeze(x, 0) y.size() Out[2]: torch.Size([2, 1, 2, 1, 2]) y = torch.squeeze(x, 1) y.size() Out[3]: torch.Size([2, 2, 1, 2]) torch.unsqueeze: torch.unsqueeze(input, dim, out=None) è¿”å›žä¸€ä¸ªæ–°çš„å¼ é‡ï¼Œå¯¹è¾“å…¥çš„åˆ¶å®šä½ç½®æ’å…¥ç»´åº¦ 1 æ³¨æ„ï¼š è¿”å›žå¼ é‡ä¸Žè¾“å…¥å¼ é‡å…±äº«å†…å­˜ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€ä¸ªçš„å†…å®¹ä¼šæ”¹å˜å¦ä¸€ä¸ª x = torch.Tensor([1, 2, 3, 4]) x.shape Out[0]: torch.Size([4]) torch.unsqueeze(x, 0).shape Out[1]: torch.Size([1, 4]) torch.unsqueeze(x, 1).shape Out[2]: torch.Size([4, 1]) torch.stack: torch.stack(sequence, dim=0) æ²¿ç€ä¸€ä¸ªæ–°ç»´åº¦å¯¹è¾“å…¥å¼ é‡åºåˆ—è¿›è¡Œè¿žæŽ¥ã€‚ åºåˆ—ä¸­æ‰€æœ‰çš„å¼ é‡éƒ½åº”è¯¥ä¸ºç›¸åŒå½¢çŠ¶ t1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) t2 = torch.tensor([[10, 20, 30], [40, 50, 60], [70, 80, 90]]) t1.shape, t2.shape Out[0]: (torch.Size([3, 3]), torch.Size([3, 3])) torch.stack((t1, t2), dim=0).shape Out[1]: torch.Size([2, 3, 3]) torch.stack((t1, t2), dim=1).shape Out[2]: torch.Size([3, 2, 3]) torch.stack((t1, t2), dim=2).shape Out[3]: torch.Size([3, 3, 2]) torch.transpose: torch.transpose(input, dim0, dim1, out=None) â†’ Tensor è¿”å›žè¾“å…¥çŸ©é˜µinputçš„è½¬ç½®ã€‚äº¤æ¢ç»´åº¦dim0å’Œdim1ã€‚ è¾“å‡ºå¼ é‡ä¸Žè¾“å…¥å¼ é‡å…±äº«å†…å­˜ï¼Œæ‰€ä»¥æ”¹å˜å…¶ä¸­ä¸€ä¸ªä¼šå¯¼è‡´å¦å¤–ä¸€ä¸ªä¹Ÿè¢«ä¿®æ”¹ã€‚ å‚æ•°: input (Tensor) â€“ è¾“å…¥å¼ é‡ dim0 (int) â€“ è½¬ç½®çš„ç¬¬ä¸€ç»´ dim1 (int) â€“ è½¬ç½®çš„ç¬¬äºŒç»´ torch.t: torch.t(input, out=None) â†’ Tensor è¾“å…¥ä¸€ä¸ªçŸ©é˜µï¼ˆ2ç»´å¼ é‡ï¼‰ï¼Œå¹¶è½¬ç½®0, 1ç»´ã€‚ å¯ä»¥è¢«è§†ä¸ºå‡½æ•°transpose(input, 0, 1)çš„ç®€å†™ x = torch.randn(2, 3) x.shape Out[0]: torch.Size([2, 3]) torch.transpose(x, 0, 1).shape Out[1]: torch.Size([3, 2]) torch.t(x).shape Out[2]: torch.Size([3, 2]) torch.unbind: torch.unbind(tensor, dim=0)[source] ç§»é™¤æŒ‡å®šç»´åŽï¼Œè¿”å›žä¸€ä¸ªå…ƒç»„ï¼ŒåŒ…å«äº†æ²¿ç€æŒ‡å®šç»´åˆ‡ç‰‡åŽçš„å„ä¸ªåˆ‡ç‰‡ å‚æ•°: tensor (Tensor) â€“ è¾“å…¥å¼ é‡ dim (int) â€“ åˆ é™¤çš„ç»´åº¦ torch.unbind(torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])) Out[0]: (tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9])) torch.unbind(torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), dim=0) Out[1]: (tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9])) torch.unbind(torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), dim=1) Out[2]: (tensor([1, 4, 7]), tensor([2, 5, 8]), tensor([3, 6, 9])) éšæœºæŠ½æ · torch.seed: è®¾ç½®torch cpuéšæœºæ•°ç§å­ torch.manual_seed: è®¾ç½®torch cpuéšæœºæ•°ç§å­ï¼Œtorch.manual_seed(seed) è®¾å®šç”Ÿæˆéšæœºæ•°çš„ç§å­ï¼Œå¹¶è¿”å›žä¸€ä¸ªtorch._C.Generatorå¯¹è±¡ torch.cuda.manual_seed: è®¾ç½®torch cudaéšæœºæ•°ç§å­ torch.seed() Out[0]: 348176808892500 torch.seed() Out[1]: 348177652492500 torch.manual_seed(0) Out[2]: torch.cuda.manual_seed(0) torch.bernoulli: torch.bernoulli(input, out=None) â†’ Tensor ä»Žä¼¯åŠªåˆ©åˆ†å¸ƒä¸­æå–äºŒè¿›åˆ¶éšæœºæ•°ï¼ˆ0æˆ–1ï¼‰ï¼Œè¾“å…¥å¼ é‡åº”ä¸ºåŒ…å«ç”¨äºŽç»˜åˆ¶äºŒè¿›åˆ¶éšæœºæ•°çš„æ¦‚çŽ‡çš„å¼ é‡ã€‚å› æ­¤ï¼Œè¾“å…¥ä¸­çš„æ‰€æœ‰å€¼éƒ½å¿…é¡»åœ¨ä»¥ä¸‹èŒƒå›´å†…(0,1) torch.poisson: æ³Šæ¾åˆ†å¸ƒç”¨äºŽè®¡ç®—ä¸€ä¸ªäº‹ä»¶åœ¨å¹³å‡ä»·å€¼çŽ‡(æ—¶é—´)çš„ä¸€å®šæ—¶é—´å†…å‘ç”Ÿçš„å¯èƒ½æ€§ã€‚æ³Šæ¾åˆ†å¸ƒæ˜¯ä¸€ä¸ªç¦»æ•£çš„æ¦‚çŽ‡åˆ†å¸ƒ a = torch.Tensor(3, 3).uniform_(0, 1) Out[0]: tensor([[0.0044, 0.7257, 0.2599], [0.1663, 0.2119, 0.7875], [0.7648, 0.8838, 0.6814]]) torch.bernoulli(a) Out[1]: tensor([[0., 1., 0.], [0., 0., 1.], [1., 1., 1.]]) a = torch.ones(3, 3) torch.bernoulli(a) Out[2]: tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) a = torch.zeros(3, 3) torch.bernoulli(a) Out[3]: tensor([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) a = torch.rand(4, 4) * 5 Out[0]: tensor([[0.2542, 1.3148, 4.2023, 2.4838], [1.2574, 0.5842, 0.1604, 0.3900], [1.9929, 3.8710, 3.8516, 0.0889], [4.0595, 0.5437, 1.9715, 1.4863]]) torch.poisson(a) Out[1]: tensor([[0., 1., 4., 2.], [2., 1., 0., 0.], [2., 8., 4., 0.], [5., 0., 1., 2.]]) torch.multinomial: torch.multinomial(input, num_samples,replacement=False, out=None) â†’ LongTensor å¯¹inputçš„æ¯ä¸€è¡Œåšn_samplesæ¬¡å–å€¼ï¼Œè¾“å‡ºçš„å¼ é‡æ˜¯æ¯ä¸€æ¬¡å–å€¼æ—¶inputå¼ é‡å¯¹åº”è¡Œçš„ä¸‹æ ‡ å‚æ•°: input (Tensor) â€“ åŒ…å«æ¦‚çŽ‡å€¼çš„å¼ é‡ num_samples (int) â€“ æŠ½å–çš„æ ·æœ¬æ•° replacement (bool, optional) â€“ å¸ƒå°”å€¼ï¼Œå†³å®šæ˜¯å¦èƒ½é‡å¤æŠ½å– out (Tensor, optional) â€“ ç»“æžœå¼ é‡ weights = torch.Tensor([0, 10, 3, 0]) torch.multinomial(weights, 4) Out[0]: tensor([2, 1, 0, 3]) # replacement=Trueæ—¶ æ¦‚çŽ‡ä¸º0çš„æ²¡æœºä¼šè¢«å–åˆ° torch.multinomial(weights, 4, replacement=True) Out[1]: tensor([2, 1, 1, 1]) torch.normal: torch.normal(means, std, out=None) è¿”å›žä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«ä»Žç»™å®šå‚æ•°means,stdçš„ç¦»æ•£æ­£æ€åˆ†å¸ƒä¸­æŠ½å–éšæœºæ•° torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1)) Out[0]: tensor([ 0.9732, 2.0833, 2.5282, 4.3588, 5.4837, 5.1150, 7.0366, 7.9774, 9.1679, 10.0248]) torch.normal(mean=0.5, std=torch.arange(1., 6.)) Out[1]: tensor([ 0.7067, 2.4856, -2.1957, -4.3114, 16.2506]) torch.normal(mean=torch.arange(1., 6.)) Out[2]: tensor([0.7835, 4.6096, 2.7244, 5.2810, 4.8413]) åºåˆ—åŒ–Serialization torch.save: ä¿å­˜ä¸€ä¸ªå¯¹è±¡åˆ°ä¸€ä¸ªç¡¬ç›˜æ–‡ä»¶ä¸Š å‚è€ƒ: Recommended approach for saving a model torch.save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True) å‚æ•°ï¼š obj â€“ ä¿å­˜å¯¹è±¡ f ï¼ ç±»æ–‡ä»¶å¯¹è±¡ (è¿”å›žæ–‡ä»¶æè¿°ç¬¦)æˆ–ä¸€ä¸ªä¿å­˜æ–‡ä»¶åçš„å­—ç¬¦ä¸² pickle_module â€“ ç”¨äºŽpicklingå…ƒæ•°æ®å’Œå¯¹è±¡çš„æ¨¡å— pickle_protocol â€“ æŒ‡å®špickle protocal å¯ä»¥è¦†ç›–é»˜è®¤å‚æ•° x = torch.tensor([0, 1, 2, 3, 4]) # Save to file torch.save(x, 'tensor.pt') # Save to io.BytesIO buffer buffer = io.BytesIO() torch.save(x, buffer) torch.load: ä»Žç£ç›˜æ–‡ä»¶ä¸­è¯»å–ä¸€ä¸ªé€šè¿‡torch.save()ä¿å­˜çš„å¯¹è±¡ torch.load(f, map_location=None, pickle_module=pickle, , weights_only=False, pickle_load_args*) torch.load('tensors.pt', encoding='ascii') torch.load('tensors.pt', map_location=torch.device('cpu')) torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'}) # Load from io.BytesIO buffer with open('tensor.pt', 'rb') as f: buffer = io.BytesIO(f.read()) torch.load(buffer) å¹¶è¡ŒåŒ– Parallelism torch.get_num_threads: èŽ·å¾—ç”¨äºŽå¹¶è¡ŒåŒ–CPUæ“ä½œçš„OpenMPçº¿ç¨‹æ•° torch.set_num_threads: è®¾å®šç”¨äºŽå¹¶è¡ŒåŒ–CPUæ“ä½œçš„OpenMPçº¿ç¨‹æ•° æ•°å­¦æ“ä½œMath operations torch.abs: è®¡ç®—è¾“å…¥å¼ é‡çš„æ¯ä¸ªå…ƒç´ ç»å¯¹å€¼ torch.abs(torch.FloatTensor([-1, -2, 3])) Out[0]: tensor([1., 2., 3.]) torch.acos: torch.acos(input, out=None) â†’ Tensor è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥å¼ é‡æ¯ä¸ªå…ƒç´ çš„åä½™å¼¦ torch.acos(torch.FloatTensor([-1, 1, 0])) Out[1]: tensor([3.1416, 0.0000, 1.5708]) torch.add: torch.add(input, value, out=None) å¯¹è¾“å…¥å¼ é‡inputé€å…ƒç´ åŠ ä¸Šæ ‡é‡å€¼valueï¼Œå¹¶è¿”å›žç»“æžœåˆ°ä¸€ä¸ªæ–°çš„å¼ é‡ a = torch.randn(4) Out[0]: tensor([ 0.3510, -0.2226, -0.7971, -0.2564]) torch.add(a, 20) Out[1]: tensor([20.3510, 19.7774, 19.2029, 19.7436]) torch.addcdiv: torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None) â†’ Tensor ç”¨tensor2å¯¹tensor1é€å…ƒç´ ç›¸é™¤ï¼Œç„¶åŽä¹˜ä»¥æ ‡é‡å€¼value å¹¶åŠ åˆ°tensor å¼ é‡çš„å½¢çŠ¶ä¸éœ€è¦åŒ¹é…ï¼Œä½†å…ƒç´ æ•°é‡å¿…é¡»ä¸€è‡´ å‚æ•°ï¼š tensor (Tensor) â€“ å¼ é‡ï¼Œå¯¹ tensor1 ./ tensor è¿›è¡Œç›¸åŠ  value (Number, optional) â€“ æ ‡é‡ï¼Œå¯¹ tensor1 ./ tensor2 è¿›è¡Œç›¸ä¹˜ tensor1 (Tensor) â€“ å¼ é‡ï¼Œä½œä¸ºè¢«é™¤æ•°(åˆ†å­) tensor2 (Tensor) â€“å¼ é‡ï¼Œä½œä¸ºé™¤æ•°(åˆ†æ¯) out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡ out _{i}=\\operatorname{input}_{i}+ value \\times \\frac{\\text { tensor } 1_{i}}{\\text { tensor 2}_{i}} t = torch.randn(1, 3) t1 = torch.randn(3, 1) t2 = torch.randn(1, 3) t, t1, t2 Out[0]: (tensor([[-1.2863, 1.1267, -1.7120]]), tensor([[-0.4294], [-0.5328], [-0.5373]]), tensor([[-0.0876, 0.4398, 1.3583]])) torch.addcdiv(t, t1, t2, value=0.1) Out[1]: tensor([[-0.7958, 1.0291, -1.7436], [-0.6778, 1.0056, -1.7512], [-0.6727, 1.0046, -1.7515]]) torch.addcmul: torch.addcmul(tensor, value=1, tensor1, tensor2, out=None) â†’ Tensor ç”¨tensor2å¯¹tensor1é€å…ƒç´ ç›¸ä¹˜ï¼Œå¹¶å¯¹ç»“æžœä¹˜ä»¥æ ‡é‡å€¼valueç„¶åŽåŠ åˆ°tensor å‚æ•°ï¼š tensor (Tensor) â€“ å¼ é‡ï¼Œå¯¹tensor1 ./ tensor è¿›è¡Œç›¸åŠ  value (Number, optional) â€“ æ ‡é‡ï¼Œå¯¹ tensor1 . tensor2 è¿›è¡Œç›¸ä¹˜ tensor1 (Tensor) â€“ å¼ é‡ï¼Œä½œä¸ºä¹˜å­1 tensor2 (Tensor) â€“å¼ é‡ï¼Œä½œä¸ºä¹˜å­2 out (Tensor, optional) â€“ è¾“å‡ºå¼ é‡ out _{i}= input _{i}+ value \\times tensor 1_{i} \\times tensor 2_{i} t = torch.randn(1, 3) t1 = torch.randn(3, 1) t2 = torch.randn(1, 3) t, t1, t2 Out[0]: (tensor([[-1.2863, 1.1267, -1.7120]]), tensor([[-0.4294], [-0.5328], [-0.5373]]), tensor([[-0.0876, 0.4398, 1.3583]])) torch.addcmul(t, t1, t2, value=0.1) Out[1]: tensor([[-1.2825, 1.1078, -1.7703], [-1.2816, 1.1033, -1.7844], [-1.2816, 1.1031, -1.7850]]) torch.asin: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„åæ­£å¼¦å‡½æ•° a = torch.randn(4) Out[0]: tensor([ 0.2583, -0.5285, 0.8979, 1.0104]) torch.asin(a) Out[1]: tensor([ 0.2613, -0.5569, 1.1149, nan]) torch.atan: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„åæ­£åˆ‡å‡½æ•° torch.atan2: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«ä¸¤ä¸ªè¾“å…¥å¼ é‡input1å’Œinput2çš„åæ­£åˆ‡å‡½æ•° torch.atan2(input1, input2, out=None) â†’ Tensor a = torch.randn(4) Out[0]: tensor([ 0.2583, -0.5285, 0.8979, 1.0104]) b = torch.randn(4) Out[2]: tensor([0.1100, 1.4311, 1.9536, 0.7652]) torch.atan(a) Out[1]: tensor([ 0.2528, -0.4862, 0.7316, 0.7906]) torch.atan2(a, b) Out[3]: tensor([ 1.1681, -0.3538, 0.4308, 0.9226]) torch.ceil: å¯¹è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ å‘ä¸Šå–æ•´, å³å–ä¸å°äºŽæ¯ä¸ªå…ƒç´ çš„æœ€å°æ•´æ•° a = torch.randn(4) Out[0]: tensor([-0.9105, -0.7277, 0.9516, -0.1081]) torch.ceil(a) Out[1]: tensor([-0., -0., 1., -0.]) torch.floor: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„floorï¼Œå³ä¸å°äºŽå…ƒç´ çš„æœ€å¤§æ•´æ•° a = torch.randn(4) Out[0]: tensor([-0.5661, -0.9135, 1.1018, -0.2633]) torch.floor(a) Out[1]: tensor([-1., -1., 1., -1.]) torch.fmod: è®¡ç®—é€å…ƒç´ ä½™æ•°ï¼Œ ä¿ç•™æ­£è´Ÿå· torch.remainder: è®¡ç®—é€å…ƒç´ ä½™æ•°ï¼Œ ç›¸å½“äºŽpython ä¸­çš„ % æ“ä½œç¬¦ t = torch.tensor([10, -22, 31, -47]) torch.fmod(t, 5) Out[0]: tensor([ 0, -2, 1, -2]) torch.remainder(t, 5) Out[1]: tensor([0, 3, 1, 3]) np.mod(np.array([10, -22, 31, -47]), 5) Out[2]: array([0, 3, 1, 3], dtype=int32) torch.clamp: torch.clamp(input, min, max, out=None) â†’ Tensor å°†è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„å¤¹ç´§åˆ°åŒºé—´ [min,max][min,max]ï¼Œå¹¶è¿”å›žç»“æžœåˆ°ä¸€ä¸ªæ–°å¼ é‡ | min, if x_i max a = torch.randn(4) Out[0]: tensor([-0.9105, -0.7277, 0.9516, -0.1081]) torch.clamp(a, min=-0.5, max=0.5) Out[1]: tensor([-0.5000, -0.5000, 0.5000, -0.1081]) torch.cos: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„ä½™å¼¦ torch.cosh: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„åŒæ›²ä½™å¼¦ a = torch.randn(4) Out[0]: tensor([-0.9105, -0.7277, 0.9516, -0.1081]) torch.cos(a) Out[1]: tensor([0.6133, 0.7467, 0.5804, 0.9942]) torch.cosh(a) Out[2]: tensor([1.4439, 1.2766, 1.4880, 1.0058]) torch.div(): å°†inputé€å…ƒç´ é™¤ä»¥æ ‡é‡å€¼valueï¼Œå¹¶è¿”å›žç»“æžœåˆ°è¾“å‡ºå¼ é‡out torch.div(input, value, out=None) ä¸¤å¼ é‡inputå’Œotheré€å…ƒç´ ç›¸é™¤ï¼Œå¹¶å°†ç»“æžœè¿”å›žåˆ°è¾“å‡º torch.div(input, other, **, rounding_mode=None, out=None*) â†’ Tensor a = torch.randn(4) Out[0]: tensor([-0.9105, -0.7277, 0.9516, -0.1081]) torch.div(a, 0.5) Out[1]: tensor([-1.8210, -1.4554, 1.9032, -0.2162]) a = torch.tensor([[-0.3711, -1.9353, -0.4605, -0.2917], [ 0.1815, -1.0111, 0.9805, -1.5923]]) b = torch.tensor([ 0.8032, 0.2930, -0.8113, -0.2308]) torch.div(a, b, rounding_mode='trunc') Out[2]: tensor([[-0., -6., 0., 1.], [ 0., -3., -1., 6.]]) torch.div(a, b, rounding_mode='floor') Out[3]: tensor([[-1., -7., 0., 1.], [ 0., -4., -2., 6.]]) torch.exp: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„æŒ‡æ•°ã€‚ import math torch.exp(torch.Tensor([0, math.log(2)])) Out[0]: tensor([1., 2.]) torch.frac: è¿”å›žæ¯ä¸ªå…ƒç´ çš„åˆ†æ•°éƒ¨åˆ† torch.frac(torch.Tensor([1, 2.5, -3.2])) Out[0]: tensor([ 0.0000, 0.5000, -0.2000]) torch.lerp: å¯¹ä¸¤ä¸ªå¼ é‡ä»¥startï¼Œendåšçº¿æ€§æ’å€¼ï¼Œ å°†ç»“æžœè¿”å›žåˆ°è¾“å‡ºå¼ é‡ torch.lerp(input, end, weight, **, out=None*) å‚æ•°ï¼š start (Tensor) â€“ èµ·å§‹ç‚¹å¼ é‡ end (Tensor) â€“ ç»ˆæ­¢ç‚¹å¼ é‡ weight (float) â€“ æ’å€¼å…¬å¼çš„weight out (Tensor, optional) â€“ ç»“æžœå¼ é‡ out_i=start_i+weight_iâˆ—(end_iâˆ’start_i) start = torch.arange(1., 5.) end = torch.empty(4).fill_(10) start, end Out[0]: (tensor([1., 2., 3., 4.]), tensor([10., 10., 10., 10.])) torch.lerp(start, end, 0.5) Out[1]: tensor([5.5000, 6.0000, 6.5000, 7.0000]) torch.lerp(start, end, torch.full_like(start, 0.5)) Out[2]: tensor([5.5000, 6.0000, 6.5000, 7.0000]) torch.log: è®¡ç®—input çš„è‡ªç„¶å¯¹æ•° torch.log1p: è®¡ç®—input + 1çš„è‡ªç„¶å¯¹æ•°y_i = log(x_i+1)ï¼Œå¯¹å€¼æ¯”è¾ƒå°çš„è¾“å…¥ï¼Œæ­¤å‡½æ•°æ¯”torch.log()æ›´å‡†ç¡® a = torch.randn(5) Out[0]: tensor([-0.3466, 2.3803, -0.0423, -0.9744, 0.4976]) torch.log(a) Out[1]: tensor([ nan, 0.8672, nan, nan, -0.6980]) torch.log1p(a) Out[2]: tensor([-0.4256, 1.2180, -0.0432, -3.6633, 0.4039]) torch.mul: ç”¨æ ‡é‡å€¼valueä¹˜ä»¥è¾“å…¥inputçš„æ¯ä¸ªå…ƒç´ ï¼Œå¹¶è¿”å›žä¸€ä¸ªæ–°çš„ç»“æžœå¼ é‡ torch.mul(input, value, out=None) ä¸¤ä¸ªå¼ é‡input,otheræŒ‰å…ƒç´ è¿›è¡Œç›¸ä¹˜ï¼Œå¹¶è¿”å›žåˆ°è¾“å‡ºå¼ é‡ torch.mul(input, other, out=None) a = torch.randn(3) Out[0]: tensor([ 0.0603, -0.5258, -0.3810]) b = torch.randn(3) Out[1]: tensor([ 1.2408, -1.3506, 0.9296]) torch.mul(a, 100) Out[2]: tensor([ 6.0299, -52.5785, -38.0989]) torch.mul(a, b) Out[3]: tensor([ 0.0748, 0.7101, -0.3542]) torch.neg: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥input å¼ é‡æŒ‰å…ƒç´ å–è´Ÿ a = torch.randn(3) Out[0]: tensor([ 0.0603, -0.5258, -0.3810]) torch.neg(a) Out[1]: tensor([-0.0603, 0.5258, 0.3810]) torch.pow: torch.pow(input, exponent, out=None) å¯¹è¾“å…¥inputçš„æŒ‰å…ƒç´ æ±‚exponentæ¬¡å¹‚å€¼ï¼Œå¹¶è¿”å›žç»“æžœå¼ é‡ã€‚ å¹‚å€¼exponent å¯ä»¥ä¸ºå•ä¸€ float æ•°æˆ–è€…ä¸Žinputç›¸åŒå…ƒç´ æ•°çš„å¼ é‡ a = torch.arange(1, 5) Out[0]: tensor([1, 2, 3, 4]) exp = torch.arange(1, 5) Out[1]: tensor([1, 2, 3, 4]) torch.pow(a, 2) Out[2]: tensor([ 1, 4, 9, 16]) torch.pow(a, exp) Out[3]: tensor([ 1, 4, 27, 256]) torch.pow(2, exp) Out[4]: tensor([ 2, 4, 8, 16]) torch.reciprocal: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„å€’æ•°ï¼Œå³ 1.0/x a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.reciprocal(a) Out[1]: tensor([1.0000, 0.5000, 0.3333, 0.2500]) torch.round: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼Œå°†è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ èˆå…¥åˆ°æœ€è¿‘çš„æ•´æ•° a = torch.randn(4) Out[0]: tensor([ 0.7995, -2.0975, 0.7273, 0.7539]) torch.round(a) Out[1]: tensor([ 1., -2., 1., 1.]) torch.rsqrt: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹æ ¹å€’æ•° a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.rsqrt(a) Out[1]: tensor([1.0000, 0.7071, 0.5774, 0.5000]) torch.sigmoid: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„sigmoidå€¼ a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.sigmoid(a) Out[1]: tensor([0.7311, 0.8808, 0.9526, 0.9820]) torch.sign: ç¬¦å·å‡½æ•°ï¼šè¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„æ­£è´Ÿ a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.sign(a) Out[1]: tensor([1., 1., 1., 1.]) torch.sin: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„æ­£å¼¦ torch.sinh: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„åŒæ›²æ­£å¼¦ a = torch.randn(4) torch.sin(a) Out[0]: tensor([-0.9215, 0.2650, 0.8285, 0.5914]) torch.sinh(a) Out[1]: tensor([-1.4591, 0.2714, 1.1392, 0.6759]) torch.sqrt: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„å¹³æ–¹æ ¹ a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.sqrt(a) Out[1]: tensor([1.0000, 1.4142, 1.7321, 2.0000]) torch.tan: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„æ­£åˆ‡ torch.tanh: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„åŒæ›²æ­£åˆ‡ a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.tan(a) Out[1]: tensor([ 1.5574, -2.1850, -0.1425, 1.1578]) torch.tanh(a) Out[2]: tensor([0.7616, 0.9640, 0.9951, 0.9993]) torch.trunc: è¿”å›žä¸€ä¸ªæ–°å¼ é‡ï¼ŒåŒ…å«è¾“å…¥inputå¼ é‡æ¯ä¸ªå…ƒç´ çš„æˆªæ–­å€¼(æ ‡é‡xçš„æˆªæ–­å€¼æ˜¯æœ€æŽ¥è¿‘å…¶çš„æ•´æ•°) ç®€è€Œè¨€ä¹‹ï¼Œæœ‰ç¬¦å·æ•°çš„å°æ•°éƒ¨åˆ†è¢«èˆå¼ƒ a = torch.randn(4) Out[0]: tensor([-2.1647, -0.2294, 0.4943, 1.5146]) torch.trunc(a) Out[1]: tensor([-2., -0., 0., 1.]) Reduction Ops torch.cumprod: torch.cumprod(input, dim, out=None) â†’ Tensor è¿”å›žè¾“å…¥æ²¿æŒ‡å®šç»´åº¦çš„ç´¯ç§¯ï¼Œä¾‹å¦‚ï¼Œå¦‚æžœè¾“å…¥æ˜¯ä¸€ä¸ªN å…ƒå‘é‡ï¼Œåˆ™ç»“æžœä¹Ÿæ˜¯ä¸€ä¸ªN å…ƒå‘é‡ï¼Œy_i= \\prod _{i}{x_i} a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.cumprod(a, dim=0) Out[1]: tensor([ 1., 2., 6., 24.]) torch.cumsum: torch.cumsum(input, dim, out=None) â†’ Tensor è¿”å›žè¾“å…¥æ²¿æŒ‡å®šç»´åº¦çš„ç´¯åŠ ï¼Œä¾‹å¦‚ï¼Œå¦‚æžœè¾“å…¥æ˜¯ä¸€ä¸ªN å…ƒå‘é‡ï¼Œåˆ™ç»“æžœä¹Ÿæ˜¯ä¸€ä¸ªN å…ƒå‘é‡ï¼Œy_i= \\sum _{i}{x_i} a = torch.Tensor([1, 2, 3, 4]) Out[0]: tensor([1., 2., 3., 4.]) torch.cumsum(a, dim=0) Out[1]: tensor([ 1., 3., 6., 10.]) torch.dist: è¿”å›ž (input - other) çš„ pèŒƒæ•° torch.dist(input, other, p=2, out=None) â†’ Tensor å‚æ•°ï¼š input (Tensor) â€“ è¾“å…¥å¼ é‡ other (Tensor) â€“ å³ä¾§è¾“å…¥å¼ é‡ p (float, optional) â€“ æ‰€è®¡ç®—çš„èŒƒæ•° out (Tensor, optional) â€“ ç»“æžœå¼ é‡ > ||x||_p = (\\sum _{i=1}^{n}{|x_i|^p})^{\\frac {1}{p}} > x = torch.Tensor([1, 2, 3, 4]) y = torch.Tensor([1, 2, 3, 0]) torch.dist(x, y, 3.5) Out[0]: tensor(4.0000) torch.dist(x, y, 3) Out[1]: tensor(4.) torch.norm: è¿”å›žè¾“å…¥å¼ é‡input çš„ p èŒƒæ•° torch.norm(input, p=2) â†’ float è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´dim ä¸Šæ¯è¡Œçš„p èŒƒæ•° torch.norm(input, p, dim, out=None) â†’ Tensor a = torch.randn(1, 3) Out[0]: tensor([[ 0.7848, -0.3629, 0.4028]]) torch.norm(a, 3) Out[1]: tensor(0.8418) a = torch.randn(3, 2) Out[2]: tensor([[ 1.0718, 3.1510], [-0.3178, -0.9579], [ 0.4065, 0.4106]]) torch.norm(a, 2, 1) Out[3]: tensor([3.3283, 1.0092, 0.5778]) torch.mean: è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦dimä¸Šæ¯è¡Œçš„å‡å€¼ torch.median: è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦æ¯è¡Œçš„ä¸­ä½æ•°ï¼ŒåŒæ—¶è¿”å›žä¸€ä¸ªåŒ…å«ä¸­ä½æ•°çš„ç´¢å¼•çš„LongTensor å‚æ•°ï¼š input (Tensor) â€“ è¾“å…¥å¼ é‡ dim (int) â€“ ç¼©å‡çš„ç»´åº¦ values (Tensor, optional) â€“ ç»“æžœå¼ é‡ indices (Tensor, optional) â€“ è¿”å›žçš„ç´¢å¼•ç»“æžœå¼ é‡ x = torch.Tensor([1, 2, 3, 4]) torch.mean(x) Out[0]: tensor(2.5000) torch.median(x) Out[1]: tensor(2.) torch.mode: è¿”å›žç»™å®šç»´dimä¸Šï¼Œæ¯è¡Œçš„ä¼—æ•°å€¼ï¼Œ åŒæ—¶è¿”å›žä¸€ä¸ªLongTensorï¼ŒåŒ…å«ä¼—æ•°èŒçš„ç´¢å¼• torch.mode(input, dim=-1, values=None, indices=None) -> (Tensor, LongTensor) è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦ä¸Šæ¯è¡Œçš„ç§¯ torch.prod(input, dim, out=None) â†’ Tensor a = torch.randn(2, 3) Out[0]: tensor([[-0.1038, 0.8983, -0.7463], [-0.6661, -0.5061, 0.2043]]) torch.mode(a, 1) Out[1]: torch.return_types.mode( values=tensor([-0.7463, -0.6661]), indices=tensor([2, 0])) torch.prod: è¿”å›žè¾“å…¥å¼ é‡input æ‰€æœ‰å…ƒç´ çš„ç§¯ x = torch.Tensor([1, 2, 3, 4]) torch.prod(x) Out[0]: tensor(24.) y = torch.Tensor([[1, 2], [3, 4]]) torch.prod(y, dim=1) Out[1]: tensor([ 2., 12.]) torch.std: è¿”å›žè¾“å…¥å¼ é‡input æ‰€æœ‰å…ƒç´ çš„æ ‡å‡†å·® torch.std(input) â†’ float è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦ä¸Šæ¯è¡Œçš„æ ‡å‡†å·® torch.std(input, dim, out=None) â†’ Tensor x = torch.Tensor([1, 2, 3, 4]) y = torch.Tensor([[1, 2], [3, 4]]) torch.std(x) Out[0]: tensor(1.2910) torch.std(y, dim=1) Out[1]: tensor([0.7071, 0.7071]) torch.sum: è¿”å›žè¾“å…¥å¼ é‡æ‰€æœ‰å…ƒç´ çš„å’Œ torch.sum(input) â†’ float è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦ä¸Šæ¯è¡Œçš„å’Œ torch.sum(input, dim, out=None) â†’ Tensor x = torch.Tensor([1, 2, 3, 4]) y = torch.Tensor([[1, 2], [3, 4]]) torch.var(x) Out[0]: tensor(10.0) torch.var(y, dim=1) Out[1]: tensor([3., 7.]) torch.var: è¿”å›žè¾“å…¥å¼ é‡æ‰€æœ‰å…ƒç´ çš„æ–¹å·® torch.var(input) â†’ float è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦ä¸Šæ¯è¡Œçš„æ–¹å·® torch.var(input, dim, out=None) â†’ Tensor x = torch.Tensor([1, 2, 3, 4]) y = torch.Tensor([[1, 2], [3, 4]]) torch.var(x) Out[0]: tensor(1.6667) torch.var(y, dim=1) Out[1]: tensor([0.5000, 0.5000]) æ¯”è¾ƒæ“ä½œ Comparison Ops torch.eq: torch.eq(input, other, out=None) â†’ Tensor æ¯”è¾ƒå…ƒç´ ç›¸ç­‰æ€§ã€‚ç¬¬äºŒä¸ªå‚æ•°å¯ä¸ºä¸€ä¸ªæ•°æˆ–ä¸Žç¬¬ä¸€ä¸ªå‚æ•°åŒç±»åž‹å½¢çŠ¶çš„å¼ é‡ torch.ge: torch.ge(input, other, out=None) â†’ Tensor é€å…ƒç´ æ¯”è¾ƒinputå’Œotherï¼Œå³æ˜¯å¦ input>=other torch.gt: torch.gt(input, other, out=None) â†’ Tensor é€å…ƒç´ æ¯”è¾ƒinputå’Œother ï¼Œ å³æ˜¯å¦input>otherinput>other torch.le: torch.le(input, other, out=None) â†’ Tensor é€å…ƒç´ æ¯”è¾ƒinputå’Œother ï¼Œ å³æ˜¯å¦input torch.lt: torch.lt(input, other, out=None) â†’ Tensor é€å…ƒç´ æ¯”è¾ƒinputå’Œother ï¼Œ å³æ˜¯å¦ input torch.ne: torch.ne(input, other, out=None) â†’ Tensor é€å…ƒç´ æ¯”è¾ƒinputå’Œotherï¼Œå³æ˜¯å¦ input!=other torch.eq(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) Out[0]: tensor([[ True, False], [False, True]]) torch.ge(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) Out[1]: tensor([[ True, True], [False, True]]) torch.gt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) Out[2]: tensor([[False, True], [False, False]]) torch.le(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) Out[3]: tensor([[ True, False], [ True, True]]) torch.lt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) Out[4]: tensor([[False, False], [ True, False]]) torch.ne(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) Out[5]: tensor([[False, True], [ True, False]]) torch.equal: torch.equal(tensor1, tensor2) â†’ bool å¦‚æžœä¸¤ä¸ªå¼ é‡æœ‰ç›¸åŒçš„å½¢çŠ¶å’Œå…ƒç´ å€¼ï¼Œåˆ™è¿”å›žTrue ï¼Œå¦åˆ™ False torch.equal(torch.Tensor([1, 2]), torch.Tensor([1, 2])) Out[0]: True torch.kthvalue: torch.kthvalue(input, k, dim=None, out=None) -> (Tensor, LongTensor) å–è¾“å…¥å¼ é‡inputæŒ‡å®šç»´ä¸Šç¬¬k ä¸ªæœ€å°å€¼ã€‚å¦‚æžœä¸æŒ‡å®šdimï¼Œåˆ™é»˜è®¤ä¸ºinputçš„æœ€åŽä¸€ç»´ torch.topk: æ²¿ç»™å®šdimç»´åº¦è¿”å›žè¾“å…¥å¼ é‡inputä¸­ k ä¸ªæœ€å¤§å€¼ã€‚ å¦‚æžœä¸æŒ‡å®šdimï¼Œåˆ™é»˜è®¤ä¸ºinputçš„æœ€åŽä¸€ç»´ã€‚ å¦‚æžœä¸ºlargestä¸º False ï¼Œåˆ™è¿”å›žæœ€å°çš„ k ä¸ªå€¼ è¿”å›žä¸€ä¸ªå…ƒç»„ (values,indices)ï¼Œå…¶ä¸­indicesæ˜¯åŽŸå§‹è¾“å…¥å¼ é‡inputä¸­æµ‹å…ƒç´ ä¸‹æ ‡ã€‚ å¦‚æžœè®¾å®šå¸ƒå°”å€¼sorted ä¸ºTrueï¼Œå°†ä¼šç¡®ä¿è¿”å›žçš„ k ä¸ªå€¼è¢«æŽ’åº torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor) å‚æ•°: input (Tensor) â€“ è¾“å…¥å¼ é‡ k (int) â€“ â€œtop-kâ€ä¸­çš„k dim (int, optional) â€“ æŽ’åºçš„ç»´ largest (bool, optional) â€“ å¸ƒå°”å€¼ï¼ŒæŽ§åˆ¶è¿”å›žæœ€å¤§æˆ–æœ€å°å€¼ sorted (bool, optional) â€“ å¸ƒå°”å€¼ï¼ŒæŽ§åˆ¶è¿”å›žå€¼æ˜¯å¦æŽ’åº out (tuple, optional) â€“ å¯é€‰è¾“å‡ºå¼ é‡ (Tensor, LongTensor) output buffers x = torch.arange(1, 6) # torch.kthvalue torch.kthvalue(x, 4) Out[0]: torch.return_types.kthvalue( values=tensor(4), indices=tensor(3)) # torch.topk x = torch.arange(1, 6) Out[1]: tensor([1, 2, 3, 4, 5]) torch.topk(x, 3) Out[2]: torch.return_types.topk( values=tensor([5, 4, 3]), indices=tensor([4, 3, 2])) torch.topk(x, 3, 0, largest=False) Out[3]: torch.return_types.topk( values=tensor([1, 2, 3]), indices=tensor([0, 1, 2])) torch.max: è¿”å›žè¾“å…¥å¼ é‡æ‰€æœ‰å…ƒç´ çš„æœ€å¤§å€¼ torch.max() è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦ä¸Šæ¯è¡Œçš„æœ€å¤§å€¼ï¼Œå¹¶åŒæ—¶è¿”å›žæ¯ä¸ªæœ€å¤§å€¼çš„ä½ç½®ç´¢å¼• torch.max(input, dim, max=None, max_indices=None) -> (Tensor, LongTensor) inputä¸­é€å…ƒç´ ä¸Žotherç›¸åº”ä½ç½®çš„å…ƒç´ å¯¹æ¯”ï¼Œè¿”å›žæœ€å¤§å€¼åˆ°è¾“å‡ºå¼ é‡ torch.max(input, other, out=None) â†’ Tensor torch.min: è¿”å›žè¾“å…¥å¼ é‡æ‰€æœ‰å…ƒç´ çš„æœ€å°å€¼ torch.min(input) â†’ float è¿”å›žè¾“å…¥å¼ é‡ç»™å®šç»´åº¦ä¸Šæ¯è¡Œçš„æœ€å°å€¼ï¼Œå¹¶åŒæ—¶è¿”å›žæ¯ä¸ªæœ€å°å€¼çš„ä½ç½®ç´¢å¼• torch.min(input, dim, min=None, min_indices=None) -> (Tensor, LongTensor) inputä¸­é€å…ƒç´ ä¸Žotherç›¸åº”ä½ç½®çš„å…ƒç´ å¯¹æ¯”ï¼Œè¿”å›žæœ€å°å€¼åˆ°è¾“å‡ºå¼ é‡ torch.min(input, other, out=None) â†’ Tensor a = torch.randn(2, 2) Out[0]: tensor([[-0.1204, -0.5016], [ 1.2717, 0.7351]]) b = torch.randn(2, 2) Out[1]: tensor([[-1.4497, 0.7534], [ 0.5994, -0.1490]]) # æœ€å¤§å€¼ torch.max(torch.arange(1, 5)) Out[2]: tensor(4) torch.max(a, 1) Out[3]: torch.return_types.max( values=tensor([-0.1204, 1.2717]), indices=tensor([0, 0])) torch.max(a, b) Out[4]: tensor([[-0.1204, 0.7534], [ 1.2717, 0.7351]]) # æœ€å°å€¼ torch.min(torch.arange(1, 5)) Out[5]: tensor(1) torch.min(a, 1) Out[6]: torch.return_types.min( values=tensor([-0.5016, 0.7351]), indices=tensor([1, 1])) torch.min(a, b) Out[7]: tensor([[-1.4497, -0.5016], [ 0.5994, -0.1490]]) torch.sort: torch.sort(input, dim=None, descending=False, out=None) -> (Tensor, LongTensor) å¯¹è¾“å…¥å¼ é‡inputæ²¿ç€æŒ‡å®šç»´æŒ‰å‡åºæŽ’åºã€‚å¦‚æžœä¸ç»™å®šdimï¼Œåˆ™é»˜è®¤ä¸ºè¾“å…¥çš„æœ€åŽä¸€ç»´ã€‚å¦‚æžœæŒ‡å®šå‚æ•°descendingä¸ºTrueï¼Œåˆ™æŒ‰é™åºæŽ’åº è¿”å›žå…ƒç»„ (sorted_tensor, sorted_indices) ï¼Œ sorted_indices ä¸ºåŽŸå§‹è¾“å…¥ä¸­çš„ä¸‹æ ‡ x = torch.randn(3, 4) Out[0]: tensor([[-2.3460, 1.3734, 1.1444, -0.4736], [-1.1785, 0.8436, -1.4403, -0.1073], [-0.1198, 0.7067, -0.0734, -1.6181]]) sorted, indices = torch.sort(x) sorted, indices Out[1]: (tensor([[-2.3460, -0.4736, 1.1444, 1.3734], [-1.4403, -1.1785, -0.1073, 0.8436], [-1.6181, -0.1198, -0.0734, 0.7067]]), tensor([[0, 3, 2, 1], [2, 0, 3, 1], [3, 0, 2, 1]])) å…¶å®ƒæ“ä½œ Other Operations torch.cross: è¿”å›žæ²¿ç€ç»´åº¦dimä¸Šï¼Œä¸¤ä¸ªå¼ é‡inputå’Œotherçš„å‘é‡ç§¯ï¼ˆå‰ç§¯ï¼‰ã€‚ inputå’Œother å¿…é¡»æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼Œä¸”æŒ‡å®šçš„dimç»´ä¸Šsizeå¿…é¡»ä¸º3 å¦‚æžœä¸æŒ‡å®šdimï¼Œåˆ™é»˜è®¤ä¸ºç¬¬ä¸€ä¸ªå°ºåº¦ä¸º3çš„ç»´ torch.cross(input, other, dim=-1, out=None) â†’ Tensor \\left[\\begin{array}{l}a_{1} \\\\ a_{2} \\\\ a_{3}\\end{array}\\right] \\times\\left[\\begin{array}{l}b_{1} \\\\ b_{2} \\\\ b_{3}\\end{array}\\right]=\\left[\\begin{array}{c}a_{2} b_{3}-a_{3} b_{2} \\\\ a_{3} b_{1}-a_{1} b_{3} \\\\ a_{1} b_{2}-a_{2} b_{1}\\end{array}\\right] a = torch.randint(1, 6, (2, 3)) Out[0]: tensor([[5, 4, 5], [4, 2, 3]]) b = torch.randint(1, 6, (2, 3)) Out[1]: tensor([[1, 1, 2], [3, 4, 2]]) torch.cross(a, a) Out[2]: tensor([[0, 0, 0], [0, 0, 0]]) torch.cross(a, b) Out[3]: tensor([[ 3, -5, 1], [-8, 1, 10]]) torch.diag: torch.diag(input, diagonal=0, out=None) â†’ Tensor å¦‚æžœè¾“å…¥æ˜¯ä¸€ä¸ªå‘é‡(1D å¼ é‡)ï¼Œåˆ™è¿”å›žä¸€ä¸ªä»¥inputä¸ºå¯¹è§’çº¿å…ƒç´ çš„2Dæ–¹é˜µ å¦‚æžœè¾“å…¥æ˜¯ä¸€ä¸ªçŸ©é˜µ(2D å¼ é‡)ï¼Œåˆ™è¿”å›žä¸€ä¸ªåŒ…å«inputå¯¹è§’çº¿å…ƒç´ çš„1Då¼ é‡ å‚æ•°diagonalæŒ‡å®šå¯¹è§’çº¿: diagonal = 0, ä¸»å¯¹è§’çº¿ diagonal > 0, ä¸»å¯¹è§’çº¿ä¹‹ä¸Š diagonal # å¦‚æžœè¾“å…¥æ˜¯ä¸€ä¸ªå‘é‡(1D å¼ é‡)ï¼Œåˆ™è¿”å›žä¸€ä¸ªä»¥`input`ä¸ºå¯¹è§’çº¿å…ƒç´ çš„2Dæ–¹é˜µ a = torch.randn(3) Out[0]: tensor([-0.3509, 0.6176, -1.4976]) torch.diag(a) Out[1]: tensor([[-0.3509, 0.0000, 0.0000], [ 0.0000, 0.6176, 0.0000], [ 0.0000, 0.0000, -1.4976]]) torch.diag(a, 1) Out[2]: tensor([[ 0.0000, -0.3509, 0.0000, 0.0000], [ 0.0000, 0.0000, 0.6176, 0.0000], [ 0.0000, 0.0000, 0.0000, -1.4976], [ 0.0000, 0.0000, 0.0000, 0.0000]]) # å¦‚æžœè¾“å…¥æ˜¯ä¸€ä¸ªçŸ©é˜µ(2D å¼ é‡)ï¼Œåˆ™è¿”å›žä¸€ä¸ªåŒ…å«`input`å¯¹è§’çº¿å…ƒç´ çš„1Då¼ é‡ # å–å¾—ç»™å®šçŸ©é˜µç¬¬kä¸ªå¯¹è§’çº¿: a = torch.randn(3, 3) Out[3]: tensor([[ 0.8224, 0.7792, 0.2605], [-0.8646, 0.2568, -0.8189], [ 1.1693, 0.8108, -1.9662]]) torch.diag(a, 0) Out[4]: tensor([ 0.8224, 0.2568, -1.9662]) torch.diag(a, 1) Out[5]: tensor([ 0.7792, -0.8189]) torch.histc: torch.histc(input, bins=100, min=0, max=0, out=None) â†’ Tensor è®¡ç®—è¾“å…¥å¼ é‡çš„ç›´æ–¹å›¾ã€‚ä»¥minå’Œmaxä¸ºrangeè¾¹ç•Œï¼Œå°†å…¶å‡åˆ†æˆbinsä¸ªç›´æ¡ï¼Œç„¶åŽå°†æŽ’åºå¥½çš„æ•°æ®åˆ’åˆ†åˆ°å„ä¸ªç›´æ¡(bins)ä¸­ å‚æ•°ï¼š input (Tensor) â€“ è¾“å…¥å¼ é‡ bins (int) â€“ ç›´æ–¹å›¾ bins(ç›´æ¡)çš„ä¸ªæ•°(é»˜è®¤100ä¸ª) min (int) â€“ rangeçš„ä¸‹è¾¹ç•Œ(åŒ…å«) max (int) â€“ rangeçš„ä¸Šè¾¹ç•Œ(åŒ…å«) out (Tensor, optional) â€“ ç»“æžœå¼ é‡ torch.histc(torch.FloatTensor([1, 2, 1]), bins=4, min=0, max=3) Out[0]: tensor([0., 2., 1., 0.]) torch.histc(torch.FloatTensor([1, 1, 2, 1]), bins=4, min=0, max=3) Out[1]: tensor([0., 3., 1., 0.]) torch.renorm: torch.renorm(input, p, dim, maxnorm, out=None) â†’ Tensor è¿”å›žä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«è§„èŒƒåŒ–åŽçš„å„ä¸ªå­å¼ é‡ï¼Œä½¿å¾—æ²¿ç€dimç»´åˆ’åˆ†çš„å„å­å¼ é‡çš„pèŒƒæ•°å°äºŽmaxnorm å¦‚æžœpèŒƒæ•°çš„å€¼å°äºŽmaxnormï¼Œåˆ™å½“å‰å­å¼ é‡ä¸éœ€è¦ä¿®æ”¹ å‚æ•°ï¼š input (Tensor) â€“ è¾“å…¥å¼ é‡ p (float) â€“ èŒƒæ•°çš„p dim (int) â€“ æ²¿ç€æ­¤ç»´åˆ‡ç‰‡ï¼Œå¾—åˆ°å¼ é‡å­é›† maxnorm (float) â€“ æ¯ä¸ªå­å¼ é‡çš„èŒƒæ•°çš„æœ€å¤§å€¼ out (Tensor, optional) â€“ ç»“æžœå¼ é‡ x = torch.ones(3, 3) x[1].fill_(2) x[2].fill_(3) Out[0]: tensor([[1., 1., 1.], [2., 2., 2.], [3., 3., 3.]]) torch.renorm(x, p=1, dim=0, maxnorm=5) Out[1]: tensor([[1.0000, 1.0000, 1.0000], [1.6667, 1.6667, 1.6667], [1.6667, 1.6667, 1.6667]]) torch.trace: è¿”å›žè¾“å…¥2ç»´çŸ©é˜µå¯¹è§’çº¿å…ƒç´ çš„å’Œ(è¿¹) x = torch.arange(1, 10).view(3, 3) Out[0]: tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) torch.trace(x) Out[1]: tensor(15) torch.tril: torch.tril(input, diagonal=0, out=None) â†’ Tensor è¿”å›žä¸€ä¸ªå¼ é‡outï¼ŒåŒ…å«è¾“å…¥çŸ©é˜µ(2Då¼ é‡)çš„ä¸‹ä¸‰è§’éƒ¨åˆ†ï¼Œoutå…¶ä½™éƒ¨åˆ†è¢«è®¾ä¸º0 x = torch.arange(1, 10).view(3, 3) Out[0]: tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) torch.tril(x) Out[1]: tensor([[1, 0, 0], [4, 5, 0], [7, 8, 9]]) torch.tril(x, diagonal=1) Out[2]: tensor([[1, 2, 0], [4, 5, 6], [7, 8, 9]]) torch.triu: torch.triu(input, k=0, out=None) â†’ Tensor è¿”å›žä¸€ä¸ªå¼ é‡ï¼ŒåŒ…å«è¾“å…¥çŸ©é˜µ(2Då¼ é‡)çš„ä¸Šä¸‰è§’éƒ¨åˆ†ï¼Œå…¶ä½™éƒ¨åˆ†è¢«è®¾ä¸º0ã€‚è¿™é‡Œæ‰€è¯´çš„ä¸Šä¸‰è§’éƒ¨åˆ†ä¸ºçŸ©é˜µæŒ‡å®šå¯¹è§’çº¿diagonalä¹‹ä¸Šçš„å…ƒç´ ã€‚ å‚æ•°kæŽ§åˆ¶å¯¹è§’çº¿: - k = 0, ä¸»å¯¹è§’çº¿ - k > 0, ä¸»å¯¹è§’çº¿ä¹‹ä¸Š - k x = torch.arange(1, 10).view(3, 3) Out[0]: tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) torch.triu(x) Out[1]: tensor([[1, 2, 3], [0, 5, 6], [0, 0, 9]]) torch.triu(x, diagonal=1) Out[2]: tensor([[0, 2, 3], [0, 0, 6], [0, 0, 0]]) BLAS and LAPACK Operations torch.addbmm torch.addmm torch.addmv torch.addr torch.baddbmm torch.bmm torch.btrifact torch.btrisolve torch.dot: è®¡ç®—ä¸¤ä¸ªå¼ é‡çš„ç‚¹ä¹˜(å†…ä¹˜),ä¸¤ä¸ªå¼ é‡éƒ½ä¸º1-D å‘é‡ torch.dot(tensor1, tensor2) â†’ float torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1])) Out[0]: tensor(7.) torch.linalg.eig: è®¡ç®—å®žæ–¹é˜µa çš„ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ torch.linalg.eig(A, * , out=None) A = torch.randn(2, 2, dtype=torch.complex128) Out[0]: tensor([[-0.2029-0.0673j, -0.5188-0.6723j], [-1.1984+0.0585j, 0.5786-0.1849j]], dtype=torch.complex128) L, V = torch.linalg.eig(A) Out[1]: (tensor([-0.7870-0.5003j, 1.1626+0.2481j], dtype=torch.complex128), tensor([[ 0.7596+0.0000j, -0.4008-0.3285j], [ 0.6258-0.1770j, 0.8552+0.0000j]], dtype=torch.complex128)) Tensor torch.Tensoræ˜¯ä¸€ç§åŒ…å«å•ä¸€æ•°æ®ç±»åž‹å…ƒç´ çš„å¤šç»´çŸ©é˜µ Torchå®šä¹‰äº†10ç§CPU tensorç±»åž‹å’ŒGPU tensorç±»åž‹ï¼š Data type dtype CPU tensor GPU tensor 32-bit floating point torch.float32 or torch.float torch.FloatTensor torch.cuda.FloatTensor 64-bit floating point torch.float64 or torch.double torch.DoubleTensor torch.cuda.DoubleTensor 16-bit floating point [1] torch.float16 or torch.half torch.HalfTensor torch.cuda.HalfTensor 16-bit floating point [2] torch.bfloat16 torch.BFloat16Tensor torch.cuda.BFloat16Tensor 32-bit complex torch.complex32 or torch.chalf 64-bit complex torch.complex64 or torch.cfloat 128-bit complex torch.complex128 or torch.cdouble 8-bit integer (unsigned) torch.uint8 torch.ByteTensor torch.cuda.ByteTensor 8-bit integer (signed) torch.int8 torch.CharTensor torch.cuda.CharTensor 16-bit integer (signed) torch.int16 or torch.short torch.ShortTensor torch.cuda.ShortTensor 32-bit integer (signed) torch.int32 or torch.int torch.IntTensor torch.cuda.IntTensor 64-bit integer (signed) torch.int64 or torch.long torch.LongTensor torch.cuda.LongTensor Boolean torch.bool torch.BoolTensor torch.cuda.BoolTensor quantized 8-bit integer (unsigned) torch.quint8 torch.ByteTensor / quantized 8-bit integer (signed) torch.qint8 torch.CharTensor / quantized 32-bit integer (signed) torch.qint32 torch.IntTensor / quantized 4-bit integer (unsigned) [3] torch.quint4x2 torch.ByteTensor / åˆ›å»º ä¸€ä¸ªå¼ é‡tensorå¯ä»¥ä»ŽPythonçš„listæˆ–åºåˆ—æž„å»º torch.FloatTensor([[1, 2, 3], [4, 5, 6]]) Out[0]: tensor([[1., 2., 3.], [4., 5., 6.]]) æ ¹æ®å¯é€‰æ‹©çš„å¤§å°å’Œæ•°æ®æ–°å»ºä¸€ä¸ªtensorã€‚ å¦‚æžœæ²¡æœ‰æä¾›å‚æ•°ï¼Œå°†ä¼šè¿”å›žä¸€ä¸ªç©ºçš„é›¶ç»´å¼ é‡ã€‚å¦‚æžœæä¾›äº†numpy.ndarray,torch.Tensoræˆ–torch.Storageï¼Œå°†ä¼šè¿”å›žä¸€ä¸ªæœ‰åŒæ ·å‚æ•°çš„tensor.å¦‚æžœæä¾›äº†pythonåºåˆ—ï¼Œå°†ä¼šä»Žåºåˆ—çš„å‰¯æœ¬åˆ›å»ºä¸€ä¸ªtensor # æŽ¥å£ ä¸€ä¸ªç©ºå¼ é‡tensorå¯ä»¥é€šè¿‡è§„å®šå…¶å¤§å°æ¥æž„å»º class torch.Tensor class torch.Tensor(*sizes) class torch.Tensor(size) class torch.Tensor(sequence) class torch.Tensor(ndarray) class torch.Tensor(tensor) class torch.Tensor(storage) # å®žä¾‹åŒ– torch.IntTensor(2, 4).zero_() å¯ä»¥ç”¨pythonçš„ç´¢å¼•å’Œåˆ‡ç‰‡æ¥èŽ·å–å’Œä¿®æ”¹ä¸€ä¸ªå¼ é‡tensorä¸­çš„å†…å®¹ x = torch.FloatTensor([[1, 2, 3], [4, 5, 6]]) x[1][2] Out[0]: tensor(6.) x[0][1] = 8 x Out[1]: tensor([[1., 8., 3.], [4., 5., 6.]]) æ¯ä¸€ä¸ªå¼ é‡tensoréƒ½æœ‰ä¸€ä¸ªç›¸åº”çš„torch.Storageç”¨æ¥ä¿å­˜å…¶æ•°æ®ã€‚ç±»tensoræä¾›äº†ä¸€ä¸ªå­˜å‚¨çš„å¤šç»´çš„ã€æ¨ªå‘è§†å›¾ï¼Œå¹¶ä¸”å®šä¹‰äº†åœ¨æ•°å€¼è¿ç®— ä¼šæ”¹å˜tensorçš„å‡½æ•°æ“ä½œä¼šç”¨ä¸€ä¸ªä¸‹åˆ’çº¿åŽç¼€æ¥æ ‡ç¤ºã€‚æ¯”å¦‚ï¼Œtorch.FloatTensor.abs_()ä¼šåœ¨åŽŸåœ°è®¡ç®—ç»å¯¹å€¼ï¼Œå¹¶è¿”å›žæ”¹å˜åŽçš„tensorï¼Œè€Œtensor.FloatTensor.abs()å°†ä¼šåœ¨ä¸€ä¸ªæ–°çš„tensorä¸­è®¡ç®—ç»“æžœ å…³é”®å±žæ€§å’Œæ–¹æ³• Tensor.new_tensor Returns a new Tensor with data as the tensor data. Tensor.new_full Returns a Tensor of size size filled with fill_value. Tensor.new_empty Returns a Tensor of size size filled with uninitialized data. Tensor.new_ones Returns a Tensor of size size filled with 1. Tensor.new_zeros Returns a Tensor of size size filled with 0. Tensor.is_cuda Is True if the Tensor is stored on the GPU, False otherwise. Tensor.is_quantized Is True if the Tensor is quantized, False otherwise. Tensor.is_meta Is True if the Tensor is a meta tensor, False otherwise. Tensor.device Is the torch.device where this Tensor is. Tensor.grad This attribute is None by default and becomes a Tensor the first time a call to backward() computes gradients for self. Tensor.ndim Alias for dim() Tensor.real Returns a new tensor containing real values of the self tensor for a complex-valued input tensor. Tensor.imag Returns a new tensor containing imaginary values of the self tensor. Tensor.abs See torch.abs() Tensor.abs_ In-place version of abs() Tensor.absolute Alias for abs() Tensor.absolute_ In-place version of absolute() Alias for abs_() Tensor.acos See torch.acos() Tensor.acos_ In-place version of acos() Tensor.arccos See torch.arccos() Tensor.arccos_ In-place version of arccos() Tensor.add Add a scalar or tensor to self tensor. Tensor.add_ In-place version of add() Tensor.addbmm See torch.addbmm() Tensor.addbmm_ In-place version of addbmm() Tensor.addcdiv See torch.addcdiv() Tensor.addcdiv_ In-place version of addcdiv() Tensor.addcmul See torch.addcmul() Tensor.addcmul_ In-place version of addcmul() Tensor.addmm See torch.addmm() Tensor.addmm_ In-place version of addmm() Tensor.sspaddmm See torch.sspaddmm() Tensor.addmv See torch.addmv() Tensor.addmv_ In-place version of addmv() Tensor.addr See torch.addr() Tensor.addr_ In-place version of addr() Tensor.adjoint Alias for adjoint() Tensor.allclose See torch.allclose() Tensor.amax See torch.amax() Tensor.amin See torch.amin() Tensor.aminmax See torch.aminmax() Tensor.angle See torch.angle() Tensor.apply_ Applies the function callable to each element in the tensor, replacing each element with the value returned by callable. Tensor.argmax See torch.argmax() Tensor.argmin See torch.argmin() Tensor.argsort See torch.argsort() Tensor.argwhere See torch.argwhere() Tensor.asin See torch.asin() Tensor.asin_ In-place version of asin() Tensor.arcsin See torch.arcsin() Tensor.arcsin_ In-place version of arcsin() Tensor.as_strided See torch.as_strided() Tensor.atan See torch.atan() Tensor.atan_ In-place version of atan() Tensor.arctan See torch.arctan() Tensor.arctan_ In-place version of arctan() Tensor.atan2 See torch.atan2() Tensor.atan2_ In-place version of atan2() Tensor.arctan2 See torch.arctan2() Tensor.arctan2_ atan2_(other) -> Tensor Tensor.all See torch.all() Tensor.any See torch.any() Tensor.backward Computes the gradient of current tensor w.r.t. Tensor.baddbmm See torch.baddbmm() Tensor.baddbmm_ In-place version of baddbmm() Tensor.bernoulli Returns a result tensor where each \\texttt{result[i]}result[i] is independently sampled from \\text{Bernoulli}(\\texttt{self[i]})Bernoulli(self[i]). Tensor.bernoulli_ Fills each location of self with an independent sample from \\text{Bernoulli}(\\texttt{p})Bernoulli(p). Tensor.bfloat16 self.bfloat16() is equivalent to self.to(torch.bfloat16). Tensor.bincount See torch.bincount() Tensor.bitwise_not See torch.bitwise_not() Tensor.bitwise_not_ In-place version of bitwise_not() Tensor.bitwise_and See torch.bitwise_and() Tensor.bitwise_and_ In-place version of bitwise_and() Tensor.bitwise_or See torch.bitwise_or() Tensor.bitwise_or_ In-place version of bitwise_or() Tensor.bitwise_xor See torch.bitwise_xor() Tensor.bitwise_xor_ In-place version of bitwise_xor() Tensor.bitwise_left_shift See torch.bitwise_left_shift() Tensor.bitwise_left_shift_ In-place version of bitwise_left_shift() Tensor.bitwise_right_shift See torch.bitwise_right_shift() Tensor.bitwise_right_shift_ In-place version of bitwise_right_shift() Tensor.bmm See torch.bmm() Tensor.bool self.bool() is equivalent to self.to(torch.bool). Tensor.byte self.byte() is equivalent to self.to(torch.uint8). Tensor.broadcast_to See torch.broadcast_to(). Tensor.cauchy_ Fills the tensor with numbers drawn from the Cauchy distribution: Tensor.ceil See torch.ceil() Tensor.ceil_ In-place version of ceil() Tensor.char self.char() is equivalent to self.to(torch.int8). Tensor.cholesky See torch.cholesky() Tensor.cholesky_inverse See torch.cholesky_inverse() Tensor.cholesky_solve See torch.cholesky_solve() Tensor.chunk See torch.chunk() Tensor.clamp See torch.clamp() Tensor.clamp_ In-place version of clamp() Tensor.clip Alias for clamp(). Tensor.clip_ Alias for clamp_(). Tensor.clone See torch.clone() Tensor.contiguous Returns a contiguous in memory tensor containing the same data as self tensor. Tensor.copy_ Copies the elements from src into self tensor and returns self. Tensor.conj See torch.conj() Tensor.conj_physical See torch.conj_physical() Tensor.conj_physical_ In-place version of conj_physical() Tensor.resolve_conj See torch.resolve_conj() Tensor.resolve_neg See torch.resolve_neg() Tensor.copysign See torch.copysign() Tensor.copysign_ In-place version of copysign() Tensor.cos See torch.cos() Tensor.cos_ In-place version of cos() Tensor.cosh See torch.cosh() Tensor.cosh_ In-place version of cosh() Tensor.corrcoef See torch.corrcoef() Tensor.count_nonzero See torch.count_nonzero() Tensor.cov See torch.cov() Tensor.acosh See torch.acosh() Tensor.acosh_ In-place version of acosh() Tensor.arccosh acosh() -> Tensor Tensor.arccosh_ acosh_() -> Tensor Tensor.cpu Returns a copy of this object in CPU memory. Tensor.cross See torch.cross() Tensor.cuda Returns a copy of this object in CUDA memory. Tensor.logcumsumexp See torch.logcumsumexp() Tensor.cummax See torch.cummax() Tensor.cummin See torch.cummin() Tensor.cumprod See torch.cumprod() Tensor.cumprod_ In-place version of cumprod() Tensor.cumsum See torch.cumsum() Tensor.cumsum_ In-place version of cumsum() Tensor.chalf self.chalf() is equivalent to self.to(torch.complex32). Tensor.cfloat self.cfloat() is equivalent to self.to(torch.complex64). Tensor.cdouble self.cdouble() is equivalent to self.to(torch.complex128). Tensor.data_ptr Returns the address of the first element of self tensor. Tensor.deg2rad See torch.deg2rad() Tensor.dequantize Given a quantized Tensor, dequantize it and return the dequantized float Tensor. Tensor.det See torch.det() Tensor.dense_dim Return the number of dense dimensions in a sparse tensor self. Tensor.detach Returns a new Tensor, detached from the current graph. Tensor.detach_ Detaches the Tensor from the graph that created it, making it a leaf. Tensor.diag See torch.diag() Tensor.diag_embed See torch.diag_embed() Tensor.diagflat See torch.diagflat() Tensor.diagonal See torch.diagonal() Tensor.diagonal_scatter See torch.diagonal_scatter() Tensor.fill_diagonal_ Fill the main diagonal of a tensor that has at least 2-dimensions. Tensor.fmax See torch.fmax() Tensor.fmin See torch.fmin() Tensor.diff See torch.diff() Tensor.digamma See torch.digamma() Tensor.digamma_ In-place version of digamma() Tensor.dim Returns the number of dimensions of self tensor. Tensor.dist See torch.dist() Tensor.div See torch.div() Tensor.div_ In-place version of div() Tensor.divide See torch.divide() Tensor.divide_ In-place version of divide() Tensor.dot See torch.dot() Tensor.double self.double() is equivalent to self.to(torch.float64). Tensor.dsplit See torch.dsplit() Tensor.element_size Returns the size in bytes of an individual element. Tensor.eq See torch.eq() Tensor.eq_ In-place version of eq() Tensor.equal See torch.equal() Tensor.erf See torch.erf() Tensor.erf_ In-place version of erf() Tensor.erfc See torch.erfc() Tensor.erfc_ In-place version of erfc() Tensor.erfinv See torch.erfinv() Tensor.erfinv_ In-place version of erfinv() Tensor.exp See torch.exp() Tensor.exp_ In-place version of exp() Tensor.expm1 See torch.expm1() Tensor.expm1_ In-place version of expm1() Tensor.expand Returns a new view of the self tensor with singleton dimensions expanded to a larger size. Tensor.expand_as Expand this tensor to the same size as other. Tensor.exponential_ Fills self tensor with elements drawn from the exponential distribution: Tensor.fix See torch.fix(). Tensor.fix_ In-place version of fix() Tensor.fill_ Fills self tensor with the specified value. Tensor.flatten See torch.flatten() Tensor.flip See torch.flip() Tensor.fliplr See torch.fliplr() Tensor.flipud See torch.flipud() Tensor.float self.float() is equivalent to self.to(torch.float32). Tensor.float_power See torch.float_power() Tensor.float_power_ In-place version of float_power() Tensor.floor See torch.floor() Tensor.floor_ In-place version of floor() Tensor.floor_divide See torch.floor_divide() Tensor.floor_divide_ In-place version of floor_divide() Tensor.fmod See torch.fmod() Tensor.fmod_ In-place version of fmod() Tensor.frac See torch.frac() Tensor.frac_ In-place version of frac() Tensor.frexp See torch.frexp() Tensor.gather See torch.gather() Tensor.gcd See torch.gcd() Tensor.gcd_ In-place version of gcd() Tensor.ge See torch.ge(). Tensor.ge_ In-place version of ge(). Tensor.greater_equal See torch.greater_equal(). Tensor.greater_equal_ In-place version of greater_equal(). Tensor.geometric_ Fills self tensor with elements drawn from the geometric distribution: Tensor.geqrf See torch.geqrf() Tensor.ger See torch.ger() Tensor.get_device For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides. Tensor.gt See torch.gt(). Tensor.gt_ In-place version of gt(). Tensor.greater See torch.greater(). Tensor.greater_ In-place version of greater(). Tensor.half self.half() is equivalent to self.to(torch.float16). Tensor.hardshrink See torch.nn.functional.hardshrink() Tensor.heaviside See torch.heaviside() Tensor.histc See torch.histc() Tensor.histogram See torch.histogram() Tensor.hsplit See torch.hsplit() Tensor.hypot See torch.hypot() Tensor.hypot_ In-place version of hypot() Tensor.i0 See torch.i0() Tensor.i0_ In-place version of i0() Tensor.igamma See torch.igamma() Tensor.igamma_ In-place version of igamma() Tensor.igammac See torch.igammac() Tensor.igammac_ In-place version of igammac() Tensor.index_add_ Accumulate the elements of alpha times source into the self tensor by adding to the indices in the order given in index. Tensor.index_add Out-of-place version of torch.Tensor.index_add_(). Tensor.index_copy_ Copies the elements of tensor into the self tensor by selecting the indices in the order given in index. Tensor.index_copy Out-of-place version of torch.Tensor.index_copy_(). Tensor.index_fill_ Fills the elements of the self tensor with value value by selecting the indices in the order given in index. Tensor.index_fill Out-of-place version of torch.Tensor.index_fill_(). Tensor.index_put_ Puts values from the tensor values into the tensor self using the indices specified in indices (which is a tuple of Tensors). Tensor.index_put Out-place version of index_put_(). Tensor.index_reduce_ Accumulate the elements of source into the self tensor by accumulating to the indices in the order given in index using the reduction given by the reduce argument. Tensor.index_reduce Tensor.index_select See torch.index_select() Tensor.indices Return the indices tensor of a sparse COO tensor. Tensor.inner See torch.inner(). Tensor.int self.int() is equivalent to self.to(torch.int32). Tensor.int_repr Given a quantized Tensor, self.int_repr() returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor. Tensor.inverse See torch.inverse() Tensor.isclose See torch.isclose() Tensor.isfinite See torch.isfinite() Tensor.isinf See torch.isinf() Tensor.isposinf See torch.isposinf() Tensor.isneginf See torch.isneginf() Tensor.isnan See torch.isnan() Tensor.is_contiguous Returns True if self tensor is contiguous in memory in the order specified by memory format. Tensor.is_complex Returns True if the data type of self is a complex data type. Tensor.is_conj Returns True if the conjugate bit of self is set to true. Tensor.is_floating_point Returns True if the data type of self is a floating point data type. Tensor.is_inference See torch.is_inference() Tensor.is_leaf All Tensors that have requires_grad which is False will be leaf Tensors by convention. Tensor.is_pinned Returns true if this tensor resides in pinned memory. Tensor.is_set_to Returns True if both tensors are pointing to the exact same memory (same storage, offset, size and stride). Tensor.is_shared Checks if tensor is in shared memory. Tensor.is_signed Returns True if the data type of self is a signed data type. Tensor.is_sparse Is True if the Tensor uses sparse storage layout, False otherwise. Tensor.istft See torch.istft() Tensor.isreal See torch.isreal() Tensor.item Returns the value of this tensor as a standard Python number. Tensor.kthvalue See torch.kthvalue() Tensor.lcm See torch.lcm() Tensor.lcm_ In-place version of lcm() Tensor.ldexp See torch.ldexp() Tensor.ldexp_ In-place version of ldexp() Tensor.le See torch.le(). Tensor.le_ In-place version of le(). Tensor.less_equal See torch.less_equal(). Tensor.less_equal_ In-place version of less_equal(). Tensor.lerp See torch.lerp() Tensor.lerp_ In-place version of lerp() Tensor.lgamma See torch.lgamma() Tensor.lgamma_ In-place version of lgamma() Tensor.log See torch.log() Tensor.log_ In-place version of log() Tensor.logdet See torch.logdet() Tensor.log10 See torch.log10() Tensor.log10_ In-place version of log10() Tensor.log1p See torch.log1p() Tensor.log1p_ In-place version of log1p() Tensor.log2 See torch.log2() Tensor.log2_ In-place version of log2() Tensor.log_normal_ Fills self tensor with numbers samples from the log-normal distribution parameterized by the given mean \\muÎ¼ and standard deviation \\sigmaÏƒ. Tensor.logaddexp See torch.logaddexp() Tensor.logaddexp2 See torch.logaddexp2() Tensor.logsumexp See torch.logsumexp() Tensor.logical_and See torch.logical_and() Tensor.logical_and_ In-place version of logical_and() Tensor.logical_not See torch.logical_not() Tensor.logical_not_ In-place version of logical_not() Tensor.logical_or See torch.logical_or() Tensor.logical_or_ In-place version of logical_or() Tensor.logical_xor See torch.logical_xor() Tensor.logical_xor_ In-place version of logical_xor() Tensor.logit See torch.logit() Tensor.logit_ In-place version of logit() Tensor.long self.long() is equivalent to self.to(torch.int64). Tensor.lt See torch.lt(). Tensor.lt_ In-place version of lt(). Tensor.less lt(other) -> Tensor Tensor.less_ In-place version of less(). Tensor.lu See torch.lu() Tensor.lu_solve See torch.lu_solve() Tensor.as_subclass Makes a cls instance with the same data pointer as self. Tensor.map_ Applies callable for each element in self tensor and the given tensor and stores the results in self tensor. Tensor.masked_scatter_ Copies elements from source into self tensor at positions where the mask is True. Tensor.masked_scatter Out-of-place version of torch.Tensor.masked_scatter_() Tensor.masked_fill_ Fills elements of self tensor with value where mask is True. Tensor.masked_fill Out-of-place version of torch.Tensor.masked_fill_() Tensor.masked_select See torch.masked_select() Tensor.matmul See torch.matmul() Tensor.matrix_power NOTEmatrix_power() is deprecated, use torch.linalg.matrix_power() instead. Tensor.matrix_exp See torch.matrix_exp() Tensor.max See torch.max() Tensor.maximum See torch.maximum() Tensor.mean See torch.mean() Tensor.nanmean See torch.nanmean() Tensor.median See torch.median() Tensor.nanmedian See torch.nanmedian() Tensor.min See torch.min() Tensor.minimum See torch.minimum() Tensor.mm See torch.mm() Tensor.smm See torch.smm() Tensor.mode See torch.mode() Tensor.movedim See torch.movedim() Tensor.moveaxis See torch.moveaxis() Tensor.msort See torch.msort() Tensor.mul See torch.mul(). Tensor.mul_ In-place version of mul(). Tensor.multiply See torch.multiply(). Tensor.multiply_ In-place version of multiply(). Tensor.multinomial See torch.multinomial() Tensor.mv See torch.mv() Tensor.mvlgamma See torch.mvlgamma() Tensor.mvlgamma_ In-place version of mvlgamma() Tensor.nansum See torch.nansum() Tensor.narrow See torch.narrow() Tensor.narrow_copy See torch.narrow_copy(). Tensor.ndimension Alias for dim() Tensor.nan_to_num See torch.nan_to_num(). Tensor.nan_to_num_ In-place version of nan_to_num(). Tensor.ne See torch.ne(). Tensor.ne_ In-place version of ne(). Tensor.not_equal See torch.not_equal(). Tensor.not_equal_ In-place version of not_equal(). Tensor.neg See torch.neg() Tensor.neg_ In-place version of neg() Tensor.negative See torch.negative() Tensor.negative_ In-place version of negative() Tensor.nelement Alias for numel() Tensor.nextafter See torch.nextafter() Tensor.nextafter_ In-place version of nextafter() Tensor.nonzero See torch.nonzero() Tensor.norm See torch.norm() Tensor.normal_ Fills self tensor with elements samples from the normal distribution parameterized by mean and std. Tensor.numel See torch.numel() Tensor.numpy Returns the tensor as a NumPy ndarray. Tensor.orgqr See torch.orgqr() Tensor.ormqr See torch.ormqr() Tensor.outer See torch.outer(). Tensor.permute See torch.permute() Tensor.pin_memory Copies the tensor to pinned memory, if it's not already pinned. Tensor.pinverse See torch.pinverse() Tensor.polygamma See torch.polygamma() Tensor.polygamma_ In-place version of polygamma() Tensor.positive See torch.positive() Tensor.pow See torch.pow() Tensor.pow_ In-place version of pow() Tensor.prod See torch.prod() Tensor.put_ Copies the elements from source into the positions specified by index. Tensor.qr See torch.qr() Tensor.qscheme Returns the quantization scheme of a given QTensor. Tensor.quantile See torch.quantile() Tensor.nanquantile See torch.nanquantile() Tensor.q_scale Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer(). Tensor.q_zero_point Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer(). Tensor.q_per_channel_scales Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer. Tensor.q_per_channel_zero_points Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer. Tensor.q_per_channel_axis Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied. Tensor.rad2deg See torch.rad2deg() Tensor.random_ Fills self tensor with numbers sampled from the discrete uniform distribution over [from, to - 1]. Tensor.ravel see torch.ravel() Tensor.reciprocal See torch.reciprocal() Tensor.reciprocal_ In-place version of reciprocal() Tensor.record_stream Ensures that the tensor memory is not reused for another tensor until all current work queued on stream are complete. Tensor.register_hook Registers a backward hook. Tensor.remainder See torch.remainder() Tensor.remainder_ In-place version of remainder() Tensor.renorm See torch.renorm() Tensor.renorm_ In-place version of renorm() Tensor.repeat Repeats this tensor along the specified dimensions. Tensor.repeat_interleave See torch.repeat_interleave(). Tensor.requires_grad Is True if gradients need to be computed for this Tensor, False otherwise. Tensor.requires_grad_ Change if autograd should record operations on this tensor: sets this tensor's requires_grad attribute in-place. Tensor.reshape Returns a tensor with the same data and number of elements as self but with the specified shape. Tensor.reshape_as Returns this tensor as the same shape as other. Tensor.resize_ Resizes self tensor to the specified size. Tensor.resize_as_ Resizes the self tensor to be the same size as the specified tensor. Tensor.retain_grad Enables this Tensor to have their grad populated during backward(). Tensor.retains_grad Is True if this Tensor is non-leaf and its grad is enabled to be populated during backward(), False otherwise. Tensor.roll See torch.roll() Tensor.rot90 See torch.rot90() Tensor.round See torch.round() Tensor.round_ In-place version of round() Tensor.rsqrt See torch.rsqrt() Tensor.rsqrt_ In-place version of rsqrt() Tensor.scatter Out-of-place version of torch.Tensor.scatter_() Tensor.scatter_ Writes all values from the tensor src into self at the indices specified in the index tensor. Tensor.scatter_add_ Adds all values from the tensor src into self at the indices specified in the index tensor in a similar fashion as scatter_(). Tensor.scatter_add Out-of-place version of torch.Tensor.scatter_add_() Tensor.scatter_reduce_ Reduces all values from the src tensor to the indices specified in the index tensor in the self tensor using the applied reduction defined via the reduce argument (\"sum\", \"prod\", \"mean\", \"amax\", \"amin\"). Tensor.scatter_reduce Out-of-place version of torch.Tensor.scatter_reduce_() Tensor.select See torch.select() Tensor.select_scatter See torch.select_scatter() Tensor.set_ Sets the underlying storage, size, and strides. Tensor.share_memory_ Moves the underlying storage to shared memory. Tensor.short self.short() is equivalent to self.to(torch.int16). Tensor.sigmoid See torch.sigmoid() Tensor.sigmoid_ In-place version of sigmoid() Tensor.sign See torch.sign() Tensor.sign_ In-place version of sign() Tensor.signbit See torch.signbit() Tensor.sgn See torch.sgn() Tensor.sgn_ In-place version of sgn() Tensor.sin See torch.sin() Tensor.sin_ In-place version of sin() Tensor.sinc See torch.sinc() Tensor.sinc_ In-place version of sinc() Tensor.sinh See torch.sinh() Tensor.sinh_ In-place version of sinh() Tensor.asinh See torch.asinh() Tensor.asinh_ In-place version of asinh() Tensor.arcsinh See torch.arcsinh() Tensor.arcsinh_ In-place version of arcsinh() Tensor.size Returns the size of the self tensor. Tensor.slogdet See torch.slogdet() Tensor.slice_scatter See torch.slice_scatter() Tensor.sort See torch.sort() Tensor.split See torch.split() Tensor.sparse_mask Returns a new sparse tensor with values from a strided tensor self filtered by the indices of the sparse tensor mask. Tensor.sparse_dim Return the number of sparse dimensions in a sparse tensor self. Tensor.sqrt See torch.sqrt() Tensor.sqrt_ In-place version of sqrt() Tensor.square See torch.square() Tensor.square_ In-place version of square() Tensor.squeeze See torch.squeeze() Tensor.squeeze_ In-place version of squeeze() Tensor.std See torch.std() Tensor.stft See torch.stft() Tensor.storage Returns the underlying storage. Tensor.storage_offset Returns self tensor's offset in the underlying storage in terms of number of storage elements (not bytes). Tensor.storage_type Returns the type of the underlying storage. Tensor.stride Returns the stride of self tensor. Tensor.sub See torch.sub(). Tensor.sub_ In-place version of sub() Tensor.subtract See torch.subtract(). Tensor.subtract_ In-place version of subtract(). Tensor.sum See torch.sum() Tensor.sum_to_size Sum this tensor to size. Tensor.svd See torch.svd() Tensor.swapaxes See torch.swapaxes() Tensor.swapdims See torch.swapdims() Tensor.symeig See torch.symeig() Tensor.t See torch.t() Tensor.t_ In-place version of t() Tensor.tensor_split See torch.tensor_split() Tensor.tile See torch.tile() Tensor.to Performs Tensor dtype and/or device conversion. Tensor.to_mkldnn Returns a copy of the tensor in torch.mkldnn layout. Tensor.take See torch.take() Tensor.take_along_dim See torch.take_along_dim() Tensor.tan See torch.tan() Tensor.tan_ In-place version of tan() Tensor.tanh See torch.tanh() Tensor.tanh_ In-place version of tanh() Tensor.atanh See torch.atanh() Tensor.atanh_ In-place version of atanh() Tensor.arctanh See torch.arctanh() Tensor.arctanh_ In-place version of arctanh() Tensor.tolist Returns the tensor as a (nested) list. Tensor.topk See torch.topk() Tensor.to_dense Creates a strided copy of self if self is not a strided tensor, otherwise returns self. Tensor.to_sparse Returns a sparse copy of the tensor. Tensor.to_sparse_csr Convert a tensor to compressed row storage format (CSR). Tensor.to_sparse_csc Convert a tensor to compressed column storage (CSC) format. Tensor.to_sparse_bsr Convert a CSR tensor to a block sparse row (BSR) storage format of given blocksize. Tensor.to_sparse_bsc Convert a CSR tensor to a block sparse column (BSC) storage format of given blocksize. Tensor.trace See torch.trace() Tensor.transpose See torch.transpose() Tensor.transpose_ In-place version of transpose() Tensor.triangular_solve See torch.triangular_solve() Tensor.tril See torch.tril() Tensor.tril_ In-place version of tril() Tensor.triu See torch.triu() Tensor.triu_ In-place version of triu() Tensor.true_divide See torch.true_divide() Tensor.true_divide_ In-place version of true_divide_() Tensor.trunc See torch.trunc() Tensor.trunc_ In-place version of trunc() Tensor.type Returns the type if dtype is not provided, else casts this object to the specified type. Tensor.type_as Returns this tensor cast to the type of the given tensor. Tensor.unbind See torch.unbind() Tensor.unflatten See torch.unflatten(). Tensor.unfold Returns a view of the original tensor which contains all slices of size size from self tensor in the dimension dimension. Tensor.uniform_ Fills self tensor with numbers sampled from the continuous uniform distribution: Tensor.unique Returns the unique elements of the input tensor. Tensor.unique_consecutive Eliminates all but the first element from every consecutive group of equivalent elements. Tensor.unsqueeze See torch.unsqueeze() Tensor.unsqueeze_ In-place version of unsqueeze() Tensor.values Return the values tensor of a sparse COO tensor. Tensor.var See torch.var() Tensor.vdot See torch.vdot() Tensor.view Returns a new tensor with the same data as the self tensor but of a different shape. Tensor.view_as View this tensor as the same size as other. Tensor.vsplit See torch.vsplit() Tensor.where self.where(condition, y) is equivalent to torch.where(condition, self, y). Tensor.xlogy See torch.xlogy() Tensor.xlogy_ In-place version of xlogy() Tensor.zero_ Fills self tensor with zeros. storage tensorçš„æ•°æ®ç»“æž„ã€storage()ã€stride()ã€storage_offset() pytorchä¸­ä¸€ä¸ªtensorå¯¹è±¡åˆ†ä¸ºå¤´ä¿¡æ¯åŒºï¼ˆTensorï¼‰å’Œå­˜å‚¨åŒºï¼ˆStorageï¼‰ä¸¤éƒ¨åˆ† å¤´ä¿¡æ¯åŒºä¸»è¦ä¿å­˜tensorçš„å½¢çŠ¶ï¼ˆsizeï¼‰ã€æ­¥é•¿ï¼ˆstrideï¼‰ã€æ•°æ®ç±»åž‹ï¼ˆtypeï¼‰ç­‰ä¿¡æ¯ï¼›è€ŒçœŸæ­£çš„dataï¼ˆæ•°æ®ï¼‰åˆ™ä»¥è¿žç»­ä¸€ç»´æ•°ç»„çš„å½¢å¼æ”¾åœ¨å­˜å‚¨åŒºï¼Œç”±torch.Storageå®žä¾‹ç®¡ç†ç€ æ³¨æ„ï¼šstorageæ°¸è¿œæ˜¯ä¸€ç»´æ•°ç»„ï¼Œä»»ä½•ç»´åº¦çš„tensorçš„å®žé™…æ•°æ®éƒ½å­˜å‚¨åœ¨ä¸€ç»´çš„storageä¸­ èŽ·å–tensorçš„storage a = torch.tensor([[1.0, 4.0],[2.0, 1.0],[3.0, 5.0]]) a.storage() Out[0]: 1.0 4.0 2.0 1.0 3.0 5.0 [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6] a.storage()[2] = 9 id(a.storage()) Out[1]: 1343354913168 å®žä¾‹ å°åœŸå †+æŽæ²è¯¾ç¨‹ç¬”è®° PyTorchæ·±åº¦å­¦ä¹ å¿«é€Ÿå…¥é—¨æ•™ç¨‹ï¼ˆç»å¯¹é€šä¿—æ˜“æ‡‚ï¼ï¼‰ã€å°åœŸå †ã€‘ PytorchåŠ è½½æ•°æ® Pytorchä¸­åŠ è½½æ•°æ®éœ€è¦Datasetã€Dataloaderã€‚ Datasetæä¾›ä¸€ç§æ–¹å¼åŽ»èŽ·å–æ¯ä¸ªæ•°æ®åŠå…¶å¯¹åº”çš„labelï¼Œå‘Šè¯‰æˆ‘ä»¬æ€»å…±æœ‰å¤šå°‘ä¸ªæ•°æ®ã€‚ Dataloaderä¸ºåŽé¢çš„ç½‘ç»œæä¾›ä¸åŒçš„æ•°æ®å½¢å¼ï¼Œå®ƒå°†ä¸€æ‰¹ä¸€æ‰¹æ•°æ®è¿›è¡Œä¸€ä¸ªæ‰“åŒ…ã€‚ Tensorboard import torchvision from torch.utils.data import DataLoader from torch.utils.tensorboard import SummaryWriter # å‡†å¤‡çš„æµ‹è¯•æ•°æ®é›† test_data = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor()) # batch_size=4 ä½¿å¾— img0, target0 = dataset[0]ã€img1, target1 = dataset[1]ã€img2, target2 = dataset[2]ã€img3, target3 = dataset[3]ï¼Œç„¶åŽè¿™å››ä¸ªæ•°æ®ä½œä¸ºDataloaderçš„ä¸€ä¸ªè¿”å›ž test_loader = DataLoader(dataset=test_data,batch_size=64,shuffle=True,num_workers=0,drop_last=False) # ç”¨forå¾ªçŽ¯å–å‡ºDataLoaderæ‰“åŒ…å¥½çš„å››ä¸ªæ•°æ® writer = SummaryWriter(\"logs\") step = 0 for data in test_loader: imgs, targets = data # æ¯ä¸ªdataéƒ½æ˜¯ç”±4å¼ å›¾ç‰‡ç»„æˆï¼Œimgs.size ä¸º [4,3,32,32]ï¼Œå››å¼ 32Ã—32å›¾ç‰‡ä¸‰é€šé“ï¼Œtargetsç”±å››ä¸ªæ ‡ç­¾ç»„æˆ writer.add_images(\"test_data\",imgs,step) step = step + 1 writer.close() Transforms â‘  Transformså½“æˆå·¥å…·ç®±çš„è¯ï¼Œé‡Œé¢çš„classå°±æ˜¯ä¸åŒçš„å·¥å…·ã€‚ä¾‹å¦‚åƒtotensorã€resizeè¿™äº›å·¥å…·ã€‚ â‘¡ Transformsæ‹¿ä¸€äº›ç‰¹å®šæ ¼å¼çš„å›¾ç‰‡ï¼Œç»è¿‡Transformsé‡Œé¢çš„å·¥å…·ï¼ŒèŽ·å¾—æˆ‘ä»¬æƒ³è¦çš„ç»“æžœã€‚ from torchvision import transforms from PIL import Image img_path = \"Data/FirstTypeData/val/bees/10870992_eebeeb3a12.jpg\" img = Image.open(img_path) tensor_trans = transforms.ToTensor() # åˆ›å»º transforms.ToTensorç±» çš„å®žä¾‹åŒ–å¯¹è±¡ tensor_img = tensor_trans(img) # è°ƒç”¨ transforms.ToTensorç±» çš„__call__çš„é­”æœ¯æ–¹æ³• print(tensor_img) torchvisionæ•°æ®é›† â‘  torchvisionä¸­æœ‰å¾ˆå¤šæ•°æ®é›†ï¼Œå½“æˆ‘ä»¬å†™ä»£ç æ—¶æŒ‡å®šç›¸åº”çš„æ•°æ®é›†æŒ‡å®šä¸€äº›å‚æ•°ï¼Œå®ƒå°±å¯ä»¥è‡ªè¡Œä¸‹è½½ã€‚ â‘¡ CIFAR-10æ•°æ®é›†åŒ…å«60000å¼ 32Ã—32çš„å½©è‰²å›¾ç‰‡ï¼Œä¸€å…±10ä¸ªç±»åˆ«ï¼Œå…¶ä¸­50000å¼ è®­ç»ƒå›¾ç‰‡ï¼Œ10000å¼ æµ‹è¯•å›¾ç‰‡ã€‚ import torchvision train_set = torchvision.datasets.CIFAR10(root=\"./dataset\",train=True,download=True) # rootä¸ºå­˜æ”¾æ•°æ®é›†çš„ç›¸å¯¹è·¯çº¿ test_set = torchvision.datasets.CIFAR10(root=\"./dataset\",train=False,download=True) # train=Trueæ˜¯è®­ç»ƒé›†ï¼Œtrain=Falseæ˜¯æµ‹è¯•é›† print(test_set[0]) # è¾“å‡ºçš„3æ˜¯target print(test_set.classes) # æµ‹è¯•æ•°æ®é›†ä¸­æœ‰å¤šå°‘ç§ img, target = test_set[0] # åˆ†åˆ«èŽ·å¾—å›¾ç‰‡ã€target print(img) print(target) print(test_set.classes[target]) # 3å·targetå¯¹åº”çš„ç§ç±» img.show() æŸå¤±å‡½æ•° â‘  LossæŸå¤±å‡½æ•°ä¸€æ–¹é¢è®¡ç®—å®žé™…è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„å·®è·ã€‚ â‘¡ LossæŸå¤±å‡½æ•°å¦ä¸€æ–¹é¢ä¸ºæˆ‘ä»¬æ›´æ–°è¾“å‡ºæä¾›ä¸€å®šçš„ä¾æ® L1lossæŸå¤±å‡½æ•° import torch from torch.nn import L1Loss inputs = torch.tensor([1,2,3],dtype=torch.float32) targets = torch.tensor([1,2,5],dtype=torch.float32) inputs = torch.reshape(inputs,(1,1,1,3)) targets = torch.reshape(targets,(1,1,1,3)) loss = L1Loss() # é»˜è®¤ä¸º maen result = loss(inputs,targets) print(result) MSEæŸå¤±å‡½æ•° import torch from torch.nn import L1Loss from torch import nn inputs = torch.tensor([1,2,3],dtype=torch.float32) targets = torch.tensor([1,2,5],dtype=torch.float32) inputs = torch.reshape(inputs,(1,1,1,3)) targets = torch.reshape(targets,(1,1,1,3)) loss_mse = nn.MSELoss() result_mse = loss_mse(inputs,targets) print(result_mse) äº¤å‰ç†µæŸå¤±å‡½æ•° import torch from torch.nn import L1Loss from torch import nn x = torch.tensor([0.1,0.2,0.3]) y = torch.tensor([1]) x = torch.reshape(x,(1,3)) # 1çš„ batch_sizeï¼Œæœ‰ä¸‰ç±» loss_cross = nn.CrossEntropyLoss() result_cross = loss_cross(x,y) print(result_cross) ä¼˜åŒ–å™¨ â‘  æŸå¤±å‡½æ•°è°ƒç”¨backwardæ–¹æ³•ï¼Œå°±å¯ä»¥è°ƒç”¨æŸå¤±å‡½æ•°çš„åå‘ä¼ æ’­æ–¹æ³•ï¼Œå°±å¯ä»¥æ±‚å‡ºæˆ‘ä»¬éœ€è¦è°ƒèŠ‚çš„æ¢¯åº¦ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ©ç”¨æˆ‘ä»¬çš„ä¼˜åŒ–å™¨å°±å¯ä»¥æ ¹æ®æ¢¯åº¦å¯¹å‚æ•°è¿›è¡Œè°ƒæ•´ï¼Œè¾¾åˆ°æ•´ä½“è¯¯å·®é™ä½Žçš„ç›®çš„ã€‚ â‘¡ æ¢¯åº¦è¦æ¸…é›¶ï¼Œå¦‚æžœæ¢¯åº¦ä¸æ¸…é›¶ä¼šå¯¼è‡´æ¢¯åº¦ç´¯åŠ  loss = nn.CrossEntropyLoss() # äº¤å‰ç†µ tudui = Tudui() optim = torch.optim.SGD(tudui.parameters(),lr=0.01) # éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ for data in dataloader: imgs, targets = data outputs = tudui(imgs) result_loss = loss(outputs, targets) # è®¡ç®—å®žé™…è¾“å‡ºä¸Žç›®æ ‡è¾“å‡ºçš„å·®è· optim.zero_grad() # æ¢¯åº¦æ¸…é›¶ result_loss.backward() # åå‘ä¼ æ’­ï¼Œè®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ optim.step() # æ ¹æ®æ¢¯åº¦ï¼Œå¯¹ç½‘ç»œçš„å‚æ•°è¿›è¡Œè°ƒä¼˜ print(result_loss) # å¯¹æ•°æ®åªçœ‹äº†ä¸€éï¼Œåªçœ‹äº†ä¸€è½®ï¼Œæ‰€ä»¥lossä¸‹é™ä¸å¤§ ç¥žç»ç½‘ç»œå­¦ä¹ çŽ‡ä¼˜åŒ– import torch import torchvision from torch import nn from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential from torch.utils.data import DataLoader from torch.utils.tensorboard import SummaryWriter dataset = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor(),download=True) dataloader = DataLoader(dataset, batch_size=64,drop_last=True) class Tudui(nn.Module): def __init__(self): super(Tudui, self).__init__() self.model1 = Sequential( Conv2d(3,32,5,padding=2), MaxPool2d(2), Conv2d(32,32,5,padding=2), MaxPool2d(2), Conv2d(32,64,5,padding=2), MaxPool2d(2), Flatten(), Linear(1024,64), Linear(64,10) ) def forward(self, x): x = self.model1(x) return x loss = nn.CrossEntropyLoss() # äº¤å‰ç†µ tudui = Tudui() optim = torch.optim.SGD(tudui.parameters(),lr=0.01) # éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1) # æ¯è¿‡ step_size æ›´æ–°ä¸€æ¬¡ä¼˜åŒ–å™¨ï¼Œæ›´æ–°æ˜¯å­¦ä¹ çŽ‡ä¸ºåŽŸæ¥çš„å­¦ä¹ çŽ‡çš„ 0.1 å€ for epoch in range(20): running_loss = 0.0 for data in dataloader: imgs, targets = data outputs = tudui(imgs) result_loss = loss(outputs, targets) # è®¡ç®—å®žé™…è¾“å‡ºä¸Žç›®æ ‡è¾“å‡ºçš„å·®è· optim.zero_grad() # æ¢¯åº¦æ¸…é›¶ result_loss.backward() # åå‘ä¼ æ’­ï¼Œè®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ optim.step() # æ ¹æ®æ¢¯åº¦ï¼Œå¯¹ç½‘ç»œçš„å‚æ•°è¿›è¡Œè°ƒä¼˜ scheduler.step() # å­¦ä¹ çŽ‡å¤ªå°äº†ï¼Œæ‰€ä»¥20ä¸ªè½®æ¬¡åŽï¼Œç›¸å½“äºŽæ²¡èµ°å¤šå°‘ running_loss = running_loss + result_loss print(running_loss) # å¯¹è¿™ä¸€è½®æ‰€æœ‰è¯¯å·®çš„æ€»å’Œ ç½‘ç»œæ¨¡åž‹ä½¿ç”¨åŠä¿®æ”¹ ç½‘ç»œæ¨¡åž‹æ·»åŠ  import torchvision from torch import nn dataset = torchvision.datasets.CIFAR10(\"./dataset\",train=True,transform=torchvision.transforms.ToTensor(),download=True) vgg16_true = torchvision.models.vgg16(pretrained=True) # ä¸‹è½½å·ç§¯å±‚å¯¹åº”çš„å‚æ•°æ˜¯å¤šå°‘ã€æ± åŒ–å±‚å¯¹åº”çš„å‚æ•°æ—¶å¤šå°‘ï¼Œè¿™äº›å‚æ•°æ—¶ImageNetè®­ç»ƒå¥½äº†çš„ vgg16_true.add_module('add_linear',nn.Linear(1000,10)) # åœ¨VGG16åŽé¢æ·»åŠ ä¸€ä¸ªçº¿æ€§å±‚ï¼Œä½¿å¾—è¾“å‡ºä¸ºé€‚åº”CIFAR10çš„è¾“å‡ºï¼ŒCIFAR10éœ€è¦è¾“å‡º10ä¸ªç§ç±» print(vgg16_true) ç½‘ç»œæ¨¡åž‹ä¿®æ”¹ import torchvision from torch import nn vgg16_false = torchvision.models.vgg16(pretrained=False) # æ²¡æœ‰é¢„è®­ç»ƒçš„å‚æ•° print(vgg16_false) vgg16_false.classifier[6] = nn.Linear(4096,10) print(vgg16_false) ç½‘ç»œæ¨¡åž‹ä¿å­˜ä¸Žè¯»å– æ¨¡åž‹ç»“æž„ + æ¨¡åž‹å‚æ•° import torchvision import torch vgg16 = torchvision.models.vgg16(pretrained=False) torch.save(vgg16,\"./model/vgg16_method1.pth\") # ä¿å­˜æ–¹å¼ä¸€ï¼šæ¨¡åž‹ç»“æž„ + æ¨¡åž‹å‚æ•° print(vgg16) model = torch.load(\"./model/vgg16_method1.pth\") # ä¿å­˜æ–¹å¼ä¸€å¯¹åº”çš„åŠ è½½æ¨¡åž‹ print(model) æ¨¡åž‹å‚æ•°ï¼ˆå®˜æ–¹æŽ¨èï¼‰ï¼Œä¸ä¿å­˜ç½‘ç»œæ¨¡åž‹ç»“æž„ import torchvision import torch vgg16 = torchvision.models.vgg16(pretrained=False) torch.save(vgg16.state_dict(),\"./model/vgg16_method2.pth\") # ä¿å­˜æ–¹å¼äºŒï¼šæ¨¡åž‹å‚æ•°ï¼ˆå®˜æ–¹æŽ¨èï¼‰,ä¸å†ä¿å­˜ç½‘ç»œæ¨¡åž‹ç»“æž„ print(vgg16) model = torch.load(\"./model/vgg16_method2.pth\") # å¯¼å…¥æ¨¡åž‹å‚æ•° print(model) å›ºå®šæ¨¡åž‹å‚æ•° åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½éœ€è¦å›ºå®šä¸€éƒ¨åˆ†æ¨¡åž‹çš„å‚æ•°ï¼Œåªæ›´æ–°å¦ä¸€éƒ¨åˆ†å‚æ•°ï¼Œæœ‰ä¸¤ç§æ€è·¯å®žçŽ°è¿™ä¸ªç›®æ ‡ ä¸€ä¸ªæ˜¯è®¾ç½®ä¸è¦æ›´æ–°å‚æ•°çš„ç½‘ç»œå±‚ä¸ºfalse å¦ä¸€ä¸ªå°±æ˜¯åœ¨å®šä¹‰ä¼˜åŒ–å™¨æ—¶åªä¼ å…¥è¦æ›´æ–°çš„å‚æ•° å½“ç„¶æœ€ä¼˜çš„åšæ³•æ˜¯ï¼Œä¼˜åŒ–å™¨ä¸­åªä¼ å…¥requires_grad=Trueçš„å‚æ•°ï¼Œè¿™æ ·å ç”¨çš„å†…å­˜ä¼šæ›´å°ä¸€ç‚¹ï¼Œæ•ˆçŽ‡ä¹Ÿä¼šæ›´é«˜ import torch import torch.nn as nn import torch.optim as optim # å®šä¹‰ä¸€ä¸ªç®€å•çš„ç½‘ç»œ class net(nn.Module): def __init__(self, num_class=3): super(net, self).__init__() self.fc1 = nn.Linear(8, 4) self.fc2 = nn.Linear(4, num_class) def forward(self, x): return self.fc2(self.fc1(x)) model = net() # å†»ç»“fc1å±‚çš„å‚æ•° for name, param in model.named_parameters(): if \"fc1\" in name: param.requires_grad = False loss_fn = nn.CrossEntropyLoss() # åªä¼ å…¥requires_grad = Trueçš„å‚æ•° optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters(), lr=1e-2) print(\"model.fc1.weight\", model.fc1.weight) print(\"model.fc2.weight\", model.fc2.weight) model.train() for epoch in range(10): x = torch.randn((3, 8)) label = torch.randint(0, 3, [3]).long() output = model(x) loss = loss_fn(output, label) optimizer.zero_grad() loss.backward() optimizer.step() print(\"model.fc1.weight\", model.fc1.weight) print(\"model.fc2.weight\", model.fc2.weight) è®­ç»ƒæµç¨‹ DataLoaderåŠ è½½æ•°æ®é›† import torchvision from torch import nn from torch.utils.data import DataLoader # å‡†å¤‡æ•°æ®é›† train_data = torchvision.datasets.CIFAR10(\"./dataset\",train=True,transform=torchvision.transforms.ToTensor(),download=True) test_data = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor(),download=True) # length é•¿åº¦ train_data_size = len(train_data) test_data_size = len(test_data) # å¦‚æžœtrain_data_size=10ï¼Œåˆ™æ‰“å°ï¼šè®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10 print(\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ï¼š{}\".format(train_data_size)) print(\"æµ‹è¯•æ•°æ®é›†çš„é•¿åº¦ï¼š{}\".format(test_data_size)) # åˆ©ç”¨ Dataloader æ¥åŠ è½½æ•°æ®é›† train_dataloader = DataLoader(train_data_size, batch_size=64) test_dataloader = DataLoader(test_data_size, batch_size=64) æµ‹è¯•ç½‘ç»œæ­£ç¡® import torch from torch import nn # æ­å»ºç¥žç»ç½‘ç»œ class Tudui(nn.Module): def __init__(self): super(Tudui, self).__init__() self.model1 = nn.Sequential( nn.Conv2d(3,32,5,1,2), # è¾“å…¥é€šé“3ï¼Œè¾“å‡ºé€šé“32ï¼Œå·ç§¯æ ¸å°ºå¯¸5Ã—5ï¼Œæ­¥é•¿1ï¼Œå¡«å……2 nn.MaxPool2d(2), nn.Conv2d(32,32,5,1,2), nn.MaxPool2d(2), nn.Conv2d(32,64,5,1,2), nn.MaxPool2d(2), nn.Flatten(), # å±•å¹³åŽå˜æˆ 64*4*4 äº† nn.Linear(64*4*4,64), nn.Linear(64,10) ) def forward(self, x): x = self.model1(x) return x if __name__ == '__main__': tudui = Tudui() input = torch.ones((64,3,32,32)) output = tudui(input) print(output.shape) # æµ‹è¯•è¾“å‡ºçš„å°ºå¯¸æ˜¯ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ ç½‘ç»œè®­ç»ƒæ•°æ® â‘  model.train()å’Œmodel.eval()çš„åŒºåˆ«ä¸»è¦åœ¨äºŽBatch Normalizationå’ŒDropoutä¸¤å±‚ã€‚ â‘¡ å¦‚æžœæ¨¡åž‹ä¸­æœ‰BNå±‚(Batch Normalizationï¼‰å’Œ Dropoutï¼Œéœ€è¦åœ¨è®­ç»ƒæ—¶æ·»åŠ model.train()ã€‚model.train()æ˜¯ä¿è¯BNå±‚èƒ½å¤Ÿç”¨åˆ°æ¯ä¸€æ‰¹æ•°æ®çš„å‡å€¼å’Œæ–¹å·®ã€‚å¯¹äºŽDropoutï¼Œmodel.train()æ˜¯éšæœºå–ä¸€éƒ¨åˆ†ç½‘ç»œè¿žæŽ¥æ¥è®­ç»ƒæ›´æ–°å‚æ•°ã€‚ â‘¢ ä¸å¯ç”¨ Batch Normalization å’Œ Dropoutã€‚ å¦‚æžœæ¨¡åž‹ä¸­æœ‰BNå±‚(Batch Normalizationï¼‰å’ŒDropoutï¼Œåœ¨æµ‹è¯•æ—¶æ·»åŠ model.eval()ã€‚model.eval()æ˜¯ä¿è¯BNå±‚èƒ½å¤Ÿç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®çš„å‡å€¼å’Œæ–¹å·®ï¼Œå³æµ‹è¯•è¿‡ç¨‹ä¸­è¦ä¿è¯BNå±‚çš„å‡å€¼å’Œæ–¹å·®ä¸å˜ã€‚å¯¹äºŽDropoutï¼Œmodel.eval()æ˜¯åˆ©ç”¨åˆ°äº†æ‰€æœ‰ç½‘ç»œè¿žæŽ¥ï¼Œå³ä¸è¿›è¡Œéšæœºèˆå¼ƒç¥žç»å…ƒã€‚ â‘£ è®­ç»ƒå®Œtrainæ ·æœ¬åŽï¼Œç”Ÿæˆçš„æ¨¡åž‹modelè¦ç”¨æ¥æµ‹è¯•æ ·æœ¬ã€‚åœ¨model(test)ä¹‹å‰ï¼Œéœ€è¦åŠ ä¸Šmodel.eval()ï¼Œå¦åˆ™çš„è¯ï¼Œæœ‰è¾“å…¥æ•°æ®ï¼Œå³ä½¿ä¸è®­ç»ƒï¼Œå®ƒä¹Ÿä¼šæ”¹å˜æƒå€¼ã€‚è¿™æ˜¯modelä¸­å«æœ‰BNå±‚å’ŒDropoutæ‰€å¸¦æ¥çš„æ€§è´¨ã€‚ â‘¤ åœ¨åšone classificationçš„æ—¶å€™ï¼Œè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„æ ·æœ¬åˆ†å¸ƒæ˜¯ä¸ä¸€æ ·çš„ï¼Œå°¤å…¶éœ€è¦æ³¨æ„è¿™ä¸€ç‚¹ import torchvision import torch from torch import nn from torch.utils.data import DataLoader from torch.utils.tensorboard import SummaryWriter # from model import * ç›¸å½“äºŽæŠŠ modelä¸­çš„æ‰€æœ‰å†…å®¹å†™åˆ°è¿™é‡Œï¼Œè¿™é‡Œç›´æŽ¥æŠŠ model å†™åœ¨è¿™é‡Œ class Tudui(nn.Module): def __init__(self): super(Tudui, self).__init__() self.model1 = nn.Sequential( nn.Conv2d(3,32,5,1,2), # è¾“å…¥é€šé“3ï¼Œè¾“å‡ºé€šé“32ï¼Œå·ç§¯æ ¸å°ºå¯¸5Ã—5ï¼Œæ­¥é•¿1ï¼Œå¡«å……2 nn.MaxPool2d(2), nn.Conv2d(32,32,5,1,2), nn.MaxPool2d(2), nn.Conv2d(32,64,5,1,2), nn.MaxPool2d(2), nn.Flatten(), # å±•å¹³åŽå˜æˆ 64*4*4 äº† nn.Linear(64*4*4,64), nn.Linear(64,10) ) def forward(self, x): x = self.model1(x) return x # å‡†å¤‡æ•°æ®é›† train_data = torchvision.datasets.CIFAR10(\"./dataset\",train=True,transform=torchvision.transforms.ToTensor(),download=True) test_data = torchvision.datasets.CIFAR10(\"./dataset\",train=False,transform=torchvision.transforms.ToTensor(),download=True) # length é•¿åº¦ train_data_size = len(train_data) test_data_size = len(test_data) # å¦‚æžœtrain_data_size=10ï¼Œåˆ™æ‰“å°ï¼šè®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10 print(\"è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ï¼š{}\".format(train_data_size)) print(\"æµ‹è¯•æ•°æ®é›†çš„é•¿åº¦ï¼š{}\".format(test_data_size)) # åˆ©ç”¨ Dataloader æ¥åŠ è½½æ•°æ®é›† train_dataloader = DataLoader(train_data, batch_size=64) test_dataloader = DataLoader(test_data, batch_size=64) # åˆ›å»ºç½‘ç»œæ¨¡åž‹ tudui = Tudui() # æŸå¤±å‡½æ•° loss_fn = nn.CrossEntropyLoss() # äº¤å‰ç†µï¼Œfn æ˜¯ fuction çš„ç¼©å†™ # ä¼˜åŒ–å™¨ learning = 0.01 # 1e-2 å°±æ˜¯ 0.01 çš„æ„æ€ optimizer = torch.optim.SGD(tudui.parameters(),learning) # éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨ # è®¾ç½®ç½‘ç»œçš„ä¸€äº›å‚æ•° # è®°å½•è®­ç»ƒçš„æ¬¡æ•° total_train_step = 0 # è®°å½•æµ‹è¯•çš„æ¬¡æ•° total_test_step = 0 # è®­ç»ƒçš„è½®æ¬¡ epoch = 10 # æ·»åŠ  tensorboard writer = SummaryWriter(\"logs\") for i in range(epoch): print(\"-----ç¬¬ {} è½®è®­ç»ƒå¼€å§‹-----\".format(i+1)) # è®­ç»ƒæ­¥éª¤å¼€å§‹ tudui.train() # å½“ç½‘ç»œä¸­æœ‰dropoutå±‚ã€batchnormå±‚æ—¶ï¼Œè¿™äº›å±‚èƒ½èµ·ä½œç”¨ for data in train_dataloader: imgs, targets = data outputs = tudui(imgs) loss = loss_fn(outputs, targets) # è®¡ç®—å®žé™…è¾“å‡ºä¸Žç›®æ ‡è¾“å‡ºçš„å·®è· # ä¼˜åŒ–å™¨å¯¹æ¨¡åž‹è°ƒä¼˜ optimizer.zero_grad() # æ¢¯åº¦æ¸…é›¶ loss.backward() # åå‘ä¼ æ’­ï¼Œè®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ optimizer.step() # æ ¹æ®æ¢¯åº¦ï¼Œå¯¹ç½‘ç»œçš„å‚æ•°è¿›è¡Œè°ƒä¼˜ total_train_step = total_train_step + 1 if total_train_step % 100 == 0: print(\"è®­ç»ƒæ¬¡æ•°ï¼š{}ï¼ŒLossï¼š{}\".format(total_train_step,loss.item())) # æ–¹å¼äºŒï¼šèŽ·å¾—losså€¼ writer.add_scalar(\"train_loss\",loss.item(),total_train_step) # æµ‹è¯•æ­¥éª¤å¼€å§‹ï¼ˆæ¯ä¸€è½®è®­ç»ƒåŽéƒ½æŸ¥çœ‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„lossæƒ…å†µï¼‰ tudui.eval() # å½“ç½‘ç»œä¸­æœ‰dropoutå±‚ã€batchnormå±‚æ—¶ï¼Œè¿™äº›å±‚ä¸èƒ½èµ·ä½œç”¨ total_test_loss = 0 total_accuracy = 0 with torch.no_grad(): # æ²¡æœ‰æ¢¯åº¦äº† for data in test_dataloader: # æµ‹è¯•æ•°æ®é›†æå–æ•°æ® imgs, targets = data outputs = tudui(imgs) loss = loss_fn(outputs, targets) # ä»…dataæ•°æ®åœ¨ç½‘ç»œæ¨¡åž‹ä¸Šçš„æŸå¤± total_test_loss = total_test_loss + loss.item() # æ‰€æœ‰loss accuracy = (outputs.argmax(1) == targets).sum() total_accuracy = total_accuracy + accuracy print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Lossï¼š{}\".format(total_test_loss)) print(\"æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®çŽ‡ï¼š{}\".format(total_accuracy/test_data_size)) writer.add_scalar(\"test_loss\",total_test_loss,total_test_step) writer.add_scalar(\"test_accuracy\",total_accuracy/test_data_size,total_test_step) total_test_step = total_test_step + 1 torch.save(tudui, \"./model/tudui_{}.pth\".format(i)) # ä¿å­˜æ¯ä¸€è½®è®­ç»ƒåŽçš„ç»“æžœ #torch.save(tudui.state_dict(),\"tudui_{}.path\".format(i)) # ä¿å­˜æ–¹å¼äºŒ print(\"æ¨¡åž‹å·²ä¿å­˜\") writer.close() Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/transformer.html":{"url":"chapters/transformer.html","title":"transformer.md","summary":null,"keywords":"","body":"Transformerè¯å‘é‡æ¨¡åž‹ä»‹ç»ArchitectureEmbeddingAttentionEncoderDecoderBertbertæ¦‚å†µArchitecture Transformer Attention Is All You Need è®ºæ–‡è§£è¯»: Attention is All you need Hugging Faceçš„GitHubä»£ç åº“ é€šå¸¸è€Œè¨€ï¼Œç»å¤§éƒ¨åˆ†NLPé—®é¢˜å¯ä»¥å½’å…¥ä¸Šå›¾æ‰€ç¤ºçš„å››ç±»ä»»åŠ¡ä¸­ åºåˆ—æ ‡æ³¨: è¿™æ˜¯æœ€å…¸åž‹çš„NLPä»»åŠ¡ï¼Œæ¯”å¦‚ä¸­æ–‡åˆ†è¯ï¼Œè¯æ€§æ ‡æ³¨ï¼Œå‘½åå®žä½“è¯†åˆ«ï¼Œè¯­ä¹‰è§’è‰²æ ‡æ³¨ç­‰éƒ½å¯ä»¥å½’å…¥è¿™ä¸€ç±»é—®é¢˜ å®ƒçš„ç‰¹ç‚¹æ˜¯å¥å­ä¸­æ¯ä¸ªå•è¯è¦æ±‚æ¨¡åž‹æ ¹æ®ä¸Šä¸‹æ–‡éƒ½è¦ç»™å‡ºä¸€ä¸ªåˆ†ç±»ç±»åˆ« åˆ†ç±»ä»»åŠ¡: æ¯”å¦‚æˆ‘ä»¬å¸¸è§çš„æ–‡æœ¬åˆ†ç±»ï¼Œæƒ…æ„Ÿè®¡ç®—ç­‰éƒ½å¯ä»¥å½’å…¥è¿™ä¸€ç±»ã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯ä¸ç®¡æ–‡ç« æœ‰å¤šé•¿ï¼Œæ€»ä½“ç»™å‡ºä¸€ä¸ªåˆ†ç±»ç±»åˆ«å³å¯ å¥å­å…³ç³»åˆ¤æ–­: æ¯”å¦‚Entailmentï¼ŒQAï¼Œè¯­ä¹‰æ”¹å†™ï¼Œè‡ªç„¶è¯­è¨€æŽ¨ç†ç­‰ä»»åŠ¡éƒ½æ˜¯è¿™ä¸ªæ¨¡å¼ï¼Œç»™å®šä¸¤ä¸ªå¥å­ï¼Œæ¨¡åž‹åˆ¤æ–­å‡ºä¸¤ä¸ªå¥å­æ˜¯å¦å…·å¤‡æŸç§è¯­ä¹‰å…³ç³» ç”Ÿæˆå¼ä»»åŠ¡: æ¯”å¦‚æœºå™¨ç¿»è¯‘ï¼Œæ–‡æœ¬æ‘˜è¦ï¼Œå†™è¯—é€ å¥ï¼Œçœ‹å›¾è¯´è¯ç­‰éƒ½å±žäºŽè¿™ä¸€ç±»ï¼Œè¾“å…¥æ–‡æœ¬å†…å®¹åŽï¼Œéœ€è¦è‡ªä¸»ç”Ÿæˆå¦å¤–ä¸€æ®µæ–‡å­— é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹ ç›®å‰æœ‰ä¸¤ç§é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹ç”¨äºŽä¸‹æ¸¸ä»»åŠ¡çš„æ–¹æ³•ï¼šfeature-based(ä»¥ELMoä¸ºä¾‹)å’Œfine-tuning(ä»¥BERTã€GPTä¸ºä¾‹) æœ‰ä¸“é—¨çš„è®ºæ–‡(To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks)è®¨è®ºäº†è¿™ä¸ªè¯é¢˜ Feature-based Pre-Training: åœ¨Feature-based Pre-Trainingä¸­ï¼Œé¦–å…ˆä½¿ç”¨å¤§è§„æ¨¡çš„æœªæ ‡è®°æ•°æ®é›†å¯¹æ¨¡åž‹è¿›è¡Œé¢„è®­ç»ƒ é¢„è®­ç»ƒä»»åŠ¡é€šå¸¸æ˜¯é€šè¿‡è‡ªç›‘ç£å­¦ä¹ æˆ–å…¶ä»–æ— ç›‘ç£å­¦ä¹ æ–¹æ³•æ¥å®Œæˆï¼Œä¾‹å¦‚é¢„æµ‹ä¸‹ä¸€ä¸ªè¯è¯­ã€å›¾åƒçš„æ—‹è½¬è§’åº¦ç­‰ é¢„è®­ç»ƒçš„ç›®æ ‡æ˜¯å­¦ä¹ åˆ°å…·æœ‰è‰¯å¥½è¡¨ç¤ºèƒ½åŠ›çš„ç‰¹å¾ï¼Œèƒ½å¤Ÿæ•æ‰æ•°æ®ä¸­çš„ä¸€èˆ¬æ€§ä¿¡æ¯ é¢„è®­ç»ƒæ¨¡åž‹é€šå¸¸æ˜¯ä¸€ä¸ªé€šç”¨çš„æ¨¡åž‹ï¼Œä¸é’ˆå¯¹ç‰¹å®šçš„ä»»åŠ¡ã€‚å®ƒå­¦ä¹ åˆ°çš„ç‰¹å¾è¡¨ç¤ºå¯ä»¥åº”ç”¨äºŽå„ç§ä¸åŒçš„ä»»åŠ¡ é¢„è®­ç»ƒæ¨¡åž‹å¯ä»¥ä½œä¸ºè¿ç§»å­¦ä¹ çš„åŸºç¡€ï¼Œé€šè¿‡å°†å…¶ç‰¹å¾æå–éƒ¨åˆ†åº”ç”¨äºŽå…·ä½“çš„ä»»åŠ¡ Fine-tuning: Fine-tuningæ˜¯åœ¨é¢„è®­ç»ƒæ¨¡åž‹çš„åŸºç¡€ä¸Šï¼Œåœ¨ç‰¹å®šä»»åŠ¡çš„æœ‰æ ‡ç­¾æ•°æ®é›†ä¸Šè¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒå’Œä¼˜åŒ– Fine-tuningé˜¶æ®µä¼šè°ƒæ•´é¢„è®­ç»ƒæ¨¡åž‹çš„æƒé‡å’Œå‚æ•°ï¼Œä»¥ä½¿å…¶é€‚åº”ç›®æ ‡ä»»åŠ¡çš„ç‰¹å®šè¦æ±‚ Fine-tuningè¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä¼šä¿æŒé¢„è®­ç»ƒæ¨¡åž‹çš„ä¸€éƒ¨åˆ†æƒé‡å›ºå®šï¼Œåªæ›´æ–°éƒ¨åˆ†æƒé‡ï¼Œä»¥ä¿ç•™é¢„è®­ç»ƒé˜¶æ®µå­¦ä¹ åˆ°çš„é€šç”¨ç‰¹å¾è¡¨ç¤º Fine-tuningæ—¨åœ¨åœ¨ç‰¹å®šä»»åŠ¡çš„æœ‰é™æ ‡è®°æ•°æ®é›†ä¸Šä¼˜åŒ–æ¨¡åž‹ï¼Œä½¿å…¶æ›´å¥½åœ°é€‚åº”è¯¥ä»»åŠ¡çš„æ•°æ®å’Œç‰¹å¾ æ€»ç»“æ¥è¯´ï¼ŒFeature-based Pre-Trainingæ˜¯é€šè¿‡åœ¨æœªæ ‡è®°æ•°æ®ä¸Šé¢„è®­ç»ƒæ¨¡åž‹æ¥å­¦ä¹ é€šç”¨çš„ç‰¹å¾è¡¨ç¤ºï¼Œè€ŒFine-tuningæ˜¯åœ¨é¢„è®­ç»ƒæ¨¡åž‹çš„åŸºç¡€ä¸Šï¼Œåœ¨ç‰¹å®šä»»åŠ¡çš„æœ‰æ ‡ç­¾æ•°æ®ä¸Šè¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–å’Œå¾®è°ƒ Feature-based Pre-Trainingæä¾›äº†ä¸€ç§å­¦ä¹ é€šç”¨ç‰¹å¾è¡¨ç¤ºçš„æ–¹å¼ï¼Œè€ŒFine-tuningåˆ™å°†è¿™äº›é€šç”¨ç‰¹å¾åº”ç”¨äºŽç‰¹å®šä»»åŠ¡ï¼Œä»¥æå‡ä»»åŠ¡æ€§èƒ½ï¼Œä¸€å¥è¯æ¦‚æ‹¬ï¼š Feature-based Pre-TrainingæŠŠè¾“å…¥è½¬ç‰¹å¾ï¼Œç‰¹å¾ä¸¢ç»™åŽé¢çš„æ¨¡åž‹(æ–°æ¨¡åž‹)ï¼Œå…¶ä»–å°±å’Œå®ƒæ— å…³äº† Fine-tuningæ˜¯åŒä¸€ä¸ªç½‘ç»œç»“æž„ï¼Œæ¢äº†æ•°æ®ï¼Œå¯ä»¥å›ºå®šæˆ–ä¸å›ºå®šå‰å‡ å±‚ï¼Œç»§ç»­è®­ç»ƒ è¯å‘é‡ é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹çš„å‰ä¸–ä»Šç”Ÿ - ä»ŽWord Embeddingåˆ°BERT å¹´ä»½ 2013 å¹´ 2014 å¹´ 2015 å¹´ 2016 å¹´ 2017 å¹´ æŠ€æœ¯ word2vec GloVe LSTM/Attention Self-Attention Transformer å¹´ä»½ 2018 å¹´ 2019 å¹´ 2020 å¹´ æŠ€æœ¯ GPT/ELMo/BERT/GNN XLNet/BoBERTa/GPT-2/ERNIE/T5 GPT-3/ELECTRA/ALBERT One-hotç¼–ç ï¼šæ—©æœŸçš„è‡ªç„¶è¯­è¨€å¤„ç†ä¸­ï¼Œè¯è¯­é€šå¸¸è¢«è¡¨ç¤ºä¸ºç¦»æ•£çš„one-hotå‘é‡ã€‚æ¯ä¸ªè¯è¯­éƒ½è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªç»´åº¦ç­‰äºŽè¯æ±‡è¡¨å¤§å°çš„å‘é‡ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªç»´åº¦ä¸º1ï¼Œå…¶ä½™ç»´åº¦éƒ½ä¸º0 è¿™ç§è¡¨ç¤ºæ–¹æ³•æ— æ³•æ•æ‰è¯è¯­ä¹‹é—´çš„è¯­ä¹‰å…³ç³»å’Œç›¸ä¼¼åº¦ Word Embeddingï¼šä¸ºäº†å…‹æœone-hotç¼–ç çš„å±€é™æ€§ï¼Œæå‡ºäº†åŸºäºŽåˆ†å¸ƒå‡è®¾çš„è¯å‘é‡è¡¨ç¤ºæ–¹æ³•ï¼Œå³Word Embeddingã€‚Word Embeddingä½¿ç”¨ä½Žç»´å®žæ•°å‘é‡è¡¨ç¤ºè¯è¯­ï¼Œé€šè¿‡è®­ç»ƒæ¨¡åž‹å°†è¯è¯­æ˜ å°„åˆ°ä¸€ä¸ªè¿žç»­çš„å‘é‡ç©ºé—´ä¸­ã€‚å…¶ä¸­ï¼Œæ¯ä¸ªç»´åº¦ä»£è¡¨ä¸€ä¸ªè¯­ä¹‰ç‰¹å¾ã€‚Word Embeddingèƒ½å¤Ÿæ•æ‰åˆ°è¯è¯­ä¹‹é—´çš„è¯­ä¹‰å…³ç³»å’Œç›¸ä¼¼åº¦ï¼Œæä¾›æ›´ä¸°å¯Œçš„è¡¨ç¤º Word2Vec(é™æ€)ï¼šWord2Vecæ˜¯ä¸€ç§ç»å…¸çš„è¯å‘é‡æ¨¡åž‹ï¼Œç”±Tomas Mikolovç­‰äººäºŽ2013å¹´æå‡ºã€‚å®ƒåŸºäºŽç¥žç»ç½‘ç»œæ¨¡åž‹ï¼Œé€šè¿‡è®­ç»ƒé¢„æµ‹è¯è¯­å‘¨å›´çš„ä¸Šä¸‹æ–‡æˆ–é¢„æµ‹ç›®æ ‡è¯è¯­ã€‚Word2Vecæ¨¡åž‹åŒ…æ‹¬ä¸¤ç§ç®—æ³•ï¼šCBOW(Continuous Bag-of-Words)å’ŒSkip-gram`ã€‚è¿™ä¸¤ç§ç®—æ³•ä½¿ç”¨æµ…å±‚çš„ç¥žç»ç½‘ç»œæ¥å­¦ä¹ è¯å‘é‡ï¼Œå…·æœ‰é«˜æ•ˆã€å¿«é€Ÿè®­ç»ƒçš„ä¼˜åŠ¿ã€‚Word2Vecæ¨¡åž‹èƒ½å¤Ÿç”Ÿæˆé™æ€çš„è¯å‘é‡ï¼Œä½†æ— æ³•æ•æ‰è¯è¯­çš„ä¸Šä¸‹æ–‡ç›¸å…³ç‰¹å¾ ELMo(Embeddings from Language Models)(åŠ¨æ€)ï¼šELMoæ˜¯åœ¨Word2Vecä¹‹åŽæå‡ºçš„ä¸€ç§ä¸Šä¸‹æ–‡ç›¸å…³çš„è¯å‘é‡è¡¨ç¤ºæ–¹æ³•ï¼Œç”±Petersç­‰äººäºŽ2018å¹´æå‡ºã€‚ELMoåˆ©ç”¨åŒå‘è¯­è¨€æ¨¡åž‹ï¼Œé€šè¿‡è®­ç»ƒæ­£å‘å’Œé€†å‘çš„LSTMæ¨¡åž‹æ¥å­¦ä¹ è¯è¯­çš„ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚ELMoèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€åœ°ç”Ÿæˆè¯å‘é‡ï¼Œæ•æ‰åˆ°è¯è¯­åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„è¯­ä¹‰ç‰¹å¾ã€‚ä¸Žé™æ€è¯å‘é‡ä¸åŒï¼ŒELMoæä¾›äº†æ›´ä¸°å¯Œã€æ›´å…·è¯­ä¹‰çš„è¯è¯­è¡¨ç¤ºï¼Œé€‚ç”¨äºŽå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ ELMo(Embeddings from Language Models)æ¨¡åž‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†åŒå‘é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆBi-LSTMï¼‰ æ€»çš„æ¥è¯´ï¼ŒåŽ†å²å‘å±•ä¸­ï¼Œä»Žone-hotç¼–ç åˆ°Word Embeddingï¼Œå†åˆ°Word2Vecå’ŒELMoï¼Œè¯å‘é‡è¡¨ç¤ºæ–¹æ³•é€æ¸ä»Žç¦»æ•£ã€é™æ€çš„è¡¨ç¤ºå‘å±•åˆ°äº†è¿žç»­ã€ä¸Šä¸‹æ–‡ç›¸å…³çš„è¡¨ç¤ºã€‚è¿™äº›æ–¹æ³•çš„æå‡ºå’Œå‘å±•ä½¿å¾—è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå¤„ç†æ–‡æœ¬æ•°æ®ï¼Œæé«˜äº†å„ç§æ–‡æœ¬ç›¸å…³ä»»åŠ¡çš„æ€§èƒ½ Word Embeddingã€Word2Vecå’ŒELMoå…³ç³»å¦‚ä¸‹ï¼š Word2Vecæ˜¯Word Embeddingçš„ä¸€ç§å…·ä½“å®žçŽ°æ–¹å¼ã€‚Word EmbeddingæŒ‡çš„æ˜¯å°†è¯è¯­æ˜ å°„åˆ°ä½Žç»´å®žæ•°å‘é‡ç©ºé—´çš„è¡¨ç¤ºæ–¹æ³•ï¼Œè€ŒWord2Vecåˆ™æ˜¯ä¸€ç§ç”¨äºŽè®­ç»ƒWord Embeddingçš„ç®—æ³• ELMoå’ŒWord2Vecæ˜¯ä¸¤ç§ä¸åŒçš„è¯å‘é‡è¡¨ç¤ºæ–¹æ³•ã€‚ELMoæ˜¯ä¸€ç§ä¸Šä¸‹æ–‡ç›¸å…³çš„è¯å‘é‡è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒåŒå‘è¯­è¨€æ¨¡åž‹æ¥å­¦ä¹ è¯è¯­åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„åŠ¨æ€è¡¨ç¤ºã€‚è€ŒWord2Vecæ˜¯ä¸€ç§ä¸Šä¸‹æ–‡æ— å…³çš„è¯å‘é‡è¡¨ç¤ºæ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒé¢„æµ‹è¯è¯­çš„ä¸Šä¸‹æ–‡æˆ–ç›®æ ‡è¯è¯­æ¥å­¦ä¹ é™æ€çš„è¯å‘é‡ æ¨¡åž‹ä»‹ç» ä»‹ç»Transformeræ¯”è¾ƒå¥½çš„æ–‡ç«  ä¸€ä¸ªæ˜¯Jay Alammarå¯è§†åŒ–åœ°ä»‹ç»Transformerçš„åšå®¢æ–‡ç« The Illustrated Transformerï¼Œéžå¸¸å®¹æ˜“ç†è§£æ•´ä¸ªæœºåˆ¶ å“ˆä½›å¤§å­¦NLPç ”ç©¶ç»„å†™çš„The Annotated Transformerï¼Œä»£ç åŽŸç†åŒç®¡é½ä¸‹ Attentionæœºåˆ¶ Attentionæœºåˆ¶æœ€æ—©åœ¨è§†è§‰é¢†åŸŸæå‡ºï¼Œ2014å¹´Google Mindå‘è¡¨äº†ã€ŠRecurrent Models of Visual Attentionã€‹ï¼Œä½¿Attentionæœºåˆ¶æµè¡Œèµ·æ¥ï¼Œè¿™ç¯‡è®ºæ–‡é‡‡ç”¨äº†RNNæ¨¡åž‹ï¼Œå¹¶åŠ å…¥äº†Attentionæœºåˆ¶æ¥è¿›è¡Œå›¾åƒçš„åˆ†ç±» 2005å¹´ï¼ŒBahdanauç­‰äººåœ¨è®ºæ–‡ã€ŠNeural Machine Translation by Jointly Learning to Align and Translateã€‹ä¸­ï¼Œå°†attentionæœºåˆ¶é¦–æ¬¡åº”ç”¨åœ¨nlpé¢†åŸŸï¼Œå…¶é‡‡ç”¨Seq2Seq+Attentionæ¨¡åž‹æ¥è¿›è¡Œæœºå™¨ç¿»è¯‘ï¼Œå¹¶ä¸”å¾—åˆ°äº†æ•ˆæžœçš„æå‡ï¼ŒSeq2Seq With Attentionä¸­è¿›è¡Œäº†ä»‹ç» 2017 å¹´ï¼ŒGoogle æœºå™¨ç¿»è¯‘å›¢é˜Ÿå‘è¡¨çš„ã€ŠAttention is All You Needã€‹ä¸­ï¼Œå®Œå…¨æŠ›å¼ƒäº†RNNå’ŒCNNç­‰ç½‘ç»œç»“æž„ï¼Œè€Œä»…ä»…é‡‡ç”¨è‡ªæ³¨æ„åŠ›(self-attention)æœºåˆ¶æ¥å­¦ä¹ æ–‡æœ¬è¡¨ç¤ºæ¥è¿›è¡Œæœºå™¨ç¿»è¯‘ä»»åŠ¡ï¼Œå¹¶ä¸”å–å¾—äº†å¾ˆå¥½çš„æ•ˆæžœï¼Œæ³¨æ„åŠ›æœºåˆ¶ä¹Ÿæˆä¸ºäº†å¤§å®¶è¿‘æœŸçš„ç ”ç©¶çƒ­ç‚¹ æœ¬æ–‡é¦–å…ˆä»‹ç»å¸¸è§çš„Attentionæœºåˆ¶ï¼Œç„¶åŽå¯¹è®ºæ–‡ã€ŠAttention is All You Needã€‹è¿›è¡Œä»‹ç»ï¼Œè¯¥è®ºæ–‡å‘è¡¨åœ¨NIPS 2017ä¸Š Architecture æ¨¡åž‹ç»“æž„å¦‚ä¸‹ è¾“å…¥å±‚ è¯åµŒå…¥ç¼–ç å±‚ ä½ç½®ç¼–ç å±‚ Encoder å¤šå¤´è‡ªæ³¨æ„åŠ› æ®‹å·®è¿žæŽ¥ å…¨è¿žæŽ¥ç½‘ç»œ Dncoder å¤šå¤´è‡ªæ³¨æ„åŠ› å¤šå¤´æ³¨æ„åŠ›(ä¸æ˜¯è‡ªæ³¨æ„, å› ä¸ºQKæ¥è‡ªEncoder) æ®‹å·®è¿žæŽ¥ å…¨è¿žæŽ¥ç½‘ç»œ æ¨¡åž‹æ•´ä½“ç»“æž„å¦‚ä¸‹æ‰€ç¤º Transformeræ˜¯ä¸€ç§åŸºäºŽè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„åºåˆ—åˆ°åºåˆ—æ¨¡åž‹ï¼Œå¹¿æ³›åº”ç”¨äºŽè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå¦‚æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦å’Œè¯­è¨€ç”Ÿæˆç­‰ Transformeræ•´ä½“ç»“æž„ç”±ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼š ç¼–ç å™¨ï¼ˆEncoderï¼‰ï¼šç¼–ç å™¨è´Ÿè´£å°†è¾“å…¥åºåˆ—ï¼ˆä¾‹å¦‚æºè¯­è¨€å¥å­ï¼‰è½¬æ¢ä¸ºä¸€ç³»åˆ—é«˜çº§ç‰¹å¾è¡¨ç¤ºã€‚å®ƒç”±å¤šä¸ªç›¸åŒçš„å±‚å †å è€Œæˆï¼Œæ¯ä¸ªå±‚éƒ½åŒ…å«ä¸¤ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå…¨è¿žæŽ¥å‰é¦ˆç¥žç»ç½‘ç»œã€‚è‡ªæ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡åž‹å¯¹è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒä½ç½®è¿›è¡Œè‡ªé€‚åº”åœ°å…³æ³¨ï¼Œä»Žè€Œæ•æ‰åºåˆ—ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ è§£ç å™¨ï¼ˆDecoderï¼‰ï¼šè§£ç å™¨è´Ÿè´£ä»Žç¼–ç å™¨ç”Ÿæˆçš„ç‰¹å¾è¡¨ç¤ºä¸­ç”Ÿæˆç›®æ ‡åºåˆ—ï¼ˆä¾‹å¦‚ç›®æ ‡è¯­è¨€å¥å­ï¼‰ã€‚è§£ç å™¨ä¹Ÿç”±å¤šä¸ªç›¸åŒçš„å±‚å †å è€Œæˆï¼Œæ¯ä¸ªå±‚åŒ…å«ä¸‰ä¸ªå­å±‚ï¼šå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›æœºåˆ¶å’Œå…¨è¿žæŽ¥å‰é¦ˆç¥žç»ç½‘ç»œã€‚ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›æœºåˆ¶ç”¨äºŽåœ¨ç”Ÿæˆç›®æ ‡åºåˆ—æ—¶ï¼Œå¼•å…¥å¯¹æºè¯­è¨€å¥å­çš„å…³æ³¨ è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰ï¼šè‡ªæ³¨æ„åŠ›æœºåˆ¶æ˜¯Transformerçš„å…³é”®ç»„ä»¶ä¹‹ä¸€ã€‚å®ƒå…è®¸æ¨¡åž‹åœ¨è¿›è¡Œç¼–ç æˆ–è§£ç æ—¶ï¼Œæ ¹æ®è¾“å…¥åºåˆ—ä¸­ä¸åŒä½ç½®ä¹‹é—´çš„å…³ç³»ï¼ŒåŠ¨æ€åœ°è®¡ç®—æ³¨æ„åŠ›æƒé‡ã€‚é€šè¿‡è‡ªé€‚åº”åœ°å…³æ³¨ä¸åŒä½ç½®çš„ä¿¡æ¯ï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæ•æ‰è¾“å…¥åºåˆ—ä¸­çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæä¾›æ›´å…¨é¢çš„è¡¨ç¤º æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttentionï¼‰ï¼šé™¤äº†è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTransformerè¿˜ä½¿ç”¨ç¼–ç å™¨-è§£ç å™¨æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ç§æ³¨æ„åŠ›æœºåˆ¶å…è®¸è§£ç å™¨åœ¨ç”Ÿæˆç›®æ ‡åºåˆ—æ—¶ï¼Œå¯¹ç¼–ç å™¨è¾“å‡ºçš„ç‰¹å¾è¡¨ç¤ºè¿›è¡Œå…³æ³¨ã€‚å®ƒèƒ½å¤Ÿå¸®åŠ©è§£ç å™¨å¯¹æºè¯­è¨€å¥å­ä¸­ä¸Žå½“å‰ç”Ÿæˆä½ç½®ç›¸å…³çš„ä¿¡æ¯è¿›è¡Œå¤„ç† å‰é¦ˆç¥žç»ç½‘ç»œï¼ˆFeed-Forward Networkï¼‰ï¼šTransformerä¸­çš„æ¯ä¸ªå­å±‚éƒ½åŒ…å«ä¸€ä¸ªå‰é¦ˆç¥žç»ç½‘ç»œã€‚è¯¥ç½‘ç»œç”±ä¸¤ä¸ªå…¨è¿žæŽ¥å±‚ç»„æˆï¼Œé€šè¿‡åº”ç”¨éžçº¿æ€§æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ReLUï¼‰æ¥å¯¹ç‰¹å¾è¡¨ç¤ºè¿›è¡Œæ˜ å°„å’Œå˜æ¢ã€‚å‰é¦ˆç¥žç»ç½‘ç»œæœ‰åŠ©äºŽæ•æ‰ç‰¹å¾ä¹‹é—´çš„éžçº¿æ€§å…³ç³» é€šè¿‡ç¼–ç å™¨å’Œè§£ç å™¨çš„ç»„åˆï¼ŒTransformeræ¨¡åž‹èƒ½å¤Ÿå°†è¾“å…¥åºåˆ—è½¬æ¢ä¸ºè¾“å‡ºåºåˆ—ï¼Œå®žçŽ°ä¸åŒçš„åºåˆ—åˆ°åºåˆ—ä»»åŠ¡ å®ƒçš„å¹¶è¡Œè®¡ç®—æ€§è´¨å’Œè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„èƒ½åŠ›ä½¿å¾—å®ƒåœ¨å¤„ç†é•¿åºåˆ—å’Œæ•æ‰å…¨å±€ä¾èµ–å…³ç³»æ–¹é¢å…·æœ‰ä¼˜åŠ¿ï¼Œæˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„é‡è¦æ¨¡åž‹ï¼Œæ›´è¯¦ç»†çš„æ¨¡åž‹ç»“æž„å¦‚ä¸‹æ‰€ç¤º Embedding Embeddingå±‚æ˜¯Transformeræ¨¡åž‹ä¸­çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ï¼Œç”¨äºŽå°†ç¦»æ•£çš„è¾“å…¥åºåˆ—ï¼ˆå¦‚å•è¯ã€å­—ç¬¦ç­‰ï¼‰æ˜ å°„åˆ°è¿žç»­çš„ä½Žç»´å‘é‡è¡¨ç¤º å®ƒè´Ÿè´£å°†è¾“å…¥çš„ç¬¦å·åž‹æ•°æ®è½¬æ¢ä¸ºå¯†é›†çš„å®žæ•°å‘é‡ï¼Œä»Žè€Œèƒ½å¤Ÿåœ¨æ¨¡åž‹ä¸­è¿›è¡Œæœ‰æ•ˆçš„å­¦ä¹ å’Œå¤„ç† åœ¨Transformerä¸­ï¼ŒEmbeddingå±‚ä¸»è¦æœ‰ä¸¤ä¸ªä½œç”¨ï¼š è¯åµŒå…¥ï¼ˆWord Embeddingï¼‰ï¼šå¯¹äºŽè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼ŒEmbeddingå±‚å°†æ¯ä¸ªè¯æ±‡æˆ–å­—ç¬¦æ˜ å°„åˆ°ä¸€ä¸ªä½Žç»´çš„è¿žç»­å‘é‡è¡¨ç¤ºï¼Œç§°ä¸ºè¯åµŒå…¥æˆ–å­—ç¬¦åµŒå…¥ã€‚è¿™äº›åµŒå…¥å‘é‡æ•æ‰äº†è¯æ±‡æˆ–å­—ç¬¦ä¹‹é—´çš„è¯­ä¹‰å’Œè¯­æ³•å…³ç³»ï¼Œèƒ½å¤Ÿç¼–ç å•è¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œè¡¨ç¤ºè¾“å…¥æ•°æ® ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰ï¼šTransformeræ¨¡åž‹ä¸­æ²¡æœ‰ä½¿ç”¨å¾ªçŽ¯ç¥žç»ç½‘ç»œæˆ–å·ç§¯ç¥žç»ç½‘ç»œï¼Œå› æ­¤æ— æ³•ç›´æŽ¥æ•æ‰è¾“å…¥åºåˆ—ä¸­é¡ºåºä¿¡æ¯ã€‚ä¸ºäº†å¼•å…¥ä½ç½®ä¿¡æ¯ï¼ŒEmbeddingå±‚ä¼šæ·»åŠ ä½ç½®ç¼–ç åˆ°è¯åµŒå…¥ä¸­ã€‚ä½ç½®ç¼–ç æ˜¯ä¸€ç§ç”¨äºŽè¡¨ç¤ºè¾“å…¥åºåˆ—ä½ç½®çš„å‘é‡ï¼Œå®ƒæä¾›äº†å…³äºŽè¯æ±‡åœ¨åºåˆ—ä¸­ç›¸å¯¹ä½ç½®çš„ä¿¡æ¯ï¼Œå¸®åŠ©æ¨¡åž‹ç†è§£åºåˆ—ä¸­çš„é¡ºåºå…³ç³» åœ¨å®žçŽ°ä¸Šï¼ŒEmbeddingå±‚å¯ä»¥ä½¿ç”¨ä¸€ä¸ªçŸ©é˜µä½œä¸ºå‚æ•°æ¥è¿›è¡Œè¯åµŒå…¥çš„æŸ¥æ‰¾ã€‚æ¯ä¸ªè¯æ±‡å¯¹åº”çŸ©é˜µä¸­çš„ä¸€è¡Œï¼Œé€šè¿‡æŸ¥æ‰¾è¾“å…¥åºåˆ—ä¸­çš„è¯æ±‡å¯¹åº”çš„è¡Œå‘é‡ï¼Œå¾—åˆ°è¯åµŒå…¥è¡¨ç¤º ä½ç½®ç¼–ç é€šå¸¸ä½¿ç”¨æ­£å¼¦å’Œä½™å¼¦å‡½æ•°çš„ç»„åˆæ¥è®¡ç®—ï¼Œä»¥èŽ·å–ä¸åŒä½ç½®çš„ç¼–ç å‘é‡ éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒEmbeddingå±‚çš„å‚æ•°é€šå¸¸æ˜¯åœ¨æ¨¡åž‹è®­ç»ƒçš„è¿‡ç¨‹ä¸­å­¦ä¹ å¾—åˆ°çš„ï¼Œæ ¹æ®ä»»åŠ¡å’Œæ•°æ®æ¥è°ƒæ•´åµŒå…¥å‘é‡çš„è¡¨ç¤ºèƒ½åŠ›ã€‚é€šè¿‡Embeddingå±‚ï¼Œæ¨¡åž‹èƒ½å¤Ÿåœ¨ä½Žç»´è¿žç»­å‘é‡ç©ºé—´ä¸­å¯¹è¾“å…¥åºåˆ—è¿›è¡Œè¡¨å¾å’Œå»ºæ¨¡ï¼Œä»Žè€Œæ›´å¥½åœ°å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†ç­‰ä»»åŠ¡ å¯¼å…¥åº“ #!/usr/bin/env Python # -- coding: utf-8 -- \"\"\" @version: v1.0 @author: huangyc @file: embedding.py @Description: @time: 2023/2/19 15:00 \"\"\" import torch import torch.nn as nn import torch.nn.functional as F from torch.autograd import Variable import math import matplotlib.pyplot as plt import numpy as np import copy Embeddingå±‚å®šä¹‰ class Embeddings(nn.Module): def __init__(self, d_model: int, vocab: int): \"\"\" æž„å»ºEmbeddingç±»æ¥å®žçŽ°æ–‡æœ¬åµŒå…¥å±‚ :param d_model: è¯åµŒå…¥çš„ç»´åº¦ :param vocab: è¯è¡¨çš„å¤§å° \"\"\" super(Embeddings, self).__init__() # å®šä¹‰Embeddingå±‚ self.lut = nn.Embedding(vocab, d_model) self.d_model = d_model def forward(self, x): return self.lut(x) * math.sqrt(self.d_model) PositionalEncodingå±‚ # å®šä¹‰ä½ç½®ç¼–ç å™¨ç±», æˆ‘ä»¬åŒæ ·æŠŠå®ƒçœ‹åšä¸€ä¸ªå±‚,å› æ­¤ä¼šç»§æ‰¿nn.Module class PositionalEncoding(nn.Module): def __init__(self, d_model: int, dropout: float, max_len: int = 5000): \"\"\" ä½ç½®ç¼–ç å™¨ç±»çš„åˆå§‹åŒ–å‡½æ•°, å…±æœ‰ä¸‰ä¸ªå‚æ•° :param d_model: è¯åµŒå…¥ç»´åº¦ :param dropout: ç½®0æ¯”çŽ‡ :param max_len: æ¯ä¸ªå¥å­çš„æœ€å¤§é•¿åº¦ :return: \"\"\" super(PositionalEncoding, self).__init__() # å®žä¾‹åŒ–nnä¸­é¢„å®šä¹‰çš„Dropoutå±‚, å¹¶å°†dropoutä¼ å…¥å…¶ä¸­,èŽ·å¾—å¯¹è±¡self.dropout self.dropout = nn.Dropout(p=dropout) # åˆå§‹åŒ–ä¸€ä¸ªä½ç½®ç¼–ç çŸ©é˜µ,å®ƒæ˜¯ä¸€ä¸ª0é˜µ, çŸ©é˜µçš„å¤§å°æ˜¯max_len * d_model pe = torch.zeros(max_len, d_model) # åˆå§‹åŒ–ä¸€ä¸ªç»å¯¹ä½ç½®çŸ©é˜µ, åœ¨æˆ‘ä»¬è¿™é‡Œ, è¯æ±‡çš„ç»å¯¹ä½ç½®å°±æ˜¯ç”¨å®ƒçš„ç´¢å¼•åŽ»è¡¨ç¤º # æ‰€ä»¥æˆ‘ä»¬é¦–å…ˆä½¿ç”¨arangeæ–¹æ³•èŽ·å¾—ä¸€ä¸ªè¿žç»­è‡ªç„¶æ•°å‘é‡, ç„¶åŽå†ä½¿ç”¨unsqueezeæ–¹æ³•æ‹“å±•å‘é‡ç»´åº¦ # #åˆå› ä¸ºå‚æ•°ä¼ çš„æ˜¯1, ä»£è¡¨çŸ©é˜µæ‹“å±•çš„ä½ç½®, ä¼šä½¿å‘é‡å˜æˆä¸€ä¸ªmax_len * 1çš„çŸ©é˜µ position = torch.arange(0, max_len).unsqueeze(1) # ç»å¯¹ä½ç½®çŸ©é˜µåˆå§‹åŒ–ä¹‹åŽ, æŽ¥ä¸‹æ¥å°±æ˜¯è€ƒè™‘å¦‚ä½•å°†è¿™äº›ä½ç½®ä¿¡æ¯åŠ å…¥åˆ°ä½ç½®ç¼–ç çŸ©é˜µä¸­ # æœ€ç®€å•æ€è·¯å°±æ˜¯å…ˆå°†max_len * 1çš„ç»å¯¹ä½ç½®çŸ©é˜µ, å˜æ¢æˆmax_len * d_modelå½¢çŠ¶, ç„¶åŽè¦†ç›–åŽŸæ¥çš„åˆå§‹ä½ç½®ç¼–ç çŸ©é˜µå³å¯ # è¦åšè¿™ç§çŸ©é˜µå˜æ¢, å°±éœ€è¦ä¸€ä¸ª1 * d_modelå½¢çŠ¶çš„å˜æ¢çŸ©é˜µdiv_term, æˆ‘ä»¬å¯¹è¿™ä¸ªå˜æ¢çŸ©é˜µçš„è¦æ±‚é™¤äº†å½¢çŠ¶å¤– # è¿˜å¸Œæœ›å®ƒèƒ½å¤Ÿå°†è‡ªç„¶æ•°çš„ç»å¯¹ä½ç½®ç¼–ç ç¼©æ”¾æˆè¶³å¤Ÿå°çš„æ•°å­—, æœ‰åŠ©äºŽåœ¨ä¹‹åŽçš„æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­æ›´å¿«çš„æ”¶æ•› # é¦–å…ˆä½¿ç”¨arangeèŽ·å¾—ä¸€ä¸ªè‡ªç„¶æ•°çŸ©é˜µ, ä½†æ˜¯ç»†å¿ƒçš„åŒå­¦ä»¬ä¼šå‘çŽ°, æˆ‘ä»¬è¿™é‡Œå¹¶æ²¡æœ‰æŒ‰ç…§é¢„è®¡çš„ä¸€æ ·åˆå§‹åŒ–ä¸€ä¸ª1 * d_modelçš„çŸ©é˜µ # è€Œæ˜¯æœ‰äº†ä¸€ä¸ªè·³è·ƒï¼Œåªåˆå§‹åŒ–äº†ä¸€åŠå³1*d_mode1/2çš„çŸ©é˜µ. ä¸ºä»€ä¹ˆæ˜¯ä¸€åŠå‘¢, å…¶å®žè¿™é‡Œå¹¶ä¸æ˜¯çœŸæ­£æ„ä¹‰ä¸Šçš„åˆå§‹åŒ– # æˆ‘ä»¬å¯ä»¥æŠŠå®ƒçœ‹ä½œæ˜¯åˆå§‹åŒ–äº†ä¸¤æ¬¡, è€Œæ¯æ¬¡åˆå§‹åŒ–çš„å˜æ¢çŸ©é˜µä¼šåšä¸åŒçš„å¤„ç†, ç¬¬ä¸€æ¬¡åˆå§‹åŒ–çš„å˜æ¢çŸ©é˜µåˆ†å¸ƒåœ¨æ­£å¼¦æ³¢ä¸Š, ç¬¬äºŒæ¬¡åˆå§‹åŒ–çš„å˜æ¢çŸ©é˜µåˆ†å¸ƒåœ¨ä½™å¼¦æ³¢ä¸Š # å¹¶æŠŠè¿™ä¸¤ä¸ªçŸ©é˜µåˆ†åˆ«å¡«å……åœ¨ä½ç½®ç¼–ç çŸ©é˜µçš„å¶æ•°å’Œå¥‡æ•°ä½ç½®ä¸Š, ç»„æˆæœ€ç»ˆçš„ä½ç½®ç¼–ç çŸ©é˜µ div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.) / d_model)) pe[:, 0::2] = torch.sin(position * div_term) pe[:, 1::2] = torch.cos(position * div_term) # è¿™æ ·æˆ‘ä»¬å°±å¾—åˆ°äº†ä½ç½®ç¼–ç çŸ©é˜µpe, peçŽ°åœ¨è¿˜æ˜¯ä¸ªäºŒç»´çŸ©é˜µï¼Œè¦æƒ³å’Œembeddingçš„è¾“å‡º(ä¸€ä¸ªä¸‰ç»´å¼ é‡)ç›¸åŠ , éœ€è¦æ‰©å±•ç»´åº¦ pe = pe.unsqueeze(0) # æˆ‘ä»¬æŠŠå®ƒè®¤ä¸ºæ˜¯å¯¹æ¨¡åž‹æ•ˆæžœæœ‰å¸®åŠ©çš„, ä½†æ˜¯å´ä¸æ˜¯æ¨¡åž‹ç»“æž„ä¸­è¶…å‚æ•°æˆ–è€…å‚æ•°,ä¸éœ€è¦éšç€ä¼˜åŒ–æ­¥éª¤ä¼˜åŒ– # æ³¨å†Œä¹‹åŽæˆ‘ä»¬å°±å¯ä»¥åœ¨æ¨¡åž‹ä¿å­˜åŽé‡åŠ è½½æ—¶å’Œæ¨¡åž‹ç»“æž„ä¸Žå‚æ•°ä¸€åŒè¢«åŠ è½½ self.register_buffer('pe', pe) def forward(self, x): \"\"\" :param x: æ–‡æœ¬åºåˆ—çš„è¯åµŒå…¥è¡¨ç¤º \"\"\" # æ ¹æ®å¥å­æœ€å¤§é•¿åº¦åˆ‡å‰², peä¸éœ€è¦åšæ¢¯åº¦æ±‚è§£ x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False) return self.dropout(x) å®žé™…æµ‹è¯• + ä½ç½®ç¼–ç å¯è§†åŒ– if __name__ == '__main__': p_d_model = 512 p_vocab = 1000 p_dropout: float = 0.1 p_max_len = 60 # è¯åµŒå…¥æµ‹è¯• x = Variable(torch.LongTensor([[100, 2, 421, 508], [491, 998, 1, 221]])) emb = Embeddings(d_model=p_d_model, vocab=p_vocab) embr = emb(x) print(\"embr\", embr) print(\"embr size\", embr.shape) # ä½ç½®ç¼–ç æµ‹è¯• pe = PositionalEncoding(d_model=p_d_model, dropout=p_dropout, max_len=p_max_len) pe_result = pe(embr) print(\"pe_result\", pe_result) print(\"pe_result size\", pe_result.shape) # åˆ›å»ºä¸€å¼ 15x5å¤§å°çš„ç”»å¸ƒ plt.figure(figsize=(15, 5)) # å®žä¾‹åŒ–PositionalEncodingç±»å¾—åˆ°peå¯¹è±¡, è¾“å…¥å‚æ•°æ˜¯20å’Œ0 pe = PositionalEncoding(20, 0) # ç„¶åŽå‘peä¼ å…¥è¢«Variableå°è£…çš„tensor, è¿™æ ·peä¼šç›´æŽ¥æ‰§è¡Œforwardå‡½æ•°, # ä¸”è¿™ä¸ªtensoré‡Œçš„æ•°å€¼éƒ½æ˜¯0, è¢«å¤„ç†åŽç›¸å½“äºŽä½ç½®ç¼–ç å¼ é‡ y = pe(Variable(torch.zeros(1, 100, 20))) # ç„¶åŽå®šä¹‰ç”»å¸ƒçš„æ¨ªçºµåæ ‡, æ¨ªåæ ‡åˆ°100çš„é•¿åº¦, çºµåæ ‡æ˜¯æŸä¸€ä¸ªè¯æ±‡ä¸­çš„æŸç»´ç‰¹å¾åœ¨ä¸åŒé•¿åº¦ä¸‹å¯¹åº”çš„å€¼ # å› ä¸ºæ€»å…±æœ‰20ç»´ä¹‹å¤š, æˆ‘ä»¬è¿™é‡ŒåªæŸ¥çœ‹4,5,6,7ç»´çš„å€¼ plt.plot(np.arange(100), y[0, :, 4:8].data.numpy()) # åœ¨ç”»å¸ƒä¸Šå¡«å†™ç»´åº¦æç¤ºä¿¡æ¯ plt.legend([\"dim %d\" % p for p in [4, 5, 6, 7]]) plt.show() embr tensor([[[-17.5113, -6.0699, 11.6839, ..., -8.1281, -7.7986, 35.1275], [ -6.3789, -7.7614, 13.2975, ..., 16.8397, -31.3230, -68.4385], [ -4.1841, 8.4322, 34.6418, ..., 38.4747, -4.9060, 25.4163], [-23.4562, -28.9742, 18.1234, ..., 38.6039, 15.0049, -2.8916]], [[-21.7485, 0.3263, 54.4449, ..., -18.3120, -15.5987, -11.4275], [ -0.6414, 2.9492, -32.3063, ..., -21.9781, -16.3307, -15.4014], [-16.1775, 20.8547, -21.0333, ..., -11.7583, -7.2429, 5.8607], [ -4.7708, -51.9955, 14.8529, ..., 21.0973, 13.4664, -10.8492]]], grad_fn=) embr size torch.Size([2, 4, 512]) pe_result tensor([[[-19.4569, -5.6332, 12.9821, ..., -7.9201, -0.0000, 0.0000], [ -6.1526, -8.0235, 15.6882, ..., 19.8219, -34.8032, -74.9317], [ -3.6387, 8.9068, 39.5314, ..., 43.8608, -5.4509, 29.3514], [-25.9057, -33.2935, 20.4094, ..., 44.0043, 16.6725, -2.1017]], [[-24.1650, 1.4736, 0.0000, ..., -19.2356, -17.3319, -11.5861], [ 0.2223, 3.8772, -34.9827, ..., -23.3090, -18.1452, -16.0015], [-16.9647, 22.7095, -22.3299, ..., -11.9537, -8.0475, 7.6230], [ -0.0000, -58.8727, 0.0000, ..., 24.5526, 14.9630, -0.0000]]], grad_fn=) pe_result size torch.Size([2, 4, 512]) Attention è¶…è¯¦ç»†å›¾è§£Self-Attentionçš„é‚£äº›äº‹å„¿ é™¤äº†Scaled Dot-Product Attentionï¼ŒTransformeræ¨¡åž‹ä¸­è¿˜æœ‰å‡ ç§å¸¸è§çš„æ³¨æ„åŠ›æœºåˆ¶ ç‚¹ç§¯æ³¨æ„åŠ›(Dot-Product Attention)ï¼šå®ƒæ˜¯Scaled Dot-Product Attentionçš„ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æŽ¥è®¡ç®—æŸ¥è¯¢ï¼ˆQï¼‰å’Œé”®ï¼ˆKï¼‰ä¹‹é—´çš„ç‚¹ç§¯ï¼Œç„¶åŽé€šè¿‡softmaxå‡½æ•°å°†ç»“æžœè½¬åŒ–ä¸ºæ³¨æ„åŠ›æƒé‡ã€‚ç‚¹ç§¯æ³¨æ„åŠ›ç›¸æ¯”äºŽScaled Dot-Product Attentionæ²¡æœ‰è¿›è¡Œç¼©æ”¾æ“ä½œ åŠ æ€§æ³¨æ„åŠ›(Additive Attention)ï¼šåŠ æ€§æ³¨æ„åŠ›ä½¿ç”¨äº†ä¸€ä¸ªé¢å¤–çš„å‰é¦ˆç¥žç»ç½‘ç»œæ¥è®¡ç®—æ³¨æ„åŠ›æƒé‡ã€‚å®ƒé€šè¿‡å°†æŸ¥è¯¢ï¼ˆQï¼‰å’Œé”®ï¼ˆKï¼‰æ˜ å°„åˆ°ç›¸åŒçš„ä½Žç»´ç©ºé—´ï¼Œç„¶åŽè®¡ç®—å®ƒä»¬çš„ç›¸ä¼¼åº¦å¾—åˆ†ï¼Œæœ€åŽå°†ç›¸ä¼¼åº¦å¾—åˆ†é€šè¿‡softmaxå‡½æ•°è¿›è¡Œå½’ä¸€åŒ–ã€‚åŠ æ€§æ³¨æ„åŠ›åœ¨ä¸€äº›åœºæ™¯ä¸­èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è¾“å…¥åºåˆ—ä¹‹é—´çš„éžçº¿æ€§å…³ç³» ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›(Scaled Dot-Product Attention)ï¼šå®ƒæ˜¯Transformerä¸­æœ€å¸¸ç”¨çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚åœ¨è®¡ç®—æ³¨æ„åŠ›æƒé‡æ—¶ï¼Œå¯¹ç‚¹ç§¯æ³¨æ„åŠ›è¿›è¡Œäº†ç¼©æ”¾æ“ä½œï¼Œé€šè¿‡é™¤ä»¥ç‰¹å¾ç»´åº¦çš„å¹³æ–¹æ ¹ï¼Œä»¥å‡å°æ³¨æ„åŠ›æƒé‡çš„å¤§å°å˜åŒ–ã€‚è¿™æœ‰åŠ©äºŽé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸ï¼Œå¹¶ä½¿å¾—æ¨¡åž‹æ›´ç¨³å®š æŒ‰ä½ç½®åŠ æƒæ³¨æ„åŠ›(Relative Positional Attention)ï¼šè¿™ç§æ³¨æ„åŠ›æœºåˆ¶è€ƒè™‘äº†ä½ç½®ä¿¡æ¯å¯¹æ³¨æ„åŠ›è®¡ç®—çš„å½±å“ã€‚å®ƒå¼•å…¥äº†ä½ç½®ç¼–ç ï¼Œé€šè¿‡è®¡ç®—ç›¸å¯¹ä½ç½®çš„å·®å¼‚ï¼Œå¯¹æ³¨æ„åŠ›æƒé‡è¿›è¡Œè°ƒæ•´ã€‚è¿™ç§æ³¨æ„åŠ›æœºåˆ¶åœ¨å¤„ç†åºåˆ—ä»»åŠ¡æ—¶èƒ½å¤Ÿæ›´å¥½åœ°å»ºæ¨¡é•¿è·ç¦»ä¾èµ–å…³ç³» åœ¨Transformerä¸­ä½¿ç”¨çš„Attentionæ˜¯Scaled Dot-Product Attentionï¼Œæ˜¯å½’ä¸€åŒ–çš„ç‚¹ä¹˜Attentionï¼Œå‡è®¾è¾“å…¥çš„query q ã€keyç»´åº¦ã€valueç»´åº¦ä¸ºd_{k}ï¼Œé‚£ä¹ˆå°±è®¡ç®—queryå’Œæ¯ä¸ªkey çš„ç‚¹ä¹˜æ“ä½œï¼Œå¹¶é™¤ä»¥\\sqrt{d_{k}}ï¼Œç„¶åŽåº”ç”¨Softmaxå‡½æ•°è®¡ç®—æƒé‡ \\operatorname{Attention}\\left(Q_{i}, K_{i}, V_{i}\\right)=\\operatorname{softmax}\\left(\\frac{Q_{i} K_{i}^{T}}{\\sqrt{d_{k}}}\\right) V_{i} åœ¨å®žè·µä¸­ï¼Œå°†queryå’Œkeysã€valuesåˆ†åˆ«å¤„ç†ä¸ºçŸ©é˜µQ, K, Vï¼Œé‚£ä¹ˆè®¡ç®—è¾“å‡ºçŸ©é˜µä¸º: \\operatorname{Attention}(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V å…¶ä¸­Q \\in R^{m \\times d_{k}}, K \\in R^{m \\times d_{k}}, V \\in R^{m \\times d_{k}}ï¼Œè¾“å‡ºçŸ©é˜µç»´åº¦ä¸ºR^{m \\times d_{k}}ï¼Œå…¶ä¸­mä¸ºå¥å­é•¿åº¦ï¼Œd_kä¸ºEmbeddingåŽçš„ç‰¹å¾é•¿åº¦ å…¶ä¸­QKçš„ç»´åº¦ä¸ºm \\times mï¼Œè¡¨ç¤ºå¥å­ä¸­æ¯ä¸ªå­—ä¹‹é—´çš„å…³æ³¨åº¦(self-attention)ï¼Œ è€Œ(QK)Vçš„ç»´åº¦ä¸ºm \\times d_kï¼Œè¡¨ç¤ºattentionä¸‹çš„å¥å­ç‰¹å¾å‘é‡ï¼ŒQKVå¦‚ä¸‹æ‰€ç¤º Q=K=V=\\left[ \\begin{matrix} d_{11} & d_{12} & \\cdots & d_{1 d_k} \\\\ d_{21} & d_{22} & \\cdots & d_{2 d_k} \\\\ \\cdots & \\cdots & \\cdots & \\cdots \\\\ d_{m1} & d_{m2} & \\cdots & d_{m d_k} \\\\ \\end{matrix} \\right] _{m \\times d_k} attentionä»£ç å¦‚ä¸‹: å…¶ä¸­qkvæ˜¯xç»è¿‡çº¿æ€§å˜æ¢ä¹‹åŽçš„ç»“æžœ def attention(query, key, value, mask=None, dropout=None): \"Compute 'Scaled Dot Product Attention'\" d_k = query.size(-1) scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k) if mask is not None: scores = scores.masked_fill(mask == 0, -1e9) p_attn = F.softmax(scores, dim = -1) if dropout is not None: p_attn = dropout(p_attn) return torch.matmul(p_attn, value), p_attn çŸ©é˜µä¸Žå…¶è½¬ç½®çš„ä¹˜ç§¯ å‘é‡æ•°é‡ç§¯çš„å‡ ä½•æ„ä¹‰ï¼šä¸€ä¸ªå‘é‡åœ¨å¦ä¸€ä¸ªå‘é‡ä¸Šçš„æŠ•å½± å‘é‡çš„ç›¸ä¼¼æ€§æ˜¯ç”¨ä¸¤è€…çš„è§’åº¦ä½™å¼¦æ¥åº¦é‡ï¼Œä½™å¼¦å€¼è¶Šå¤§åˆ™ä¸¤è€…è¶Šç›¸ä¼¼ cos \\theta = \\frac {x^Ty}{||x|| \\cdot ||y||} è€Œä½™å¼¦å€¼ç­‰äºŽä¸¤è€…å†…ç§¯ä¸Žä¸¤è€…æ¨¡é•¿ç§¯çš„æ¯”ï¼Œå½“ä¸¤ä¸ªå‘é‡æ¨¡é•¿å›ºå®šçš„æƒ…å½¢ä¸‹ï¼Œå†…ç§¯å¤§å°åˆ™åæ˜ äº†ä¸¤è€…ç›¸ä¼¼æ€§çš„å¤§å° import numpy as np mat_a = np.array([1, 2, 2], [4, 5, 8]) np.matmul(mat_a,mat_a.T) Out[5]: array([[ 9, 30], [ 30, 105]]) é‚£ä¹ˆScaled Dot-Product Attentionçš„ç¤ºæ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼ŒMaskæ˜¯å¯é€‰çš„ï¼Œå¦‚æžœæ˜¯èƒ½å¤ŸèŽ·å–åˆ°æ‰€æœ‰æ—¶åˆ»çš„è¾“å…¥(K, V)ï¼Œé‚£ä¹ˆå°±ä¸ä½¿ç”¨Maskï¼›å¦‚æžœæ˜¯ä¸èƒ½èŽ·å–åˆ°ï¼Œé‚£ä¹ˆå°±éœ€è¦ä½¿ç”¨Mask ä½¿ç”¨äº†Maskçš„Transformeræ¨¡åž‹ä¹Ÿè¢«ç§°ä¸ºTransformer Decoderï¼Œä¸ä½¿ç”¨Maskçš„Transformeræ¨¡åž‹ä¹Ÿè¢«ç§°ä¸ºTransformer Encoder å¦‚æžœåªå¯¹Qã€Kã€Våšä¸€æ¬¡è¿™æ ·çš„æƒé‡æ“ä½œæ˜¯ä¸å¤Ÿçš„ï¼Œè¿™é‡Œæå‡ºäº†Multi-Head Attentionæ“ä½œï¼ŒåŒ…æ‹¬ï¼š é¦–å…ˆå¯¹Q, \\mathrm{~K}, \\mathrm{~V}åšä¸€æ¬¡çº¿æ€§æ˜ å°„ï¼Œå°†è¾“å…¥ç»´åº¦å‡ä¸ºd_{\\text {model }}çš„Q, K, VçŸ©é˜µæ˜ å°„åˆ°Q \\in R^{m \\times d_{k}}, K \\in R^{m \\times d_{k}}, V \\in R^{m \\times d_{v}} ç„¶åŽå†é‡‡ç”¨Scaled Dot-Product Attentionç®—å‡ºç»“æžœ å¤šæ¬¡è¿›è¡Œä¸Šè¿°ä¸¤æ­¥æ“ä½œï¼Œç„¶åŽå°†å¾—åˆ°çš„ç»“æžœè¿›è¡Œåˆå¹¶ å°†åˆå¹¶çš„ç»“æžœè¿›è¡Œçº¿æ€§å˜æ¢ å¤šå¤´æ³¨æ„åŠ›çš„å¼•å…¥æœ‰ä»¥ä¸‹å‡ ä¸ªç›®çš„ï¼š å¹³è¡Œè®¡ç®—ï¼šé€šè¿‡ä½¿ç”¨å¤šä¸ªæ³¨æ„åŠ›å¤´ï¼Œå¯ä»¥å¹¶è¡Œåœ°è®¡ç®—æ³¨æ„åŠ›æƒé‡å’ŒåŠ æƒæ±‚å’Œï¼Œä»Žè€ŒåŠ å¿«æ¨¡åž‹çš„è®¡ç®—é€Ÿåº¦ã€‚æ¯ä¸ªæ³¨æ„åŠ›å¤´éƒ½ä¸“æ³¨äºŽä¸åŒçš„è¡¨ç¤ºå­ç©ºé—´ï¼Œå› æ­¤å¯ä»¥ç‹¬ç«‹åœ°è®¡ç®—å’Œå¤„ç†ä¿¡æ¯ï¼Œæé«˜æ¨¡åž‹çš„æ•ˆçŽ‡ã€‚ å¤šæ ·æ€§è¡¨è¾¾ï¼šæ¯ä¸ªæ³¨æ„åŠ›å¤´å­¦ä¹ åˆ°çš„è¡¨ç¤ºå­ç©ºé—´ä¸åŒï¼Œé€šè¿‡å¤šä¸ªæ³¨æ„åŠ›å¤´çš„ç»„åˆï¼Œå¯ä»¥èŽ·å¾—æ›´ä¸°å¯Œã€å¤šæ ·æ€§çš„è¡¨ç¤ºã€‚è¿™æœ‰åŠ©äºŽæ¨¡åž‹æ›´å¥½åœ°æ•æ‰è¾“å…¥åºåˆ—ä¸­çš„ä¸åŒç‰¹å¾å’Œå…³ç³»ï¼Œæé«˜æ¨¡åž‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚ ç»„åˆæ³¨æ„åŠ›ï¼šå¤šå¤´æ³¨æ„åŠ›å…è®¸æ¨¡åž‹åœ¨ä¸åŒçš„è¡¨ç¤ºå­ç©ºé—´ä¸Šè¿›è¡Œå¤šæ¬¡æ³¨æ„åŠ›è®¡ç®—ï¼Œå¹¶å°†è¿™äº›è®¡ç®—çš„ç»“æžœè¿›è¡Œç»„åˆã€‚è¿™ç§ç»„åˆèƒ½å¤Ÿä»Žä¸åŒçš„å…³æ³¨è§’åº¦å’Œè§†è§’æ¥å¤„ç†è¾“å…¥åºåˆ—ï¼Œå¸®åŠ©æ¨¡åž‹æ›´å…¨é¢åœ°ç†è§£åºåˆ—ä¸­çš„ä¿¡æ¯ã€‚ é€šè¿‡è¿™äº›æ–¹å¼ï¼Œå¤šå¤´æ³¨æ„åŠ›å¯ä»¥æä¾›æ›´çµæ´»ã€æ›´å¼ºå¤§çš„å»ºæ¨¡èƒ½åŠ›ï¼Œå¢žå¼ºæ¨¡åž‹å¯¹åºåˆ—ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ã€å…¨å±€ä¸Šä¸‹æ–‡å’Œç‰¹å¾ä¹‹é—´å¤æ‚å…³ç³»çš„å»ºæ¨¡èƒ½åŠ› å®ƒæ˜¯Transformeræ¨¡åž‹åœ¨å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æ—¶å–å¾—æˆåŠŸçš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œæ€»ç»“æ¥è¯´å…¬å¼å¦‚ä¸‹æ‰€ç¤º \\begin{array}{l} \\operatorname{Attention}(Q, K, V)=\\text { Concat }\\left(\\text {head}_{1}, \\text {head}_{2}, \\cdots, \\text {head}_{h}\\right) W^{O} \\\\ where \\quad {head}_{i}=\\operatorname{Attention}\\left(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\\right) \\\\ \\end{array} å…¶ä¸­ç¬¬1æ­¥çš„çº¿æ€§å˜æ¢å‚æ•°ä¸ºW_{i}^{Q} \\in R^{d_{\\text {model }} \\times d_{k}}, W_{i}^{K} \\in R^{d_{\\text {model }} \\times d_{k}}, W_{i}^{V} \\in R^{d_{\\text {model }} \\times d_{v}}ï¼Œç¬¬4 æ­¥çš„çº¿æ€§å˜åŒ–å‚æ•°ä¸ºW^{O} \\in R^{h d_{v} \\times d_{\\text {model }}}ï¼Œè€Œç¬¬ä¸‰æ­¥è®¡ç®—çš„æ¬¡æ•°æ˜¯h åœ¨è®ºæ–‡ä¸­å– d_{\\text {model }}=512ï¼Œè¡¨ç¤ºæ¯ä¸ªæ—¶åˆ»çš„è¾“å…¥ç»´åº¦å’Œè¾“å‡ºç»´åº¦ï¼Œh=8 è¡¨ç¤º8æ¬¡Attentionæ“ä½œï¼Œd_{k}=d_{v}=\\frac{d_{\\text {model }}}{h}=64 è¡¨ç¤ºç»è¿‡çº¿æ€§å˜æ¢ä¹‹åŽã€è¿›è¡ŒAttentionæ“ä½œä¹‹å‰çš„ç»´åº¦ è¿›è¡Œä¸€æ¬¡Attentionä¹‹åŽè¾“å‡ºçš„çŸ©é˜µç»´åº¦æ˜¯R^{m \\times d_{v}}=R^{m \\times 64}ï¼Œç„¶åŽè¿›è¡Œ\\mathrm{h}=8æ¬¡æ“ä½œåˆå¹¶ä¹‹åŽè¾“å‡ºçš„ç»“æžœæ˜¯R^{m \\times\\left(h \\times d_{v}\\right)}=R^{m \\times 512}ï¼Œå› æ­¤è¾“å…¥å’Œè¾“å‡ºçš„çŸ©é˜µç»´åº¦ç›¸åŒ è¿™æ ·è¾“å‡ºçš„çŸ©é˜µR^{m \\times 512}ï¼Œæ¯è¡Œçš„å‘é‡éƒ½æ˜¯å¯¹Vå‘é‡ä¸­æ¯ä¸€è¡Œv_{i}çš„åŠ æƒï¼Œç¤ºæ„å›¾å¦‚ä¸Šæ‰€ç¤º å¤šå¤´æ³¨æ„åŠ›ä»£ç å®žçŽ° class MultiHeadedAttention(nn.Module): def __init__(self, h, d_model, dropout=0.1): \"Take in model size and number of heads.\" super(MultiHeadedAttention, self).__init__() assert d_model % h == 0 # We assume d_v always equals d_k self.d_k = d_model // h self.h = h # å¤šå¤´åœ¨è¿™é‡Œä½“çŽ° self.linears = clones(nn.Linear(d_model, d_model), 4) self.attn = None self.dropout = nn.Dropout(p=dropout) def forward(self, query, key, value, mask=None): if mask is not None: # Same mask applied to all h heads. mask = mask.unsqueeze(1) nbatches = query.size(0) # 1) Do all the linear projections in batch from d_model => h x d_k query, key, value = \\ [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))] # 2) Apply attention on all the projected vectors in batch. x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout) # 3) \"Concat\" using a view and apply a final linear. x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k) # 4) çº¿æ€§å˜æ¢æŠ•å½±å›žåŽŸå§‹è¡¨ç¤ºç»´åº¦ return self.linears[-1](x) å¦‚æžœä¸å¥½ç†è§£å¯ä»¥çœ‹ä¸‹è¿™éƒ¨åˆ†ä»£ç  def multihead_attention(Q, K, V, num_heads): # çº¿æ€§å˜æ¢å¾—åˆ°æŸ¥è¯¢ã€é”®å’Œå€¼çš„è¡¨ç¤º Q_transformed = linear_transform(Q) K_transformed = linear_transform(K) V_transformed = linear_transform(V) # åˆ†å‰²å¤´ Q_heads = split_heads(Q_transformed, num_heads) K_heads = split_heads(K_transformed, num_heads) V_heads = split_heads(V_transformed, num_heads) # æ¯ä¸ªå¤´çš„æ³¨æ„åŠ›è®¡ç®— attention_heads = [] for i in range(num_heads): attention_head = scaled_dot_product_attention(Q_heads[i], K_heads[i], V_heads[i]) attention_heads.append(attention_head) # æ‹¼æŽ¥æ³¨æ„åŠ›å¤´ concatenated_attention = concatenate_heads(attention_heads) # çº¿æ€§å˜æ¢æŠ•å½±å›žåŽŸå§‹è¡¨ç¤ºç»´åº¦ output = linear_transform(concatenated_attention) return output Encoder ç¼–ç å™¨å’Œè§£ç å™¨å¦‚ä¸‹æ‰€ç¤º Decoder åœ¨encoderéƒ¨åˆ†ä¸­çš„self-attentionæ˜¯ä¸éœ€è¦maskçš„ï¼Œè€Œdecoderéƒ¨åˆ†çš„self-attentionæ˜¯éœ€è¦maskçš„ï¼Œå› ä¸ºæ­£æ˜¯æœ‰äº†maské®æŒ¡åŽé¢çš„ä¿¡æ¯ï¼Œæ‰èƒ½å°†transformerç”¨æ¥åšæŽ¨ç† ç¼–ç å™¨å’Œè§£ç å™¨å¦‚ä¸‹æ‰€ç¤º ç¼–ç å™¨æŠŠæœ€åŽä¸€å±‚çš„KVå–‚ç»™äº†ç¼–ç å™¨ï¼Œæ­¤æ—¶Qæ¥æºè§£ç å™¨ï¼ŒK=Væ¥æºäºŽç¼–ç å™¨ï¼Œæ˜¯ä¸ºäº†è®©è§£ç å™¨èƒ½å¤Ÿåœ¨ç”Ÿæˆè¾“å‡ºæ—¶ä½¿ç”¨ç¼–ç å™¨çš„ä¿¡æ¯ é€šè¿‡ç»™è§£ç å™¨æä¾›ç¼–ç å™¨çš„é”®å’Œå€¼çŸ©é˜µï¼Œå¯ä»¥å®žçŽ°ä»¥ä¸‹ä¸¤ä¸ªç›®çš„ï¼š ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼ é€’ï¼šç¼–ç å™¨ä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶èƒ½å¤Ÿæ•æ‰åˆ°è¾“å…¥åºåˆ—ä¸­çš„å±€éƒ¨å’Œå…¨å±€å…³ç³»ï¼Œç”Ÿæˆå¯¹åº”çš„é”®å’Œå€¼ã€‚å°†è¿™äº›é”®å’Œå€¼ä¼ é€’ç»™è§£ç å™¨ï¼Œå¯ä»¥å°†ç¼–ç å™¨çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼ é€’ç»™è§£ç å™¨ï¼Œä»¥å¸®åŠ©è§£ç å™¨åœ¨ç”Ÿæˆè¾“å‡ºæ—¶äº†è§£è¾“å…¥åºåˆ—çš„ç›¸å…³å†…å®¹ã€‚ å¯¹é½å’Œä¿¡æ¯æå–ï¼šè§£ç å™¨å¯ä»¥é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶å¯¹ç¼–ç å™¨çš„é”®å’Œå€¼è¿›è¡ŒåŠ æƒæ±‡æ€»ï¼Œä»¥èŽ·å–ä¸Žå½“å‰è§£ç ä½ç½®ç›¸å…³çš„ä¿¡æ¯ã€‚é€šè¿‡è®¡ç®—è§£ç å™¨å½“å‰ä½ç½®ä¸Žç¼–ç å™¨ä¸­æ¯ä¸ªä½ç½®ä¹‹é—´çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œå¯ä»¥å®žçŽ°å¯¹é½å’Œä¿¡æ¯æå–ï¼Œä½¿è§£ç å™¨èƒ½å¤Ÿä¸“æ³¨äºŽä¸Žå½“å‰ä½ç½®ç›¸å…³çš„è¾“å…¥ä¿¡æ¯ã€‚ æ€»ç»“æ¥è¯´ï¼Œé€šè¿‡å°†ç¼–ç å™¨çš„é”®å’Œå€¼çŸ©é˜µæä¾›ç»™è§£ç å™¨ï¼Œå¯ä»¥å®žçŽ°ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼ é€’å’Œå¯¹é½æœºåˆ¶ï¼Œå¸®åŠ©è§£ç å™¨åœ¨ç”Ÿæˆè¾“å‡ºæ—¶åˆ©ç”¨ç¼–ç å™¨çš„ä¿¡æ¯ï¼Œä»Žè€Œæ”¹å–„æ¨¡åž‹çš„æ€§èƒ½å’Œè¾“å‡ºè´¨é‡ mask Attention Mask Padding Mask Bert The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) ELMoã€GPT å’Œ BERT ä¸‰è€…çš„åŒºåˆ« GPTï¼šGPT ä½¿ç”¨Transformer Decoderä½œä¸ºç‰¹å¾æå–å™¨ï¼Œå®žçŽ°äº†å•å‘ç¼–ç ã€å…·æœ‰è‰¯å¥½çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ï¼Œç„¶è€Œå½“å‰è¯çš„è¯­ä¹‰åªèƒ½ç”±å…¶å‰åºè¯å†³å®šï¼Œå¹¶ä¸”åœ¨è¯­ä¹‰ç†è§£ä¸Šä¸è¶³ BERTï¼šä½¿ç”¨äº†Transformer Encoderä½œä¸ºç‰¹å¾æå–å™¨ï¼Œä¸ºåŒå‘ç¼–ç å™¨ï¼Œå¹¶ä½¿ç”¨äº†ä¸Žå…¶é…å¥—çš„æŽ©ç è®­ç»ƒæ–¹æ³•ã€‚è™½ç„¶ä½¿ç”¨åŒå‘ç¼–ç è®©BERTä¸å†å…·æœ‰æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ï¼Œä½†æ˜¯BERTçš„è¯­ä¹‰ä¿¡æ¯æå–èƒ½åŠ›æ›´å¼º ELMo: ä½¿ç”¨è‡ªå·¦å‘å³ç¼–ç å’Œè‡ªå³å‘å·¦ç¼–ç çš„ä¸¤ä¸ªLSTMç½‘ç»œï¼Œåˆ†åˆ«ä»¥P\\left(w_{i} \\mid w_{1}, \\cdots, w_{i-1}\\right)å’ŒP\\left(w_{i} \\mid w_{i+1}, \\cdots, w_{n}\\right)ä¸ºç›®æ ‡å‡½æ•°ç‹¬ç«‹è®­ç»ƒï¼Œå°†è®­ç»ƒå¾—åˆ°çš„ç‰¹å¾å‘é‡ä»¥æ‹¼æŽ¥çš„å½¢å¼å®žçŽ°åŒå‘ç¼–ç ï¼Œæœ¬è´¨ä¸Šè¿˜æ˜¯å•å‘ç¼–ç ï¼Œåªä¸è¿‡æ˜¯ä¸¤ä¸ªæ–¹å‘ä¸Šçš„å•å‘ç¼–ç çš„æ‹¼æŽ¥è€Œæˆçš„åŒå‘ç¼–ç  bertæ˜¯è‡ªç¼–ç æ¨¡åž‹ï¼Œè€Œgptæ˜¯è‡ªå›žå½’æ¨¡åž‹ bertæ¦‚å†µ BERT(Bidirectional Encoder Representations from Transformers)æ¨¡åž‹çš„ç¼–ç å™¨ç”±å¤šä¸ªTransformerç¼–ç å™¨å±‚ç»„æˆï¼Œé€šå¸¸ä½¿ç”¨äº†å¤šä¸ªé‡å¤çš„ç¼–ç å™¨æ¥å½¢æˆæ·±å±‚çš„è¡¨ç¤º æ¯ä¸ªBERTç¼–ç å™¨å±‚åŒ…å«äº†ä»¥ä¸‹ç»„ä»¶ï¼š å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ˆMulti-Head Self-Attentionï¼‰ï¼šè¯¥å±‚ä½¿ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥å¯¹è¾“å…¥åºåˆ—è¿›è¡Œå»ºæ¨¡ã€‚è‡ªæ³¨æ„åŠ›å…è®¸æ¨¡åž‹åœ¨å¤„ç†åºåˆ—æ—¶å…³æ³¨ä¸åŒä½ç½®ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œæœ‰åŠ©äºŽæ•æ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ å‰é¦ˆç¥žç»ç½‘ç»œï¼ˆFeed-Forward Neural Networkï¼‰ï¼šåœ¨è‡ªæ³¨æ„åŠ›å±‚åŽé¢æ˜¯ä¸€ä¸ªå‰é¦ˆç¥žç»ç½‘ç»œã€‚è¯¥ç½‘ç»œé€šå¸¸ç”±ä¸¤ä¸ªçº¿æ€§å±‚å’Œæ¿€æ´»å‡½æ•°ï¼ˆå¦‚ReLUï¼‰ç»„æˆï¼Œç”¨äºŽå¯¹è‡ªæ³¨æ„åŠ›è¾“å‡ºè¿›è¡Œéžçº¿æ€§å˜æ¢å’Œç‰¹å¾æå– æ®‹å·®è¿žæŽ¥ï¼ˆResidual Connectionsï¼‰å’Œå±‚å½’ä¸€åŒ–ï¼ˆLayer Normalizationï¼‰ï¼šåœ¨æ¯ä¸ªå­å±‚ï¼ˆè‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç¥žç»ç½‘ç»œï¼‰ä¹‹åŽéƒ½åº”ç”¨äº†æ®‹å·®è¿žæŽ¥å’Œå±‚å½’ä¸€åŒ–æ“ä½œã€‚è¿™äº›æ“ä½œæœ‰åŠ©äºŽç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¹¶æä¾›æ›´ç¨³å®šå’Œé«˜æ•ˆçš„è®­ç»ƒ BERTæ¨¡åž‹ä¸­é€šå¸¸ä¼šå †å å¤šä¸ªç¼–ç å™¨å±‚æ¥å½¢æˆæ·±å±‚è¡¨ç¤ºã€‚æ¯ä¸ªç¼–ç å™¨å±‚çš„è¾“å‡ºä¼šä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ï¼Œé€šè¿‡å¤šæ¬¡é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œå¯ä»¥é€æ¸ä¸°å¯Œè¾“å…¥åºåˆ—çš„è¡¨ç¤ºèƒ½åŠ› å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒBERTæ¨¡åž‹è¿˜åœ¨ç¼–ç å™¨è¾“å…¥çš„å¼€å¤´æ·»åŠ äº†ç‰¹æ®Šçš„æ ‡è®°ï¼Œå¦‚[CLS]ï¼ˆç”¨äºŽåˆ†ç±»ä»»åŠ¡ï¼‰å’Œ[SEP]ï¼ˆç”¨äºŽåˆ†éš”è¾“å…¥ï¼‰ã€‚è¿™äº›ç‰¹æ®Šæ ‡è®°æœ‰åŠ©äºŽæ¨¡åž‹åœ¨å¤„ç†ä¸åŒä»»åŠ¡æ—¶è¿›è¡Œåºåˆ—çº§åˆ«çš„æ“ä½œå’Œåˆ†ç±» æ€»ç»“èµ·æ¥ï¼ŒBERTçš„ç¼–ç å™¨ç”±å¤šä¸ªTransformerç¼–ç å™¨å±‚ç»„æˆï¼Œæ¯ä¸ªç¼–ç å™¨å±‚ç”±å¤šå¤´è‡ªæ³¨æ„åŠ›ã€å‰é¦ˆç¥žç»ç½‘ç»œå’Œæ®‹å·®è¿žæŽ¥/å±‚å½’ä¸€åŒ–ç»„æˆã€‚é€šè¿‡å †å å¤šä¸ªç¼–ç å™¨å±‚ï¼ŒBERTæ¨¡åž‹å¯ä»¥èŽ·å¾—æ·±å±‚ã€é«˜è´¨é‡çš„è¯­è¨€è¡¨ç¤º Architecture è¾“å…¥ è®­ç»ƒæ–¹å¼ ç”±äºŽæ— æ³•ä½¿ç”¨æ ‡å‡†è¯­è¨€æ¨¡åž‹çš„è®­ç»ƒæ¨¡å¼ï¼ŒBERTå€Ÿé‰´å®Œå½¢å¡«ç©ºä»»åŠ¡å’ŒCBOWçš„æ€æƒ³ï¼Œä½¿ç”¨è¯­è¨€æŽ©ç æ¨¡åž‹(MLM)æ–¹æ³•è®­ç»ƒæ¨¡åž‹ è®­ç»ƒä¸­çš„mask MLMæ–¹æ³•ä¹Ÿå°±æ˜¯éšæœºåŽ»æŽ‰å¥å­ä¸­çš„éƒ¨åˆ†token(å•è¯)ï¼Œç„¶åŽæ¨¡åž‹æ¥é¢„æµ‹è¢«åŽ»æŽ‰çš„tokenæ˜¯ä»€ä¹ˆã€‚è¿™æ ·å®žé™…ä¸Šå·²ç»ä¸æ˜¯ä¼ ç»Ÿçš„ç¥žç»ç½‘ç»œè¯­è¨€æ¨¡åž‹(ç±»ä¼¼äºŽç”Ÿæˆæ¨¡åž‹)äº†ï¼Œè€Œæ˜¯å•çº¯ä½œä¸ºåˆ†ç±»é—®é¢˜ï¼Œæ ¹æ®è¿™ä¸ªæ—¶åˆ»çš„hidden stateæ¥é¢„æµ‹è¿™ä¸ªæ—¶åˆ»çš„tokenåº”è¯¥æ˜¯ä»€ä¹ˆï¼Œè€Œä¸æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶åˆ»çš„è¯çš„æ¦‚çŽ‡åˆ†å¸ƒäº† éšæœºåŽ»æŽ‰çš„tokenè¢«ç§°ä½œæŽ©ç è¯ï¼Œåœ¨è®­ç»ƒä¸­ï¼ŒæŽ©ç è¯å°†ä»¥15%çš„æ¦‚çŽ‡è¢«æ›¿æ¢æˆ[MASK]ï¼Œä¹Ÿå°±æ˜¯è¯´éšæœºmaskè¯­æ–™ä¸­15%çš„tokenï¼Œè¿™ä¸ªæ“ä½œåˆ™ç§°ä¸ºæŽ©ç æ“ä½œ åœ¨é€‰æ‹©15%çš„è¯ä½œä¸ºæŽ©ç è¯åŽè¿™äº›æŽ©ç è¯æœ‰ä¸‰ç±»æ›¿æ¢é€‰é¡¹ï¼š 80% ç»ƒæ ·æœ¬ä¸­ï¼šå°†é€‰ä¸­çš„è¯ç”¨ [MASK] æ¥ä»£æ›¿ 10% çš„è®­ç»ƒæ ·æœ¬ä¸­ï¼šé€‰ä¸­çš„è¯ä¸å‘ç”Ÿå˜åŒ–ï¼Œè¯¥åšæ³•æ˜¯ä¸ºäº†ç¼“è§£è®­ç»ƒæ–‡æœ¬å’Œé¢„æµ‹æ–‡æœ¬çš„åå·®å¸¦æ¥çš„æ€§èƒ½æŸå¤± 10% çš„è®­ç»ƒæ ·æœ¬ä¸­ï¼šå°†é€‰ä¸­çš„è¯ç”¨ä»»æ„çš„è¯æ¥è¿›è¡Œä»£æ›¿ï¼Œè¯¥åšæ³•æ˜¯ä¸ºäº†è®© BERT å­¦ä¼šæ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯è‡ªåŠ¨çº é”™ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/å›¾åƒåˆ†å‰²ç®—æ³•.html":{"url":"chapters/å›¾åƒåˆ†å‰²ç®—æ³•.html","title":"å›¾åƒåˆ†å‰²ç®—æ³•.md","summary":"å›¾åƒåˆ†å‰²ç®—æ³•","keywords":"","body":"å›¾åƒåˆ†å‰²UNetè¯­ä¹‰åˆ†å‰²å®žä¾‹åˆ†å‰² å›¾åƒåˆ†å‰² UNet U-Net: Convolutional Networks for Biomedical Image Segmentation 2015 å›¾åƒåˆ†å‰²å¿…å¤‡çŸ¥è¯†ç‚¹ | Unetè¯¦è§£ ç†è®º+ ä»£ç  U-Netæ˜¯ä¸€ç§å¸¸ç”¨çš„å·ç§¯ç¥žç»ç½‘ç»œç»“æž„ï¼Œç‰¹åˆ«é€‚ç”¨äºŽå›¾åƒåˆ†å‰²ä»»åŠ¡ã€‚å®ƒç”±Olaf Ronnebergerç­‰äººåœ¨2015å¹´æå‡ºï¼Œå¹¶å› å…¶åœ¨ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„å‡ºè‰²è¡¨çŽ°è€Œå—åˆ°å¹¿æ³›å…³æ³¨ U-Netçš„æ•´ä½“ç»“æž„å‘ˆUå­—å½¢ï¼Œå› æ­¤å¾—åã€‚å®ƒåŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šç¼–ç å™¨(Encoder)å’Œè§£ç å™¨(Decoder) ç¼–ç å™¨ç”±ä¸€ç³»åˆ—å·ç§¯å±‚å’Œæ± åŒ–å±‚ç»„æˆï¼Œç”¨äºŽæå–å›¾åƒä¸­çš„ç‰¹å¾å¹¶é€æ¸ç¼©å°æ„Ÿå—é‡Ž è§£ç å™¨ç”±ä¸€ç³»åˆ—åå·ç§¯å±‚å’Œè·³è·ƒè¿žæŽ¥(Skip Connection)ç»„æˆï¼Œç”¨äºŽå°†ç¼–ç å™¨æå–çš„ç‰¹å¾æ˜ å°„é‡æ–°æ”¾å¤§ï¼Œå¹¶ä¸Žè§£ç å™¨ä¸­çš„ç‰¹å¾è¿›è¡Œèžåˆ è·³è·ƒè¿žæŽ¥çš„ä½œç”¨æ˜¯å°†åº•å±‚çš„ç»†èŠ‚ä¿¡æ¯ä¼ é€’ç»™è§£ç å™¨ï¼Œæœ‰åŠ©äºŽæ›´å¥½åœ°æ¢å¤åˆ†å‰²ç»“æžœçš„ç»†èŠ‚ U-Netçš„è®¾è®¡æ€æƒ³æ˜¯åœ¨ç‰¹å¾æå–çš„åŒæ—¶ä¿ç•™æ›´å¤šçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»¥åŠä¿ç•™é«˜åˆ†è¾¨çŽ‡çš„ç»†èŠ‚ã€‚é€šè¿‡ç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´çš„ç‰¹å¾ä¼ é€’å’Œèžåˆï¼ŒU-Netèƒ½å¤ŸåŒæ—¶èŽ·å¾—å±€éƒ¨å’Œå…¨å±€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆç»†è‡´å‡†ç¡®çš„åˆ†å‰²ç»“æžœ ç”±äºŽå…¶ç®€å•è€Œæœ‰æ•ˆçš„ç»“æž„ï¼ŒU-Netåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ã€è¯­ä¹‰åˆ†å‰²ã€é¥æ„Ÿå›¾åƒåˆ†æžç­‰é¢†åŸŸå¾—åˆ°äº†å¹¿æ³›åº”ç”¨ï¼Œå¹¶æˆä¸ºå›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­çš„ç»å…¸æ¨¡åž‹ä¹‹ä¸€ è¯­ä¹‰åˆ†å‰² å®žä¾‹åˆ†å‰² Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/å›¾åƒåˆ†ç±»ç®—æ³•.html":{"url":"chapters/å›¾åƒåˆ†ç±»ç®—æ³•.html","title":"å›¾åƒåˆ†ç±»ç®—æ³•.md","summary":"åŸºäºŽæ·±åº¦å­¦ä¹ çš„å›¾åƒåˆ†ç±»ç®—æ³•","keywords":"","body":"å›¾åƒåˆ†ç±»ç»å…¸æ¨¡åž‹ç»¼è¿°åˆ†ç±»æ•°æ®é›†ImageNettorchvisionLenetAlexNetVggæ¦‚è¿°æ¨¡åž‹ç¼ºç‚¹GoogleNetInception-v1Inception-v2Inception-v3Inception-v4ä¸ŽResNetResNetæ¨¡åž‹æ®‹å·®DenseNetæ¦‚è¿°æ¨¡åž‹ResnextVitDeiTModelçŸ¥è¯†è’¸é¦Clipæ¦‚è¿°zero-shotåˆ†ç±»TOnICS å›¾åƒåˆ†ç±» è®¡ç®—æœºè§†è§‰ä¸­å›¾åƒåˆ†ç±»ä»»åŠ¡è„‰ç»œæ¢³ç† An Analysis of Deep Neural Network Models for Practical Applications ç»å…¸æ¨¡åž‹ç»¼è¿° æ¨¡åž‹ç»¼è¿° LeNet-5: æ—©æœŸå·ç§¯ç¥žç»ç½‘ç»œä¸­æœ€æœ‰ä»£è¡¨æ€§çš„æž¶æž„ï¼Œæ˜¯Yann LeCunåœ¨1998å¹´è®¾è®¡çš„ï¼Œç”¨äºŽæ‰‹å†™æ•°å­—è¯†åˆ«çš„å·ç§¯ç¥žç»ç½‘ç»œ AlexNet: 2012å¹´ILSVRCå† å†›ï¼Œ6åƒä¸‡å‚æ•°ã€‚ç”±äºŽå‡†ç¡®çŽ‡è¿œè¶…ä¼ ç»Ÿæ–¹æ³•çš„ç¬¬äºŒåï¼ˆtop5é”™è¯¯çŽ‡ä¸º15.3%ï¼Œç¬¬äºŒåä¸º26.2%ï¼‰ï¼Œå¼•èµ·äº†å¾ˆå¤§çš„è½°åŠ¨ã€‚è‡ªæ­¤ä¹‹åŽï¼ŒCNNæˆä¸ºåœ¨å›¾åƒè¯†åˆ«åˆ†ç±»çš„æ ¸å¿ƒç®—æ³•æ¨¡åž‹ï¼Œå¸¦æ¥äº†æ·±åº¦å­¦ä¹ çš„å¤§çˆ†å‘ ZF-Net: 2013å¹´ILSVRCå† å†›ï¼Œç»“æž„å’ŒAlexNetåŒºåˆ«ä¸å¤§ï¼Œåˆ†ç±»æ•ˆæžœä¹Ÿå·®ä¸å¤šã€‚è¿™ç¯‡æ–‡ç« çš„è´¡çŒ®åœ¨äºŽï¼Œæå‡ºäº†ä¸€ç§CNNç‰¹å¾å¯è§†åŒ–æ–¹æ³•ï¼šåæ± åŒ–ã€åæ¿€æ´»ã€åå·ç§¯ï¼Œä»Žè€Œæˆä¸ºCNNç‰¹å¾å¯è§†åŒ–çš„å¼€å±±ä¹‹ä½œ GoogLeNet: 2014å¹´ILSVRCå† å†›ç½‘ç»œã€‚åŒæ ·ä¹Ÿæ˜¯5+3çš„æ¨¡å¼ï¼ˆä»¥æ± åŒ–å±‚ä¸ºç•Œï¼‰ï¼Œå‚æ•°é‡çº¦ä¸º5ç™¾ä¸‡ï¼Œæ ¸å¿ƒæ¨¡å—æ˜¯Inception Moduleã€‚InceptionåŽ†ç»äº†V1ã€V2ã€V3ã€V4ç­‰å¤šä¸ªç‰ˆæœ¬çš„å‘å±•ï¼Œä¸æ–­è¶‹äºŽå®Œå–„ Inception V1ï¼šä¸»è¦æå‡ºäº†å¤šåˆ†æ”¯(å¤šåˆ†è¾¨çŽ‡çš„filterç»„åˆ)çš„ç½‘ç»œ Inception V2ï¼š ä¸»è¦æå‡ºäº†BNå±‚ï¼Œæé«˜ç½‘ç»œæ€§èƒ½(å‡å°‘æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸ã€é˜²æ­¢è¿‡æ‹Ÿåˆã€ä»£æ›¿dropoutå±‚ã€ä½¿åˆå§‹åŒ–å­¦ä¹ å‚æ•°æ›´å¤§) Inception V3ï¼šä¸»è¦æå‡ºäº†åˆ†è§£å·ç§¯ï¼ŒæŠŠå¤§å·ç§¯å› å¼åˆ†è§£æˆå°å·ç§¯å’Œéžå¯¹ç§°å·ç§¯ VGG: 2014å¹´ILSVRCäºšå†›ç½‘ç»œï¼Œ1.38äº¿å‚æ•°ã€‚ç”±äºŽç½‘ç»œç»“æž„ååˆ†ç®€å•ï¼Œå¾ˆé€‚åˆè¿ç§»å­¦ä¹  ResNet: 2015å¹´ILSVRCå† å†›ç½‘ç»œã€‚æ ¸å¿ƒæ˜¯å¸¦çŸ­è¿žæŽ¥çš„æ®‹å·®æ¨¡å—ï¼Œå…¶ä¸­ä¸»è·¯å¾„æœ‰ä¸¤å±‚å·ç§¯æ ¸ï¼ˆRes34ï¼‰ï¼ŒçŸ­è¿žæŽ¥æŠŠæ¨¡å—çš„è¾“å…¥ä¿¡æ¯ç›´æŽ¥å’Œç»è¿‡ä¸¤æ¬¡å·ç§¯ä¹‹åŽçš„ä¿¡æ¯èžåˆï¼Œç›¸å½“äºŽåŠ äº†ä¸€ä¸ªæ’ç­‰å˜æ¢ã€‚çŸ­è¿žæŽ¥æ˜¯æ·±åº¦å­¦ä¹ åˆä¸€é‡è¦æ€æƒ³ï¼Œé™¤è®¡ç®—æœºè§†è§‰å¤–ï¼ŒçŸ­è¿žæŽ¥æ€æƒ³ä¹Ÿè¢«ç”¨åˆ°äº†æœºå™¨ç¿»è¯‘ã€è¯­éŸ³è¯†åˆ«/åˆæˆé¢†åŸŸ ResNeXt: ResNetçš„å¦ä¸€æ”¹è¿›ã€‚ä¸»è¦æ˜¯é‡‡ç”¨äº†VGGå †å æ€æƒ³å’ŒInceptionçš„split-transform-mergeæ€æƒ³ï¼Œåœ¨ä¸å¢žåŠ å‚æ•°å¤æ‚åº¦çš„å‰æä¸‹æé«˜å‡†ç¡®çŽ‡ã€‚ResNeXtå‘çŽ°ï¼Œå¢žåŠ åˆ†æ”¯æ•°æ˜¯æ¯”åŠ æ·±æˆ–åŠ å®½æ›´æœ‰æ•ˆåœ°æå‡ç½‘ç»œæ€§èƒ½çš„æ–¹å¼ DenseNet: CVPR2017çš„oralã€‚ä¸»è¦æ€æƒ³æ˜¯å°†æ¯ä¸€å±‚éƒ½ä¸ŽåŽé¢çš„å±‚è¿žæŽ¥èµ·æ¥ï¼Œå¦‚æžœä¸€ä¸ªç½‘ç»œä¸­æœ‰Lå±‚ï¼Œé‚£ä¹ˆä¼šæœ‰L(L+1)/2ä¸ªè¿žæŽ¥ã€‚é€šè¿‡è¿™æ ·çš„å¯†é›†è¿žæŽ¥ï¼Œæ¯ä¸€å±‚åœ¨æ­£å‘æ—¶å€™éƒ½èƒ½ç›´æŽ¥æŽ¥å—åŽŸå§‹è¾“å…¥ä¿¡å·ï¼Œåœ¨åå‘æ—¶å€™ä¹Ÿéƒ½èƒ½ç›´æŽ¥æŽ¥å—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œå³è¿™ç§è¿žæŽ¥æ–¹å¼ä½¿å¾—ç‰¹å¾å’Œæ¢¯åº¦çš„ä¼ é€’æ›´åŠ æœ‰æ•ˆï¼Œç½‘ç»œä¹Ÿå°±æ›´åŠ å®¹æ˜“è®­ç»ƒ å½“ç„¶ï¼Œå¦‚æžœå…¨éƒ¨é‡‡ç”¨è¿™ç§å¯†é›†è¿žæŽ¥çš„æ–¹å¼ï¼Œç‰¹å¾å›¾çš„åŽšåº¦å°±ä¼šå¾ˆå¤§ã€‚äºŽæ˜¯é‡‡ç”¨ä¸¤ç§æ–¹å¼é™ä½Žå‚æ•°é‡ï¼šä¸€æ˜¯å°†å¯†é›†è¿žæŽ¥çš„å±‚åšæˆä¸€ä¸ªæ¨¡å—ï¼Œæ•´ä¸ªç½‘ç»œé‡‡ç”¨æ¨¡å—å †å çš„æ–¹å¼ï¼Œè€Œä¸æ˜¯æ‰€æœ‰å±‚å…¨éƒ¨å¯†é›†è¿žæŽ¥ï¼›äºŒæ˜¯åœ¨dense blockä¸­å¼•å…¥bottleneck layerï¼Œå³å·ç§¯3x3å‰å¢žåŠ 1x1å·ç§¯ï¼Œä»¥æ­¤æ¥å‡å°‘feature mapæ•°é‡ ç¼ºç‚¹æ˜¯å¤ªåƒæ˜¾å­˜ã€‚é€šå¸¸å ç”¨æ˜¾å­˜çš„ä¸»è¦æ˜¯æŽ¨æ–­è¿‡ç¨‹ä¸­äº§ç”Ÿçš„feature mapå’Œå‚æ•°é‡ã€‚æœ‰äº›æ¡†æž¶ä¼šæœ‰ä¼˜åŒ–ï¼Œè‡ªåŠ¨æŠŠæ¯”è¾ƒé å‰çš„å±‚çš„feature mapé‡Šæ”¾æŽ‰ï¼Œæ‰€ä»¥æ˜¾å­˜å°±ä¼šå‡å°‘ï¼Œæˆ–è€…inplaceæ“ä½œé€šè¿‡é‡æ–°è®¡ç®—çš„æ–¹æ³•å‡å°‘ä¸€éƒ¨åˆ†æ˜¾å­˜ï¼Œä½†æ˜¯densenetå› ä¸ºéœ€è¦é‡å¤åˆ©ç”¨æ¯”è¾ƒé å‰çš„feature mapï¼Œæ‰€ä»¥æ— æ³•é‡Šæ”¾ï¼Œå¯¼è‡´æ˜¾å­˜å ç”¨è¿‡å¤§ SENet: 2017å¹´ILSVRCå† å†›ç½‘ç»œã€‚æ˜¯ä¸€ä¸ªæ¨¡å—ï¼Œå¯ä»¥å’Œå…¶ä»–çš„ç½‘ç»œæž¶æž„ç»“åˆï¼Œæ¯”å¦‚GoogLeNetã€ResNetç­‰ åŽ†å²è„‰ç»œ 1998 2012 2013 2014 2014 LeNet-5 AlexNet ZF-Net GoogLeNetV1ã€V2ã€V3ã€V4 VGG 2015 2016 2017 2017 ResNet ResNeXt DenseNet SENet 2020 2021 2022 2023 2024 Vit DeiTã€Clip TOnICS åˆ†ç±»æ•°æ®é›† ImageNet ImageNetæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸå¸¸ç”¨çš„æ•°æ®é›†ä¹‹ä¸€ã€‚åœ¨ å›¾åƒåˆ†ç±»ã€ç›®æ ‡åˆ†å‰²å’Œ ç›®æ ‡æ£€æµ‹ä¸­æœ‰ç€æ— æ³•æ’¼åŠ¨çš„åœ°ä½ ImageNetæœ€åˆæ˜¯ç”±æŽé£žé£žç­‰äººåœ¨CVPR 2009å¹´å‘è¡¨çš„è®ºæ–‡â€”â€”ã€ŒImageNet: A Large-Scale Hierarchical Image Databaseã€ä¸­å‘å¸ƒçš„ å¤šå¹´æ¥ï¼ŒImageNet çš„ç›¸å…³è®ºæ–‡å¯¹ä¸šå†…æœ‰æžå¤§çš„å½±å“ ImageNetæœ¬èº«åˆ™æ˜¯ä¸€ä¸ªæµ·é‡çš„å¸¦æ ‡æ³¨å›¾åƒæ•°æ®é›†ã€‚é€šè¿‡ä¼—åŒ…ç­‰æ–¹å¼è¿›è¡Œæ ‡æ³¨ï¼Œä»Ž2007å¹´å¼€å§‹ç›´åˆ°2009å¹´å®Œæˆã€‚ImageNetæœ‰è¶…è¿‡1500ä¸‡å¼ å›¾ç‰‡ï¼Œä»…æ±½è½¦å›¾åƒçš„æ•°é‡è¾¾åˆ°äº†70ä¸‡å¼ ï¼Œç±»åˆ«æ•°é‡ä¸º2567ä¸ªã€‚å¦‚æ­¤å·¨é‡ã€ æ ‡æ³¨é”™è¯¯æžä½Žä¸”å…è´¹çš„æ•°æ®é›†ï¼Œå·²ç»æˆä¸ºå›¾åƒå¤„ç†é¢†åŸŸç ”ç©¶è€…é¦–å…ˆæŽ¥è§¦çš„æ•°æ®é›†ä¹‹ä¸€ æ¯«ä¸å¤¸å¼ çš„è¯´ï¼ŒImageNetæ˜¯å›¾åƒå¤„ç†ç®—æ³•çš„è¯•é‡‘çŸ³ã€‚ä»Ž2010å¹´èµ·ï¼Œæ¯å¹´ImageNetå®˜æ–¹ä¼šä¸¾åŠžæŒ‘æˆ˜èµ›ã€‚2017å¹´åŽçš„æ¯”èµ›ç”±Kaggleç¤¾åŒºä¸»æŒã€‚è‡ª2012å¹´Hintonç­‰çš„å›¢é˜Ÿæå‡ºAlexNetå¼€å§‹ï¼Œæ¯å¹´éƒ½æœ‰å±‚å‡ºä¸ç©·çš„æ¨¡åž‹å¸Œæœ›åœ¨ImageNetæŽ’è¡Œæ¦œä¸Šå–å¾—ä¸€å¸­ä¹‹åœ° torchvision Models and pre-trained weights â€” Torchvision main documentation (pytorch.org) Datasets torchvisionæ˜¯PyTorchåº“ä¸­çš„ä¸€ä¸ªå­æ¨¡å—ï¼Œä¸“é—¨ç”¨äºŽå¤„ç†è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚å®ƒæä¾›äº†è®¸å¤šæœ‰ç”¨çš„å‡½æ•°ã€å·¥å…·å’Œé¢„è®­ç»ƒæ¨¡åž‹ï¼Œä½¿å¾—å¤„ç†å›¾åƒå’Œè§†é¢‘æ•°æ®å˜å¾—æ›´åŠ ç®€å•å’Œé«˜æ•ˆ torchvisionçš„åŠŸèƒ½ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š æ•°æ®é›†å’Œæ•°æ®åŠ è½½ï¼štorchvisionæä¾›äº†å¸¸è§çš„è®¡ç®—æœºè§†è§‰æ•°æ®é›†ï¼Œå¦‚MNISTã€CIFAR10ã€ImageNetç­‰ã€‚å®ƒè¿˜æä¾›äº†æ–¹ä¾¿çš„æ•°æ®åŠ è½½å‡½æ•°å’Œæ•°æ®è½¬æ¢å·¥å…·ï¼Œä½¿å¾—åŠ è½½å’Œé¢„å¤„ç†æ•°æ®å˜å¾—ç®€å•ã€‚å¯ä»¥ä½¿ç”¨è¿™äº›åŠŸèƒ½æ¥å‡†å¤‡è®­ç»ƒæ•°æ®é›†ã€éªŒè¯æ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›† æ•°æ®è½¬æ¢ï¼štorchvisionåŒ…å«äº†å„ç§å¸¸ç”¨çš„æ•°æ®è½¬æ¢æ“ä½œï¼Œä¾‹å¦‚å›¾åƒç¼©æ”¾ã€è£å‰ªã€æ—‹è½¬ã€ç¿»è½¬ã€æ ‡å‡†åŒ–ç­‰ã€‚è¿™äº›è½¬æ¢æ“ä½œå¯ä»¥æ–¹ä¾¿åœ°åº”ç”¨äºŽæ•°æ®é›†ï¼Œä»¥å¢žå¼ºæ•°æ®çš„å¤šæ ·æ€§å’Œé€‚åº”æ¨¡åž‹çš„éœ€æ±‚ æ¨¡åž‹å’Œé¢„è®­ç»ƒæ¨¡åž‹ï¼štorchvisionæä¾›äº†ä¸€äº›ç»å…¸çš„è®¡ç®—æœºè§†è§‰æ¨¡åž‹ï¼Œå¦‚AlexNetã€VGGã€ResNetã€Inceptionç­‰ã€‚è¿™äº›æ¨¡åž‹éƒ½åœ¨å¤§è§„æ¨¡å›¾åƒæ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œå¯ä»¥ç”¨äºŽå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œtorchvisionè¿˜æä¾›äº†åŠ è½½å’Œä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡åž‹çš„ä¾¿æ·æŽ¥å£ å›¾åƒå·¥å…·ï¼štorchvisionè¿˜åŒ…å«äº†ä¸€äº›å›¾åƒå¤„ç†å·¥å…·ï¼Œå¦‚ç»˜åˆ¶è¾¹ç•Œæ¡†ã€ç»˜åˆ¶å›¾åƒç½‘æ ¼ã€ç»˜åˆ¶ç±»åˆ«æ ‡ç­¾ç­‰ã€‚è¿™äº›å·¥å…·å¯ä»¥ç”¨äºŽå¯è§†åŒ–å’Œè°ƒè¯•æ¨¡åž‹çš„è¾“å‡ºç»“æžœ æ€»ä¹‹ï¼Œtorchvisionæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„PyTorchæ¨¡å—ï¼Œæä¾›äº†è®¸å¤šå¤„ç†è®¡ç®—æœºè§†è§‰ä»»åŠ¡æ‰€éœ€çš„å·¥å…·å’ŒåŠŸèƒ½ã€‚å®ƒç®€åŒ–äº†æ•°æ®åŠ è½½ã€æ•°æ®è½¬æ¢ã€æ¨¡åž‹åŠ è½½å’Œé¢„æµ‹ç­‰æ“ä½œï¼Œä¸ºè®¡ç®—æœºè§†è§‰ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›äº†ä¾¿åˆ© Lenet Gradient-Based Learning Applied to Document Recognition 1998 LeNet-5, convolutional neural networks æ‰‹å†™å­—ä½“è¯†åˆ«æ¨¡åž‹LeNet5è¯žç”ŸäºŽ1994å¹´ï¼Œæ˜¯æœ€æ—©çš„å·ç§¯ç¥žç»ç½‘ç»œä¹‹ä¸€ã€‚LeNet5é€šè¿‡å·§å¦™çš„è®¾è®¡ï¼Œåˆ©ç”¨å·ç§¯ã€å‚æ•°å…±äº«ã€æ± åŒ–ç­‰æ“ä½œæå–ç‰¹å¾ï¼Œé¿å…äº†å¤§é‡çš„è®¡ç®—æˆæœ¬ï¼Œæœ€åŽå†ä½¿ç”¨å…¨è¿žæŽ¥ç¥žç»ç½‘ç»œè¿›è¡Œåˆ†ç±»è¯†åˆ«ï¼Œè¿™ä¸ªç½‘ç»œä¹Ÿæ˜¯æœ€è¿‘å¤§é‡ç¥žç»ç½‘ç»œæž¶æž„çš„èµ·ç‚¹ LeNetæ˜¯ç”±Yann Lecun(2018å¹´å›¾çµå¥–å¾—ä¸»ï¼ŒCNNçš„ç¼”é€ è€…)åˆ›é€ çš„CNNç»å…¸ç½‘ç»œï¼Œæ˜¯å·ç§¯ç¥žç»ç½‘ç»œå²ä¸Šçš„å¼€ç¯‡ä¹‹ä½œ ä»£ç  import torch import torch.nn as nn import torch.nn.functional as F class LeNet5(nn.Module): def __init__(self, num_classes, grayscale=False): \"\"\" num_classes: åˆ†ç±»çš„æ•°é‡ grayscaleï¼šæ˜¯å¦ä¸ºç°åº¦å›¾ \"\"\" super(LeNet5, self).__init__() self.grayscale = grayscale self.num_classes = num_classes if self.grayscale: # å¯ä»¥é€‚ç”¨å•é€šé“å’Œä¸‰é€šé“çš„å›¾åƒ in_channels = 1 else: in_channels = 3 # å·ç§¯ç¥žç»ç½‘ç»œ self.features = nn.Sequential( nn.Conv2d(in_channels, 6, kernel_size=5), nn.ReLU(), nn.MaxPool2d(kernel_size=2), nn.Conv2d(6, 16, kernel_size=5), nn.ReLU(), nn.MaxPool2d(kernel_size=2) # åŽŸå§‹çš„æ¨¡åž‹ä½¿ç”¨çš„æ˜¯ å¹³å‡æ± åŒ– ) # åˆ†ç±»å™¨ self.classifier = nn.Sequential( nn.Linear(16*5*5, 120), # è¿™é‡ŒæŠŠç¬¬ä¸‰ä¸ªå·ç§¯å½“ä½œæ˜¯å…¨è¿žæŽ¥å±‚äº† nn.ReLU(), nn.Linear(120, 84), nn.ReLU(), nn.Linear(84, num_classes) ) def forward(self, x): x = self.features(x) # è¾“å‡º 16*5*5 ç‰¹å¾å›¾ x = torch.flatten(x, 1) # å±•å¹³ ï¼ˆ1ï¼Œ 16*5*5ï¼‰ logits = self.classifier(x) # è¾“å‡º 10 probas = F.softmax(logits, dim=1) return logits, probas AlexNet AlexNetä¸ŽLeNetåŒºåˆ«ï¼š å±‚æ•°æ›´å¤š: ç›¸å¯¹è¾ƒå°çš„LeNetç›¸æ¯”ï¼ŒAlexNetåŒ…å«8å±‚å˜æ¢ï¼Œå…¶ä¸­æœ‰5å±‚å·ç§¯å’Œ2å±‚å…¨è¿žæŽ¥éšè—å±‚ï¼Œä»¥åŠ1ä¸ªå…¨è¿žæŽ¥è¾“å‡ºå±‚ æ¿€æ´»å‡½æ•°: AlexNetå°†sigmoidæ¿€æ´»å‡½æ•°æ”¹æˆäº†æ›´åŠ ç®€å•çš„ReLUæ¿€æ´»å‡½æ•° dropout: AlexNeté€šè¿‡dropoutæ¥æŽ§åˆ¶å…¨è¿žæŽ¥å±‚çš„æ¨¡åž‹å¤æ‚åº¦ã€‚è€ŒLeNetå¹¶æ²¡æœ‰ä½¿ç”¨ä¸¢å¼ƒæ³• æ•°æ®å¢žå¼º: AlexNetå¼•å…¥äº†å¤§é‡çš„å›¾åƒå¢žå¹¿ï¼Œå¦‚ç¿»è½¬ã€è£å‰ªå’Œé¢œè‰²å˜åŒ–ï¼Œä»Žè€Œè¿›ä¸€æ­¥æ‰©å¤§æ•°æ®é›†æ¥ç¼“è§£è¿‡æ‹Ÿåˆ æœ€å¤§æ± åŒ–: ç”¨MaxPoolingè€Œä¸æ˜¯AvgPooling æ¨¡åž‹ç»“æž„æ¯”è¾ƒ Vgg Very Deep Convolutional Networks For Large-Scale Image Recognition VGG â€” Torchvision main documentation (pytorch.org) æ¦‚è¿° å¿«é€Ÿç†è§£VGGç½‘ç»œ VGG(Visual Geometry Group)æ˜¯ä¸€ç§ç»å…¸çš„å·ç§¯ç¥žç»ç½‘ç»œæž¶æž„ï¼Œæ˜¯ç‰›æ´¥å¤§å­¦è®¡ç®—æœºè§†è§‰ç»„(Visual Geometry Group)å’Œè°·æ­ŒDeepMindä¸€èµ·ç ”ç©¶å‡ºæ¥çš„æ·±åº¦å·ç§¯ç¥žç»ç½‘ç»œã€‚å…¶åœ¨åœ¨2014å¹´çš„ImageNetå¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜(ILSVRC-2014)ä¸­èŽ·å¾—äº†äºšå†›ï¼Œå…¶ä¸»è¦è´¡çŒ®æ˜¯é€šè¿‡å¢žåŠ ç½‘ç»œçš„æ·±åº¦æ¥æé«˜å‡†ç¡®çŽ‡ï¼Œå½“å¹´èŽ·å¾—å† å†›çš„æ˜¯GoogLeNet è™½ç„¶å…¶å±ˆå±…äºšå†›ï¼Œä½†æ˜¯ç”±äºŽå…¶è§„å¾‹çš„è®¾è®¡ã€ç®€æ´å¯å †å çš„å·ç§¯å—ï¼Œä¸”åœ¨å…¶ä»–æ•°æ®é›†ä¸Šéƒ½æœ‰ç€å¾ˆå¥½çš„è¡¨çŽ°ï¼Œä»Žè€Œè¢«äººä»¬å¹¿æ³›ä½¿ç”¨ï¼Œä»Žè¿™ç‚¹ä¸Šè¿˜æ˜¯è¶…è¿‡äº†GoogLenet VGG16ç›¸æ¯”AlexNetçš„ä¸€ä¸ªæ”¹è¿›æ˜¯é‡‡ç”¨è¿žç»­çš„å‡ ä¸ª3 \\times 3çš„å·ç§¯æ ¸ä»£æ›¿AlexNetä¸­çš„è¾ƒå¤§å·ç§¯æ ¸(11 \\times 11ï¼Œ7 \\times 7ï¼Œ5 \\times 5) VGGç½‘ç»œçš„æ ¸å¿ƒæ€æƒ³ ä½¿ç”¨å¤šä¸ªè¿žç»­çš„ 3 \\times 3å·ç§¯å±‚æ¥æ›¿ä»£è¾ƒå¤§æ„Ÿå—é‡Žçš„å·ç§¯å±‚ï¼Œè¿™ç§è®¾è®¡çš„ä¼˜åŠ¿ å¯ä»¥å¢žåŠ ç½‘ç»œçš„æ·±åº¦ï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å›¾åƒçš„ç»†èŠ‚å’Œå¤æ‚ç‰¹å¾ å¯¹äºŽç»™å®šçš„æ„Ÿå—é‡Ž(ä¸Žè¾“å‡ºæœ‰å…³çš„è¾“å…¥å›¾ç‰‡çš„å±€éƒ¨å¤§å°)ï¼Œé‡‡ç”¨å †ç§¯çš„å°å·ç§¯æ ¸æ˜¯ä¼˜äºŽé‡‡ç”¨å¤§çš„å·ç§¯æ ¸ å‚æ•°æ›´å°‘: æ¯”å¦‚ï¼Œ3ä¸ªæ­¥é•¿ä¸º1çš„ 3 \\times 3å·ç§¯æ ¸çš„ä¸€å±‚å±‚å åŠ ä½œç”¨å¯çœ‹æˆä¸€ä¸ªå¤§å°ä¸º7çš„æ„Ÿå—é‡Ž(å…¶å®žå°±è¡¨ç¤º3ä¸ª 3 \\times 3è¿žç»­å·ç§¯ç›¸å½“äºŽä¸€ä¸ª 7 \\times 7å·ç§¯) å…¶å‚æ•°æ€»é‡ä¸º 3 \\times (9 \\times C^2) ï¼Œå¦‚æžœç›´æŽ¥ä½¿ç”¨ 7 \\times 7å·ç§¯æ ¸ï¼Œå…¶å‚æ•°æ€»é‡ä¸º 49 \\times C^2 ï¼Œè¿™é‡ŒCæŒ‡çš„æ˜¯è¾“å…¥å’Œè¾“å‡ºçš„é€šé“æ•° å¾ˆæ˜Žæ˜¾å‡å°‘äº†å‚æ•°ï¼Œè€Œä¸”3x3å·ç§¯æ ¸æœ‰åˆ©äºŽæ›´å¥½åœ°ä¿æŒå›¾åƒæ€§è´¨ ä¸Šå›¾å°±æ˜¯ç”¨ä¸¤ä¸ª 3 \\times 3å·ç§¯çº§è”(å åŠ )èµ·æ¥ä»£æ›¿ä¸€ä¸ª 5 \\times 5å·ç§¯ï¼ŒåŒç†å¯ä»¥ç”¨ä¸‰ä¸ª 3 \\times 3å·ç§¯çº§è”(å åŠ )èµ·æ¥ä»£æ›¿ä¸€ä¸ª 7 \\times 7 å·ç§¯ ç®€æ´ä¸€è‡´ VGGç½‘ç»œçš„ä¸€ä¸ªé‡è¦ç‰¹ç‚¹æ˜¯å…¶ç®€æ´è€Œä¸€è‡´çš„ç»“æž„ã€‚å®ƒä½¿ç”¨äº†å°å°ºå¯¸çš„å·ç§¯æ ¸( 3 \\times 3)ï¼Œå¹¶ä¸”åœ¨æ¯ä¸ªå·ç§¯å±‚å—ä¸­éƒ½ä½¿ç”¨äº†ç›¸åŒæ•°é‡çš„å·ç§¯å±‚å’Œæ± åŒ–å±‚ï¼Œè¿™ç§è®¾è®¡ä½¿å¾—ç½‘ç»œçš„ç»“æž„éžå¸¸è§„æ•´ï¼Œæ–¹ä¾¿ç†è§£å’Œå®žçŽ° VGGç½‘ç»œçš„æž¶æž„å¯ä»¥æ ¹æ®æ·±åº¦çš„ä¸åŒè¿›è¡Œåˆ†ç±»ï¼Œæœ€å¸¸è§çš„æ˜¯VGG16å’ŒVGG19ã€‚VGG16åŒ…å«16ä¸ªå·ç§¯å±‚å’Œ3ä¸ªå…¨è¿žæŽ¥å±‚ï¼Œè€ŒVGG19åˆ™åŒ…å«19ä¸ªå·ç§¯å±‚å’Œ3ä¸ªå…¨è¿žæŽ¥å±‚ã€‚è¿™äº›ç½‘ç»œåœ¨ImageNetå›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ï¼Œæˆä¸ºäº†åŽç»­å·ç§¯ç¥žç»ç½‘ç»œè®¾è®¡çš„é‡è¦å‚è€ƒ å°½ç®¡VGGç½‘ç»œå·²ç»è¢«æ›´å…ˆè¿›çš„ç½‘ç»œæž¶æž„æ‰€å–ä»£ï¼Œä½†å…¶ç®€æ´è€Œä¸€è‡´çš„ç»“æž„ä»¥åŠè‰¯å¥½çš„æ€§èƒ½ä½¿å…¶ä»ç„¶è¢«å¹¿æ³›åº”ç”¨äºŽå›¾åƒåˆ†ç±»ã€ç‰¹å¾æå–å’Œè¿ç§»å­¦ä¹ ç­‰ä»»åŠ¡ã€‚åŒæ—¶ï¼ŒVGGç½‘ç»œä¹Ÿä¸ºåŽç»­æ·±åº¦å­¦ä¹ ç ”ç©¶æä¾›äº†é‡è¦çš„å¯ç¤ºï¼Œå°¤å…¶æ˜¯å…³äºŽç½‘ç»œæ·±åº¦å’Œå·ç§¯æ ¸å°ºå¯¸å¯¹æ€§èƒ½çš„å½±å“ æ¨¡åž‹ æ•´ä½“ç»“æž„ VGGNetä»¥ä¸‹6ç§ä¸åŒç»“æž„ï¼Œæˆ‘ä»¬ä»¥é€šå¸¸æ‰€è¯´çš„VGG-16(å³ä¸‹å›¾Dåˆ—)ä¸ºä¾‹ï¼Œå±•ç¤ºå…¶ç»“æž„ç¤ºæ„å›¾ å®˜æ–¹ç»™å‡ºçš„VGGç³»åˆ—ç¥žç»ç½‘ç»œçš„å‚æ•°é‡å¦‚ä¸‹ï¼š Network A, A-LRN B C D E å‚æ•°é‡(in millions) 133 133 134 138 144 å¯¹äºŽVGG16æ¥è®²ï¼Œå®ƒçš„ç½‘ç»œç»“ç»“æž„å›¾å°±å¦‚ä¸‹æ‰€ç¤º vgg-blockå—ç”±nä¸ªç›¸åŒç»“æž„çš„å·ç§¯å±‚+1ä¸ªçš„æ± åŒ–å±‚æž„æˆï¼Œæ„å‘³ç€è¾“å…¥å’Œè¾“å‡ºçš„å°ºå¯¸ä¸€æ ·ï¼Œä¸”å·ç§¯å±‚å¯ä»¥å †å å¤ç”¨ å¯¹äºŽVgg-16ï¼Œæ•´ä¸ªç½‘ç»œæœ‰5ä¸ªvgg-blockå—å’Œ5ä¸ªmaxpoolå±‚é€ä¸ªç›¸è¿žï¼Œç„¶åŽè¿›å…¥FCå±‚ï¼Œç›´åˆ°æœ€åŽ1000è·¯softmaxè¾“å‡º æ¥è®¡ç®—ä¸€ä¸‹VGG16çš„å‚æ•°é‡ layer shape filter å‚æ•°æ•°é‡(å¸¦bias) 2-block 224 \\times 224 \\times 64 3 \\times 3 \\times 3 \\times 64 1792+36864(3 \\times 3 \\times 64 \\times 64 \\times 1) 4-block 112 \\times 112 \\times 128 3 \\times 3 \\times 64 \\times 128 73856+147456(3 \\times 3 \\times 128 \\times 128 \\times 1) 6-block 56 \\times 56 \\times 256 3 \\times 3 \\times 128 \\times 256 295168+1179648(3 \\times 3 \\times 256 \\times 256 \\times 2) 8-block 55 \\times 55 \\times 96 3 \\times 3 \\times 256 \\times 512 1180160+4718592(3 \\times 3 \\times 512 \\times 512 \\times 2) 10-block 28 \\times 28 \\times 512 3 \\times 3 \\times 512 \\times 512 2359808+4718592(3 \\times 3 \\times 512 \\times 512 \\times 2) 12-Dense 1 \\times 1 \\times 4096 4096 \\times 25088+4096=102764544 13-Dense 1 \\times 1 \\times 4096 4096 \\times 4096+4096=16781312 14-Dense 1 \\times 1 \\times 1000 1000 \\times 4096+1000=4097000 æ€»æ•° 138354792(1.38äº¿) VGGçš„ç‰¹ç‚¹ vgg-blockå†…çš„å·ç§¯å±‚éƒ½æ˜¯åŒç»“æž„çš„ æ± åŒ–å±‚éƒ½å¾—ä¸Šä¸€å±‚çš„å·ç§¯å±‚ç‰¹å¾ç¼©å‡ä¸€åŠ æ·±åº¦è¾ƒæ·±ï¼Œå‚æ•°é‡å¤Ÿå¤§ è¾ƒå°çš„filter size/kernel size æ•°æ®å¢žå¼ºæ–¹é¢ VGGç½‘ç»œä¸­ï¼Œæ•°æ®å¢žå¼ºä½¿ç”¨çš„æ˜¯Multi-Scale è¿™é‡Œçš„Multi-Scaleä¸»è¦æ˜¯å°†å›¾åƒæ”¾å¤§åˆ°éšæœºçš„å¤§å°ï¼Œç„¶åŽå†è£å‰ªåˆ°224*224çš„å›¾åƒ æ ¸å¿ƒä»£ç -ç»å…¸å·ç§¯ç¥žç»ç½‘ç»œâ€”â€”VGG import torch from torch import nn from torchvision import transforms import torchvision from torch.utils import data from d2l import torch as d2l import numpy as np import matplotlib.pyplot as plt # è®¾è®¡VGGå—ï¼Œå¤šä¸ªå·ç§¯è¿‡åŽä¸€ä¸ªæœ€å¤§æ± åŒ–å±‚ # å·ç§¯è¿‡åŽçš„è¾“å…¥è¾“å‡ºå›¾ç‰‡å¤§å°ä¸å˜ï¼Œé€šé“æœ‰å˜åŒ– # ç»è¿‡æœ€å¤§æ± åŒ–åŽï¼Œå®½é«˜ç¼©å‡ä¸€åŠ def vgg_block(num_convs, in_channels, out_channels): layers = [] for _ in range(num_convs): layers.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1)) layers.append(nn.ReLU()) in_channels = out_channels layers.append(nn.MaxPool2d(kernel_size=2,stride=2)) return nn.Sequential(*layers) # VGGæž¶æž„ï¼ŒVGGå—(å·ç§¯å±‚ï¼Œouttput),ç»è¿‡äº”å±‚VGGå—è¿‡åŽï¼Œå®½é«˜ä¸ºï¼ˆ7ï¼Œ7ï¼‰ # è¿™ä¸ªæž¶æž„å¯ä»¥ç§°ä¸ºVGG-11,1+1+2*3+1+1+1 = 11 conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512)) def vgg(conv_arch): conv_blocks = [] in_channels = 1 for (num_convs, out_channels) in conv_arch: conv_blocks.append(vgg_block(num_convs,in_channels,out_channels)) in_channels = out_channels return nn.Sequential( *conv_blocks, nn.Flatten(), # å…¨è¿žæŽ¥å±‚éƒ¨åˆ† nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5), nn.Linear(4096, 10) ) net = vgg(conv_arch) # è§‚å¯Ÿæ¯ä¸ªå±‚çš„è¾“å‡ºæƒ…å†µ x = torch.randn(1,1,224,224) for layer in net: x = layer(x) print(layer.__class__.__name__,\"output shape:\",x.shape) small_conv_arch = ((1, 16), (1, 32), (2, 32), (2, 64), (2, 64)) net = vgg(small_conv_arch) # çŽ°åœ¨ä½¿ç”¨mnistæ•°æ®é›†æµ‹è¯•ä¸€ä¸‹ç»“æžœ def load_data_fashion_mnist(batch_size, resize=None): \"\"\"ä¸‹è½½æˆ–è€…åŠ è½½Fashion-MNISTæ•°æ®é›†\"\"\" trans = [transforms.ToTensor()] if resize: # éœ€è¦æŠŠå›¾ç‰‡æ‹‰é•¿,æ­£å¸¸æ—¶ä¸ä¼šè¿™ä¹ˆåšçš„ trans.insert(0, transforms.Resize(resize)) trans = transforms.Compose(trans) # è¿™æ˜¯ä¸€æ­¥å¯ä»¥åŽ»æŽ‰çš„æ“ä½œï¼Œè¿™ä¸ªå°±æ˜¯æŠŠå¤šä¸ªå›¾åƒå¤„ç†çš„æ­¥éª¤æ•´åˆåˆ°ä¸€èµ· mnist_train = torchvision.datasets.FashionMNIST( root=\"../data/\", train=True, transform=trans, download=False # è¦æ˜¯æ²¡ä¸‹è½½è¿‡å°±é€‰æ‹©true ) mnist_test = torchvision.datasets.FashionMNIST( root=\"../data/\", train=False, transform=trans, download=False # è¦æ˜¯æ²¡ä¸‹è½½è¿‡å°±é€‰æ‹©true ) return (data.DataLoader(mnist_train,batch_size=batch_size,shuffle=True,num_workers=0), data.DataLoader(mnist_test,batch_size=batch_size,shuffle=True,num_workers=0)) batch_size = 64 learning_rate = 0.01 epochs = 10 train_iter,test_iter = load_data_fashion_mnist(batch_size,resize=(224)) d2l.train_ch6(net,train_iter,test_iter,epochs,lr=learning_rate,device=d2l.try_gpu()) ç¼ºç‚¹ å°½ç®¡VGGåœ¨æ·±åº¦å­¦ä¹ ä¸­å…·æœ‰é‡è¦çš„åœ°ä½å’Œå½±å“åŠ›ï¼Œä½†å®ƒä¹Ÿå­˜åœ¨ä¸€äº›ç¼ºç‚¹ï¼ŒåŒ…æ‹¬ï¼š å¤§é‡å‚æ•°ï¼šVGGç½‘ç»œå…·æœ‰å¾ˆæ·±çš„ç»“æž„ï¼Œå…¶ä¸­åŒ…å«å¤šä¸ªå·ç§¯å±‚å’Œå…¨è¿žæŽ¥å±‚ã€‚è¿™å¯¼è‡´äº†ç½‘ç»œä¸­çš„å‚æ•°æ•°é‡å¾ˆå¤§ï¼Œéœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºå’Œå­˜å‚¨ç©ºé—´ã€‚åœ¨è®­ç»ƒå’ŒæŽ¨ç†è¿‡ç¨‹ä¸­ï¼Œè¿™ä¼šå¢žåŠ è®¡ç®—çš„å¤æ‚æ€§å’Œæ—¶é—´æˆæœ¬ è®¡ç®—èµ„æºè¦æ±‚é«˜ï¼šç”±äºŽVGGç½‘ç»œçš„æ·±åº¦å’Œå‚æ•°é‡è¾ƒå¤§ï¼Œéœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºæ¥è¿›è¡Œè®­ç»ƒå’ŒæŽ¨ç†ã€‚è¿™å¯¹äºŽä¸€äº›èµ„æºå—é™çš„çŽ¯å¢ƒæ¥è¯´å¯èƒ½æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ç§»åŠ¨è®¾å¤‡æˆ–åµŒå…¥å¼ç³»ç»Ÿä¸Šåº”ç”¨VGGç½‘ç»œæ—¶ è¿‡åº¦æ‹Ÿåˆï¼šç”±äºŽVGGç½‘ç»œçš„æ·±åº¦å’Œå‚æ•°é‡è¾ƒå¤§ï¼Œå®ƒå¯¹äºŽè¾ƒå°çš„æ•°æ®é›†å®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆçš„æƒ…å†µã€‚åœ¨åº”ç”¨VGGç½‘ç»œæ—¶ï¼Œå¦‚æžœè®­ç»ƒæ•°æ®ä¸å¤Ÿä¸°å¯Œï¼Œæ¨¡åž‹å¯èƒ½ä¼šè¿‡åº¦ä¾èµ–äºŽè®­ç»ƒé›†çš„ç‰¹ç‚¹ï¼Œå¯¼è‡´åœ¨æ–°æ•°æ®ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¸‹é™ ç¼ºä¹ç©ºé—´ä¿¡æ¯åˆ©ç”¨ï¼šVGGç½‘ç»œä»…ä½¿ç”¨äº†æ± åŒ–å±‚æ¥å‡å°ç‰¹å¾å›¾çš„å°ºå¯¸ï¼Œä½†åœ¨å‡å°å°ºå¯¸çš„åŒæ—¶ä¸¢å¤±äº†ä¸€éƒ¨åˆ†ç©ºé—´ä¿¡æ¯ã€‚ç›¸æ¯”äºŽä¸€äº›å…·æœ‰è·³è·ƒè¿žæŽ¥æˆ–æ³¨æ„åŠ›æœºåˆ¶çš„ç½‘ç»œï¼ŒVGGåœ¨åˆ©ç”¨å›¾åƒä¸­çš„ç©ºé—´å…³ç³»æ–¹é¢ç›¸å¯¹è¾ƒå¼± è¾ƒé«˜çš„å†…å­˜éœ€æ±‚ï¼šç”±äºŽVGGç½‘ç»œä¸­çš„å·ç§¯å±‚å’Œå…¨è¿žæŽ¥å±‚è¾ƒå¤šï¼Œå…¶ç”Ÿæˆçš„ç‰¹å¾å›¾è¾ƒå¤§ï¼Œéœ€è¦è¾ƒå¤§çš„å†…å­˜æ¥å­˜å‚¨ä¸­é—´ç»“æžœã€‚è¿™å¯èƒ½ä¼šé™åˆ¶VGGç½‘ç»œåœ¨ä¸€äº›å†…å­˜å—é™çš„è®¾å¤‡æˆ–å¹³å°ä¸Šçš„åº”ç”¨ GoogleNet Rethinking the Inception Architecture for Computer Vision 2015 Inception-V3è®ºæ–‡ç¿»è¯‘â€”â€”ä¸­è‹±æ–‡å¯¹ç…§ GoogLeNetç½‘ç»œç³»åˆ—è§£è¯» GoogLeNetæ˜¯ç”±Googleå›¢é˜Ÿåœ¨2014å¹´æå‡ºçš„ä¸€ç§æ·±åº¦å·ç§¯ç¥žç»ç½‘ç»œæž¶æž„ï¼Œä¹Ÿè¢«ç§°ä¸ºInceptionç½‘ç»œã€‚ç›¸æ¯”äºŽä¼ ç»Ÿçš„å·ç§¯ç¥žç»ç½‘ç»œï¼ŒGoogLeNeté‡‡ç”¨äº†ä¸€ç§ç‰¹æ®Šçš„æ¨¡å—åŒ–è®¾è®¡ï¼Œæ—¨åœ¨æé«˜ç½‘ç»œçš„è®¡ç®—æ•ˆçŽ‡å’Œè¡¨è¾¾èƒ½åŠ› GooLeNetæ·±åº¦åªæœ‰22å±‚ï¼Œä½†å¤§å°å´æ¯”AlexNetå’ŒVGGå°å¾ˆå¤šï¼ŒGooLeNetçš„å‚æ•°ä¸º500ä¸‡ä¸ªï¼ŒAlexNetå‚æ•°ä¸ªæ•°æ˜¯GooLeNetçš„12å€ï¼ŒVGGNetå‚æ•°åˆæ˜¯AlexNetçš„3å€ InceptionV1 å¦‚ä½•æå‡ç½‘ç»œæ€§èƒ½ ä¸€èˆ¬æå‡ç½‘ç»œæ€§èƒ½æœ€ç›´æŽ¥çš„æ–¹æ³•æ˜¯å¢žåŠ ç½‘ç»œæ·±åº¦å’Œå®½åº¦ï¼Œæ·±åº¦æŒ‡ç½‘ç»œå±‚æ•°ï¼Œå®½åº¦æŒ‡ç¥žç»å…ƒæ•°é‡ï¼Œä½†æ˜¯ä¼šå­˜åœ¨ä¸€äº›é—®é¢˜ï¼š å‚æ•°å¤ªå¤šï¼Œå¦‚æžœè®­ç»ƒæ•°æ®é›†æœ‰é™ï¼Œå¾ˆå®¹æ˜“äº§ç”Ÿè¿‡æ‹Ÿåˆ ç½‘ç»œè¶Šå¤§ï¼Œå‚æ•°è¶Šå¤šï¼Œåˆ™è®¡ç®—å¤æ‚åº¦è¶Šå¤§ï¼Œéš¾ä»¥åº”ç”¨ ç½‘ç»œè¶Šæ·±ï¼Œå®¹æ˜“å‡ºçŽ°æ¢¯åº¦å¼¥æ•£é—®é¢˜(æ¢¯åº¦è¶Šå¾€åŽè¶Šå®¹æ˜“æ¶ˆå¤±)ï¼Œéš¾ä»¥ä¼˜åŒ–æ¨¡åž‹ æœ‰ä¸€ç§è§£å†³æ–¹å¼æ˜¯å¢žåŠ ç½‘ç»œçš„æ·±åº¦å’Œå®½åº¦çš„åŒæ—¶å‡å°‘å‚æ•°ï¼Œä¸ºäº†å‡å°‘å‚æ•°ä¸€ç§æ–¹å¼æ˜¯å°†å…¨è¿žæŽ¥å˜æˆç¨€ç–è¿žæŽ¥(Dropout) ä½†å®žé™…ä¸Šç¨€ç–è¿žæŽ¥çš„è®¡ç®—æ€§èƒ½å¹¶ä¸ä¼šæœ‰è´¨çš„æå‡ã€‚è¿™æ˜¯å› ä¸ºå¤§éƒ¨åˆ†ç¡¬ä»¶æ˜¯é’ˆå¯¹å¯†é›†çŸ©é˜µè®¡ç®—ä¼˜åŒ–çš„ GooLeNetæå‡ºäº†ä¸€ç§Inceptionç½‘ç»œç»“æž„ï¼Œæž„é€ ä¸€ç§â€œåŸºç¡€ç¥žç»å…ƒâ€ç»“æž„ï¼Œæ¥æ­å»ºä¸€ä¸ªç¨€ç–æ€§ï¼Œé«˜è®¡ç®—æ€§èƒ½çš„ç½‘ç»œç»“æž„ã€‚æ—¢èƒ½ä¿æŒç½‘ç»œç»“æž„çš„ç¨€ç–æ€§ï¼Œåˆèƒ½åˆ©ç”¨å¯†é›†çŸ©é˜µçš„é«˜è®¡ç®—æ€§èƒ½ Inceptionæ¨¡å— GoogLeNetçš„æ ¸å¿ƒæ˜¯Inceptionæ¨¡å—ï¼Œè¿™æ˜¯ä¸€ç§å¤šå°ºåº¦ç‰¹å¾æå–æ¨¡å—ã€‚å®ƒé€šè¿‡å¹¶è¡Œåœ°ä½¿ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸å’Œæ± åŒ–æ“ä½œæ¥æ•æ‰å›¾åƒä¸­ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚è¿™æ ·çš„è®¾è®¡å¯ä»¥åœ¨ä¿æŒè®¡ç®—æ•ˆçŽ‡çš„åŒæ—¶ï¼Œå¢žåŠ ç½‘ç»œå¯¹ä¸åŒå°ºåº¦ä¿¡æ¯çš„æ„ŸçŸ¥èƒ½åŠ› å¦ä¸€ä¸ªå€¼å¾—æ³¨æ„çš„ç‰¹ç‚¹æ˜¯GoogLeNetä¸­é‡‡ç”¨äº† 1 \\times 1å·ç§¯æ ¸çš„å·ç§¯å±‚ï¼Œç§°ä¸ºç“¶é¢ˆå±‚ã€‚è¿™äº› 1 \\times 1å·ç§¯å±‚ä¸»è¦ç”¨äºŽé™ä½Žè¾“å…¥é€šé“çš„ç»´åº¦ï¼Œå‡å°‘ç½‘ç»œçš„å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦ã€‚åŒæ—¶ï¼Œå®ƒä»¬è¿˜èƒ½å¤Ÿå¼•å…¥éžçº¿æ€§å˜æ¢ï¼Œæé«˜ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ› GoogLeNetè¿˜é‡‡ç”¨äº†å…¨å±€å¹³å‡æ± åŒ–å±‚ï¼Œå°†æœ€åŽä¸€ä¸ªå·ç§¯å±‚çš„ç‰¹å¾å›¾è¿›è¡Œå¹³å‡æ± åŒ–ï¼Œå¾—åˆ°å…¨å±€çš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™æ ·å¯ä»¥æ˜¾è‘—å‡å°‘å…¨è¿žæŽ¥å±‚çš„å‚æ•°é‡ï¼Œæé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”é™ä½Žè¿‡æ‹Ÿåˆçš„é£Žé™© Inceptionç½‘ç»œå’ŒVGGç½‘ç»œ VGGç½‘ç»œæ³¨é‡å¢žåŠ ç½‘ç»œçš„æ·±åº¦æ¥æå–æ›´å¤æ‚çš„ç‰¹å¾ï¼Œè€ŒInceptionç½‘ç»œåˆ™é€šè¿‡å¹¶è¡Œçš„å·ç§¯åˆ†æ”¯æ¥æ•æ‰å¤šå°ºåº¦çš„ç‰¹å¾ä¿¡æ¯ã€‚å› æ­¤ï¼ŒInceptionç½‘ç»œç›¸å¯¹äºŽVGGç½‘ç»œæ¥è¯´å…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆçŽ‡å’Œå‚æ•°æ•ˆçŽ‡ Inception-v1 Going Deeper with Convolutions 2014 Inception-v1 Inception Moduleæ˜¯GoogLeNetçš„æ ¸å¿ƒç»„æˆå•å…ƒï¼Œç»“æž„å¦‚ä¸‹å›¾ Inception ModuleåŸºæœ¬ç»„æˆç»“æž„æœ‰å››ä¸ªæˆåˆ†ã€‚ 1 \\times 1å·ç§¯ï¼Œ 3 \\times 3å·ç§¯ï¼Œ 5 \\times 5å·ç§¯ï¼Œ 3 \\times 3æœ€å¤§æ± åŒ–ï¼Œæœ€åŽå¯¹å››ä¸ªæˆåˆ†è¿ç®—ç»“æžœè¿›è¡Œé€šé“ä¸Šç»„åˆ è¿™å°±æ˜¯Inception Moduleçš„æ ¸å¿ƒæ€æƒ³ï¼Œé€šè¿‡å¤šä¸ªå·ç§¯æ ¸æå–å›¾åƒä¸åŒå°ºåº¦çš„ä¿¡æ¯ï¼Œæœ€åŽè¿›è¡Œèžåˆï¼Œå¯ä»¥å¾—åˆ°å›¾åƒæ›´å¥½çš„è¡¨å¾ è¾…åŠ©åˆ†ç±»å™¨(æœŸæœ›ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜) å®Œæ•´çš„ç»“æž„å¯ä»¥çœ‹åŽŸè®ºæ–‡ï¼Œæˆ–è€…æ˜¯è¿™ä¸ªé“¾æŽ¥ ä¸ºäº†é¿å…æ¢¯åº¦æ¶ˆå¤±ï¼Œç½‘ç»œé¢å¤–å¢žåŠ 2ä¸ªè¾…åŠ©çš„softmaxç”¨äºŽå‘å‰ä¼ å¯¼æ¢¯åº¦(è¾…åŠ©åˆ†ç±»å™¨)ï¼Œè¾…åŠ©åˆ†ç±»å™¨æ˜¯å°†ä¸­é—´æŸä¸€å±‚çš„è¾“å‡ºç”¨ä½œåˆ†ç±»ï¼Œå¹¶æŒ‰ä¸€ä¸ªè¾ƒå°çš„æƒé‡(0.3)åŠ åˆ°æœ€ç»ˆåˆ†ç±»ç»“æžœä¸­ï¼Œè¿™æ ·å°±ç›¸å½“äºŽåšäº†æ¨¡åž‹èžåˆï¼ŒåŒæ—¶ç»™ç½‘ç»œå¢žåŠ äº†åå‘ä¼ æ’­çš„æ¢¯åº¦ä¿¡å·ï¼Œä¹Ÿæä¾›äº†é¢å¤–çš„æ­£åˆ™åŒ–ï¼Œå¯¹äºŽæ•´ä¸ªç½‘ç»œçš„è®­ç»ƒå¾ˆæœ‰è£¨ç›Šï¼Œå®žé™…æµ‹è¯•æ—¶ä¼šåŽ»æŽ‰è¿™ä¸¤ä¸ªé¢å¤–çš„softmax Inception-v2 Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift 2015 Inception-v2 Inception v2åœ¨åŽŸå§‹çš„Inception v1çš„åŸºç¡€ä¸Šå¼•å…¥äº†Batch Normalization(æ‰¹é‡å½’ä¸€åŒ–)æŠ€æœ¯ï¼Œè¿™æ˜¯å®ƒçš„ä¸»è¦è´¡çŒ®ã€‚Batch Normalizationæ˜¯ä¸€ç§ç”¨äºŽåŠ é€Ÿç¥žç»ç½‘ç»œè®­ç»ƒå’Œæé«˜ç½‘ç»œæ€§èƒ½çš„æŠ€æœ¯ é€šè¿‡ä½¿ç”¨Batch Normalizationï¼ŒInception v2å®žçŽ°äº†ä»¥ä¸‹å‡ ä¸ªé‡è¦çš„ä¼˜åŠ¿ï¼š åŠ é€Ÿè®­ç»ƒï¼šBatch Normalizationå¯ä»¥ä½¿ç½‘ç»œæ›´å¿«åœ°æ”¶æ•›ï¼Œå› ä¸ºå®ƒå‡å°‘äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ï¼Œä»Žè€ŒåŠ é€Ÿäº†æ¢¯åº¦ä¼ æ’­å’Œå‚æ•°æ›´æ–° æé«˜ç½‘ç»œçš„ç¨³å®šæ€§ï¼šBatch Normalization ä½¿å¾—ç½‘ç»œå¯¹è¾“å…¥æ•°æ®çš„å˜åŒ–æ›´åŠ é²æ£’ï¼Œå‡å°‘äº†å¯¹è¾“å…¥æ•°æ®åˆ†å¸ƒå’Œå¤§å°çš„æ•æ„Ÿæ€§ï¼Œæé«˜äº†ç½‘ç»œçš„ç¨³å®šæ€§ å‡å°‘å¯¹è¶…å‚æ•°çš„æ•æ„Ÿæ€§ï¼šBatch Normalization å‡å°‘äº†ç½‘ç»œå¯¹å­¦ä¹ çŽ‡å’Œæƒé‡åˆå§‹åŒ–ç­‰è¶…å‚æ•°çš„æ•æ„Ÿæ€§ï¼Œä½¿å¾—ç½‘ç»œæ›´å®¹æ˜“è°ƒä¼˜å’Œè®­ç»ƒ æ­£åˆ™åŒ–æ•ˆæžœï¼šBatch Normalization å…·æœ‰ä¸€å®šçš„æ­£åˆ™åŒ–æ•ˆæžœï¼Œå¯ä»¥å‡å°‘è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæé«˜ç½‘ç»œçš„æ³›åŒ–èƒ½åŠ› å› æ­¤ï¼ŒInception v2çš„ä¸»è¦è´¡çŒ®åœ¨äºŽå¼•å…¥äº†Batch NormalizationæŠ€æœ¯ï¼Œä½¿å¾—ç½‘ç»œçš„è®­ç»ƒæ›´åŠ ç¨³å®šå’Œé«˜æ•ˆï¼Œè¿›ä¸€æ­¥æŽ¨åŠ¨äº†æ·±åº¦å­¦ä¹ æ¨¡åž‹çš„å‘å±•å’Œåº”ç”¨ ç›¸æ¯”è¾ƒäºŽv1 5 \\times 5å·ç§¯å±‚è¢«æ›¿æ¢ä¸ºä¸¤ä¸ªè¿žç»­çš„3 \\times 3å·ç§¯å±‚. ç½‘ç»œçš„æœ€å¤§æ·±åº¦å¢žåŠ 9ä¸ªæƒé‡å±‚. å‚æ•°é‡å¢žåŠ äº†å¤§çº¦25%ï¼Œè®¡ç®—é‡å¢žåŠ äº†å¤§çº¦30% ä½¿ç”¨BNå±‚ï¼Œå°†æ¯ä¸€å±‚çš„è¾“å‡ºéƒ½è§„èŒƒåŒ–åˆ°ä¸€ä¸ªN(0,1)çš„æ­£æ€åˆ†å¸ƒï¼Œæé«˜ç½‘ç»œæ”¶æ•›é€Ÿåº¦ Inception-v3 Rethinking the Inception Architecture for Computer Vision 2015 Inception-v3 Inception V3ä¸€ä¸ªæœ€é‡è¦çš„æ”¹è¿›æ˜¯åˆ†è§£(Factorization)ï¼Œå°†7 \\times 7åˆ†è§£æˆä¸¤ä¸ªä¸€ç»´çš„å·ç§¯(1 \\times 7ï¼Œ7 \\times 1)ï¼Œ3 \\times 3ä¹Ÿæ˜¯ä¸€æ ·(1 \\times 3ï¼Œ3 \\times 1)ï¼Œè¿™æ ·çš„å¥½å¤„ï¼Œæ—¢å¯ä»¥åŠ é€Ÿè®¡ç®—ï¼Œåˆå¯ä»¥å°†1ä¸ªå·ç§¯æ‹†æˆ2ä¸ªå·ç§¯ï¼Œä½¿å¾—ç½‘ç»œæ·±åº¦è¿›ä¸€æ­¥å¢žåŠ ï¼Œå¢žåŠ äº†ç½‘ç»œçš„éžçº¿æ€§(æ¯å¢žåŠ ä¸€å±‚éƒ½è¦è¿›è¡ŒReLU)ï¼Œå¦å¤–ï¼Œç½‘ç»œè¾“å…¥ä»Ž 224 \\times 224å˜ä¸ºäº† 229 \\times 229 åœ¨Inception v2çš„åŸºç¡€ä¸Šå¼•å…¥äº†ä¸€äº›é‡è¦çš„æ”¹è¿›ï¼Œå…¶ä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š è¾…åŠ©åˆ†ç±»å™¨ï¼šInception v3åœ¨ç½‘ç»œçš„ä¸­é—´å±‚æ·»åŠ äº†è¾…åŠ©åˆ†ç±»å™¨ï¼Œè¿™äº›åˆ†ç±»å™¨æœ‰åŠ©äºŽåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å¯¼æ¢¯åº¦æµåŠ¨å’Œæä¾›æ­£åˆ™åŒ–ã€‚è¾…åŠ©åˆ†ç±»å™¨ä½äºŽç½‘ç»œçš„ä¸åŒå±‚çº§ï¼Œå¹¶ä¸Žä¸»åˆ†ç±»å™¨å…±åŒè¿›è¡Œè®­ç»ƒã€‚è¿™äº›è¾…åŠ©åˆ†ç±»å™¨æœ‰åŠ©äºŽå‡è½»æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œæé«˜ç½‘ç»œçš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ æ›´æ·±çš„ç½‘ç»œç»“æž„ï¼šInception v3ç›¸å¯¹äºŽä¹‹å‰çš„ç‰ˆæœ¬å¢žåŠ äº†æ›´å¤šçš„ç½‘ç»œå±‚ï¼Œä½¿å¾—ç½‘ç»œæ›´æ·±ã€‚æ›´æ·±çš„ç½‘ç»œç»“æž„æœ‰åŠ©äºŽæé«˜ç‰¹å¾è¡¨ç¤ºçš„èƒ½åŠ›ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ å¤æ‚çš„å›¾åƒç‰¹å¾ æ›´å¤šçš„1x1å·ç§¯æ ¸ï¼šInception v3è¿›ä¸€æ­¥å¢žåŠ äº†ç½‘ç»œä¸­çš„1x1å·ç§¯æ ¸çš„æ•°é‡ã€‚1x1å·ç§¯æ ¸å…·æœ‰é™ä½Žé€šé“æ•°å’Œç»´åº¦çš„ä½œç”¨ï¼Œå®ƒèƒ½å¤Ÿå‡å°‘ç½‘ç»œçš„è®¡ç®—é‡ï¼Œå¹¶å¼•å…¥äº†æ›´å¤šçš„éžçº¿æ€§å˜æ¢ï¼Œæé«˜äº†ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›å’Œç‰¹å¾æå–èƒ½åŠ› åˆ†æ”¯ç»“æž„ï¼šInception v3ä¸­çš„Inceptionæ¨¡å—å¼•å…¥äº†åˆ†æ”¯ç»“æž„ï¼Œå³åœ¨ä¸åŒå°ºåº¦ä¸Šä½¿ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸è¿›è¡Œç‰¹å¾æå–ã€‚è¿™ç§åˆ†æ”¯ç»“æž„æœ‰åŠ©äºŽæ•æ‰ä¸åŒå°ºåº¦çš„å›¾åƒç‰¹å¾ï¼Œå¹¶æé«˜äº†ç½‘ç»œå¯¹å›¾åƒçš„æ„ŸçŸ¥èƒ½åŠ› å…¶ä»–ä¼˜åŒ–æŽªæ–½ï¼šInception v3è¿˜å¼•å…¥äº†å…¶ä»–ä¸€äº›ä¼˜åŒ–æŽªæ–½ï¼Œå¦‚ä½¿ç”¨æ›´å°çš„å·ç§¯æ ¸ã€å¼•å…¥æ‰¹é‡å½’ä¸€åŒ–ç­‰ï¼Œä»¥è¿›ä¸€æ­¥æå‡ç½‘ç»œçš„æ€§èƒ½å’Œè®­ç»ƒæ•ˆæžœ Inception-v4ä¸ŽResNet Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning 2016 Inception-v4 Inception-v4ä¸ŽInception-ResNetç»“æž„è¯¦è§£(åŽŸåˆ›) å¾®è½¯äºšæ´²ç ”ç©¶é™¢çš„ä½•æºæ˜Žåœ¨2015å¹´æå‡ºäº†éœ‡æƒŠä¸šç•Œçš„ResNetç»“æž„ï¼Œè¿™ç§ç»“æž„å’Œä»¥å¾€çš„Inceptionç»“æž„èµ°äº†ä¸¤æ¡ä¸åŒçš„é“è·¯ï¼š å‰è€…ä¸»è¦å…³æ³¨åŠ å¤§ç½‘ç»œæ·±åº¦åŽçš„æ”¶æ•›é—®é¢˜ è€ŒInceptionæ›´å…³æ³¨ç‰¹å¾ç»´åº¦ä¸Šçš„åˆ©ç”¨ å¦‚æžœæŠŠè¿™ä¸¤ç§æ–¹æ³•ç»“åˆèµ·æ¥ä¼šæœ‰ä»€ä¹ˆæ•ˆæžœå‘¢ï¼ŸSzegedyåœ¨2016å¹´å°±è¯•éªŒäº†ä¸€æŠŠï¼ŒæŠŠè¿™ä¸¤ç§ æœ€é¡¶å°–çš„ç»“æž„æ··åˆåˆ°ä¸€èµ·æå‡ºäº†Inception-ResNetï¼Œå®ƒçš„æ”¶æ•›é€Ÿåº¦æ›´å¿«ä½†åœ¨é”™è¯¯çŽ‡ä¸Šå’ŒåŒå±‚æ¬¡çš„Inceptionç›¸åŒï¼›Szegedyè¿˜å¯¹è‡ªå·±ä»¥å‰æå‡ºçš„Inception-v3è¿›è¡Œäº†ä¸€ç•ªæ”¹è‰¯ï¼Œæå‡ºäº†Inception-v4 Inception-v4ç½‘ç»œç»“æž„ Inception-v4ä¸ŽInception-ResNeté›†æˆçš„ç»“æž„åœ¨ImageNetç«žèµ›ä¸Šè¾¾åˆ°äº†3.08%çš„top5é”™è¯¯çŽ‡ï¼Œä¹Ÿç®—å½“æ—¶çš„state-of-art performanceäº† Inception-v4ç½‘ç»œï¼Œå¯¹äºŽInceptionå—çš„æ¯ä¸ªç½‘æ ¼å¤§å°è¿›è¡Œäº†ç»Ÿä¸€ Inception V4ä¸»è¦åˆ©ç”¨æ®‹å·®è¿žæŽ¥ï¼ˆResidual Connectionï¼‰æ¥æ”¹è¿›V3ç»“æž„ï¼Œå¾—åˆ°Inception-ResNet-v1ï¼ŒInception-ResNet-v2ï¼ŒInception-v4ç½‘ç»œ Inception-ResNet-v1ç»“æž„ Inception-ResNet-v2ç»“æž„ ResNet Deep residual learning for image recognition 2015 æ·±åº¦å­¦ä¹ â€”â€”ResNetè¶…è¯¦ç»†è®²è§£ï¼Œè¯¦è§£å±‚æ•°è®¡ç®—ã€å„å±‚ç»´åº¦è®¡ç®— ResNet(Residual Network)æ˜¯ä¸€ç§æ·±åº¦æ®‹å·®ç½‘ç»œï¼Œå®ƒæ˜¯ç”±Kaiming Heç­‰äººäºŽ2015å¹´æå‡ºçš„ã€‚ResNetçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¼•å…¥äº†æ®‹å·®è¿žæŽ¥ï¼ˆResidual Connectionï¼‰ï¼Œé€šè¿‡è·¨å±‚ç›´æŽ¥è¿žæŽ¥æ¥è§£å†³æ·±å±‚ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ¨¡åž‹é€€åŒ–é—®é¢˜ ä¼ ç»Ÿçš„æ·±åº¦ç¥žç»ç½‘ç»œåœ¨å±‚æ•°å¢žåŠ æ—¶ä¼šé¢ä¸´æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ï¼Œå¯¼è‡´æ¨¡åž‹éš¾ä»¥è®­ç»ƒã€‚ResNeté€šè¿‡åœ¨ç½‘ç»œä¸­æ·»åŠ æ®‹å·®å—ï¼ˆResidual Blockï¼‰ï¼Œå…è®¸ä¿¡æ¯åœ¨è·³è¿‡å±‚çš„è·¯å¾„ä¸Šç›´æŽ¥ä¼ é€’ï¼Œä½¿å¾—ç½‘ç»œå¯ä»¥æ›´å®¹æ˜“åœ°å­¦ä¹ æ’ç­‰æ˜ å°„ã€‚å…·ä½“æ¥è¯´ï¼Œæ®‹å·®å—å°†è¾“å…¥å’Œè¾“å‡ºè¿›è¡Œç›¸åŠ ï¼Œç„¶åŽé€šè¿‡æ¿€æ´»å‡½æ•°è¿›è¡Œéžçº¿æ€§å˜æ¢ã€‚è¿™æ ·çš„è®¾è®¡å…è®¸ç½‘ç»œåœ¨éœ€è¦æ—¶å°†æ®‹å·®ä¿¡å·ä¼ é€’åˆ°åŽç»­å±‚ï¼Œè§£å†³äº†æ¢¯åº¦æ¶ˆå¤±å’Œæ¨¡åž‹é€€åŒ–çš„é—®é¢˜ ResNetçš„ä¸€ä¸ªé‡è¦å˜ç§æ˜¯ResNet-50ï¼Œå®ƒç”±50ä¸ªå·ç§¯å±‚ç»„æˆï¼Œå…¶ä¸­åŒ…æ‹¬æ®‹å·®å—ã€æ± åŒ–å±‚å’Œå…¨è¿žæŽ¥å±‚ã€‚ResNet-50åœ¨ImageNetå›¾åƒåˆ†ç±»ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ï¼Œæˆä¸ºå½“æ—¶æœ€å…ˆè¿›çš„æ¨¡åž‹ä¹‹ä¸€ äº‹å®žä¸Šï¼ŒResNetå¹¶ä¸æ˜¯ç¬¬ä¸€ä¸ªåˆ©ç”¨è¿‘è·¯è¿žæŽ¥ã€Highway Networkså¼•å…¥é—¨æŽ§è¿‘è·¯è¿žæŽ¥çš„ã€‚è¿™äº›å‚æ•°åŒ–é—¨æŽ§åˆ¶å…è®¸å¤šå°‘ä¿¡æ¯æµè¿‡è¿‘è·¯(shortcut)ã€‚ç±»ä¼¼çš„æƒ³æ³•å¯ä»¥åœ¨é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)å•å…ƒä¸­æ‰¾åˆ°ï¼Œå…¶ä¸­å­˜åœ¨å‚æ•°åŒ–çš„å¿˜è®°é—¨ï¼Œå…¶æŽ§åˆ¶å¤šå°‘ä¿¡æ¯å°†æµå‘ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ã€‚å› æ­¤ï¼ŒResNetå¯ä»¥è¢«è®¤ä¸ºæ˜¯Highway Networksçš„ä¸€ç§ç‰¹æ®Šæƒ…å†µ å±‚æ•°è¶Šå¤šè¶Šå¥½å— åœ¨ResNetä¹‹å‰çš„ç½‘ç»œå±‚æ•°éƒ½ä¸æ˜¯å¾ˆé«˜ï¼Œ14å¹´çš„VGGç½‘ç»œæ‰åªæœ‰19å±‚ï¼Œä½†æ˜¯ResNetçš„ç½‘ç»œå±‚æ•°è¾¾åˆ°äº†æƒŠäººçš„152å±‚ã€‚è®¸å¤šäººä¼šæœ‰ä¸€ä¸ªç›´è§‚çš„å°è±¡ï¼Œä¹Ÿå°±æ˜¯ç½‘ç»œå±‚æ•°è¶Šå¤šï¼Œè®­ç»ƒæ•ˆæžœè¶Šå¥½ï¼Œä½†æ˜¯è¿™æ ·çš„è¯VGGç½‘ç»œä¸ºä»€ä¹ˆä¸é‡‡å–152å±‚è€Œæ˜¯é‡‡ç”¨19å±‚å‘¢ï¼Ÿå…¶å®žæ˜¯å› ä¸ºè®­ç»ƒæ¨¡åž‹çš„å‡†ç¡®åº¦ä¸ä¸€å®šå’Œæ¨¡åž‹å±‚æ•°å‘ˆçœŸç›¸å…³çš„å…³ç³»ã€‚å› ä¸ºéšç€ç½‘ç»œå±‚æ•°çš„åŠ æ·±ï¼Œç½‘ç»œå‡†ç¡®éœ€å‡ºçŽ°é¥±å’Œï¼Œä¼šå‡ºçŽ°ä¸‹é™çš„çŽ°è±¡ 56å±‚çš„ç½‘ç»œæ¯”20å±‚ç½‘ç»œçš„è®­ç»ƒæ•ˆæžœè¦å·®ï¼Œè®¸å¤šäººç¬¬ä¸€ååº”å°±æ˜¯è¿‡æ‹Ÿåˆï¼Œä½†äº‹å®žå¹¶ä¸å¦‚æ­¤ï¼Œå› ä¸ºè¿‡æ‹ŸåˆçŽ°è±¡çš„è®­ç»ƒé›†å‡†ç¡®åº¦ä¼šå¾ˆé«˜ï¼Œä½†æ˜¯ä»Žå›¾ä¸­å¯ä»¥çœ‹å‡º56å±‚ç½‘ç»œçš„è®­ç»ƒé›†å‡†ç¡®åº¦åŒæ ·å¾ˆä½Žã€‚å¾ˆæ˜¾ç„¶å¯çŸ¥çš„æ˜¯ï¼Œéšç€å±‚åº¦åŠ æ·±ï¼Œä¼šå‡ºçŽ°æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ï¼Œä½¿å¾—æ·±åº¦æ¨¡åž‹å¾ˆéš¾è®­ç»ƒï¼Œä½†æ˜¯å·²ç»å­˜åœ¨BatchNormç­‰æ‰‹æ®µç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œå› æ­¤å¦‚ä½•è§£å†³æ·±åº¦ç½‘ç»œçš„é€€åŒ–é—®é¢˜æ˜¯ç¥žç»ç½‘ç»œå‘å±•çš„ä¸‹ä¸€ä¸ªæ–¹å‘ æ¨¡åž‹ å®˜æ–¹ç»™äº†ä¸¤ä¸ªResNetå—çš„ç»“æž„å›¾ï¼Œå›¾ä¸€ä¸ºBasicBlockä¹Ÿå°±æ˜¯æœ€å¸¸è§„çš„å—ï¼Œå›¾äºŒè¢«æˆä¸ºBottleBlock BasicBlock(å¸¸è§„)(ä¸¤å±‚ç»“æž„) åœ¨ResNet34çš„æ—¶å€™æ˜¯ç”¨çš„è¿™ä¸ª BottleBlock(ä¸‰å±‚ç»“æž„) åœ¨ResNet50/101/152çš„æ—¶å€™ç”¨çš„æ˜¯è¿™ä¸ª æ˜¯å‚è€ƒGoogleNetçš„æ–¹å¼å¯¹ç½‘ç»œå†…å®¹è¿›è¡Œçš„ä¸€å®šä¼˜åŒ– åœ¨è®¡ç®—å‰å…ˆæŽ¥ç”¨ 1 \\times 1çš„å·é˜¶å±‚é™ç»´ï¼Œæ—¢ä¿æŒç²¾åº¦åˆå‡å°‘è®¡ç®—é‡ï¼Œå†å¯¹64ç»´è¿›è¡Œè®¡ç®—åŽç»è¿‡ 1 \\times 1çš„å·ç§¯æ¢å¤ æ®‹å·® å¯¹æ®‹å·®ç½‘ç»œçš„ç†è§£ ä¸ºä»€ä¹ˆæ®‹å·®å­¦ä¹ ç›¸å¯¹æ›´å®¹æ˜“ï¼Œä»Žç›´è§‚ä¸Šçœ‹æ®‹å·®å­¦ä¹ éœ€è¦å­¦ä¹ çš„å†…å®¹å°‘ï¼Œå› ä¸ºæ®‹å·®ä¸€èˆ¬ä¼šæ¯”è¾ƒå°ï¼Œå­¦ä¹ éš¾åº¦å°ç‚¹ã€‚ä¸è¿‡æˆ‘ä»¬å¯ä»¥ä»Žæ•°å­¦çš„è§’åº¦æ¥åˆ†æžè¿™ä¸ªé—®é¢˜ï¼Œé¦–å…ˆæ®‹å·®å•å…ƒå¯ä»¥è¡¨ç¤ºä¸ºï¼š \\begin{array}{l} y_{l}=h\\left(x_{l}\\right)+F\\left(x_{l}, W_{l}\\right) \\\\ x_{l+1}=f\\left(y_{l}\\right) \\end{array} å…¶ä¸­x_{l}å’Œx_{l+1}åˆ†åˆ«è¡¨ç¤ºçš„æ˜¯ç¬¬lä¸ªæ®‹å·®å•å…ƒçš„è¾“å…¥å’Œè¾“å‡ºï¼Œæ³¨æ„æ¯ä¸ªæ®‹å·®å•å…ƒä¸€èˆ¬åŒ…å«å¤šå±‚ç»“æž„ã€‚Fæ˜¯æ®‹å·®å‡½æ•°ï¼Œè¡¨ç¤ºå­¦ä¹ åˆ°çš„æ®‹å·®ï¼Œè€Œh\\left(x_{l}\\right)=x_{l}è¡¨ç¤ºæ’ç­‰æ˜ å°„ï¼Œfæ˜¯ReLUæ¿€æ´»å‡½æ•°ã€‚åŸºäºŽä¸Šå¼ï¼Œæˆ‘ä»¬æ±‚å¾—ä»Žæµ…å±‚låˆ°æ·±å±‚lçš„å­¦ä¹ ç‰¹å¾ä¸º: x_{L}=x_{l}+\\sum_{i=l}^{L-1} F\\left(x_{i}, W_{i}\\right) åˆ©ç”¨é“¾å¼è§„åˆ™ï¼Œå¯ä»¥æ±‚å¾—åå‘è¿‡ç¨‹çš„æ¢¯åº¦ï¼š \\frac{\\partial \\text { loss }}{\\partial x_{l}}=\\frac{\\partial \\text { loss }}{\\partial x_{L}} \\cdot \\frac{\\partial x_{L}}{\\partial x_{l}}=\\frac{\\partial \\text { loss }}{\\partial x_{L}} \\cdot\\left(1+\\frac{\\partial}{\\partial x_{l}} \\sum_{i=l}^{L-1} F\\left(x_{i}, W_{i}\\right)\\right) å¼å­çš„ç¬¬ä¸€ä¸ªå› å­\\frac{\\partial l o s s}{\\partial x_{L}}è¡¨ç¤ºçš„æŸå¤±å‡½æ•°åˆ°è¾¾Lçš„æ¢¯åº¦ï¼Œå°æ‹¬å·ä¸­çš„1è¡¨æ˜ŽçŸ­è·¯æœºåˆ¶å¯ä»¥æ— æŸåœ°ä¼ æ’­æ¢¯åº¦ï¼Œè€Œå¦å¤–ä¸€é¡¹æ®‹å·®æ¢¯åº¦åˆ™éœ€è¦ç»è¿‡å¸¦æœ‰weightçš„å±‚ï¼Œæ¢¯åº¦ä¸æ˜¯ç›´æŽ¥ä¼ é€’è¿‡æ¥çš„ã€‚æ®‹å·®æ¢¯åº¦ä¸ä¼šé‚£ä¹ˆå·§å…¨ä¸º-1ï¼Œè€Œä¸”å°±ç®—å…¶æ¯”è¾ƒå°ï¼Œæœ‰1çš„å­˜åœ¨ä¹Ÿä¸ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ã€‚æ‰€ä»¥æ®‹å·®å­¦ä¹ ä¼šæ›´å®¹æ˜“ã€‚è¦æ³¨æ„ä¸Šé¢çš„æŽ¨å¯¼å¹¶ä¸æ˜¯ä¸¥æ ¼çš„è¯æ˜Ž å¦‚æžœä»ŽResNetçš„è®ºæ–‡æ¥çœ‹ï¼Œç¡®å®žResNetå‡ºå‘ç‚¹ä¸æ˜¯æ¢¯åº¦æ¶ˆå¤±è€Œæ˜¯ç½‘ç»œé€€åŒ–ï¼›ä½†æ˜¯Kaimingéš”å¹´çš„è®ºæ–‡ç¡®å®žæœ‰æåˆ°ï¼Œæ®‹å·®ç»“æž„å¯ä»¥ä½¿å¾—åå‘çš„æ¢¯åº¦æ€»ä¸æ¶ˆå¤±ï¼Œå³ä¾¿ä¸­é—´æƒé‡çŸ©é˜µå¾ˆå° æ®‹å·®æ˜ å°„æ›´å®¹æ˜“å­¦ä¹ æœ‰ä¸ªåŽŸå› æ˜¯åå‘ä¼ æ’­çš„æ—¶å€™H(x)=x+F(x)ï¼Œxåˆ†èµ°äº†ä¸€éƒ¨åˆ†æ¢¯åº¦ï¼Œæ‰€ä»¥åŒæ ·çš„è¯¯å·®F(x)å¾—åˆ°çš„æ¢¯åº¦æ›´å° åˆ°ä¸€å®šæ·±åº¦çš„æ—¶å€™ï¼Œæ¢¯åº¦ä¼šå˜æˆ0ï¼Œä½†æ˜¯æˆ‘ä»¬è¿˜æœ‰ä¸Šä¸€å±‚çš„æ¢¯åº¦ï¼Œæ‰€ä»¥è¯´ä¸ä¼šæ¯”ä¹‹å‰çš„å·® DenseNet Densely Connected Convolutional Networks 2018 æ¦‚è¿° ä½œä¸ºCVPR2017å¹´çš„Best Paperï¼ŒDenseNetè„±ç¦»äº†åŠ æ·±ç½‘ç»œå±‚æ•°(ResNet)å’ŒåŠ å®½ç½‘ç»œç»“æž„(Inception)æ¥æå‡ç½‘ç»œæ€§èƒ½çš„å®šå¼æ€ç»´ï¼Œä»Žç‰¹å¾çš„è§’åº¦è€ƒè™‘ï¼Œé€šè¿‡ç‰¹å¾é‡ç”¨å’Œæ—è·¯(Bypass)è®¾ç½®ï¼Œæ—¢å¤§å¹…åº¦å‡å°‘äº†ç½‘ç»œçš„å‚æ•°é‡ï¼Œåˆåœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†gradient vanishingé—®é¢˜çš„äº§ç”Ÿã€‚ç»“åˆä¿¡æ¯æµå’Œç‰¹å¾å¤ç”¨çš„å‡è®¾ï¼ŒDenseNetå½“ä¹‹æ— æ„§æˆä¸º2017å¹´è®¡ç®—æœºè§†è§‰é¡¶ä¼šçš„å¹´åº¦æœ€ä½³è®ºæ–‡ DenseNetä½œä¸ºå¦ä¸€ç§æ‹¥æœ‰è¾ƒæ·±å±‚æ•°çš„å·ç§¯ç¥žç»ç½‘ç»œï¼Œå…·æœ‰å¦‚ä¸‹ä¼˜ç‚¹: ç›¸æ¯”ResNetæ‹¥æœ‰æ›´å°‘çš„å‚æ•°æ•°é‡ æ—è·¯åŠ å¼ºäº†ç‰¹å¾çš„é‡ç”¨ ç½‘ç»œæ›´æ˜“äºŽè®­ç»ƒï¼Œå¹¶å…·æœ‰ä¸€å®šçš„æ­£åˆ™æ•ˆæžœ ç¼“è§£äº†gradient vanishingå’Œmodel degradationçš„é—®é¢˜ ä½•æºæ˜Žåœ¨æå‡ºResNetæ—¶åšå‡ºäº†è¿™æ ·çš„å‡è®¾ï¼šè‹¥æŸä¸€è¾ƒæ·±çš„ç½‘ç»œå¤šå‡ºå¦ä¸€è¾ƒæµ…ç½‘ç»œçš„è‹¥å¹²å±‚æœ‰èƒ½åŠ›å­¦ä¹ åˆ°æ’ç­‰æ˜ å°„ï¼Œé‚£ä¹ˆè¿™ä¸€è¾ƒæ·±ç½‘ç»œè®­ç»ƒå¾—åˆ°çš„æ¨¡åž‹æ€§èƒ½ä¸€å®šä¸ä¼šå¼±äºŽè¯¥æµ…å±‚ç½‘ç»œ é€šä¿—çš„è¯´å°±æ˜¯å¦‚æžœå¯¹æŸä¸€ç½‘ç»œä¸­å¢žæ·»ä¸€äº›å¯ä»¥å­¦åˆ°æ’ç­‰æ˜ å°„çš„å±‚ç»„æˆæ–°çš„ç½‘è·¯ï¼Œé‚£ä¹ˆæœ€å·®çš„ç»“æžœä¹Ÿæ˜¯æ–°ç½‘ç»œä¸­çš„è¿™äº›å±‚åœ¨è®­ç»ƒåŽæˆä¸ºæ’ç­‰æ˜ å°„è€Œä¸ä¼šå½±å“åŽŸç½‘ç»œçš„æ€§èƒ½ åŒæ ·DenseNetåœ¨æå‡ºæ—¶ä¹Ÿåšè¿‡å‡è®¾ï¼šä¸Žå…¶å¤šæ¬¡å­¦ä¹ å†—ä½™çš„ç‰¹å¾ï¼Œç‰¹å¾å¤ç”¨æ˜¯ä¸€ç§æ›´å¥½çš„ç‰¹å¾æå–æ–¹å¼ æ¨¡åž‹ DenseNetæ˜¯ä¸€ç§æ·±åº¦ç¥žç»ç½‘ç»œæž¶æž„ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å¯†é›†è¿žæŽ¥(Dense Connectivity)ã€‚ç›¸æ¯”äºŽä¼ ç»Ÿçš„ç¥žç»ç½‘ç»œç»“æž„ï¼Œå¦‚VGGå’ŒResNetï¼ŒDenseNeté€šè¿‡å¼•å…¥å¯†é›†è¿žæŽ¥çš„æ–¹å¼ï¼Œåœ¨ç½‘ç»œä¸­æ¯ä¸€å±‚éƒ½ä¸Žå‰é¢æ‰€æœ‰å±‚ç›´æŽ¥ç›¸è¿žï¼Œä»Žè€Œå¢žå¼ºäº†ä¿¡æ¯æµåŠ¨å’Œç‰¹å¾é‡ç”¨çš„èƒ½åŠ› DenseNetçš„ä¸»è¦ç‰¹ç‚¹å¦‚ä¸‹ï¼š å¯†é›†è¿žæŽ¥ï¼šåœ¨DenseNetä¸­ï¼Œæ¯ä¸ªå±‚éƒ½ä¸Žå‰é¢æ‰€æœ‰å±‚ç›´æŽ¥ç›¸è¿žã€‚å…·ä½“è€Œè¨€ï¼ŒæŸä¸€å±‚çš„è¾“å…¥åŒ…æ‹¬å®ƒä¹‹å‰æ‰€æœ‰å±‚çš„è¾“å‡ºã€‚è¿™ç§å¯†é›†è¿žæŽ¥çš„æ–¹å¼ä½¿å¾—ä¿¡æ¯å¯ä»¥åœ¨ç½‘ç»œä¸­è‡ªç”±åœ°æµåŠ¨ï¼Œä¿ƒè¿›äº†ç‰¹å¾çš„ä¼ é€’å’Œå…±äº« æ··åˆç‰¹å¾é‡ç”¨ï¼šç”±äºŽå¯†é›†è¿žæŽ¥çš„å­˜åœ¨ï¼Œæ¯ä¸ªå±‚å¯ä»¥ç›´æŽ¥è®¿é—®ä¹‹å‰æ‰€æœ‰å±‚çš„ç‰¹å¾å›¾ã€‚è¿™æ ·ï¼Œä½Žå±‚ç‰¹å¾å¯ä»¥ç›´æŽ¥ä¼ é€’ç»™åŽç»­å±‚ï¼Œå®žçŽ°äº†æ··åˆç‰¹å¾é‡ç”¨ã€‚è¿™ç§ç‰¹å¾é‡ç”¨æœºåˆ¶æœ‰æ•ˆåœ°åˆ©ç”¨äº†ç½‘ç»œä¸­çš„ä¿¡æ¯ï¼Œå¢žå¼ºäº†ç‰¹å¾çš„å¤šæ ·æ€§å’Œä¸°å¯Œæ€§ åŸºæœ¬ç»„ä»¶ï¼šDenseNetçš„åŸºæœ¬ç»„ä»¶æ˜¯\"Dense Block\"ï¼Œå®ƒç”±å¤šä¸ªå…·æœ‰ç›¸åŒè¾“å‡ºé€šé“æ•°çš„å·ç§¯å±‚ç»„æˆã€‚åœ¨æ¯ä¸ªDense Blockå†…éƒ¨ï¼Œå±‚ä¸Žå±‚ä¹‹é—´é€šè¿‡å¯†é›†è¿žæŽ¥ç›¸è¿žã€‚ä¸ºäº†æŽ§åˆ¶å‚æ•°æ•°é‡å’Œè®¡ç®—é‡ï¼Œæ¯ä¸ªå·ç§¯å±‚é€šå¸¸é‡‡ç”¨è¾ƒå°çš„3x3å·ç§¯ è¿‡æ¸¡å±‚ï¼šä¸ºäº†æŽ§åˆ¶ç½‘ç»œçš„å®½åº¦ï¼ŒDenseNetåœ¨ç›¸é‚»çš„Dense Blockä¹‹é—´å¼•å…¥äº†è¿‡æ¸¡å±‚(Transition Layer)ã€‚è¿‡æ¸¡å±‚ç”±ä¸€ä¸ª1x1å·ç§¯å±‚å’Œä¸€ä¸ª2x2çš„å¹³å‡æ± åŒ–å±‚ç»„æˆï¼Œå®ƒå¯ä»¥å‡å°ç‰¹å¾å›¾çš„å°ºå¯¸å¹¶é™ä½Žé€šé“æ•°ï¼Œä»Žè€Œå‡å°‘è®¡ç®—é‡ DenseNetçš„ä¼˜ç‚¹åŒ…æ‹¬æ¨¡åž‹å‚æ•°ç›¸å¯¹è¾ƒå°‘ã€ç‰¹å¾é‡ç”¨æ€§å¼ºã€æ¢¯åº¦ä¼ æ’­æ›´åŠ é¡ºç•…ç­‰ Dense Block DenseNetä¸­çš„æ ¸å¿ƒç»„ä»¶æ˜¯\"Dense Block\"ï¼Œå®ƒç”±å¤šä¸ªå¯†é›†è¿žæŽ¥çš„å·ç§¯å±‚ç»„æˆã€‚Dense Blockçš„è®¾è®¡æ—¨åœ¨ä¿ƒè¿›ç‰¹å¾çš„ä¼ é€’å’Œé‡ç”¨ï¼Œå¢žå¼ºç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ› å…·ä½“æ¥è¯´ï¼ŒDense Blockç”±ä¸€ç³»åˆ—å †å åœ¨ä¸€èµ·çš„å·ç§¯å±‚ç»„æˆï¼Œæ¯ä¸ªå·ç§¯å±‚éƒ½ç›´æŽ¥è¿žæŽ¥åˆ°å‰é¢æ‰€æœ‰å±‚çš„è¾“å‡ºã€‚è¿™æ„å‘³ç€æŸä¸€å±‚çš„è¾“å…¥æ˜¯å…¶ä¹‹å‰æ‰€æœ‰å±‚çš„è¾“å‡ºçš„ä¸²è”ã€‚è¿™ç§å¯†é›†è¿žæŽ¥çš„æ–¹å¼ä½¿å¾—ä¿¡æ¯å¯ä»¥åœ¨ç½‘ç»œä¸­è‡ªç”±åœ°æµåŠ¨ï¼Œä»Žè€Œæœ‰æ•ˆåœ°æé«˜äº†ç‰¹å¾ä¼ é€’å’Œå…±äº«çš„èƒ½åŠ› ä¸ºäº†æŽ§åˆ¶å‚æ•°æ•°é‡å’Œè®¡ç®—é‡ï¼Œæ¯ä¸ªå·ç§¯å±‚é€šå¸¸é‡‡ç”¨å…·æœ‰ç›¸åŒè¾“å‡ºé€šé“æ•°çš„3 \\times 3å·ç§¯ã€‚è¿™æ ·ï¼Œæ¯ä¸ªå·ç§¯å±‚éƒ½å¯ä»¥åˆ©ç”¨ä¹‹å‰å±‚çš„ä¸°å¯Œç‰¹å¾æ¥ç”Ÿæˆæ›´åŠ å¤æ‚å’ŒæŠ½è±¡çš„ç‰¹å¾è¡¨ç¤ºã€‚è¿™ç§å¯†é›†è¿žæŽ¥çš„æ–¹å¼ä¸ä»…å¢žåŠ äº†ç‰¹å¾çš„å¤šæ ·æ€§ï¼Œè¿˜å‡è½»äº†æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œä½¿å¾—ç½‘ç»œæ›´å®¹æ˜“è®­ç»ƒ åœ¨æ¯ä¸ªDense Blockä¹‹é—´ï¼Œä¸ºäº†æŽ§åˆ¶ç½‘ç»œçš„å®½åº¦å’Œæ·±åº¦ï¼Œé€šå¸¸ä¼šå¼•å…¥è¿‡æ¸¡å±‚(Transition Layer)ã€‚è¿‡æ¸¡å±‚ç”±ä¸€ä¸ª1 \\times 1å·ç§¯å±‚å’Œä¸€ä¸ª2 \\times 2çš„å¹³å‡æ± åŒ–å±‚ç»„æˆã€‚1 \\times 1å·ç§¯å±‚ç”¨äºŽé™ä½Žé€šé“æ•°ï¼Œå‡å°‘è®¡ç®—é‡ã€‚å¹³å‡æ± åŒ–å±‚åˆ™ç”¨äºŽå‡å°ç‰¹å¾å›¾çš„å°ºå¯¸ï¼Œè¿›ä¸€æ­¥å‡å°‘å‚æ•°å’Œè®¡ç®—å¤æ‚åº¦ æ¨¡åž‹ DenseNetæ˜¯ä¸€ç§åŸºäºŽå¯†é›†è¿žæŽ¥çš„å·ç§¯ç¥žç»ç½‘ç»œ(CNN)ï¼Œå…¶ä¸»è¦ç‰¹ç‚¹æ˜¯åœ¨ç½‘ç»œä¸­å¼•å…¥äº†å¯†é›†è¿žæŽ¥å±‚ï¼Œä»Žè€Œæ”¹å–„äº†ä¿¡æ¯çš„æµåŠ¨å’Œæ¢¯åº¦çš„ä¼ é€’ã€‚ä¸‹é¢æ˜¯DenseNetçš„ç½‘ç»œç»“æž„ï¼š 1.è¾“å…¥å±‚ï¼šè¾“å…¥å±‚æŽ¥æ”¶è¾“å…¥æ•°æ®ï¼Œå¹¶å°†å…¶é€å…¥ç¬¬ä¸€ä¸ªå·ç§¯å±‚ä¸­ 2.å·ç§¯å±‚ï¼šDenseNetä¸­çš„å·ç§¯å±‚é€šå¸¸é‡‡ç”¨3\\times 3çš„å·ç§¯æ ¸ï¼Œå¹¶é‡‡ç”¨paddingæ¥ä¿æŒç‰¹å¾å›¾çš„å¤§å°ä¸å˜ã€‚åœ¨æ¯ä¸ªå·ç§¯å±‚åŽé¢ï¼Œéƒ½ä¼šæŽ¥ä¸ŠBNå±‚å’ŒReLUæ¿€æ´»å‡½æ•° 3.å¯†é›†å—(Dense Block)ï¼šå¯†é›†å—æ˜¯DenseNetçš„æ ¸å¿ƒï¼Œå®ƒç”±å¤šä¸ªå¯†é›†è¿žæŽ¥å±‚ç»„æˆã€‚æ¯ä¸ªå¯†é›†å—ä¸­ï¼Œæ‰€æœ‰å‰é¢å±‚çš„è¾“å‡ºéƒ½ä¼šä¸Žå½“å‰å±‚çš„è¾“å…¥è¿›è¡Œè¿žæŽ¥ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªéžçº¿æ€§å˜æ¢è¿›è¡Œå¤„ç† 4.è¿‡æ¸¡å±‚(Transition Block)ï¼šä¸ºäº†é¿å…ç½‘ç»œè¿‡æ·±å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±å’Œè®¡ç®—èµ„æºè¿‡åº¦æ¶ˆè€—ï¼ŒDenseNetä¸­é‡‡ç”¨äº†è¿‡æ¸¡å±‚æ¥æŽ§åˆ¶ç½‘ç»œçš„å¤§å°ã€‚åœ¨æ¯ä¸ªå¯†é›†å—ä¹‹é—´ï¼Œéƒ½ä¼šæŽ¥ä¸Šä¸€ä¸ªè¿‡æ¸¡å±‚ï¼Œå®ƒåŒ…å«ä¸€ä¸ª1\\times 1çš„å·ç§¯å±‚ã€BNå±‚å’Œå¹³å‡æ± åŒ–å±‚ï¼Œå…¶ä¸­å¹³å‡æ± åŒ–çš„æ­¥å¹…ä¸º2ï¼Œç”¨äºŽå‡å°‘ç‰¹å¾å›¾çš„å¤§å° 5.å…¨å±€æ± åŒ–å±‚å’Œå…¨è¿žæŽ¥å±‚ï¼šæœ€åŽï¼ŒDenseNetä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–å±‚å°†ç‰¹å¾å›¾é™ç»´ä¸ºä¸€ä¸ªå‘é‡ï¼Œç„¶åŽé€šè¿‡ä¸€ä¸ªå…¨è¿žæŽ¥å±‚è¿›è¡Œåˆ†ç±» æœ€åŽä¸€ä¸ªæ± åŒ–ç”¨çš„æ˜¯å…¨å±€æ± åŒ–å±‚ å…·ä½“æ¥è¯´ï¼ŒDenseNetçš„å¯†é›†è¿žæŽ¥æœºåˆ¶ä½¿å¾—å‰é¢çš„å±‚å¯ä»¥ç›´æŽ¥è¿žæŽ¥åˆ°åŽé¢çš„å±‚ï¼Œä»Žè€Œä¿ç•™äº†æ›´å¤šçš„ç‰¹å¾ä¿¡æ¯ã€‚ç„¶è€Œï¼Œè¿™ç§å¯†é›†è¿žæŽ¥ä¹Ÿå¯¼è‡´äº†ç‰¹å¾å›¾çš„å°ºå¯¸é€æ¸å¢žå¤§ã€‚ä¸ºäº†æŽ§åˆ¶æ¨¡åž‹çš„å¤æ‚æ€§å’Œè®¡ç®—é‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒå°ºåº¦çš„è¾“å…¥ï¼ŒDenseNetå¼•å…¥äº†å…¨å±€æ± åŒ–å±‚ å…¨å±€æ± åŒ–å±‚å¯ä»¥å°†æ•´ä¸ªç‰¹å¾å›¾è½¬åŒ–ä¸ºå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ï¼Œè¿™æ ·å¯ä»¥æœ‰æ•ˆåœ°é™ä½Žç‰¹å¾çš„ç»´åº¦ï¼Œå¹¶ä¸”ä¿ç•™äº†å…¨å±€æ„Ÿå—é‡Žçš„ç‰¹å¾ä¿¡æ¯ã€‚é€šè¿‡å°†ç‰¹å¾å›¾çš„æ¯ä¸ªé€šé“è¿›è¡Œå¹³å‡æ± åŒ–æˆ–æœ€å¤§æ± åŒ–æ“ä½œï¼Œå…¨å±€æ± åŒ–å±‚å¯ä»¥æ•æ‰åˆ°æ•´ä¸ªç‰¹å¾å›¾çš„ç»Ÿè®¡ç‰¹å¾ï¼Œä»Žè€Œå¯¹å…¨å±€ä¿¡æ¯è¿›è¡Œæ±‡èš ä½¿ç”¨å…¨å±€æ± åŒ–å±‚çš„å¥½å¤„æ˜¯å‡å°‘äº†æ¨¡åž‹çš„å‚æ•°æ•°é‡å’Œè®¡ç®—é‡ï¼ŒåŒæ—¶ä»ç„¶èƒ½å¤Ÿä¿ç•™é‡è¦çš„å…¨å±€ç‰¹å¾ã€‚è¿™æœ‰åŠ©äºŽæé«˜æ¨¡åž‹çš„æ•ˆçŽ‡å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒå’ŒæŽ¨æ–­é˜¶æ®µéƒ½èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒå°ºåº¦çš„è¾“å…¥å›¾åƒ Resnext Resnetæ€§èƒ½æœ€å¥½çš„å˜ä½“æ˜¯Resnext Vit Vit An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale 2020 Vision Transformerè¯¦è§£ Vision Transformer (base-sized model) æ¦‚è¿° ViT(Vision Transformer)æ˜¯ä¸€ç§åŸºäºŽTransformerçš„è§†è§‰æ¨¡åž‹ï¼Œå®ƒå°†è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„Transformeræ¨¡åž‹æˆåŠŸåº”ç”¨äºŽè®¡ç®—æœºè§†è§‰ä»»åŠ¡ ä¼ ç»Ÿçš„è®¡ç®—æœºè§†è§‰æ¨¡åž‹ä¸»è¦åŸºäºŽå·ç§¯ç¥žç»ç½‘ç»œ(CNN)ï¼Œè€ŒViTå°è¯•ä½¿ç”¨Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥å¤„ç†å›¾åƒæ•°æ® ViTçš„å…³é”®æ€æƒ³ å°†è¾“å…¥å›¾åƒåˆ‡åˆ†ä¸ºå›ºå®šå¤§å°çš„å›¾åƒå—(patches)ï¼Œå¹¶å°†è¿™äº›å›¾åƒå—å±•å¹³ä¸ºåºåˆ—å½¢å¼çš„è¾“å…¥ã€‚æ¯ä¸ªå›¾åƒå—é€šè¿‡ä¸€ä¸ªçº¿æ€§æ˜ å°„å±‚è¿›è¡Œç‰¹å¾åµŒå…¥ï¼Œç„¶åŽé€šè¿‡æ·»åŠ ä½ç½®åµŒå…¥æ¥å¼•å…¥ä½ç½®ä¿¡æ¯ ä¹‹å‰å­¦ä¹ çš„Transformerç»“æž„ä¸­ï¼Œè¾“å…¥éœ€è¦æ˜¯ä¸€ä¸ªäºŒç»´çš„çŸ©é˜µï¼ŒçŸ©é˜µçš„å½¢çŠ¶å¯ä»¥è¡¨ç¤ºä¸º(N, D)ï¼Œå…¶ä¸­Næ˜¯sequenceçš„é•¿åº¦ï¼Œè€ŒDæ˜¯sequenceä¸­æ¯ä¸ªå‘é‡çš„ç»´åº¦ å› æ­¤ï¼Œåœ¨ViTç®—æ³•ä¸­ï¼Œé¦–å…ˆéœ€è¦è®¾æ³•å°†H \\times W \\times Cçš„ä¸‰ç»´å›¾åƒè½¬åŒ–ä¸º(N, D)çš„äºŒç»´è¾“å…¥ ViTä¸­çš„å…·ä½“å®žçŽ°æ–¹å¼ä¸º: å°†H \\times W \\times Cçš„å›¾åƒï¼Œå˜ä¸ºä¸€ä¸ªN \\times\\left(P^{2} * C\\right)çš„åºåˆ—ã€‚è¿™ä¸ªåºåˆ—å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç³»åˆ—å±•å¹³çš„å›¾åƒå—ï¼Œä¹Ÿå°±æ˜¯å°†å›¾åƒåˆ‡åˆ†æˆå°å—åŽï¼Œå†å°†å…¶å±•å¹³ã€‚è¯¥åºåˆ—ä¸­ä¸€å…±åŒ…å«äº†N=H W / P^{2}ä¸ªå›¾åƒå—ï¼Œæ¯ä¸ªå›¾åƒå—çš„ç»´åº¦åˆ™æ˜¯\\left(P^{2} * C\\right)ã€‚å…¶ä¸­Pæ˜¯å›¾åƒå—çš„å¤§å°ï¼ŒCæ˜¯é€šé“æ•°é‡ã€‚ç»è¿‡å¦‚ä¸Šå˜æ¢ï¼Œå°±å¯ä»¥å°†Nè§†ä¸ºsequenceçš„é•¿åº¦äº† ä½†æ˜¯ï¼Œæ­¤æ—¶æ¯ä¸ªå›¾åƒå—çš„ç»´åº¦æ˜¯\\left(P^{2} * C\\right)ï¼Œè€Œæˆ‘ä»¬å®žé™…éœ€è¦çš„å‘é‡ç»´åº¦æ˜¯Dï¼Œå› æ­¤æˆ‘ä»¬è¿˜éœ€è¦å¯¹å›¾åƒå—è¿›è¡ŒEmbeddingã€‚è¿™é‡ŒEmbeddingçš„æ–¹å¼éžå¸¸ç®€å•ï¼Œåªéœ€è¦å¯¹æ¯ä¸ª\\left(P^{2} * C\\right)çš„å›¾åƒå—åšä¸€ä¸ªçº¿æ€§å˜æ¢ï¼Œå°†ç»´åº¦åŽ‹ç¼©ä¸ºDå³å¯ æ¨¡åž‹ç»“æž„ ViTæ¨¡åž‹é€šå¸¸åŒ…å«å¤šä¸ªTransformerç¼–ç å™¨å±‚ï¼Œæ¯ä¸ªå±‚ç”±å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç¥žç»ç½‘ç»œç»„æˆ åœ¨ViTä¸­ï¼Œåºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®éƒ½å¯ä»¥è¿›è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿåœ¨å…¨å±€ä¸Šå¯¹å›¾åƒè¿›è¡Œç¼–ç å’Œç†è§£ æœ€åŽï¼ŒViTæ¨¡åž‹å°†åºåˆ—çš„è¡¨ç¤ºé€šè¿‡ä¸€ä¸ªæ± åŒ–æ“ä½œå¾—åˆ°æ•´ä¸ªå›¾åƒçš„è¡¨ç¤ºï¼Œç„¶åŽå¯ä»¥é€šè¿‡ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨è¿›è¡Œåˆ†ç±»æˆ–è¿›è¡Œå…¶ä»–ä»»åŠ¡ ä¼˜ç¼ºç‚¹ ViTçš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯å®ƒèƒ½å¤Ÿæ•æ‰å…¨å±€ä¿¡æ¯ï¼Œå¹¶ä¸”åœ¨ä¸€äº›è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„è¡¨çŽ°ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œå›¾åƒåˆ†å‰² ç„¶è€Œï¼ŒViTå¯¹äºŽå¤§å°ºå¯¸é«˜åˆ†è¾¨çŽ‡å›¾åƒçš„å¤„ç†ç›¸å¯¹è¾ƒæ…¢ï¼Œä¸”å¯¹äºŽç©ºé—´ä¿¡æ¯çš„å»ºæ¨¡ç›¸å¯¹è¾ƒå¼±ï¼Œå› æ­¤åœ¨å¤„ç†å…·æœ‰ç»†ç²’åº¦ç»“æž„çš„å›¾åƒæ—¶å¯èƒ½å­˜åœ¨ä¸€å®šçš„é™åˆ¶ ViTé€šè¿‡å°†å›¾åƒåˆ’åˆ†ä¸ºåºåˆ—ï¼Œå¹¶åˆ©ç”¨Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„Transformeræ¨¡åž‹å¼•å…¥äº†è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œä¸ºå›¾åƒç†è§£ä»»åŠ¡æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯å’Œæ–¹æ³• Transformeræ¨¡åž‹æ˜¯å¦‚ä½•åœ¨CVé¢†åŸŸé‡Œç”¨èµ·æ¥çš„ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼ŒTransformeræ¨¡åž‹é€šå¸¸ç”¨äºŽå¤„ç†åºåˆ—æ•°æ®å’Œå®žçŽ°ä¸€äº›ç‰¹å®šä»»åŠ¡ï¼Œè€Œä¸æ˜¯ç›´æŽ¥åº”ç”¨äºŽå›¾åƒè¾“å…¥ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä½¿ç”¨Transformeræ¨¡åž‹çš„å¸¸è§æ–¹å¼ï¼š å›¾åƒåˆ†ç±»ï¼šå¯ä»¥å°†å›¾åƒåˆ’åˆ†ä¸ºç½‘æ ¼å•å…ƒï¼Œå¹¶å°†æ¯ä¸ªå•å…ƒçš„ç‰¹å¾è¡¨ç¤ºä¸ºåºåˆ—ã€‚ç„¶åŽï¼Œå°†åºåˆ—è¾“å…¥Transformeræ¨¡åž‹è¿›è¡Œåˆ†ç±»ä»»åŠ¡ã€‚è¿™æ ·åšçš„ä¸€ä¸ªä¾‹å­æ˜¯Vision Transformer(ViT)æ¨¡åž‹ï¼Œå®ƒå°†å›¾åƒåˆ’åˆ†ä¸ºå›¾åƒå—ï¼Œç„¶åŽé€šè¿‡Transformerç¼–ç å™¨å¯¹è¿™äº›å—è¿›è¡Œå¤„ç† ç›®æ ‡æ£€æµ‹ï¼šä¸€ç§ä½¿ç”¨Transformerçš„ç›®æ ‡æ£€æµ‹æ–¹æ³•æ˜¯å°†å›¾åƒåˆ’åˆ†ä¸ºä¸€ç»„å›ºå®šå¤§å°çš„åŒºåŸŸï¼Œç„¶åŽå¯¹æ¯ä¸ªåŒºåŸŸæå–ç‰¹å¾ï¼Œå¹¶å°†è¿™äº›ç‰¹å¾åºåˆ—è¾“å…¥Transformeræ¨¡åž‹ä¸­è¿›è¡Œå¯¹è±¡åˆ†ç±»å’Œè¾¹ç•Œæ¡†å›žå½’ã€‚è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªä¾‹å­æ˜¯DETR(Detection Transformer)æ¨¡åž‹ å›¾åƒç”Ÿæˆï¼šTransformeræ¨¡åž‹ä¹Ÿå¯ä»¥ç”¨äºŽç”Ÿæˆè§†è§‰å†…å®¹ï¼Œå¦‚å›¾åƒç”Ÿæˆã€å›¾åƒæè¿°ç”Ÿæˆç­‰ä»»åŠ¡ã€‚é€šè¿‡å°†Transformeræ¨¡åž‹ä½œä¸ºç”Ÿæˆå™¨ï¼Œå¯ä»¥å­¦ä¹ ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒæˆ–å›¾åƒæè¿° éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç”±äºŽå›¾åƒæ•°æ®çš„é«˜ç»´æ€§å’Œç©ºé—´ç»“æž„ï¼Œç›´æŽ¥å°†Transformeræ¨¡åž‹åº”ç”¨äºŽæ•´ä¸ªå›¾åƒé€šå¸¸ä¸æ˜¯å¸¸è§çš„åšæ³•ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå·ç§¯ç¥žç»ç½‘ç»œ(CNN)åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­æ›´ä¸ºå¸¸è§ï¼Œå› ä¸ºå®ƒä»¬æ›´é€‚åˆå¤„ç†å›¾åƒæ•°æ®çš„å±€éƒ¨ç‰¹å¾å’Œç©ºé—´ç»“æž„ã€‚ä½†æ˜¯ï¼Œé€šè¿‡å°†Transformeræ¨¡åž‹ä¸ŽCNNç»“åˆä½¿ç”¨ï¼Œå¯ä»¥åˆ©ç”¨Transformeræ¨¡åž‹çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›å’Œæ³¨æ„åŠ›æœºåˆ¶æ¥å¤„ç†å›¾åƒä¸­çš„åºåˆ—æˆ–å±€éƒ¨ç‰¹å¾ï¼Œä»Žè€Œæé«˜è®¡ç®—æœºè§†è§‰ä»»åŠ¡çš„æ€§èƒ½ Tranformerå’ŒCNNæ¯”è¾ƒ Tranformerç›¸è¾ƒäºŽCNNç»“æž„ï¼Œç¼ºå°‘ä¸€å®šçš„å¹³ç§»ä¸å˜æ€§å’Œå±€éƒ¨æ„ŸçŸ¥æ€§ï¼Œå› æ­¤åœ¨æ•°æ®é‡ä¸å……åˆ†æ—¶ï¼Œå¾ˆéš¾è¾¾åˆ°åŒç­‰çš„æ•ˆæžœï¼Œè¡¨çŽ°ä¸ºä½¿ç”¨ä¸­ç­‰è§„æ¨¡çš„ImageNetè®­ç»ƒçš„Tranformerä¼šæ¯”ResNetåœ¨ç²¾åº¦ä¸Šä½Žå‡ ä¸ªç™¾åˆ†ç‚¹ å½“æœ‰å¤§é‡çš„è®­ç»ƒæ ·æœ¬æ—¶ï¼Œç»“æžœåˆ™ä¼šå‘ç”Ÿæ”¹å˜ã€‚ä½¿ç”¨å¤§è§„æ¨¡æ•°æ®é›†è¿›è¡Œé¢„è®­ç»ƒåŽï¼Œå†ä½¿ç”¨è¿ç§»å­¦ä¹ çš„æ–¹å¼åº”ç”¨åˆ°å…¶ä»–æ•°æ®é›†ä¸Šï¼Œå¯ä»¥è¾¾åˆ°æˆ–è¶…è¶Šå½“å‰çš„SOTAæ°´å¹³ DeiTModel Training data-efficient image transformers & distillation through attention 2021 è§†è§‰Transformerç»å…¸è®ºæ–‡â€”â€”ViTã€DeiTçš„ä¸ŽåŽŸç†è§£è¯»ä¸Žå®žçŽ° huggingface DeiTModel DeiTï¼šæ³¨æ„åŠ›Attentionä¹Ÿèƒ½è’¸é¦ DeiTModel(Data-efficient Image Transformers Model)å’ŒViT(Vision Transformer)ä¹‹é—´å­˜åœ¨å…³ç³»ï¼ŒDeiTModelå¯ä»¥çœ‹ä½œæ˜¯å¯¹ViTæ¨¡åž‹çš„æ”¹è¿›å’Œä¼˜åŒ– ViTåœ¨å¤§æ•°æ®é›† mageNet-21k(14million)æˆ–è€…JFT-300M(300million)ä¸Šè¿›è¡Œè®­ç»ƒï¼ŒBatch Size 128ä¸‹NVIDIA A100 32G GPUçš„è®¡ç®—èµ„æºåŠ æŒä¸‹é¢„è®­ç»ƒViT-Base/32éœ€è¦3å¤©æ—¶é—´ ViTæ˜¯ä¸€ç§åŸºäºŽTransformerçš„å›¾åƒåˆ†ç±»æ¨¡åž‹ï¼Œé€šè¿‡å°†å›¾åƒæ‹†åˆ†æˆå›ºå®šå¤§å°çš„å›¾åƒå—ï¼Œå¹¶ä½¿ç”¨çº¿æ€§åµŒå…¥å°†æ¯ä¸ªå›¾åƒå—è½¬æ¢ä¸ºå‘é‡åºåˆ—ï¼Œç„¶åŽå°†åºåˆ—è¾“å…¥åˆ°Transformerç¼–ç å™¨ä¸­è¿›è¡Œå¤„ç†ã€‚ViTæ¨¡åž‹åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†å‡ºè‰²çš„æ€§èƒ½ï¼Œä½†éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æº Facebookä¸Žç´¢é‚¦å¤§å­¦Matthieu Cordæ•™æŽˆåˆä½œDeiTModelï¼ŒDeiTæ¨¡åž‹(8600ä¸‡å‚æ•°)ä»…ç”¨ä¸€å°GPUæœåŠ¡å™¨åœ¨53 hours trainï¼Œ20 hours finetuneï¼Œä»…ä½¿ç”¨ImageNetå°±è¾¾åˆ°äº† 84.2 top-1å‡†ç¡®æ€§ï¼Œè€Œæ— éœ€ä½¿ç”¨ä»»ä½•å¤–éƒ¨æ•°æ®è¿›è¡Œè®­ç»ƒã€‚æ€§èƒ½ä¸Žæœ€å…ˆè¿›çš„å·ç§¯ç¥žç»ç½‘ç»œ(CNN)å¯ä»¥æŠ—è¡¡ è¾ƒäºŽVitçš„æ”¹è¿›ç‚¹ DeiTModelåˆ™æ˜¯åœ¨ViTçš„åŸºç¡€ä¸Šè¿›è¡Œäº†æ”¹è¿›ï¼Œæ—¨åœ¨æé«˜æ•°æ®æ•ˆçŽ‡ è®­ç»ƒç­–ç•¥: é«˜ä½Žç²¾åº¦+æ•°æ®å¢žå¼º æ›´å°‘çš„æ•°æ®å’Œè®¡ç®—èµ„æº: DeiTæ¨¡åž‹ä½¿ç”¨æ›´å°‘çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œä»…ä½¿ç”¨ImageNetæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨è¾ƒçŸ­çš„æ—¶é—´å†…å®Œæˆè®­ç»ƒ è’¸é¦æœºåˆ¶: DeiTæ¨¡åž‹è¿˜å¼•å…¥äº†ä¸€ç§æ•™å¸ˆ-å­¦ç”Ÿç­–ç•¥ï¼Œé€šè¿‡è’¸é¦æœºåˆ¶ä½¿å­¦ç”Ÿæ¨¡åž‹ä»Žæ•™å¸ˆæ¨¡åž‹ä¸­å­¦ä¹ ï¼Œè¿™ç§ç­–ç•¥æœ‰åŠ©äºŽæé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ€§èƒ½ çŸ¥è¯†è’¸é¦ DeiTï¼šæ³¨æ„åŠ›Attentionä¹Ÿèƒ½è’¸é¦ çŸ¥è¯†è’¸é¦ä½¿ç”¨çš„æ˜¯Teacherâ€”Studentæ¨¡åž‹ï¼Œå…¶ä¸­Teacheræ˜¯çŸ¥è¯†çš„è¾“å‡ºè€…ï¼ŒStudentæ˜¯çŸ¥è¯†çš„æŽ¥å—è€…ã€‚çŸ¥è¯†è’¸é¦çš„è¿‡ç¨‹åˆ†ä¸º2ä¸ªé˜¶æ®µ: åŽŸå§‹æ¨¡åž‹è®­ç»ƒ: è®­ç»ƒTeacheræ¨¡åž‹, ç®€ç§°ä¸ºNet-Tï¼Œå®ƒçš„ç‰¹ç‚¹æ˜¯æ¨¡åž‹ç›¸å¯¹å¤æ‚ï¼Œä¹Ÿå¯ä»¥ç”±å¤šä¸ªåˆ†åˆ«è®­ç»ƒçš„æ¨¡åž‹é›†æˆè€Œæˆã€‚æˆ‘ä»¬å¯¹Teacheræ¨¡åž‹ä¸ä½œä»»ä½•å…³äºŽæ¨¡åž‹æž¶æž„ã€å‚æ•°é‡ã€æ˜¯å¦é›†æˆæ–¹é¢çš„é™åˆ¶ï¼Œå”¯ä¸€çš„è¦æ±‚å°±æ˜¯ï¼Œå¯¹äºŽè¾“å…¥X, å…¶éƒ½èƒ½è¾“å‡ºYï¼Œå…¶ä¸­Yç»è¿‡softmaxçš„æ˜ å°„ï¼Œè¾“å‡ºå€¼å¯¹åº”ç›¸åº”ç±»åˆ«çš„æ¦‚çŽ‡å€¼ ç²¾ç®€æ¨¡åž‹è®­ç»ƒ: è®­ç»ƒStudentæ¨¡åž‹, ç®€ç§°ä¸ºNet-Sï¼Œå®ƒæ˜¯å‚æ•°é‡è¾ƒå°ã€æ¨¡åž‹ç»“æž„ç›¸å¯¹ç®€å•çš„å•æ¨¡åž‹ã€‚åŒæ ·çš„ï¼Œå¯¹äºŽè¾“å…¥Xï¼Œå…¶éƒ½èƒ½è¾“å‡ºYï¼ŒYç»è¿‡softmaxæ˜ å°„åŽåŒæ ·èƒ½è¾“å‡ºå¯¹åº”ç›¸åº”ç±»åˆ«çš„æ¦‚çŽ‡å€¼ å°†é—®é¢˜é™å®šåœ¨åˆ†ç±»é—®é¢˜ä¸‹ï¼Œæˆ–è€…å…¶ä»–æœ¬è´¨ä¸Šå±žäºŽåˆ†ç±»é—®é¢˜çš„é—®é¢˜ï¼Œè¯¥ç±»é—®é¢˜çš„å…±åŒç‚¹æ˜¯æ¨¡åž‹æœ€åŽä¼šæœ‰ä¸€ä¸ªsoftmaxå±‚ï¼Œå…¶è¾“å‡ºå€¼å¯¹åº”äº†ç›¸åº”ç±»åˆ«çš„æ¦‚çŽ‡å€¼ã€‚çŸ¥è¯†è’¸é¦æ—¶ï¼Œç”±äºŽå·²ç»æœ‰äº†ä¸€ä¸ªæ³›åŒ–èƒ½åŠ›è¾ƒå¼ºçš„Net-Tï¼Œæˆ‘ä»¬åœ¨åˆ©ç”¨Net-Tæ¥è’¸é¦è®­ç»ƒNet-Sæ—¶ï¼Œå¯ä»¥ç›´æŽ¥è®©Net-SåŽ»å­¦ä¹ Net-Tçš„æ³›åŒ–èƒ½åŠ› ä¸Šå›¾æ˜¯æ•™å¸ˆå­¦ç”Ÿæ¨¡åž‹çš„ä¸€èˆ¬å½¢å¼ï¼Œå°±æ˜¯æœ‰ä¸¤éƒ¨åˆ†çš„lossï¼Œä¸€ä¸ªå…³æ³¨çœŸå®žæ ‡ç­¾ï¼Œå¦ä¸€ä¸ªå…³æ³¨Net-Tçš„è¾“å‡ºï¼Œè®­ç»ƒçš„æ¨¡åž‹å¯ä»¥å…¼é¡¾è‡ªèº«å’Œæ•™å¸ˆæ¨¡åž‹çš„çº¦æŸï¼Œå³ L = \\alpha L_{soft} + \\beta L_{hard} ä¸‹é¢å·¦å›¾æ¯”è¾ƒäº†æ”¹å˜è®­ç»ƒç­–ç•¥å’Œæ·»åŠ è’¸é¦å­¦ä¹ çš„ç»“æžœæ¯”è¾ƒï¼Œå³å›¾æ˜¯DeiTæ¨¡åž‹ç»“æž„ å·¦å›¾ å›¾ä¸­çš„æŒ‡æ ‡å‡ä¸ºåœ¨ImageNetæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¸”åœ¨ImageNetæ•°æ®é›†ä¸Šè¯„ä¼°çš„ç»“æžœ å…¶ä¸­Ours(Deit)ä¸ºä½¿ç”¨ä¸ŽViTå®Œå…¨ä¸€è‡´çš„ç½‘ç»œç»“æž„ï¼Œä½†æ˜¯æ”¹è¿›äº†è®­ç»ƒç­–ç•¥ è€ŒOursâš—(DeiTâš—)åˆ™æ˜¯åœ¨DeiTçš„åŸºç¡€ä¸Šç»§ç»­ä½¿ç”¨äº†è’¸é¦å­¦ä¹ çš„æ–¹å¼è¿›è¡Œæ”¹è¿› å¯ä»¥çœ‹åˆ°ï¼ŒViTç®—æ³•åœ¨è¿™ç§ä¸­ç­‰è§„æ¨¡çš„æ•°æ®é›†ä¸Šï¼ŒæŒ‡æ ‡è¿œä¸å¦‚CNNç½‘ç»œEfficientNet è€Œé€šè¿‡æ”¹å˜è®­ç»ƒç­–ç•¥ï¼Œä½¿ç”¨è’¸é¦å­¦ä¹ ï¼Œç½‘ç»œç»“æž„ä¸ŽViTåŸºæœ¬ä¸€è‡´çš„DeiTæ€§èƒ½æœ‰äº†å¾ˆå¤§çš„æå‡ï¼Œè¶…è¿‡äº†EfficientNet å³å›¾ DeiTä¸ŽViTçš„ä¸»è¦å·®å¼‚åœ¨äºŽå¼•å…¥äº†ä¸€ä¸ªdistillation tokenï¼Œå…¶ä¸»è¦ç”¨äºŽç½‘ç»œè®­ç»ƒä¸­çš„è’¸é¦å­¦ä¹  è¿™ä¸ªdistillation tokenä¸Žclass tokenå¾ˆåƒï¼Œå…¶åœ¨self-attention layersä¸­ä¼šè·Ÿclass tokenä»¥åŠå›¾åƒpatchä¸æ–­äº¤äº’ è€Œdistillation tokenä¸Žclass tokenå”¯ä¸€åŒºåˆ«åœ¨äºŽï¼Œclass tokençš„ç›®æ ‡æ˜¯è·ŸçœŸå®žçš„labelä¸€è‡´ï¼Œè€Œdistillation tokenæ˜¯è¦è·Ÿè’¸é¦å­¦ä¹ ä¸­æ•™å¸ˆç½‘ç»œé¢„æµ‹çš„labelä¸€è‡´ Loss = Loss\\{class\\_token, label\\} + Loss\\{distillation\\_token , Net_T's\\_label\\} åœ¨æœ€ç»ˆé¢„æµ‹æ—¶ï¼Œç½‘ç»œæ—¢ä¼šè¾“å‡ºclass tokençš„ç»“æžœï¼Œä¹Ÿä¼šè¾“å‡ºdistillation tokençš„ç»“æžœï¼Œè®ºæ–‡ç­”æ¡ˆæ˜¯å°†ä¸¤è€…çš„softmaxç»“æžœè¿›è¡Œç›¸åŠ ï¼Œå³å¯ç®€å•åœ°å¾—åˆ°ç®—æ³•çš„æœ€ç»ˆé¢„æµ‹ç»“æžœ è¿™é‡Œåœ¨è®¡ç®—å’ŒNet-Tçš„lossæ—¶ï¼Œè¿˜å¯ä»¥ç»†åˆ†ä¸ºä¸¤ç§ï¼Œåˆ†åˆ«æ˜¯è½¯è’¸é¦(soft distillation)å’Œç¡¬è’¸é¦(hard distillation) è½¯è’¸é¦: å°†å­¦ç”Ÿç½‘ç»œçš„è¾“å‡ºç»“æžœä¸Žæ•™å¸ˆç½‘ç»œçš„softmaxè¾“å‡ºç»“æžœå–KL Loss L_{\\text {global }}^{\\text {SoftDistill }}=(1-\\lambda) L_{C E}\\left(\\psi\\left(Z_{s}\\right), y\\right)+\\lambda \\tau^{2} K L\\left(\\psi\\left(Z_{s} / \\tau\\right), \\psi\\left(Z_{t} / \\tau\\right)\\right) ç¡¬è’¸é¦: å°†å­¦ç”Ÿç½‘ç»œçš„è¾“å‡ºç»“æžœä¸Žæ•™å¸ˆç½‘ç»œçš„æ ‡ç­¾å–äº¤å‰ç†µæŸå¤± L_{\\text {global }}^{\\text {Hardistill }}=\\frac{1}{2} L_{C E}\\left(\\psi\\left(Z_{s}\\right), y\\right)+\\frac{1}{2} L_{C E}\\left(\\psi\\left(Z_{s}\\right), y_{t}\\right) Hard Labelä¹Ÿå¯ä»¥é€šè¿‡æ ‡ç­¾å¹³æ»‘æŠ€æœ¯(Label smoothing)è½¬æ¢æˆSoft Labeï¼Œå…¶ä¸­çœŸå€¼å¯¹åº”çš„æ ‡ç­¾è¢«è®¤ä¸ºå…·æœ‰1-esilonçš„æ¦‚çŽ‡ï¼Œå‰©ä½™çš„esilonç”±å‰©ä½™çš„ç±»åˆ«å…±äº« ViTã€Deitè¿™ç±»è§†è§‰transformeræ˜¯å¦‚ä½•å¤„ç†å˜é•¿åºåˆ—è¾“å…¥çš„ å½“å¢žåŠ è¾“å…¥å›¾åƒçš„åˆ†è¾¨çŽ‡æ—¶ï¼Œä¾‹å¦‚DeiTä»Ž224åˆ°384ï¼Œä¸€èˆ¬æ¥è¯´ä¼šä¿æŒpatch size(ä¾‹å¦‚9)ï¼Œå› æ­¤patchçš„æ•°é‡Nä¼šå‘ç”Ÿäº†å˜åŒ– ç”±äºŽTransformerç»“æž„çš„åŽŸå› ï¼Œå†…ç½®äº†position embeddingä½ç½®ç¼–ç çš„å·®å€¼ï¼Œä¸€èˆ¬å°†ä½ç½®ç¼–ç åŒçº¿æ€§æ’å€¼åˆ°å›¾ç‰‡åˆ†è¾¨çŽ‡ï¼Œå½“Nå‘ç”Ÿå˜åŒ–æ—¶ï¼Œæ¨¡åž‹çš„æƒé‡ä¸éœ€è¦åšå‡ºä»»ä½•å˜åŒ–ä¹Ÿå¯ä»¥ä»¥åŒæ ·çš„æ–¹å¼è®¡ç®—å‡ºQã€Kã€Vçš„å€¼ï¼Œæ‰€ä»¥Visual transformerçš„æ¨¡åž‹ç»“æž„é€‚ç”¨äºŽä»»ä½•é•¿åº¦çš„sequenceã€‚æœ€ç»ˆè¾“å‡ºé¢„æµ‹çš„æ—¶å€™ï¼Œçœ‹æ ·å­åºåˆ—é•¿äº†å¥½å¤šï¼Œä½†å…¶å®žè¿˜æ˜¯åªå–cls tokenè¾“å‡ºä½œä¸ºè¾“å‡ºé¢„æµ‹ Clip Learning Transferable Visual Models From Natural Language Supervision Clip 2021 CLIP openaiå®˜æ–¹æºç  Openaiè¿žæŽ¥æ–‡æœ¬å’Œå›¾åƒCLIPæ¨¡åž‹(Huggingfaceç‰ˆ)zero-shotåˆ†ç±»ä»£ç æ¡ˆä¾‹ 2021å¹´è§è¯äº†vision transformerçš„å¤§çˆ†å‘ï¼Œéšç€è°·æ­Œæå‡ºViTä¹‹åŽï¼Œä¸€å¤§æ‰¹çš„vision transformerçš„å·¥ä½œå¸­å·è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚é™¤äº†vision transformerï¼Œå¦å¤–ä¸€ä¸ªå¯¹è®¡ç®—æœºè§†è§‰å½±å“æ¯”è¾ƒå¤§çš„å·¥ä½œå°±æ˜¯Open AIåœ¨2021å¹´1æœˆä»½å‘å¸ƒçš„DALL-Eå’ŒCLIPï¼Œè¿™ä¸¤ä¸ªéƒ½å±žäºŽç»“åˆå›¾åƒå’Œæ–‡æœ¬çš„å¤šæ¨¡æ€æ¨¡åž‹ DALL-Eæ˜¯åŸºäºŽæ–‡æœ¬æ¥ç”Ÿæˆæ¨¡åž‹çš„æ¨¡åž‹ CLIPæ˜¯ç”¨æ–‡æœ¬ä½œä¸ºç›‘ç£ä¿¡å·æ¥è®­ç»ƒå¯è¿ç§»çš„è§†è§‰æ¨¡åž‹ è¿™ä¸¤ä¸ªå·¥ä½œä¹ŸåƒViTä¸€æ ·å¸¦åŠ¨äº†ä¸€æ³¢æ–°çš„ç ”ç©¶é«˜æ½® æ¦‚è¿° Openaiè¿žæŽ¥æ–‡æœ¬å’Œå›¾åƒCLIPæ¨¡åž‹(Huggingfaceç‰ˆ)zero-shotåˆ†ç±»ä»£ç æ¡ˆä¾‹ CLIPçš„è‹±æ–‡å…¨ç§°æ˜¯Contrastive Language-Image Pre-trainingï¼Œå³ä¸€ç§åŸºäºŽå¯¹æ¯”æ–‡æœ¬-å›¾åƒå¯¹çš„é¢„è®­ç»ƒæ–¹æ³•æˆ–è€…æ¨¡åž‹ CLIPæ˜¯ä¸€ç§åŸºäºŽå¯¹æ¯”å­¦ä¹ çš„å¤šæ¨¡æ€æ¨¡åž‹ï¼Œä¸ŽCVä¸­çš„ä¸€äº›å¯¹æ¯”å­¦ä¹ æ–¹æ³•å¦‚mocoå’Œsimclrä¸åŒçš„æ˜¯ï¼ŒCLIPçš„è®­ç»ƒæ•°æ®æ˜¯æ–‡æœ¬-å›¾åƒå¯¹ï¼šä¸€å¼ å›¾åƒå’Œå®ƒå¯¹åº”çš„æ–‡æœ¬æè¿°ï¼Œè¿™é‡Œå¸Œæœ›é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œæ¨¡åž‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ–‡æœ¬-å›¾åƒå¯¹çš„åŒ¹é…å…³ç³» å¦‚ä¸Šå›¾(1)æ‰€ç¤ºï¼ŒCLIPåŒ…æ‹¬ä¸¤ä¸ªæ¨¡åž‹ï¼šText Encoderå’ŒImage Encoderï¼Œå…¶ä¸­Text Encoderç”¨æ¥æå–æ–‡æœ¬çš„ç‰¹å¾ï¼Œå¯ä»¥é‡‡ç”¨NLPä¸­å¸¸ç”¨çš„text transformeræ¨¡åž‹ï¼›è€ŒImage Encoderç”¨æ¥æå–å›¾åƒçš„ç‰¹å¾ï¼Œå¯ä»¥é‡‡ç”¨å¸¸ç”¨CNNæ¨¡åž‹æˆ–è€…vision transformer å¯¹æå–çš„æ–‡æœ¬ç‰¹å¾å’Œå›¾åƒç‰¹å¾è¿›è¡Œå¯¹æ¯”å­¦ä¹  å¯¹äºŽä¸€ä¸ªåŒ…å«Nä¸ªæ–‡æœ¬-å›¾åƒå¯¹çš„è®­ç»ƒbatchï¼Œå°†Nä¸ªæ–‡æœ¬ç‰¹å¾å’ŒNä¸ªå›¾åƒç‰¹å¾ä¸¤ä¸¤ç»„åˆï¼ŒCLIPæ¨¡åž‹ä¼šé¢„æµ‹å‡ºNæ–¹ä¸ªå¯èƒ½çš„æ–‡æœ¬-å›¾åƒå¯¹çš„ç›¸ä¼¼åº¦ï¼Œè¿™é‡Œçš„ç›¸ä¼¼åº¦ç›´æŽ¥è®¡ç®—æ–‡æœ¬ç‰¹å¾å’Œå›¾åƒç‰¹å¾çš„ä½™å¼¦ç›¸ä¼¼æ€§(cosine similarity)ï¼Œå³ä¸Šå›¾æ‰€ç¤ºçš„çŸ©é˜µ è¿™é‡Œå…±æœ‰Nä¸ªæ­£æ ·æœ¬ï¼Œå³çœŸæ­£å±žäºŽä¸€å¯¹çš„æ–‡æœ¬å’Œå›¾åƒ(çŸ©é˜µä¸­çš„å¯¹è§’çº¿å…ƒç´ )ï¼Œè€Œå‰©ä½™çš„N*(N-1)ä¸ªæ–‡æœ¬-å›¾åƒå¯¹ä¸ºè´Ÿæ ·æœ¬ é‚£ä¹ˆCLIPçš„è®­ç»ƒç›®æ ‡å°±æ˜¯æœ€å¤§Nä¸ªæ­£æ ·æœ¬çš„ç›¸ä¼¼åº¦ï¼ŒåŒæ—¶æœ€å°åŒ–Næ–¹-Nä¸ªè´Ÿæ ·æœ¬çš„ç›¸ä¼¼åº¦ ä¸ºäº†è®­ç»ƒCLIPï¼ŒOpenAIä»Žäº’è”ç½‘æ”¶é›†äº†å…±4ä¸ªäº¿çš„æ–‡æœ¬-å›¾åƒå¯¹ zero-shotåˆ†ç±» ä¸ŽCVä¸­å¸¸ç”¨çš„å…ˆé¢„è®­ç»ƒç„¶åŽå¾®è°ƒä¸åŒï¼ŒCLIPå¯ä»¥ç›´æŽ¥å®žçŽ°zero-shotçš„å›¾åƒåˆ†ç±»ï¼Œå³ä¸éœ€è¦ä»»ä½•è®­ç»ƒæ•°æ®ï¼Œå°±èƒ½åœ¨æŸä¸ªå…·ä½“ä¸‹æ¸¸ä»»åŠ¡ä¸Šå®žçŽ°åˆ†ç±»ï¼Œè¿™ä¹Ÿæ˜¯CLIPäº®ç‚¹å’Œå¼ºå¤§ä¹‹å¤„ æ ¹æ®ä»»åŠ¡çš„åˆ†ç±»æ ‡ç­¾æž„å»ºæ¯ä¸ªç±»åˆ«çš„æè¿°æ–‡æœ¬ï¼šA photo of {label}ï¼Œç„¶åŽå°†è¿™äº›æ–‡æœ¬é€å…¥Text Encoderå¾—åˆ°å¯¹åº”çš„æ–‡æœ¬ç‰¹å¾ å°†è¦é¢„æµ‹çš„å›¾åƒé€å…¥Image Encoderå¾—åˆ°å›¾åƒç‰¹å¾ï¼Œç„¶åŽä¸ŽNä¸ªæ–‡æœ¬ç‰¹å¾è®¡ç®—ç¼©æ”¾çš„ä½™å¼¦ç›¸ä¼¼åº¦(å’Œè®­ç»ƒè¿‡ç¨‹ä¸€è‡´) ç„¶åŽé€‰æ‹©ç›¸ä¼¼åº¦æœ€å¤§çš„æ–‡æœ¬å¯¹åº”çš„ç±»åˆ«ä½œä¸ºå›¾åƒåˆ†ç±»é¢„æµ‹ç»“æžœï¼Œè¿›ä¸€æ­¥åœ°ï¼Œå¯ä»¥å°†è¿™äº›ç›¸ä¼¼åº¦çœ‹æˆlogitsï¼Œé€å…¥softmaxåŽå¯ä»¥åˆ°æ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æ¦‚çŽ‡ from PIL import Image from transformers import CLIPProcessor,CLIPModel model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\") processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\") #è¿™é‡ŒåŠ å…¥è‡ªå·±å›¾ç‰‡çš„åœ°å€å°±è¡Œ image = Image.open('xxx.jpg') #è¿™é‡ŒåŠ å…¥ç±»åˆ«çš„æ ‡ç­¾ç±»åˆ« text = ['plane','car','dog','bird'] inputs = processor(text=text,images = image,return_tensors=\"pt\",padding=True) outputs = model(**inputs) logits_per_image = outputs.logits_per_image probs = logits_per_image.softmax(dim=1) for i in range(len(text)): print(text[i],\":\",probs[0][i]) ä½¿ç”¨CLIPè¿›è¡Œzero-shotåˆ†ç±»ï¼Œå¦å¤–ä¸€ä¸ªæ¯”è¾ƒé‡è¦çš„åœ°æ–¹æ˜¯æ–‡æœ¬æè¿°çš„ç”Ÿæˆï¼Œä¸Šé¢çš„ä¾‹å­æˆ‘ä»¬é‡‡ç”¨åˆ†ç±»æ ‡ç­¾ï¼Œä½†å…¶å®žä¹Ÿæœ‰å…¶å®ƒé€‰æ‹© æ¯”å¦‚æˆ‘ä»¬ç›´æŽ¥ç”¨ç±»åˆ«æ ‡ç­¾ï¼Œè¿™å…¶å®žå±žäºŽæœ€è¿‘NLPé¢†åŸŸæ¯”è¾ƒç«çš„ä¸€ä¸ªç ”ç©¶ï¼šprompt learningæˆ–è€…prompt engineering æ‰©å±• CLIPæ˜¯åŸºäºŽæ–‡æœ¬-å›¾åƒå¯¹æ¥åšçš„ï¼Œä½†æ˜¯å®ƒå¯ä»¥æ‰©å±•åˆ°æ–‡æœ¬-è§†é¢‘ï¼Œæ¯”å¦‚VideoCLIPå°±æ˜¯å°†CLIPåº”ç”¨åœ¨è§†é¢‘é¢†åŸŸæ¥å®žçŽ°ä¸€äº›zero-shotè§†é¢‘ç†è§£ä»»åŠ¡ VQGAN+CLIPå®žçŽ°å„ç§å›¾åƒç”Ÿæˆæ¨¡åž‹ TOnICS Curriculum Learning for Data-Efficient Vision-Language Alignment TOnICS 2022 è¶…è¶ŠCLIPçš„å¤šæ¨¡æ€æ¨¡åž‹ï¼Œåªéœ€ä¸åˆ°1%çš„è®­ç»ƒæ•°æ®ï¼å—åŠ å¤§æœ€æ–°ç ”ç©¶æ¥äº† CLIP(Contrastive Languageâ€“Image Pre-training)ï¼Œæ˜¯ä¸€ç§åŸºäºŽå¯¹æ¯”çš„å›¾ç‰‡-æ–‡æœ¬å­¦ä¹ çš„è·¨æ¨¡æ€é¢„è®­ç»ƒæ¨¡åž‹ï¼Œç”±OpenAIäºŽ2021å¹´1æœˆå‘å¸ƒ å®ƒå­˜åœ¨ä¸€ä¸ªç¼ºç‚¹å°±æ˜¯æ•°æ®éœ€æ±‚å¤ªå¤§ï¼š4äº¿ä¸ªå›¾åƒæ–‡æœ¬å¯¹ã€256ä¸ªGPUï¼Œè¿™å¯¹è®¸å¤šå…¬å¸å’Œä¸ªäººéƒ½å¾ˆä¸å‹å¥½ å¯¹æ­¤ï¼Œå—åŠ å·žå¤§å­¦çš„æœ€æ–°ç ”ç©¶å‘çŽ°äº†ä¸€ç§åŸºäºŽæœ¬ä½“çš„è¯¾ç¨‹å­¦ä¹ (Curriculum Learning)ç®—æ³•ï¼Œåªéœ€ä¸åˆ°1%çš„è®­ç»ƒæ•°æ®å°±èƒ½è¾¾åˆ°CLIPåŒæ¬¾æ•ˆæžœï¼Œç”šè‡³åœ¨å›¾åƒæ£€ç´¢æ–¹é¢è¡¨çŽ°æ›´å¥½ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/æ•°æ®æ ‡æ³¨å·¥å…·.html":{"url":"chapters/æ•°æ®æ ‡æ³¨å·¥å…·.html","title":"æ•°æ®æ ‡æ³¨å·¥å…·.md","summary":null,"keywords":"","body":"label-studioå‰ç«¯å®‰è£…æ•°æ®åº“é…ç½®å¯¼å…¥çŽ°æœ‰æ ‡æ³¨Cloudreveæ•°æ®å¯¼å…¥æ–°å»ºæ ‡æ³¨é¡¹ç›®åŽç«¯Roboflow label-studio label-studioç¤¾åŒºç‰ˆå’Œä¼ä¸šç‰ˆæ¯”è¾ƒ Label Studioæ˜¯ä¸€ä¸ªå¼€æºçš„ï¼Œå¯é…ç½®çš„æ•°æ®æ³¨é‡Šå·¥å…·ï¼Œå…¶ç›®çš„æ˜¯ä½¿æ‚¨èƒ½å¤Ÿä½¿ç”¨æ ‡å‡†åŒ–è¾“å‡ºæ ¼å¼çš„æœ€æ–¹ä¾¿çš„ç•Œé¢æ ‡è®°ä¸åŒç±»åž‹çš„æ•°æ® ç‰¹è‰²ï¼šæ”¯æŒå¤šäººåä½œï¼Œæ”¯æŒä¸»åŠ¨å­¦ä¹ ã€æ”¯æŒå¤šç§çš„æ ‡æ³¨çš„ä»»åŠ¡ ç¼ºç‚¹ï¼šåœ¨ç›®æ ‡æ£€æµ‹æ ‡æ³¨æ—¶ï¼Œå¥½åƒæ²¡æœ‰åå­—è¾…åŠ©çº¿ æ”¯æŒçš„æ ‡æ³¨ä»»åŠ¡ï¼ŒåŒ…æ‹¬äº†å¦‚ä¸‹æ‰€ç¤ºï¼Œå…·ä½“çš„è§å®˜æ–¹gitä»‹ç» label studio ç»“åˆ MMDetection å®žçŽ°æ•°æ®é›†è‡ªåŠ¨æ ‡è®°ã€æ¨¡åž‹è¿­ä»£è®­ç»ƒçš„é—­çŽ¯ Label Studioä½¿ç”¨æŠ€å·§ å…³é”®çš„ä¸¤ä¸ªgitä»“åº“ï¼Œå…¶ä¸­label-studioçš„å®˜æ–¹æ–‡æ¡£åœ¨è¿™é‡Œ label-studioï¼Œ è¿›è¡Œæ™®é€šçš„å›¾ç‰‡æ ‡è®°å·¥ä½œï¼Œå¦‚æžœè¦ä½¿ç”¨å…¶æä¾›çš„è¾…åŠ©é¢„æ ‡è®°åŠŸèƒ½ï¼Œåˆ™éœ€è¦è¿›è¡ŒåŽç»­é…ç½® label-studio-ml-backendï¼Œä¸»è¦æä¾›æ·±åº¦å­¦ä¹ æœåŠ¡ï¼ŒåŒ…æ‹¬é¢„æ ‡è®°å’Œæ¨¡åž‹è®­ç»ƒï¼Œç»“åˆå‰ç«¯å½¢æˆæ¨¡åž‹è¿­ä»£è®­ç»ƒçš„ä¸»åŠ¨å­¦ä¹ æ•ˆæžœ å‰åŽç«¯ç»“åˆå¯ä»¥è¾¾åˆ°æ¨¡åž‹è‡ªåŠ¨æ ‡è®°æ•°æ®é›†ã€æ•°æ®é›†æ›´æ–°è¿­ä»£è®­ç»ƒæ¨¡åž‹çš„é—­çŽ¯ å‰ç«¯ å®‰è£… pip install label-studio # å¦‚æžœå®‰è£…psycopg2==2.9.5 å¤±è´¥, å¯ä»¥å…ˆè£…ä¸‹ä¸‹é¢çš„åº“ sudo yum install python-devel postgresql-devel postgresql-libs gcc çŽ¯å¢ƒå®‰è£…å®ŒæˆåŽåœ¨ä»»æ„ä½ç½®æ‰“å¼€å‘½ä»¤è¡Œï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨ label studio # ä¸æŒ‡å®šè·¯å¾„æ—¶, é»˜è®¤æ”¾åœ¨äº† /root/.local/share/label-studio label-studio --data-dir Label-Studio -p 80 å…¶ä¸­ --data-dir ç”¨äºŽæŒ‡å®šå·¥ä½œç›®å½•ï¼Œ -p ç”¨æ¥æŒ‡å®šè¿è¡Œç«¯å£ï¼Œè¿è¡ŒæˆåŠŸåŽä¼šå½“å‰ç›®å½•ä¼šç”Ÿæˆ Label-Studio ç›®å½• æµè§ˆå™¨æ‰“å¼€label studioå·¥ä½œç•Œé¢ï¼Œåˆ›å»ºç”¨æˆ·åŽå³å¯ç™»å½•ä½¿ç”¨(è¿™é‡Œçš„åˆ›å»ºå¾ˆç®€å•ï¼Œç¬¦åˆè§„èŒƒå°±å¯ä»¥) æ–‡ä»¶å¤¹ä¸­ä¸»è¦åŒ…æ‹¬äº†exportå’Œmediaæ–‡ä»¶å¤¹ï¼Œä»¥åŠä¸€ä¸ªlabel_studio.sqlite3æ•°æ®åº“æ–‡ä»¶ æ•°æ®åº“é…ç½® æ•°æ®åº“é»˜è®¤ä½¿ç”¨çš„æ˜¯sqlite3ï¼Œè¿˜å¯ä»¥é…ç½®å…¶ä»–çš„å…³ç³»åº“ï¼Œå¦‚PostgreSQLç­‰ï¼Œé€šå¸¸å¦‚æžœä½ æƒ³æ ‡æ³¨æ•°ç™¾ä¸‡ä¸ªä»»åŠ¡ï¼Œæˆ–è€…é¢„è®¡ä¼šæœ‰å¾ˆå¤šå¹¶å‘ç”¨æˆ·ï¼Œæˆ–è€…ä½ è®¡åˆ’åœ¨çŽ°å®žç”Ÿæ´»ä¸­çš„é¡¹ç›®ä¸­å·¥ä½œï¼Œé‚£ä¹ˆä½¿ç”¨PostgreSQLæ•°æ®åº“ å®˜æ–¹æä¾›çš„è®¾ç½®pgçš„çŽ¯å¢ƒå˜é‡å¥½åƒä¸èµ·æ•ˆæžœï¼Œä¸çŸ¥é“æŠŠæ•°æ®åº“å»ºå“ªé‡ŒåŽ»äº†ï¼Œè¿™é‡Œç›´æŽ¥åœ¨å‘½ä»¤è¡Œå¸¦ä¸Špgåº“çš„å‚æ•° DJANGO_DB=default POSTGRE_NAME=label_studio_db POSTGRE_USER=postgres POSTGRE_PASSWORD=xxx POSTGRE_PORT=5432 POSTGRE_HOST=192.168.123.xx LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/home/huangyc/label_ws label-studio start --data-dir /home/huangyc/label_ws -p 8080 LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOTç”¨äºŽæŒ‡å®šæœ¬åœ°æ–‡ä»¶çš„ä½ç½®ï¼Œé¡¹ç›®è®¾ç½®é‡Œé¢é…ç½®æœ¬åœ°è·¯å¾„ä¸º/home/huangyc/label_ws/media(è¿™åªæ˜¯ä¸ªä¾‹å­å¥½åƒé…æˆ/home/huangyc/label_ws/media/uploadä¹Ÿæ˜¯ä¸€æ ·çš„)ï¼Œæ­¤æ—¶å¯ä»¥è®¿é—® # æ³¨æ„?dåŽé¢çš„è·¯å¾„æ˜¯LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOTé…ç½®çš„è·¯å¾„åŽé¢ç»§ç»­å¼€å§‹ http://192.168.123.xx:8080/data/local-files?d=media/upload/3/demo.jpg å½“å‰ç›®å½•ç»“æž„å¦‚ä¸‹ (label38) [root@uslave02 label_ws]# tree -d . â”œâ”€â”€ export â””â”€â”€ media â”œâ”€â”€ avatars â”œâ”€â”€ export â””â”€â”€ upload â”œâ”€â”€ 1 â”œâ”€â”€ 3 â”œâ”€â”€ demo.jpg â””â”€â”€ 4 8 directories æ³¨æ„è¿™é‡Œéœ€è¦æå‰åˆ›å»ºå¥½æ•°æ®åº“label_studio_dbï¼Œå¯åŠ¨å®ŒæˆæŽ§åˆ¶å°è¾“å‡ºå¦‚ä¸‹çš„æ—¥å¿— label-studio start --data-dir /home/huangyc/label_ws -p 8080 => Database and media directory: /root/.local/share/label-studio => Static URL is set to: /static/ => Database and media directory: /home/huangyc/label_ws => Static URL is set to: /static/ Starting new HTTPS connection (1): pypi.org:443 https://pypi.org:443 \"GET /pypi/label-studio/json HTTP/1.1\" 200 56156 Initializing database.. Performing system checks... [2023-03-29 05:01:46,560] [django::register_actions_from_dir::97] [INFO] No module named 'data_manager.actions.__pycache_' [2023-03-29 05:01:46,560] [django::register_actions_from_dir::97] [INFO] No module named 'data_manager.actions.__pycache_' System check identified no issues (1 silenced). March 29, 2023 - 05:01:46 Django version 3.2.16, using settings 'label_studio.core.settings.label_studio' Starting development server at http://0.0.0.0:8080/ Quit the server with CONTROL-C. æ­¤æ—¶æ•°æ®åº“label_studio_dbé‡Œé¢ä¼šå»ºå¥½æ‰€æœ‰çš„è¡¨ï¼Œæ¯”å¦‚htx_userå­˜çš„å°±æ˜¯æ³¨å†Œçš„ç”¨æˆ·ä¿¡æ¯ å¦‚æžœè¦åŽå°æ‰§è¡Œï¼Œå¯ä»¥æ–°å»ºä¸€ä¸ªstart.shè„šæœ¬ DJANGO_DB=default POSTGRE_NAME=label_studio_db POSTGRE_USER=postgres POSTGRE_PASSWORD=xxx POSTGRE_PORT=5432 POSTGRE_HOST=192.168.123.xx label-studio start --data-dir /home/huangyc/label_ws -p 8080 ç„¶åŽæ‰§è¡Œnohup sh start.sh > log_start.log & å¯¼å…¥çŽ°æœ‰æ ‡æ³¨ å°†çŽ°æœ‰æ ‡æ³¨è½¬ä¸ºjsonæ ¼å¼å¯ä»¥ç”¨label-studio-converterå·¥å…·ï¼Œå®‰è£…å‘½ä»¤ä¸ºpip install label-studio-converter è½¬æ¢çš„ä¾‹å­ï¼Œç›®å½•ç»“æž„ä¸º: Q:. â”œâ”€images â”œâ”€ 1.jpg â”œâ”€ 2.jpg â””â”€labels â”œâ”€ 1.txt â”œâ”€ 2.txt â”œâ”€ classes.txt # æ³¨æ„è¿™é‡Œçš„classes.txté‡Œé¢çš„ç±»åˆ«é¡ºåºä¸€å®šè¦æ­£ç¡®ï¼Œå¦‚æžœæ˜¯ä»Žlabel-studioå‰ç«¯å¯¼å‡ºçš„ï¼Œå¥½åƒé¡ºåºä¼šæœ‰é—®é¢˜ï¼Œå¯ä»¥ç”¨notes.jsonåŽ»èŽ·å–æ­£ç¡®çš„é¡ºåº # ä»£ç ä¸º annotation_labels = json_load_op('notes.json')['categories'] annotation_labels = sorted(annotation_labels, key=lambda k: int(k['id'])) annotation_labels = [anno['name'] for anno in annotation_labels] å‘½ä»¤è¡Œä¸º label-studio-converter import yolo -i project-1 -o ls-tasks.json --image-root-url /data/local-files?d=tmp/images è¾“å‡ºls-tasks.jsonå’Œls-tasks.label_config.xmlä¸¤ä¸ªæ–‡ä»¶ï¼Œç¬¬ä¸€ä¸ªæ˜¯æ•°æ®çš„ç´¢å¼•å’Œæ ‡ç­¾ä¿¡æ¯ï¼Œç¬¬äºŒä¸ªæ˜¯é¡¹ç›®çš„æ ‡ç­¾é…ç½®æ–‡ä»¶ æ­¤æ—¶è¦æŠŠæ–‡ä»¶ä¸Šä¼ åˆ°LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT/tmp/imagesä¸‹æ‰å¯ä»¥çœ‹åˆ° å¦‚æžœè¿™é‡Œè½¬æ¢å‡ºæ¥çš„è·¯å¾„ä¸å¯¹ï¼Œå¯ä»¥ä¿®æ”¹label_studio_converter\\imports\\yolo.py.pyä¸‹çš„ task = { \"data\": { # eg. '../../foo+you.py' -> '../../foo%2Byou.py' \"image\": f\"{image_root_url}{sp}{image_file_base}\" # æ”¹å®ŒåŽçš„ }, # 'annotations' or 'predictions' out_type: [ { \"result\": [], \"ground_truth\": False, } ] } ä¸ç„¶ä¼šè®¿é—®ä¸åˆ°æ•°æ® å¦‚æžœæ•°æ®æ²¡æœ‰æ ‡æ³¨ä¿¡æ¯ï¼Œå¯ä»¥å°†æ•°æ®ä¼ åˆ°LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT/tmp/imagesä¸‹ï¼Œå¹¶ç”Ÿæˆå¦‚ä¸‹jsonæ–‡ä»¶ï¼Œå¹¶åœ¨é¡¹ç›®ç•Œé¢å¯¼å…¥è¯¥æ–‡ä»¶å³å¯ [ {\"image\":\"/data/local-files?d=tmp/images/175.jpg\"}, {\"image\":\"/data/local-files?d=tmp/images/696.jpg\"} ] Cloudreveæ•°æ®å¯¼å…¥ cloudreveç§æœ‰äº‘ç›˜é…ç½®åŽå°è¿è¡Œ å®‰è£…é…ç½®Cloudreve Cloudreveå¯åŠ©ä½ å³åˆ»æž„å»ºå‡ºå…¼å¤‡è‡ªç”¨æˆ–å…¬ç”¨çš„ç½‘ç›˜æœåŠ¡ï¼Œé€šè¿‡å¤šç§å­˜å‚¨ç­–ç•¥çš„æ”¯æŒã€è™šæ‹Ÿæ–‡ä»¶ç³»ç»Ÿç­‰ç‰¹æ€§å®žçŽ°çµæ´»çš„æ–‡ä»¶ç®¡ç†ä½“éªŒ Linux ä¸‹ï¼Œç›´æŽ¥è§£åŽ‹å¹¶æ‰§è¡Œä¸»ç¨‹åºå³å¯ï¼š #è§£åŽ‹èŽ·å–åˆ°çš„ä¸»ç¨‹åº tar -zxvf cloudreve_VERSION_OS_ARCH.tar.gz # èµ‹äºˆæ‰§è¡Œæƒé™ chmod +x ./cloudreve # å¯åŠ¨ Cloudreve nohup ./cloudreve > start.log & Windowsä¸‹ï¼Œç›´æŽ¥è§£åŽ‹èŽ·å–åˆ°çš„ zip åŽ‹ç¼©åŒ…ï¼Œå¯åŠ¨ cloudreve.exe å³å¯ Cloudreveåœ¨é¦–æ¬¡å¯åŠ¨æ—¶ï¼Œä¼šåˆ›å»ºåˆå§‹ç®¡ç†å‘˜è´¦å·ï¼Œè¯·æ³¨æ„ä¿ç®¡ç®¡ç†å‘˜å¯†ç ï¼Œæ­¤å¯†ç åªä¼šåœ¨é¦–æ¬¡å¯åŠ¨æ—¶å‡ºçŽ°ã€‚å¦‚æžœæ‚¨å¿˜è®°åˆå§‹ç®¡ç†å‘˜å¯†ç ï¼Œéœ€è¦åˆ é™¤åŒçº§ç›®å½•ä¸‹çš„cloudreve.dbï¼Œé‡æ–°å¯åŠ¨ä¸»ç¨‹åºä»¥åˆå§‹åŒ–æ–°çš„ç®¡ç†å‘˜è´¦æˆ·ã€‚æˆ–è€…ä½¿ç”¨./cloudreve --database-script ResetAdminPasswordé‡ç½®å¯†ç  Cloudreveé»˜è®¤ä¼šç›‘å¬5212ç«¯å£ã€‚ä½ å¯ä»¥åœ¨æµè§ˆå™¨ä¸­è®¿é—®http://æœåŠ¡å™¨IP:5212è¿›å…¥ Cloudreveã€‚ ä»¥ä¸Šæ­¥éª¤æ“ä½œå®ŒåŽï¼Œæœ€ç®€å•çš„éƒ¨ç½²å°±å®Œæˆäº†ã€‚ä½ å¯èƒ½éœ€è¦ä¸€äº›æ›´ä¸ºå…·ä½“çš„é…ç½®ï¼Œæ‰èƒ½è®© Cloudreve æ›´å¥½çš„å·¥ä½œ ç™»å½•ç®¡ç†å‘˜ï¼Œç¼–è¾‘å­˜å‚¨ç­–ç•¥ä¸‹çš„Default storage policyï¼Œå°†å­˜å‚¨æ–‡ä»¶åæ”¹ä¸º{originname}ï¼Œä¸ç„¶ä¼šé»˜è®¤ä¼šå¸¦ä¸Šä¸€äº›å‰ç¼€ Cloudreveçš„æ–‡ä»¶å®žé™…ä¸Šæ˜¯å­˜å‚¨åœ¨/home/huangyc/cloudreve/uploads/1ä¸‹ï¼Œåœ¨æ­¤ç›®å½•ä¸‹æ–°å»ºè½¯é“¾æŽ¥label_wsåˆ°label-studioçš„å·¥ä½œç›®å½•ä¸‹ï¼Œè‡³æ­¤ [root@uslave02 1]# ln -s /home/huangyc/label_ws/uploads label_ws [root@uslave02 1]# pwd /home/huangyc/cloudreve/uploads/1 æ­¤æ—¶ï¼Œç•Œé¢ç½‘é¡µä¸Šå¯ä»¥çœ‹åˆ°label_wsæ–‡ä»¶å¤¹ï¼ŒåŽç»­çš„é¡¹ç›®æ–‡ä»¶å¯ä»¥ä¼ åˆ°è¿™é‡Œï¼Œè‡³æ­¤Cloudreveé…ç½®å®Œæˆ label-studioé¡¹ç›®è®¾ç½® è¿™é‡Œå¯ä»¥å°†label-studioé¡¹ç›®çš„äº‘å­˜å‚¨ä½ç½®è®¾ç½®ä¸ºæœ¬åœ°/home/huangyc/label_ws/uploadsï¼Œç„¶åŽå¯¼å…¥ä¸€ä¸‹jsonæ–‡ä»¶åˆ°é¡¹ç›® [ {\"image\":\"/data/local-files?d=uploads/tricycle_samples/ç­é¬¼ä¹‹åˆƒ.png\"} ] æœ€åŽé€šè¿‡Cloudreveï¼ŒæŠŠæ–‡ä»¶ç­é¬¼ä¹‹åˆƒ.pngä¸Šä¼ åˆ°label_ws/tricycle_samplesä¸‹å°±å¯ä»¥çœ‹åˆ°å›¾ç‰‡äº†ï¼Œæ³¨æ„ï¼šè¿™é‡Œçš„label_wsç›¸å½“äºŽ/home/huangyc/label_ws/uploadsï¼Œè¿™å°±æ˜¯è½¯é“¾æŽ¥çš„é­…åŠ› æ–°å»ºæ ‡æ³¨é¡¹ç›® åœ¨ label studio å‰ç«¯ä¸»é¡µä¸­é€‰æ‹©åˆ›å»ºé¡¹ç›®ï¼Œä¸»è¦æµç¨‹ å¡«å†™é¡¹ç›®åŸºæœ¬ä¿¡æ¯ å¯¼å…¥æ•°æ® é€‰æ‹©æ ‡è®°æ¨¡æ¿: label studioå†…ç½®äº†å¾ˆå¤šå¸¸è§çš„æ·±åº¦å­¦ä¹ æ ‡è®°æ¨¡æ¿ ä»¥ä¸‹æ˜¯ç›®æ ‡æ£€æµ‹çš„æ¨¡æ¿ categoryå¾ˆé‡è¦ï¼Œèƒ½ä¿è¯æ ‡ç­¾çš„é¡ºåºï¼Œè¿™é‡Œè¦ä»Ž0å¼€å§‹ æ­¤æ—¶æˆ‘ä»¬å·²ç»å¯ä»¥é€šè¿‡ label studio è¿›è¡Œæ™®é€šçš„å›¾ç‰‡æ ‡è®°å·¥ä½œï¼Œå¦‚æžœè¦ä½¿ç”¨å…¶æä¾›çš„è¾…åŠ©é¢„æ ‡è®°åŠŸèƒ½ï¼Œåˆ™éœ€è¦è¿›è¡ŒåŽç»­é…ç½® åŽç«¯ label studio mlæ˜¯label studioçš„åŽç«¯é…ç½®ï¼Œå…¶ä¸»è¦æä¾›äº†ä¸€ç§èƒ½å¤Ÿå¿«é€Ÿå°†AIæ¨¡åž‹å°è£…ä¸ºlabel studioå¯ä½¿ç”¨çš„é¢„æ ‡è®°æœåŠ¡(æä¾›æ¨¡åž‹é¢„æµ‹æœåŠ¡) å®‰è£…: ä¾èµ–äº†rqåº“å’Œredisåº“ï¼Œæ³¨æ„æœ‰äº›åº“çš„ç‰ˆæœ¬ä¸èƒ½è¿‡é«˜ pip install label-studio-ml åˆ›å»ºåŽç«¯æ¨¡åž‹ å¯¼å…¥ç›¸å…³åº“ import os from PIL import Image from label_studio_ml import model from label_studio_ml.model import LabelStudioMLBase from label_studio_ml.utils import get_env from label_studio_tools.core.utils.io import get_local_path model.LABEL_STUDIO_ML_BACKEND_V2 = True os.environ['HOSTNAME'] = 'http://192.168.123.xx:8080' os.environ['API_KEY'] = 'TOKEN,åœ¨é¡¹ç›®çš„settingsé‡Œé¢å¤åˆ¶' os.environ['LABEL_STUDIO_ML_BACKEND_V2'] = 'True' æ¨¡åž‹ç±» class MyModel(LabelStudioMLBase): def __init__(self, **kwargs): super(MyModel, self).__init__(**kwargs) # æŒ‰ mmdetection çš„æ–¹å¼åŠ è½½æ¨¡åž‹åŠæƒé‡ print(kwargs) print(\"åˆå§‹åŒ–å®Œæˆ\") def predict(self, tasks, **kwargs): # èŽ·å–å¾…æ ‡è®°å›¾ç‰‡ print(\"å¼€å§‹é¢„æµ‹\") images = [get_local_path(task['data']['image'], hostname=HOSTNAME, access_token=API_KEY) for task in tasks] results = [] all_scores = [] # è¿™é‡Œåªæ˜¯ç¤ºä¾‹, è¿”å›žç»“æžœéƒ½ä¸€æ · for img_path in images: for _ in range(1): w, h = Image.open(img_path).size pixel_x, pixel_y, pixel_width, pixel_height = convert_to_ls(0, 0, 200, 250, w, h) result = { 'id': '0', # å¿…é¡»ä¸º strï¼Œå¦åˆ™å‰ç«¯ä¸æ˜¾ç¤º 'from_name': 'label', 'to_name': 'image', 'type': 'rectanglelabels', 'value': { 'rectanglelabels': ['tricycle'], 'x': pixel_x, # xy ä¸ºå·¦ä¸Šè§’åæ ‡ç‚¹ 'y': pixel_y, 'width': pixel_width, # width,height ä¸ºå®½é«˜ 'height': pixel_height }, 'score': 0.95 } results.append(result) all_scores.append(0.95) print(tasks) print(kwargs) avg_score = sum(all_scores) / max(len(all_scores), 1) results = [{ 'result': results, 'score': avg_score }] return results def fit(self, completions, num_epochs=5, **kwargs): \"\"\" æ¨¡åž‹è®­ç»ƒ \"\"\" print(\"å¼€å§‹è®­ç»ƒ\") if self.gen_train_data(project_id): # è®­ç»ƒæ¨¡åž‹ return {'model_path': r'\\runs\\detect\\TriCycle\\weights\\best.pt'} else: raise \"gen_train_data error\" def gen_train_data(self, project_id): \"\"\" èŽ·å–æ•°æ®è®­ç»ƒæ•°æ® \"\"\" print(\"èŽ·å–æ•°æ® project_id\", project_id) import zipfile import glob download_url = f'{HOSTNAME.rstrip(\"/\")}/api/projects/{project_id}/export?export_type=COCO&download_all_tasks=false&download_resources=true' response = requests.get(download_url, headers={'Authorization': f'Token {API_KEY}'}) zip_path = os.path.join(conf['workdir'], \"train.zip\") train_path = os.path.join(conf['workdir'], \"train\") with open(zip_path, 'wb') as file: file.write(response.content) # é€šè¿‡äºŒè¿›åˆ¶å†™æ–‡ä»¶çš„æ–¹å¼ä¿å­˜èŽ·å–çš„å†…å®¹ file.flush() f = zipfile.ZipFile(zip_path) # åˆ›å»ºåŽ‹ç¼©åŒ…å¯¹è±¡ f.extractall(train_path) # åŽ‹ç¼©åŒ…è§£åŽ‹ç¼© f.close() os.remove(zip_path) if not os.path.exists(os.path.join(train_path, \"images\", str(project_id))): os.makedirs(os.path.join(train_path, \"images\", str(project_id))) for img in glob.glob(os.path.join(train_path, \"images\", \"*.jpg\")): basename = os.path.basename(img) shutil.move(img, os.path.join(train_path, \"images\", str(project_id), basename)) return True å¯åŠ¨åŽç«¯æœåŠ¡: åˆ†ä¸ºä¸‰æ­¥ï¼Œç”ŸæˆæœåŠ¡ä»£ç +å¯åŠ¨æœåŠ¡+è¿žæŽ¥æœåŠ¡+è®­ç»ƒæ¨¡åž‹ ç¬¬ä¸€æ­¥ï¼šç”ŸæˆæœåŠ¡ä»£ç  label-studio-ml init backend/model --script label_studio_backend/yolo_detection.py --force label-studio-ml init å‘½ä»¤æä¾›äº†ä¸€ç§æ ¹æ®åŽç«¯æ¨¡åž‹è‡ªåŠ¨ç”ŸæˆåŽç«¯æœåŠ¡ä»£ç çš„åŠŸèƒ½ï¼Œ model ä¸ºè¾“å‡ºç›®å½•ï¼Œ --script æŒ‡å®šåŽç«¯æ¨¡åž‹è·¯å¾„ï¼Œ --force è¡¨ç¤ºè¦†ç›–ç”Ÿæˆã€‚è¯¥å‘½ä»¤æ‰§è¡ŒæˆåŠŸåŽä¼šåœ¨ backend ç›®å½•ä¸‹ç”Ÿæˆ model ç›®å½• ä¸»è¦åŒ…æ‹¬äº†_wsgi.pyã€docker-compose.ymlã€Dockerfileã€yolo_detection.pyç­‰æ–‡ä»¶ ç¬¬äºŒæ­¥ï¼šå¯åŠ¨æœåŠ¡ å¦‚æžœæœ‰ä¾èµ–çš„æ–‡ä»¶ï¼Œéœ€è¦è‡ªå·±å¤åˆ¶åˆ° model ç›®å½•ä¸‹ï¼ŒæŽ¥ç€å¯åŠ¨åŽç«¯æœåŠ¡ label-studio-ml start backend/model --host 0.0.0.0 -p 8888 # or python backend/model/_wsgi.py --host 0.0.0.0 -p 8888 # æ–¹ä¾¿debug å¯åŠ¨æˆåŠŸçš„è¯ï¼ŒæŽ§åˆ¶å°ä¼šè¾“å‡ºå¦‚ä¸‹çš„æ—¥å¿— => ROOT = Q:\\pyCharmWS\\object_detection\\smart_city_management\\label_studio_backend\\backend\\yolo-detector => LABEL STUDIO HOSTNAME = http://192.168.123.xx:8080 * Serving Flask app \"label_studio_ml.api\" (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off [2023-03-29 14:21:59,286] [WARNING] [werkzeug::_log::225] * Running on all addresses. WARNING: This is a development server. Do not use it in a production deployment. [2023-03-29 14:21:59,286] [INFO] [werkzeug::_log::225] * Running on http://10.10.0.xx:8888/ (Press CTRL+C to quit) PS: æµ‹è¯•çš„æ—¶å€™å‘çŽ°ï¼Œç›´æŽ¥æ‰§è¡Œ_wsgi.pyæ–‡ä»¶ä¸€æ ·å¯ä»¥å¯åŠ¨åŽç«¯ï¼Œè·Ÿè¸ªlabel_studio_mlçš„server.pyæ–‡ä»¶å¯ä»¥çœ‹åˆ°æ‰§è¡Œæ ¸å¿ƒä»£ç  def main(): args, subargs = get_args() if args.command == 'init': create_dir(args) elif args.command == 'start': start_server(args, subargs) elif args.command == 'deploy': if args.provider == 'gcp': deploy_to_gcp(args) ç¬¬ä¸‰æ­¥ï¼šè¿žæŽ¥æœåŠ¡ åœ¨æˆ‘ä»¬åˆ›å»ºçš„å‰ç«¯é¡¹ç›®ä¸­ä¾æ¬¡é€‰æ‹© Settings -> Machine Learning -> Add model ï¼Œç„¶åŽè¾“å…¥åŽç«¯åœ°å€ http://10.100.143.xxx:8888/(è¿™é‡Œæ˜¯åŽç«¯çš„åœ°å€å’Œç«¯å£)ï¼Œç‚¹å‡»ä¿å­˜ æ­¤æ—¶æˆ‘ä»¬ä»Žå‰ç«¯é¡¹ç›®ä¸­æ‰“å¼€å¾…æ ‡è®°å›¾ç‰‡ï¼Œå‰ç«¯ä¼šè‡ªåŠ¨è¯·æ±‚åŽç«¯å¯¹å…¶è¿›è¡Œæ ‡è®°(è°ƒç”¨åŽç«¯çš„ predict æ–¹æ³•)ï¼Œç­‰å¾…ç‰‡åˆ»åŽå³å¯çœ‹è§é¢„æ ‡è®°ç»“æžœï¼Œæˆ‘ä»¬åªéœ€è¦å¤§è‡´æ ¸å¯¹æ— è¯¯åŽç‚¹å‡» submit å³å¯ å¦‚æžœè§‰å¾—æ¯æ¬¡æ‰“å¼€å›¾ç‰‡éƒ½éœ€è¦ç­‰å¾…ç‰‡åˆ»æ‰ä¼šæ”¶åˆ°åŽç«¯é¢„æµ‹ç»“æžœæ¯”è¾ƒè´¹æ—¶ï¼Œå¯ä»¥åœ¨ Settings -> Machine Learning è®¾ç½®ä¸­é€‰æ‹©æ‰“å¼€ Retrieve predictions when loading a task automatically ï¼Œæ­¤åŽå‰ç«¯ä¼šåœ¨æˆ‘ä»¬æ¯æ¬¡æ‰“å¼€é¡¹ç›®æ—¶è‡ªåŠ¨å¯¹æ‰€æœ‰ä»»åŠ¡è¿›è¡Œè‡ªåŠ¨é¢„æµ‹ï¼ŒåŸºæœ¬èƒ½å¤Ÿåšåˆ°æ— ç­‰å¾… ç¬¬å››æ­¥ï¼šè®­ç»ƒæ¨¡åž‹ åœ¨ Settings -> Machine Learning ä¸­ç‚¹å‡»åŽç«¯æœåŠ¡çš„ Start Training æŒ‰é’®ï¼Œå³å¯è°ƒç”¨åŽç«¯æ¨¡åž‹ä½¿ç”¨å·²æ ‡è®°ä¿¡æ¯è¿›è¡Œè®­ç»ƒ ä¹Ÿå¯ä»¥ Settings -> Machine Learning ä¸­å…è®¸æ¨¡åž‹è‡ªåŠ¨è®­ç»ƒï¼Œä½†è®­ç»ƒé¢‘çŽ‡è¿‡é«˜ä¼šå½±å“ç¨‹åºæ•ˆçŽ‡ ç›®æ ‡æ£€æµ‹ä»»åŠ¡æ³¨æ„äº‹é¡¹ predictè¿”å›žçš„åæ ‡ä¸ºconvert_to_lsè½¬æ¢åŽçš„åæ ‡å€¼ # convert from LS percent units to pixels def convert_from_ls(result): if 'original_width' not in result or 'original_height' not in result: return None value = result['value'] w, h = result['original_width'], result['original_height'] if all([key in value for key in ['x', 'y', 'width', 'height']]): return w * value['x'] / 100.0, \\ h * value['y'] / 100.0, \\ w * value['width'] / 100.0, \\ h * value['height'] / 100.0 # convert from pixels to LS percent units def convert_to_ls(x, y, width, height, original_width, original_height): return x / original_width * 100.0, y / original_height * 100.0, \\ width / original_width * 100.0, height / original_height * 100 # convert from LS output = convert_from_ls(task['annotations'][0]['result'][0]) if output is None: raise Exception('Wrong convert') pixel_x, pixel_y, pixel_width, pixel_height = output print(pixel_x, pixel_y, pixel_width, pixel_height) # convert back to LS x, y, width, height = convert_to_ls(pixel_x, pixel_y, pixel_width, pixel_height, 600, 403) print(x, y, width, height) Roboflow å¦‚ä½•ä½¿ç”¨ Roboflow æ ‡æ³¨å…³é”®ç‚¹ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹ä¼˜åŒ–å™¨.html":{"url":"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹ä¼˜åŒ–å™¨.html","title":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹ä¼˜åŒ–å™¨.md","summary":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹ä¼˜åŒ–å™¨","keywords":"","body":"ä¼˜åŒ–ç®—æ³•æ¦‚è¿°åŸºæœ¬çš„æ¢¯åº¦ä¸‹é™æ³•BGDSGDMBGDåŠ¨é‡ä¼˜åŒ–æ³•SGDMNAGè‡ªé€‚åº”å­¦ä¹ çŽ‡ä¼˜åŒ–å™¨AdaGradRMSPropAdadeltaAdamAdaMaxNadamå…¶ä»–ä¼˜åŒ–å™¨å­¦ä¹ çŽ‡è¡°å‡ ä¼˜åŒ–ç®—æ³• æœ€ä¼˜åŒ–æ˜¯æŒ‡éžçº¿æ€§æœ€ä¼˜åŒ–ï¼Œè§£éžçº¿æ€§æœ€ä¼˜åŒ–çš„æ–¹æ³•æœ‰å¾ˆå¤š æ¯”å¦‚æ¢¯åº¦ä¸‹é™æ³•ã€å…±è½­æ¢¯åº¦æ³•ã€å˜å°ºåº¦æ³•å’Œæ­¥é•¿åŠ é€Ÿæ³•ç­‰ å‚è€ƒæœ¬ç«™é“¾æŽ¥æœºå™¨å­¦ä¹ _æœ€ä¼˜åŒ–æ–¹æ³• æ¦‚è¿° pytorchä¼˜åŒ–å™¨ é£žæµ†å®˜æ–¹æ–‡æ¡£ï¼Œæ€»ç»“åˆ°ä½ æ·±åº¦å­¦ä¹ ä¼˜åŒ–å™¨æ–¹æ³•åŠå­¦ä¹ çŽ‡è¡°å‡æ–¹å¼ç»¼è¿° An overview of gradient descent optimization algorithms 1847 1951 1983 2011 2012 GD(BGD) SGD SGDM(Momentum)ã€NAG AdaGrad Adadeltaã€RMSprop 2015 2016 2018 Adamã€AdaMax Nadam AMSGrad ç›¸å¯¹åº”çš„è®ºæ–‡ A Stochastic Approximation Method SGD 1951 Learning representations by back-propagating errors Momentum 1983 A method for unconstrained convex minimization problem with the rate of convergence o(1/k2) NAG 1983 Adaptive subgradient methods for online learning and stochastic optimization AdaGrad 2011 ADADELTA: an adaptive learning rate method. Adadelta 2012 Neural Networks for Machine Learning Lecture 6a Overview of mini-batch gradient descent RMSprop 2012 Adam: A method for stochastic optimization Adam & AdaMax 2014 Incorporating Nesterov Momentum into Adam NAdam 2016 ä»¥ä¸‹æ˜¯ä¼˜åŒ–å™¨çš„å‘å±•è„‰ç»œï¼ŒæŒ‰ç…§æ—¶é—´é¡ºåºåˆ—å‡ºäº†ä¸€äº›é‡è¦çš„ä¼˜åŒ–å™¨åŠå…¶å¹´ä»½ï¼š Gradient Descent (GD)ï¼šæœ€æ—©çš„ä¼˜åŒ–å™¨ä¹‹ä¸€ï¼Œç”¨äºŽæ±‚è§£æ— çº¦æŸä¼˜åŒ–é—®é¢˜ã€‚æ²¡æœ‰ç‰¹å®šçš„å¹´ä»½ï¼Œä½†æ—©åœ¨20ä¸–çºª50å¹´ä»£å°±å¼€å§‹è¢«å¹¿æ³›åº”ç”¨ Stochastic Gradient Descent (SGD)ï¼šå¼•å…¥éšæœºæ€§æ¥ä¼°è®¡æ¢¯åº¦çš„ä¼˜åŒ–å™¨ï¼Œç”¨äºŽå¤§è§„æ¨¡æ•°æ®é›†å’Œæ·±åº¦å­¦ä¹ æ¨¡åž‹ã€‚æ²¡æœ‰ç‰¹å®šçš„å¹´ä»½ï¼Œä½†åœ¨æ·±åº¦å­¦ä¹ çš„æ—©æœŸå°±è¢«å¹¿æ³›ä½¿ç”¨ Momentumï¼ˆ1983ï¼‰ï¼šæå‡ºäº†åŠ¨é‡æ¦‚å¿µï¼Œé€šè¿‡ç´¯ç§¯æ¢¯åº¦çš„æŒ‡æ•°åŠ æƒå¹³å‡æ¥åŠ é€Ÿæ”¶æ•› AdaGradï¼ˆ2011ï¼‰ï¼šè‡ªé€‚åº”æ¢¯åº¦ç®—æ³•ï¼Œé€šè¿‡å¯¹æ¢¯åº¦è¿›è¡Œå½’ä¸€åŒ–å’Œè°ƒæ•´å­¦ä¹ çŽ‡ï¼Œé€‚åº”ä¸åŒå‚æ•°çš„æ›´æ–°éœ€æ±‚ Adadeltaï¼ˆ2012ï¼‰ï¼šæ”¹è¿›äº†AdaGradçš„ç¼ºç‚¹ï¼Œé€šè¿‡è€ƒè™‘åŽ†å²æ¢¯åº¦çš„å¹³å‡å€¼æ¥è°ƒæ•´å­¦ä¹ çŽ‡ RMSpropï¼ˆ2012ï¼‰ï¼šå¼•å…¥äº†æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡çš„æ¦‚å¿µï¼Œç”¨äºŽè°ƒæ•´å­¦ä¹ çŽ‡ä»¥å¹³è¡¡åŽ†å²æ¢¯åº¦ä¿¡æ¯ Adamï¼ˆ2014ï¼‰ï¼šç»“åˆäº†åŠ¨é‡å’Œè‡ªé€‚åº”å­¦ä¹ çŽ‡çš„ä¼˜ç‚¹ï¼Œé€šè¿‡è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ çŽ‡å’Œæ¢¯åº¦çš„ä¸€é˜¶çŸ©ä¼°è®¡å’ŒäºŒé˜¶çŸ©ä¼°è®¡æ¥è¿›è¡Œå‚æ•°æ›´æ–° AdaMaxï¼ˆ2014ï¼‰ï¼šåŸºäºŽAdamç®—æ³•ï¼Œé€šè¿‡æ›¿æ¢äºŒé˜¶çŸ©ä¼°è®¡çš„èŒƒæ•°ä¸ºæ— ç©·èŒƒæ•°ï¼Œæä¾›äº†æ›´ç¨³å®šçš„æ›´æ–°è§„åˆ™ Nadamï¼ˆ2016ï¼‰ï¼šç»“åˆäº†NesterovåŠ¨é‡å’ŒAdamç®—æ³•ï¼Œåˆ©ç”¨åŠ¨é‡æ¥åŠ é€Ÿæ”¶æ•› AMSGradï¼ˆ2018ï¼‰ï¼šå¯¹Adamç®—æ³•è¿›è¡Œäº†æ”¹è¿›ï¼Œè§£å†³äº†Adamç®—æ³•å­¦ä¹ çŽ‡ä¸‹é™ä¸ç¨³å®šçš„é—®é¢˜ è¿™äº›æ˜¯ä¸€äº›æ¯”è¾ƒé‡è¦çš„ä¼˜åŒ–å™¨ï¼Œå¹¶ä¸”æŒ‰ç…§æ—¶é—´é¡ºåºåˆ—å‡ºã€‚ç„¶è€Œï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¹¶éžæ‰€æœ‰çš„ä¼˜åŒ–å™¨éƒ½æ˜¯çº¿æ€§å‘å±•çš„ï¼Œè€Œæ˜¯ç›¸äº’å€Ÿé‰´ã€æ”¹è¿›å’Œç»“åˆçš„ç»“æžœã€‚ä¼˜åŒ–å™¨çš„å‘å±•æ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸï¼Œä»ç„¶æœ‰è®¸å¤šæ–°çš„ä¼˜åŒ–ç®—æ³•è¢«æå‡ºå’Œæ”¹è¿› ä»€ä¹ˆæ˜¯ä¼˜åŒ–å™¨ æ·±åº¦å­¦ä¹ çš„ç›®æ ‡æ˜¯é€šè¿‡ä¸æ–­æ”¹å˜ç½‘ç»œå‚æ•°ï¼Œä½¿å¾—å‚æ•°èƒ½å¤Ÿå¯¹è¾“å…¥åšå„ç§éžçº¿æ€§å˜æ¢æ‹Ÿåˆè¾“å‡ºï¼Œæœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªå‡½æ•°åŽ»å¯»æ‰¾æœ€ä¼˜è§£ï¼Œæ‰€ä»¥å¦‚ä½•åŽ»æ›´æ–°å‚æ•°æ˜¯æ·±åº¦å­¦ä¹ ç ”ç©¶çš„é‡ç‚¹ é€šå¸¸å°†æ›´æ–°å‚æ•°çš„ç®—æ³•ç§°ä¸ºä¼˜åŒ–å™¨ï¼Œå­—é¢ç†è§£å°±æ˜¯é€šè¿‡ä»€ä¹ˆç®—æ³•åŽ»ä¼˜åŒ–ç½‘ç»œæ¨¡åž‹çš„å‚æ•° æ¢¯åº¦ä¸‹é™æ ¸å¿ƒç‚¹ æ–¹å‘: ç¡®å®šä¼˜åŒ–çš„æ–¹å‘ï¼Œä¸€èˆ¬é€šè¿‡æ±‚å¯¼ä¾¿å¯ä»¥æ±‚å¾— æ­¥é•¿: æ­¥å­å°±æ˜¯å†³å®šå½“å‰èµ°å¤šå¤§ï¼Œå¦‚æžœå­¦ä¹ çŽ‡è®¾çš„è¿‡å¤§ï¼Œæ¢¯åº¦ä¼šåœ¨æœ€ä¼˜ç‚¹æ¥å›žè·³åŠ¨ï¼Œè®¾çš„è¿‡å°éœ€è¦å¾ˆä¹…çš„è®­ç»ƒæ‰èƒ½è¾¾åˆ°æœ€ä¼˜ç‚¹ ä¼˜åŒ–å™¨çš„ä¸»è¦ä½œç”¨ å‚æ•°æ›´æ–°ï¼šä¼˜åŒ–å™¨æ ¹æ®æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¿¡æ¯ï¼Œè®¡ç®—å‡ºæ¯ä¸ªå‚æ•°çš„æ›´æ–°é‡ï¼Œå¹¶å°†æ›´æ–°é‡åº”ç”¨äºŽå‚æ•°ï¼Œä»Žè€Œæ›´æ–°æ¨¡åž‹çš„å‚æ•°ã€‚è¿™æ ·ï¼Œæ¨¡åž‹çš„å‚æ•°å°±å¯ä»¥æœç€èƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®çš„æ–¹å‘è¿›è¡Œè°ƒæ•´ å­¦ä¹ çŽ‡è°ƒæ•´ï¼šä¼˜åŒ–å™¨é€šå¸¸ä¼šè‡ªåŠ¨è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œä»¥æŽ§åˆ¶å‚æ•°æ›´æ–°çš„æ­¥å¹…ã€‚å­¦ä¹ çŽ‡å†³å®šäº†æ¯æ¬¡å‚æ•°æ›´æ–°çš„å¹…åº¦ï¼Œè¿‡å¤§çš„å­¦ä¹ çŽ‡å¯èƒ½å¯¼è‡´å‚æ•°æ›´æ–°è¿‡å¿«è€Œé”™è¿‡æœ€ä¼˜è§£ï¼Œè€Œè¿‡å°çš„å­¦ä¹ çŽ‡å¯èƒ½å¯¼è‡´æ”¶æ•›é€Ÿåº¦ç¼“æ…¢ã€‚ä¼˜åŒ–å™¨æ ¹æ®å½“å‰è®­ç»ƒçš„è¿›åº¦å’Œå‚æ•°çš„å˜åŒ–æƒ…å†µï¼ŒåŠ¨æ€åœ°è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œä»¥èŽ·å¾—æ›´å¥½çš„è®­ç»ƒæ•ˆæžœ ä¼˜åŒ–ç®—æ³•é€‰æ‹©ï¼šä¼˜åŒ–å™¨æä¾›äº†å¤šç§ä¸åŒçš„ä¼˜åŒ–ç®—æ³•ï¼Œå¦‚æ¢¯åº¦ä¸‹é™ã€åŠ¨é‡ä¼˜åŒ–ã€è‡ªé€‚åº”å­¦ä¹ çŽ‡ç­‰ã€‚è¿™äº›ç®—æ³•åœ¨å‚æ•°æ›´æ–°çš„æ–¹å¼ã€å­¦ä¹ çŽ‡è°ƒæ•´ç­–ç•¥ç­‰æ–¹é¢æœ‰æ‰€ä¸åŒï¼Œå¯ä»¥æ ¹æ®å…·ä½“ä»»åŠ¡çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç®—æ³• é€šè¿‡åˆé€‚çš„ä¼˜åŒ–å™¨é€‰æ‹©å’Œå‚æ•°è°ƒæ•´ï¼Œå¯ä»¥æé«˜ç¥žç»ç½‘ç»œçš„è®­ç»ƒæ•ˆçŽ‡å’Œæ€§èƒ½ï¼ŒåŠ é€Ÿæ”¶æ•›è¿‡ç¨‹ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå¹¶åœ¨æµ‹è¯•æ•°æ®ä¸Šå–å¾—è¾ƒå¥½çš„æ³›åŒ–èƒ½åŠ› ä¼˜åŒ–å™¨åˆ†ç±» æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨(Gradient Descent Optimizers)ï¼šåŸºäºŽæ¢¯åº¦ä¿¡æ¯æ¥æ›´æ–°å‚æ•°çš„ä¼˜åŒ–å™¨ï¼ŒåŒ…æ‹¬æ‰¹é‡æ¢¯åº¦ä¸‹é™(BGD)ã€éšæœºæ¢¯åº¦ä¸‹é™(SGD)å’Œå°æ‰¹é‡æ¢¯åº¦ä¸‹é™(Mini-Batch Gradient Descentï¼ŒMBGD)ç­‰ åŸºäºŽåŠ¨é‡çš„ä¼˜åŒ–å™¨(Momentum-based Optimizers)ï¼šåœ¨æ¢¯åº¦ä¸‹é™çš„åŸºç¡€ä¸Šå¼•å…¥åŠ¨é‡çš„æ¦‚å¿µï¼Œæ—¨åœ¨åŠ é€Ÿæ”¶æ•›è¿‡ç¨‹å¹¶å‡å°‘éœ‡è¡ï¼Œå¸¸è§çš„åŒ…æ‹¬åŠ¨é‡ä¼˜åŒ–å™¨(Momentum Optimizer)ã€ç‰›é¡¿åŠ é€Ÿåº¦åŠ¨é‡ä¼˜åŒ–æ³•Nesterov Accelerated Gradient(NAG)ç­‰ è‡ªé€‚åº”å­¦ä¹ çŽ‡ä¼˜åŒ–å™¨(Adaptive Learning Rate Optimizers)ï¼šæ ¹æ®å‚æ•°æ›´æ–°çš„æƒ…å†µåŠ¨æ€åœ°è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œä»¥æé«˜æ”¶æ•›é€Ÿåº¦å’Œæ•ˆæžœï¼Œå¸¸è§çš„åŒ…æ‹¬AdaGradã€RMSpropã€Adamã€AdaDeltaã€Adamaxç­‰ å­¦ä¹ çŽ‡è¡°å‡ä¼˜åŒ–å™¨(Learning Rate Decay Optimizers)ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å‡å°å­¦ä¹ çŽ‡çš„ä¼˜åŒ–å™¨ï¼Œå¸¸è§çš„åŒ…æ‹¬Step Decayã€Exponential Decayã€Piecewise Decayç­‰ æ­£åˆ™åŒ–ä¼˜åŒ–å™¨(Regularization Optimizers)ï¼šç»“åˆæ­£åˆ™åŒ–æŠ€æœ¯ï¼Œé€šè¿‡å¯¹æŸå¤±å‡½æ•°æ·»åŠ æ­£åˆ™åŒ–é¡¹æ¥æŽ§åˆ¶æ¨¡åž‹çš„å¤æ‚åº¦ï¼Œå¸¸è§çš„åŒ…æ‹¬L1æ­£åˆ™åŒ–ã€L2æ­£åˆ™åŒ–ç­‰ äºŒé˜¶ä¼˜åŒ–å™¨(Second-Order Optimizers)ï¼šè€ƒè™‘å‚æ•°äºŒé˜¶ä¿¡æ¯çš„ä¼˜åŒ–å™¨ï¼Œå¦‚ç‰›é¡¿æ³•(Newton's Method)ã€å…±è½­æ¢¯åº¦æ³•(Conjugate Gradient)ç­‰ ä¸åŒç±»åž‹çš„ä¼˜åŒ–å™¨åœ¨æ›´æ–°å‚æ•°çš„æ–¹å¼ã€å­¦ä¹ çŽ‡è°ƒæ•´ç­–ç•¥ã€æ”¶æ•›é€Ÿåº¦ã€å¯¹å™ªå£°å’Œå±€éƒ¨æœ€ä¼˜çš„é²æ£’æ€§ç­‰æ–¹é¢æœ‰æ‰€åŒºåˆ«ï¼Œé€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨å–å†³äºŽå…·ä½“çš„é—®é¢˜å’Œæ•°æ®é›†ç‰¹å¾ åŸºæœ¬çš„æ¢¯åº¦ä¸‹é™æ³• ä¼˜åŒ–å™¨ç»¼è¿° æ·±åº¦å­¦ä¹ â€”â€”ä¼˜åŒ–å™¨ç®—æ³•Optimizerè¯¦è§£ï¼ˆBGDã€SGDã€MBGDã€Momentumã€NAGã€Adagradã€Adadeltaã€RMSpropã€Adamï¼‰ ä¼˜åŒ–å™¨çš„å­˜åœ¨å°±æ˜¯ç¡®å®šä¼˜åŒ–çš„æ–¹å‘å’Œé¢å¯¹å½“å‰çš„æƒ…å†µåŠ¨æ€çš„è°ƒæ•´æ­¥å­ BGDã€SGDå’ŒMBGDçš„åŒºåˆ« ä¼˜åŒ–å™¨ BGD SGD MBGD æ ·æœ¬æ•° N(æ‰€æœ‰) 1 batch_size BGD BGD(Batch Gradient Descent)é‡‡ç”¨æ•´ä¸ªè®­ç»ƒé›†çš„æ•°æ®æ¥è®¡ç®—cost functionå¯¹å‚æ•°çš„æ¢¯åº¦ w_{t+1}=w_{t}-\\alpha \\Delta L\\left(w_{t}\\right) å…¶ä¸­\\alpha ä¸ºå­¦ä¹ çŽ‡ï¼Œè€Œ\\Delta L\\left(w_{t}\\right)ä¸ºæŸå¤±å‡½æ•°çš„ä¸€é˜¶å¯¼æ•° BGDåœ¨è®¡ç®—æ¢¯åº¦æ—¶ä¼šå‡ºçŽ°å†—ä½™ å› ä¸ºBGDåœ¨æ¯ä¸€æ¬¡è¿­ä»£ä¸­éƒ½ä½¿ç”¨äº†æ•´ä¸ªè®­ç»ƒé›†ï¼Œè€Œä¸”åœ¨æ¢¯åº¦è®¡ç®—è¿‡ç¨‹ä¸­å¹¶æ²¡æœ‰è€ƒè™‘æ ·æœ¬ä¹‹é—´çš„ç›¸å…³æ€§ å› æ­¤ï¼Œå¯¹äºŽæ ·æœ¬ä¸­çš„æŸäº›éƒ¨åˆ†ï¼Œå…¶æ¢¯åº¦è®¡ç®—å¯èƒ½ä¼šä¸Žå…¶ä»–æ ·æœ¬çš„æ¢¯åº¦è®¡ç®—é‡å¤ï¼Œè¿™ç§å†—ä½™è®¡ç®—å¯èƒ½ä¼šå¯¼è‡´è®¡ç®—æ•ˆçŽ‡çš„é™ä½Žï¼Œç‰¹åˆ«æ˜¯åœ¨è®­ç»ƒé›†å¾ˆå¤§çš„æƒ…å†µä¸‹ ä¼˜ç‚¹ æ”¶æ•›ç¨³å®šï¼šç”±äºŽæ¯æ¬¡è¿­ä»£ä½¿ç”¨æ•´ä¸ªè®­ç»ƒé›†çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œå‚æ•°æ›´æ–°ï¼Œæ”¶æ•›è¿‡ç¨‹ç›¸å¯¹ç¨³å®š å‚æ•°æ›´æ–°å‡†ç¡®ï¼šä½¿ç”¨å…¨å±€æ¢¯åº¦æ¥æ›´æ–°å‚æ•°ï¼Œå¯¹äºŽå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå¯ä»¥è¾¾åˆ°å…¨å±€æœ€ä¼˜è§£ ç¼ºç‚¹ è®­ç»ƒé€Ÿåº¦æ…¢ï¼šBGD æ˜¯ä¸€ç§æ‰¹é‡æ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œæ¯æ¬¡æ›´æ–°æ¨¡åž‹å‚æ•°æ—¶ä½¿ç”¨æ•´ä¸ªè®­ç»ƒæ•°æ®é›† è®¡ç®—å¼€é”€å¤§ï¼šéœ€è¦è®¡ç®—æ•´ä¸ªè®­ç»ƒé›†çš„æ¢¯åº¦ï¼Œå¯¹äºŽå¤§è§„æ¨¡æ•°æ®é›†æˆ–å¤æ‚æ¨¡åž‹ï¼Œè®¡ç®—å¼€é”€è¾ƒé«˜ å†…å­˜å ç”¨é«˜ï¼šéœ€è¦å­˜å‚¨æ•´ä¸ªè®­ç»ƒé›†çš„æ•°æ®å’Œæ¢¯åº¦ä¿¡æ¯ SGD SGD(Stochastic Gradient Descent)æ˜¯ä¸€ç§éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œæ¯æ¬¡æ›´æ–°æ¨¡åž‹å‚æ•°æ—¶ä½¿ç”¨å•ä¸ªæ ·æœ¬æˆ–ä¸€å°æ‰¹æ ·æœ¬(é€šå¸¸ç§°ä¸ºmini-batchï¼Œä¹Ÿç§°MBGD) w_{t+1}=w_{t}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\Delta L\\left(w_{i}\\right) å…¶ä¸­\\alpha ä¸ºå­¦ä¹ çŽ‡ï¼Œè€Œ\\Delta L\\left(w_{t}\\right)ä¸ºæŸå¤±å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°ï¼Œmä¸ºbatch_sizeï¼Œå½“m=1å°±æ˜¯SGDï¼Œå¦åˆ™å°±æ˜¯MBGD ä¼˜ç‚¹ è®¡ç®—å¼€é”€å°ï¼šæ¯æ¬¡è¿­ä»£åªä½¿ç”¨ä¸€ä¸ªæ ·æœ¬è¿›è¡Œå‚æ•°æ›´æ–°ï¼Œè®¡ç®—å¼€é”€è¾ƒå° é€‚ç”¨äºŽå¤§è§„æ¨¡æ•°æ®é›†ï¼šç”±äºŽæ ·æœ¬çš„éšæœºé€‰æ‹©ï¼Œå¯ä»¥å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†ï¼Œä¸”æ˜“äºŽå¹¶è¡Œå¤„ç† ç¼ºç‚¹ å‚æ•°æ›´æ–°ä¸ç¨³å®šï¼šç”±äºŽå•ä¸ªæ ·æœ¬çš„æ¢¯åº¦è®¡ç®—å¯èƒ½å­˜åœ¨å™ªå£°ï¼Œå‚æ•°æ›´æ–°ä¸ç¨³å®šï¼Œå¯èƒ½å¼•èµ·å‚æ•°åœ¨æœ€ä¼˜ç‚¹é™„è¿‘éœ‡è¡ æ”¶æ•›é€Ÿåº¦è¾ƒæ…¢ï¼šç”±äºŽå‚æ•°æ›´æ–°çš„ä¸ç¨³å®šæ€§ï¼Œæ”¶æ•›é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ MBGD MBGD(Mini-Batch Gradient Descent)æ¯ä¸€æ¬¡åˆ©ç”¨ä¸€å°æ‰¹æ ·æœ¬ï¼Œå³batch_sizeä¸ªæ ·æœ¬è¿›è¡Œè®¡ç®—ï¼Œè¿™æ ·å®ƒå¯ä»¥é™ä½Žå‚æ•°æ›´æ–°æ—¶çš„æ–¹å·®ï¼Œæ”¶æ•›æ›´ç¨³å®šï¼Œå¦ä¸€æ–¹é¢å¯ä»¥å……åˆ†åœ°åˆ©ç”¨æ·±åº¦å­¦ä¹ åº“ä¸­é«˜åº¦ä¼˜åŒ–çš„çŸ©é˜µæ“ä½œæ¥è¿›è¡Œæ›´æœ‰æ•ˆçš„æ¢¯åº¦è®¡ç®— w_{t+1}=w_{t}-\\alpha \\frac{1}{m} \\sum_{i=1}^{m} \\Delta L\\left(w_{i}\\right) å…¶ä¸­\\alpha ä¸ºå­¦ä¹ çŽ‡ï¼Œè€Œ\\Delta L\\left(w_{t}\\right)ä¸ºæŸå¤±å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°ï¼Œmä¸ºbatch_sizeï¼Œå½“m=1å°±æ˜¯SGDï¼Œå¦åˆ™å°±æ˜¯MBGD ä¼˜ç‚¹ å¹³è¡¡äº†å¼€é”€å’Œå‚æ•°ç¨³å®šæ€§ï¼šä½¿ç”¨ä¸€å°æ‰¹æ ·æœ¬è¿›è¡Œå‚æ•°æ›´æ–°ï¼Œç»¼åˆäº†å…¨å±€æ¢¯åº¦å’Œéšæœºæ¢¯åº¦çš„ä¿¡æ¯ï¼Œè®¡ç®—å¼€é”€å’Œå‚æ•°æ›´æ–°çš„ç¨³å®šæ€§å¾—åˆ°ä¸€å®šçš„å¹³è¡¡ æ”¶æ•›é€Ÿåº¦è¾ƒå¿«ï¼šç›¸å¯¹äºŽBGDï¼Œä½¿ç”¨è¾ƒå°çš„æ‰¹é‡æ ·æœ¬æ›´æ–°å‚æ•°ï¼Œæ”¶æ•›é€Ÿåº¦æ›´å¿« ç¼ºç‚¹ æ‰¹é‡å¤§å°éœ€è°ƒä¼˜ï¼šæ‰¹é‡å¤§å°çš„é€‰æ‹©å¯èƒ½ä¼šå½±å“æ¨¡åž‹çš„æ€§èƒ½ï¼Œéœ€è¦è¿›è¡Œè°ƒä¼˜ å¯èƒ½å¯¼è‡´å±€éƒ¨æœ€ä¼˜ï¼šè¾ƒå°çš„æ‰¹é‡æ ·æœ¬å¯èƒ½ä¼šå¼•å…¥ä¸€å®šçš„éšæœºæ€§ï¼Œå¯èƒ½å¯¼è‡´é™·å…¥å±€éƒ¨æœ€ä¼˜è€Œæ— æ³•è¾¾åˆ°å…¨å±€æœ€ä¼˜ åŠ¨é‡ä¼˜åŒ–æ³• SGDM éšæœºæ¢¯åº¦ä¸‹é™æ³•è™½ç„¶æœ‰æ•ˆï¼Œä½†å®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°å€¼ç‚¹ï¼Œç”šè‡³åœ¨é©»ç‚¹é™„è¿‘ä»¥åŠæ¢¯åº¦å€¼éžå¸¸å°çš„ç‚¹é™„è¿‘æ—¶å‚æ•°æ›´æ–°æžä¸ºç¼“æ…¢ ä¸ºäº†æŠ‘åˆ¶SGDçš„éœ‡è¡ï¼ŒSGDM(Stochastic Gradient Descent Momentum)è®¤ä¸ºæ¢¯åº¦ä¸‹é™è¿‡ç¨‹å¯ä»¥åŠ å…¥æƒ¯æ€§ ä¸»è¦æ€æƒ³æ˜¯ä¸‹é™è¿‡ç¨‹ä¸­ï¼Œå¦‚æžœå‘çŽ°æ˜¯é™¡å¡ï¼Œé‚£å°±åˆ©ç”¨æƒ¯æ€§è·‘çš„å¿«ä¸€äº›ã€‚å› æ­¤ï¼Œå…¶åœ¨SGDåŸºç¡€ä¸Šå¼•å…¥äº†ä¸€é˜¶åŠ¨é‡ åœ¨å¡åº¦æ¯”è¾ƒé™¡çš„åœ°æ–¹ï¼Œä¼šæœ‰è¾ƒå¤§çš„æƒ¯æ€§ï¼Œè¿™æ˜¯ä¸‹é™çš„å¤šã€‚å¡åº¦å¹³ç¼“çš„åœ°æ–¹ï¼Œæƒ¯æ€§è¾ƒå°ï¼Œä¸‹é™çš„ä¼šæ¯”è¾ƒæ…¢ \\begin{array}{c} m_{t}=\\lambda m_{t-1}+ \\alpha \\Delta L(w_t) \\\\ w_{t+1}=w_{t}-m_{t} \\end{array} å…¶ä¸­\\alpha ä¸ºå­¦ä¹ çŽ‡ï¼Œ\\Delta L(w_t)è¡¨ç¤ºå½“å‰tæ—¶åˆ»æ¢¯åº¦ï¼Œm_tè¡¨ç¤ºå½“å‰æ—¶åˆ»çš„åŠ æƒåŽçš„æ¢¯åº¦ï¼Œ\\lambdaæ˜¯åŠ¨é‡ç³»æ•° \\lambdaçš„ç»éªŒå€¼ä¸º0.9(è¡¨ç¤ºæœ€å¤§é€Ÿåº¦10å€äºŽSGD)ï¼Œè¿™å°±æ„å‘³ç€ä¸‹é™æ–¹å‘ä¸»è¦æ˜¯æ­¤å‰ç´¯ç§¯çš„ä¸‹é™æ–¹å‘ï¼Œå¹¶ç•¥å¾®åå‘å½“å‰æ—¶åˆ»çš„ä¸‹é™æ–¹å‘ ä¸€é˜¶åŠ¨é‡æ˜¯å„ä¸ªæ—¶åˆ»æ¢¯åº¦æ–¹å‘çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œtæ—¶åˆ»çš„ä¸‹é™æ–¹å‘ï¼Œä¸ä»…ç”±å½“å‰ç‚¹çš„æ¢¯åº¦æ–¹å‘\\Delta L(w_t)å†³å®šï¼Œè€Œä¸”ç”±æ­¤å‰ç´¯ç§¯çš„ä¸‹é™æ–¹å‘m_{t-1}å†³å®š æ¢¯åº¦æ˜¯å¦‚ä½•ç´¯ç§¯çš„ è¿™é‡Œå°†m_tå±•å¼€ï¼Œå¯ä»¥çœ‹åˆ°å½“å‰æ—¶åˆ»çš„æ¢¯åº¦æ˜¯å¯¹åŽ†å²æ¢¯åº¦è¿›è¡ŒåŠ æƒå¾—åˆ°çš„ï¼Œå…¶ä¸­ï¼Œ\\lambdaæ˜¯ä¸€ä¸ªä»‹äºŽ0å’Œ1ä¹‹é—´çš„å‚æ•°ï¼ŒæŽ§åˆ¶äº†åŽ†å²æ¢¯åº¦å¯¹å½“å‰åŠ¨é‡çš„è´¡çŒ®ç¨‹åº¦ è¾ƒå¤§çš„\\lambdaå€¼ä¼šä½¿åŽ†å²æ¢¯åº¦çš„è´¡çŒ®æ›´å¤§ï¼Œä»Žè€Œä½¿åŠ¨é‡æ›´åŠ å¹³æ»‘ è¾ƒå°çš„\\lambdaå€¼ä¼šä½¿å½“å‰æ¢¯åº¦çš„è´¡çŒ®æ›´å¤§ï¼Œä»Žè€Œå¯¹å˜åŒ–æ›´ä¸ºæ•æ„Ÿ è¿™ç§æƒé‡è¡°å‡çš„æ–¹å¼ä½¿å¾—åŽ†å²æ¢¯åº¦çš„è´¡çŒ®é€æ¸å‡å°ï¼Œæ›´åŠ å…³æ³¨è¿‘æœŸçš„æ¢¯åº¦å˜åŒ–ï¼Œæœ‰åŠ©äºŽé€‚åº”å˜åŒ–çš„æ•°æ®å’Œæ¨¡åž‹å‚æ•° \\begin{aligned} m_{t}= & -\\alpha \\Delta L(w_t) -\\alpha \\lambda \\Delta L(w_{t-1})-\\alpha \\lambda^{2} \\Delta L(w_{t-2})-\\alpha \\lambda^{3} \\Delta L(w_{t-3}) \\cdots \\end{aligned} ä¼˜ç‚¹ åŠ é€Ÿæ”¶æ•›ï¼šSGDMå¼•å…¥äº†åŠ¨é‡çš„æ¦‚å¿µï¼Œé€šè¿‡ç´¯ç§¯ä¹‹å‰çš„åŠ¨é‡ä¿¡æ¯ï¼Œæœ‰åŠ©äºŽåŠ é€Ÿæ¨¡åž‹çš„æ”¶æ•›é€Ÿåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨å­˜åœ¨å¹³å¦åŒºåŸŸçš„æƒ…å†µä¸‹æ›´ä¸ºæ˜Žæ˜¾ å‡å°‘éœ‡è¡ï¼šåŠ¨é‡çš„ç´¯ç§¯ä½œç”¨å¯ä»¥å‡å°‘å‚æ•°æ›´æ–°æ—¶çš„éœ‡è¡çŽ°è±¡ï¼Œæœ‰åŠ©äºŽæ›´ç¨³å®šåœ°æ›´æ–°æ¨¡åž‹å‚æ•° å°½å¯èƒ½è·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼šåŠ¨é‡çš„å¼•å…¥å¯ä»¥å¸®åŠ©æ¨¡åž‹è·³å‡ºå±€éƒ¨æœ€ä¼˜ç‚¹ï¼Œä»¥ä¾¿æ›´å¥½åœ°æœç´¢å…¨å±€æœ€ä¼˜ç‚¹ å½“å±€éƒ¨æ²Ÿå£‘æ¯”è¾ƒæ·±ï¼ŒåŠ¨é‡åŠ æŒç”¨å®Œäº†ï¼Œä¾ç„¶ä¼šå›°åœ¨å±€éƒ¨æœ€ä¼˜é‡Œæ¥å›žæŒ¯è¡ ç¼ºç‚¹ éœ€è¦è°ƒæ•´è¶…å‚æ•°ï¼šSGDMä¸­çš„åŠ¨é‡ç³»æ•°éœ€è¦æ‰‹åŠ¨è®¾ç½®ï¼Œé€‰æ‹©åˆé€‚çš„åŠ¨é‡ç³»æ•°å¯¹äºŽæ¨¡åž‹çš„æ€§èƒ½å½±å“è¾ƒå¤§ï¼Œéœ€è¦è¿›è¡Œè°ƒè¯•å’Œè°ƒä¼˜ å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼šå½“åŠ¨é‡ç³»æ•°è¾ƒå¤§æ—¶ï¼ŒSGDMå¯èƒ½åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è¿‡åº¦ä¾èµ–ä¹‹å‰çš„åŠ¨é‡ä¿¡æ¯ï¼Œå¯¼è‡´æ¨¡åž‹è¿‡æ‹Ÿåˆ éš¾ä»¥å¤„ç†éžå¹³ç¨³æ•°æ®ï¼šå¯¹äºŽéžå¹³ç¨³æ•°æ®ï¼ŒSGDMçš„åŠ¨é‡ç´¯ç§¯å¯èƒ½ä¼šå¯¼è‡´æ¨¡åž‹åœ¨å˜åŒ–å¿«é€Ÿçš„æ–¹å‘ä¸Šè¿‡åº¦è¿½è¸ªï¼Œè€Œæ— æ³•åŠæ—¶é€‚åº”å˜åŒ– æ”¹è¿›æ–¹æ³• è‡ªé€‚åº”è°ƒæ•´åŠ¨é‡ç³»æ•°ï¼šå¯ä»¥é‡‡ç”¨è‡ªé€‚åº”çš„æ–¹å¼æ¥è°ƒæ•´åŠ¨é‡ç³»æ•°ï¼Œä¾‹å¦‚ä½¿ç”¨è‡ªé€‚åº”çš„åŠ¨é‡æ–¹æ³•(å¦‚Adam)æ¥æ ¹æ®æ¢¯åº¦çš„å˜åŒ–è‡ªåŠ¨è°ƒæ•´åŠ¨é‡ç³»æ•° å­¦ä¹ çŽ‡è°ƒåº¦ç­–ç•¥ï¼šç»“åˆå­¦ä¹ çŽ‡è°ƒåº¦ç­–ç•¥ï¼Œå¦‚å­¦ä¹ çŽ‡è¡°å‡æˆ–è‡ªé€‚åº”å­¦ä¹ çŽ‡æ–¹æ³•ï¼Œå¯ä»¥æ›´å¥½åœ°æŽ§åˆ¶æ¨¡åž‹çš„å­¦ä¹ é€Ÿåº¦å’Œæ–¹å‘ æ­£åˆ™åŒ–æŠ€æœ¯ï¼šä½¿ç”¨æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œå¦‚L1æ­£åˆ™åŒ–æˆ–L2æ­£åˆ™åŒ–ï¼Œå¯ä»¥ç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œä½¿æ¨¡åž‹æ›´å…·æ³›åŒ–èƒ½åŠ› å› ä¸ºåŠ å…¥äº†åŠ¨é‡å› ç´ ï¼ŒSGDMç¼“è§£äº†SGDåœ¨å±€éƒ¨æœ€ä¼˜ç‚¹æ¢¯åº¦ä¸º0ï¼Œæ— æ³•æŒç»­æ›´æ–°çš„é—®é¢˜å’ŒæŒ¯è¡å¹…åº¦è¿‡å¤§çš„é—®é¢˜ï¼Œä½†æ˜¯å¹¶æ²¡æœ‰å®Œå…¨è§£å†³ï¼Œå½“å±€éƒ¨æ²Ÿå£‘æ¯”è¾ƒæ·±ï¼ŒåŠ¨é‡åŠ æŒç”¨å®Œäº†ï¼Œä¾ç„¶ä¼šå›°åœ¨å±€éƒ¨æœ€ä¼˜é‡Œæ¥å›žæŒ¯è¡ NAG æ·±åº¦å­¦ä¹ ä¼˜åŒ–å‡½æ•°è¯¦è§£-- Nesterov accelerated gradient (NAG) æ¯”Momentumæ›´å¿«ï¼šæ­å¼€Nesterov Accelerated Gradientçš„çœŸé¢ç›® åŠ¨é‡æ³•æ¯ä¸‹é™ä¸€æ­¥éƒ½æ˜¯ç”±å‰é¢ä¸‹é™æ–¹å‘çš„ä¸€ä¸ªç´¯ç§¯å’Œå½“å‰ç‚¹çš„æ¢¯åº¦æ–¹å‘ç»„åˆè€Œæˆã€‚äºŽæ˜¯ä¸€ä½å¤§ç¥ž(Nesterov)å°±å¼€å§‹æ€è€ƒï¼Œæ—¢ç„¶æ¯ä¸€æ­¥éƒ½è¦å°†ä¸¤ä¸ªæ¢¯åº¦æ–¹å‘(åŽ†å²æ¢¯åº¦ã€å½“å‰æ¢¯åº¦)åšä¸€ä¸ªåˆå¹¶å†ä¸‹é™ï¼Œé‚£ä¸ºä»€ä¹ˆä¸å…ˆæŒ‰ç…§åŽ†å²æ¢¯åº¦å¾€å‰èµ°é‚£ä¹ˆä¸€å°æ­¥ï¼ŒæŒ‰ç…§å‰é¢ä¸€å°æ­¥ä½ç½®çš„è¶…å‰æ¢¯åº¦æ¥åšæ¢¯åº¦åˆå¹¶å‘¢ å¦‚æ­¤ä¸€æ¥ï¼Œå°çƒå°±å¯ä»¥å…ˆä¸ç®¡ä¸‰ä¸ƒäºŒåä¸€å…ˆå¾€å‰èµ°ä¸€æ­¥ï¼Œåœ¨é å‰ä¸€ç‚¹çš„ä½ç½®çœ‹åˆ°æ¢¯åº¦ï¼Œç„¶åŽæŒ‰ç…§é‚£ä¸ªä½ç½®å†æ¥ä¿®æ­£è¿™ä¸€æ­¥çš„æ¢¯åº¦æ–¹å‘ï¼ŒåŒSGDMæ¯”è¾ƒçš„å·®ä¸€ç‚¹å¦‚ä¸‹å…¬å¼æ‰€ç¤º \\Delta L(w_{t-1}) \\longrightarrow \\Delta L(w_{t-1}-\\lambda m_{t-1}) æ—¢ç„¶çŸ¥é“ä¼šèµ°\\lambda m_{t-1}ï¼Œå°±ä¸éœ€è¦è¿˜ç”¨å½“å‰ä½ç½®çš„æ¢¯åº¦ï¼Œå¯ä»¥ç›´æŽ¥èµ°åˆ°\\lambda m_{t-1}çš„ä½ç½®è®¡ç®—æ¢¯åº¦ï¼Œè¿™æ ·å­å°±æœ‰äº†è¶…å‰çœ¼å…‰ æœ‰äº†è¶…å‰çš„çœ¼å…‰ï¼Œå°çƒå°±ä¼šæ›´åŠ èªæ˜Ž, è¿™ç§æ–¹æ³•è¢«å‘½åä¸ºç‰›é¡¿åŠ é€Ÿæ¢¯åº¦(Nesterov accelerated gradient)ç®€ç§°NAGï¼Œä¸‹å›¾æ˜¯SGDMä¸‹é™æ³•ä¸ŽNAGä¸‹é™æ³•çš„å¯è§†åŒ–æ¯”è¾ƒ NAGç®—æ³•å…¬å¼è¡¨è¾¾å¦‚ä¸‹ï¼š \\begin{array}{c} m_{t}=\\lambda m_{t-1}+ \\alpha \\Delta L(w_{t-1}-\\lambda m_{t-1}) \\\\ w_{t+1}=w_{t}-m_{t} \\end{array} ä¸ºä»€ä¹ˆNAGæ¯”SGDMå¿« å¯¹NAGåŽŸæ¥çš„æ›´æ–°å…¬å¼è¿›è¡Œå˜æ¢ï¼Œå¾—åˆ°è¿™æ ·çš„ç­‰æ•ˆå½¢å¼(å…·ä½“æŽ¨å¯¼è¿‡ç¨‹) \\begin{array}{c} m_{t}=\\lambda m_{t-1}+ \\alpha \\Delta L(w_{t-1}) + \\lambda ( \\Delta L(w_{t-1}) - \\Delta L(w_{t-2}) ) \\\\ w_{t+1}=w_{t}-m_{t} \\end{array} ä¸ŽMomentumçš„åŒºåˆ«åœ¨äºŽï¼Œæœ¬æ¬¡æ›´æ–°æ–¹å‘å¤šåŠ äº†ä¸€ä¸ª\\lambda ( \\Delta L(w_{t-1}) - \\Delta L(w_{t-2}) ) ç›´è§‚å«ä¹‰å°±å¾ˆæ˜Žæ˜¾äº†ï¼šå¦‚æžœè¿™æ¬¡çš„æ¢¯åº¦æ¯”ä¸Šæ¬¡çš„æ¢¯åº¦å˜å¤§äº†ï¼Œé‚£ä¹ˆæœ‰å¯èƒ½ä¼šç»§ç»­å˜å¤§ï¼Œå¯ä»¥æŠŠé¢„è®¡å¢žå¤§çš„éƒ¨åˆ†æå‰åŠ è¿›æ¥ï¼›å˜å°çš„æƒ…å†µç±»ä¼¼ è¿™ä¸ªå¤šåŠ ä¸ŠåŽ»çš„é¡¹å°±æ˜¯åœ¨è¿‘ä¼¼ç›®æ ‡å‡½æ•°çš„äºŒé˜¶å¯¼å˜›ï¼Œå› æ­¤ï¼ŒNAGæœ¬è´¨ä¸Šæ˜¯å¤šè€ƒè™‘äº†ç›®æ ‡å‡½æ•°çš„äºŒé˜¶å¯¼ä¿¡æ¯ï¼Œå…¶å®žæ‰€è°“å¾€å‰çœ‹çš„è¯´æ³•ï¼Œåœ¨ç‰›é¡¿æ³•è¿™æ ·çš„äºŒé˜¶æ–¹æ³•ä¸­ä¹Ÿæ˜¯ç»å¸¸æåˆ°çš„ï¼Œä»Žæ•°å­¦è§’åº¦ä¸Šçœ‹ï¼Œåˆ™æ˜¯åˆ©ç”¨äº†ç›®æ ‡å‡½æ•°çš„äºŒé˜¶å¯¼ä¿¡æ¯ è‡ªé€‚åº”å­¦ä¹ çŽ‡ä¼˜åŒ–å™¨ AdaGrad æŽå®æ¯…æ·±åº¦å­¦ä¹ ç¬”è®°-Adagradç®—æ³• AdaGrad ç®—æ³• ä¼˜åŒ–çš„å˜é‡å¯¹äºŽç›®æ ‡å‡½æ•°çš„ä¾èµ–æ˜¯å„ä¸ç›¸åŒ åœ¨åŸºæœ¬çš„æ¢¯åº¦ä¸‹é™æ³•ä¼˜åŒ–ä¸­ï¼Œæœ‰ä¸€ä¸ªå¸¸è§çš„é—®é¢˜æ˜¯ï¼Œè¦ä¼˜åŒ–çš„å˜é‡å¯¹äºŽç›®æ ‡å‡½æ•°çš„ä¾èµ–æ˜¯å„ä¸ç›¸åŒçš„ å¯¹äºŽæŸäº›å˜é‡ï¼Œå·²ç»ä¼˜åŒ–åˆ°äº†æžå°å€¼é™„è¿‘ï¼Œä½†æ˜¯æœ‰çš„å˜é‡ä»ç„¶åœ¨æ¢¯åº¦å¾ˆå¤§çš„åœ°æ–¹ï¼Œè¿™æ—¶å€™ä¸€ä¸ªç»Ÿä¸€çš„å…¨å±€å­¦ä¹ çŽ‡æ˜¯å¯èƒ½å‡ºçŽ°é—®é¢˜çš„ å¦‚æžœå­¦ä¹ çŽ‡å¤ªå°ï¼Œåˆ™æ¢¯åº¦å¾ˆå¤§çš„å˜é‡ä¼šæ”¶æ•›å¾ˆæ…¢ï¼Œå¦‚æžœæ¢¯åº¦å¤ªå¤§ï¼Œå·²ç»ä¼˜åŒ–å·®ä¸å¤šçš„å˜é‡å°±å¯èƒ½ä¼šä¸ç¨³å®š çŽ°å®žä¸–ç•Œçš„æ•°æ®é›†ä¸­ï¼Œä¸€äº›ç‰¹å¾æ˜¯ç¨€ç–çš„(å¤§éƒ¨åˆ†ç‰¹å¾ä¸ºé›¶ï¼Œæ‰€ä»¥å®ƒæ˜¯ç¨€ç–çš„)ï¼Œè€Œå¦ä¸€äº›åˆ™æ˜¯å¯†é›†çš„(denseï¼Œå¤§éƒ¨åˆ†ç‰¹å¾æ˜¯éžé›¶çš„)ï¼Œå› æ­¤ä¸ºæ‰€æœ‰æƒå€¼ä¿æŒç›¸åŒçš„å­¦ä¹ çŽ‡ä¸åˆ©äºŽä¼˜åŒ– é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œå½“æ—¶åœ¨ä¼¯å…‹åˆ©åŠ å·žå¤§å­¦è¯»åšå£«çš„Jhon Duchiï¼Œ2011å¹´æå‡ºäº†AdaGrad(Adaptive Gradient)ï¼Œä¹Ÿå°±æ˜¯è‡ªé€‚åº”å­¦ä¹ çŽ‡ åŸºæœ¬æ€æƒ³ AdaGradçš„åŸºæœ¬æ€æƒ³æ˜¯å¯¹æ¯ä¸ªå˜é‡ç”¨ä¸åŒçš„å­¦ä¹ çŽ‡ï¼Œè®¾ç½®äº†å…¨å±€å­¦ä¹ çŽ‡ä¹‹åŽï¼Œæ¯æ¬¡é€šè¿‡ï¼Œå…¨å±€å­¦ä¹ çŽ‡é€å‚æ•°çš„é™¤ä»¥åŽ†å²æ¢¯åº¦å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹ï¼Œä½¿å¾—æ¯ä¸ªå‚æ•°çš„å­¦ä¹ çŽ‡ä¸åŒ è¿™ä¸ªå­¦ä¹ çŽ‡åœ¨ä¸€å¼€å§‹ä¼šæ¯”è¾ƒå¤§ï¼Œç”¨äºŽå¿«é€Ÿæ¢¯åº¦ä¸‹é™ã€‚éšç€ä¼˜åŒ–è¿‡ç¨‹çš„è¿›è¡Œï¼Œå¯¹äºŽå·²ç»ä¸‹é™å¾ˆå¤šçš„å˜é‡ï¼Œåˆ™å‡ç¼“å­¦ä¹ çŽ‡ï¼Œå¯¹äºŽè¿˜æ²¡æ€Žä¹ˆä¸‹é™çš„å˜é‡ï¼Œåˆ™ä¿æŒä¸€ä¸ªè¾ƒå¤§çš„å­¦ä¹ çŽ‡ å…¬å¼ w_{t+1} =w_{t}-\\frac{\\alpha}{\\sqrt{G_{t}+\\epsilon }} \\odot \\eta \\Delta L(w_t) å…¶ä¸­\\etaä¸ºå­¦ä¹ çŽ‡ï¼Œè€Œ\\Delta L\\left(w_{t}\\right)ä¸ºæŸå¤±å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°ï¼Œ\\epsilonæ˜¯ä¸€ä¸ªå¹³æ»‘é¡¹ï¼Œé¿å…äº†é™¤ä»¥é›¶(é€šå¸¸å–å€¼åœ¨1e-8å·¦å³)ï¼Œ\\odotè¡¨ç¤ºå…ƒç´ é€å…ƒç´ ç›¸ä¹˜æ“ä½œ G_{t+1}å¯ä»¥å†™æˆä¸‹å¼ï¼Œæ¯ä¸ªå‚æ•°çš„æ‰€æœ‰åå¾®åˆ†çš„å¹³æ–¹å’Œï¼Œg_iæ˜¯å¯¹æ¢¯åº¦çš„ç¼©å†™ G_{t+1} =G_{t}+g_{t+1} \\odot g_{t+1} = \\sum _{i=0}^{t} { {g_i} ^2 } ä¼˜ç¼ºç‚¹ ä¼˜ç‚¹ï¼š è‡ªé€‚åº”çš„å­¦ä¹ çŽ‡ï¼Œæ— éœ€äººå·¥è°ƒèŠ‚ï¼ŒAdaGradåœ¨è¿­ä»£è¿‡ç¨‹ä¸­ä¸æ–­è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œå¹¶è®©ç›®æ ‡å‡½æ•°ä¸­çš„æ¯ä¸ªå‚æ•°éƒ½åˆ†åˆ«æ‹¥æœ‰è‡ªå·±çš„å­¦ä¹ çŽ‡ï¼Œå­¦ä¹ çŽ‡é»˜è®¤å€¼ä¸º0.01 æœ‰æ•ˆåœ°å¤„ç†ç¨€ç–ç‰¹å¾ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿè‡ªåŠ¨è°ƒæ•´æ¯ä¸ªç‰¹å¾çš„å­¦ä¹ çŽ‡ï¼Œä½¿å¾—ç¨€ç–ç‰¹å¾çš„æ›´æ–°æ›´å°‘ ç¼ºç‚¹ï¼š å…¨å±€å­¦ä¹ çŽ‡: ä»éœ€è¦æ‰‹å·¥è®¾ç½®ä¸€ä¸ªå…¨å±€å­¦ä¹ çŽ‡\\eta, å¦‚æžœ\\etaè®¾ç½®è¿‡å¤§çš„è¯ï¼Œä¼šä½¿regularizerè¿‡äºŽæ•æ„Ÿï¼Œå¯¹æ¢¯åº¦çš„è°ƒèŠ‚å¤ªå¤§ è®­ç»ƒåœæ­¢: ç”±äºŽæ¢¯åº¦å¹³æ–¹å’Œçš„ç´¯ç§¯ï¼Œå­¦ä¹ çŽ‡ä¼šä¸æ–­è¡°å‡ï¼Œå¯èƒ½å¯¼è‡´åœ¨è®­ç»ƒåŽæœŸå­¦ä¹ çŽ‡è¿‡å°ï¼Œé€ æˆæ”¶æ•›é€Ÿåº¦è¿‡æ…¢æˆ–è€…æå‰åœæ­¢è®­ç»ƒçš„é—®é¢˜(Adadeltaç®—æ³•è§£å†³) é™„ä¸Šåˆ«äººå†™çš„ä»£ç  def sgd_adagrad(parameters, sqrs, lr): eps = 1e-10 for param, sqr in zip(parameters, sqrs): sqr[:] = sqr + param.grad.data ** 2 div = lr / torch.sqrt(sqr + eps) * param.grad.data param.data = param.data - div RMSProp An overview of gradient descent optimization algorithms 2017 RMSProp(Root Mean Square Propagation)æ˜¯Hintonå¤§ç¥žäºŽ2012å¹´åœ¨ä¸€é—¨å«Neural Networks for Machine Learningçš„åœ¨çº¿è¯¾ç¨‹ä¸­æå‡º(å¹¶æœªæ­£å¼å‘è¡¨)ï¼Œæ˜¯æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç®—æ³•çš„æ‰©å±• RMSPropå®žé™…ä¸Šæ˜¯Adagradå¼•å…¥äº†Momentumï¼Œå…¬å¼è¡¨è¾¾å¦‚ä¸‹æ‰€ç¤º \\begin{array}{c} G_{t+1} = \\beta G_t + (1-\\beta) \\Delta L (w_{t})^2 \\\\ w_{t+1} = w_t - \\frac {\\alpha}{\\sqrt{ G_{t} + \\epsilon }} \\odot \\Delta L (w_t) \\end{array} \\alphaæ˜¯å­¦ä¹ çŽ‡ï¼Œ\\betaåˆ™ç±»ä¼¼äºŽåŠ¨é‡æ¢¯åº¦ä¸‹é™æ³•ä¸­çš„è¡°å‡å› å­ï¼Œä»£è¡¨è¿‡åŽ»æ¢¯åº¦å¯¹å½“å‰æ¢¯åº¦çš„å½±å“ï¼Œä¸€èˆ¬å–å€¼0.9ï¼Œ\\epsilonæ˜¯ä¸€ä¸ªå¹³æ»‘é¡¹ï¼Œé¿å…äº†é™¤ä»¥é›¶(é€šå¸¸å–å€¼åœ¨1e-8å·¦å³)ï¼Œ\\odotè¡¨ç¤ºå…ƒç´ é€å…ƒç´ ç›¸ä¹˜æ“ä½œ(ä¹Ÿå¯ä»¥çœç•¥ä¸å†™) å…¬å¼é‡Œçš„ç´¯ç§¯æ¢¯åº¦å¹³æ–¹å’ŒG_{t+1}å¯ä»¥å±•å¼€å†™æˆä¸‹é¢çš„å½¢å¼ï¼Œg_iæ˜¯å¯¹æ¢¯åº¦çš„ç¼©å†™(åŒAdaGrad) G_{t+1} = \\beta G_t + (1-\\beta) \\sum _{i=0}^{t} { {g_i} ^2 } ä¼˜ç‚¹ ç¼ºç‚¹ ä»£ç (å‚è€ƒæ–‡æ¡£) drad_squared = 0 for _ in num_iterations: dw = compute_gradients(x, y) grad_squared = 0.9 * grads_squared + 0.1 * dx * dx w = w - (lr / np.sqrt(grad_squared)) * dw Adadelta ä¼˜åŒ–å™¨(AdaGrad,AdaDelta,RmsProp,Adam,Nadam,Nesterovs,Sgd,momentum) AdaDeltaç®—æ³•ä¸¤ç§è§£å†³æ–¹æ¡ˆ Adadelta ä¼˜åŒ–å™¨ ç”±äºŽAdaGradè°ƒæ•´å­¦ä¹ çŽ‡å˜åŒ–è¿‡äºŽæ¿€è¿›ï¼Œæˆ‘ä»¬è€ƒè™‘ä¸€ä¸ªæ”¹å˜äºŒé˜¶åŠ¨é‡è®¡ç®—æ–¹æ³•çš„ç­–ç•¥ï¼šä¸ç´¯ç§¯å…¨éƒ¨åŽ†å²æ¢¯åº¦ï¼Œè€Œåªå…³æ³¨è¿‡åŽ»ä¸€æ®µæ—¶é—´çª—å£çš„ä¸‹é™æ¢¯åº¦ å³Adadeltaåªç´¯åŠ å›ºå®šå¤§å°çš„é¡¹ï¼Œå¹¶ä¸”ä¹Ÿä¸ç›´æŽ¥å­˜å‚¨è¿™äº›é¡¹ï¼Œä»…ä»…æ˜¯è¿‘ä¼¼è®¡ç®—å¯¹åº”çš„å¹³å‡å€¼(æŒ‡æ•°ç§»åŠ¨å¹³å‡å€¼)ï¼Œè¿™å°±é¿å…äº†äºŒé˜¶åŠ¨é‡æŒç»­ç´¯ç§¯ã€å¯¼è‡´è®­ç»ƒè¿‡ç¨‹æå‰ç»“æŸçš„é—®é¢˜äº† è®ºæ–‡ä¸­æåˆ°äº†ä¸¤ç§å®žçŽ°ç­–ç•¥ æ–¹æ³•ä¸€: Accumulate Over Window ä»Žå…¨éƒ¨åŽ†å²æ¢¯åº¦å˜ä¸ºå½“å‰æ—¶é—´å‘å‰çš„ä¸€ä¸ªçª—å£æœŸå†…çš„ç´¯ç§¯ï¼Œè®¡ç®—å®šä¹‰ä¸º \\mathrm{E}\\left[\\mathrm{g}^{2}\\right]_{\\mathrm{t}}=\\rho * \\mathrm{E}\\left[\\mathrm{g}^{2}\\right]_{\\mathrm{t}-1}+(1-\\rho) * \\mathrm{~g}_{\\mathrm{t}}^{2} ç›¸å½“äºŽåŽ†å²æ¢¯åº¦ä¿¡æ¯çš„ç´¯è®¡ä¹˜ä¸Šä¸€ä¸ªè¡°å‡ç³»æ•°\\rhoï¼Œç„¶åŽç”¨\\rhoä½œä¸ºå½“å‰æ¢¯åº¦çš„å¹³æ–¹åŠ æƒç³»æ•°ç›¸åŠ  æ¢¯åº¦æ›´æ–°å…¬å¼ä¸º \\mathrm{w}_{\\mathrm{t+1}}=\\mathrm{w}_{\\mathrm{t}}-\\frac{\\eta}{\\sqrt{\\mathrm{E}\\left[\\mathrm{g}^{2}\\right]_{\\mathrm{t}}+\\epsilon}} * \\mathrm{~g}_{\\mathrm{t}} è§£å†³äº†å¯¹åŽ†å²æ¢¯åº¦ä¸€ç›´ç´¯åŠ è€Œå¯¼è‡´å­¦ä¹ çŽ‡ä¸€ç›´ä¸‹é™çš„é—®é¢˜ æ–¹æ³•äºŒ: Correct Units with Hessian Approximation åœ¨1988å¹´LeCunç­‰äººæ›¾ç»æå‡ºä¸€ç§ç”¨çŸ©é˜µå¯¹è§’çº¿å…ƒç´ æ¥è¿‘ä¼¼é€†çŸ©é˜µ \\Delta x_{t}=-\\frac{1}{\\left|\\operatorname{diag}\\left(H_{t}\\right)\\right|+\\mu} g_{t} diagå‡½æ•°æŒ‡çš„æ˜¯æž„é€ HessiançŸ©é˜µçš„å¯¹è§’çŸ©é˜µï¼Œ\\muæ˜¯å¸¸æ•°é¡¹ï¼Œé˜²æ­¢åˆ†æ¯ä¸º0 å¦‚æžœå­¦è¿‡æ•°å€¼åˆ†æžçš„åŒå­¦åº”è¯¥çŸ¥é“ï¼Œç‰›é¡¿æ³•ç”¨HessiançŸ©é˜µæ›¿ä»£äººå·¥è®¾ç½®çš„å­¦ä¹ çŽ‡ï¼Œåœ¨æ¢¯åº¦ä¸‹é™çš„æ—¶å€™ï¼Œå¯ä»¥å®Œç¾Žçš„æ‰¾å‡ºä¸‹é™æ–¹å‘ï¼Œä¸ä¼šé™·å…¥å±€éƒ¨æœ€å°å€¼å½“ä¸­ï¼Œæ˜¯ç†æƒ³çš„æ–¹æ³•ï¼Œä½†æ˜¯HessiançŸ©é˜µçš„é€†åœ¨æ•°æ®å¾ˆå¤§çš„æƒ…å†µä¸‹æ ¹æœ¬æ²¡åŠžæ³•æ±‚ 2012å¹´ï¼Œ[Schaul&S. Zhang&LeCun]å€Ÿé‰´äº†AdaGradçš„åšæ³•ï¼Œæå‡ºäº†æ›´ç²¾ç¡®çš„è¿‘ä¼¼ \\Delta x_{t}=-\\frac{1}{\\left|\\operatorname{diag}\\left(H_{t}\\right)\\right|} \\frac{E\\left[g_{t-w: t}\\right]^{2}}{E\\left[g_{t-w: t}^{2}\\right]} g_{t} E\\left[g_{t-w: t}\\right]æŒ‡çš„æ˜¯ä»Žå½“å‰tå¼€å§‹çš„å‰wä¸ªæ¢¯åº¦çŠ¶æ€çš„æœŸæœ›å€¼ E\\left[g_{t-w: t}^{2}\\right]æŒ‡çš„æ˜¯ä»Žå½“å‰tå¼€å§‹çš„å‰wä¸ªæ¢¯åº¦çŠ¶æ€çš„å¹³æ–¹çš„æœŸæœ›å€¼ åŒæ ·æ˜¯åŸºäºŽGradientçš„Regularizerï¼Œä¸è¿‡åªå–æœ€è¿‘çš„wä¸ªçŠ¶æ€ï¼Œè¿™æ ·ä¸ä¼šè®©æ¢¯åº¦è¢«æƒ©ç½šè‡³0 è¿™é‡Œå¦‚æžœæ±‚æœŸæœ›çš„è¯ï¼Œéžå¸¸çš„éº»çƒ¦ï¼Œæ‰€ä»¥é‡‡å–äº†ç§»åŠ¨å¹³å‡æ³•æ¥è®¡ç®—ã€‚è¿™é‡Œä½œè€…åœ¨è®ºæ–‡ä¸­ä¹Ÿç»™å‡ºäº†è¿‘ä¼¼çš„è¯æ˜Ž \\Delta \\mathrm{x} \\propto \\mathrm{g} \\propto \\frac{\\mathrm{df}}{\\mathrm{dx}} \\propto \\frac{1}{x} è¿™é‡Œæ˜¯å½“ä¸ºæŒ‡æ•°åž‹å‡½æ•°, æœ€åŽä¸€ä¸ªè¿‘ä¼¼æˆç«‹ã€‚ å¯¹äºŽç‰›é¡¿æ³•ï¼š \\Delta \\mathrm{x} \\propto H^{-1} \\mathrm{~g} \\propto \\frac{\\frac{\\mathrm{df}}{\\mathrm{dx}}}{\\frac{\\partial^{2} f}{\\partial x^{2}}} ç”±ä¸Šå¼å¯å¾—ï¼š \\frac{\\frac{d f}{d x}}{\\frac{\\partial^{2} f}{\\partial x^{2}}}=\\frac{1}{\\frac{\\partial^{2} f}{\\partial x^{2}}} g_{t} åŸºä¸­: \\frac{\\frac{d f}{d x}}{\\frac{\\partial^{2} f}{\\partial x^{2}}}=\\frac{1}{\\frac{\\partial^{2} f}{\\partial x^{2}}} g_{t} è¿™é‡Œå¯ä»¥ç”¨å±€éƒ¨çš„åŠ æƒæŒ‡æ•°å¹³æ»‘æ¥æ›¿ä»£ï¼Œå³ï¼š \\frac{\\Delta x}{\\frac{\\partial f}{\\partial x}} \\approx-\\frac{R M S[\\Delta x]_{t-1}}{R M S[\\Delta g]_{t}} è¿™é‡Œçš„RMSè¡¨ç¤ºå‡æ–¹: \\operatorname{RMS}[g]_{t}=\\sqrt{E\\left[g^{2}\\right]_{t}+\\epsilon} å¯ä»¥å¾—åˆ°: \\Delta x_{t}=-\\frac{\\operatorname{RMS}[\\Delta x]_{t-1}}{\\operatorname{RMS}[g]_{t}} g_{t} æœ€åŽçš„æ›´æ–°å…¬å¼ä¸º \\mathrm{x}_{\\mathrm{t+1}}=\\mathrm{x}_{\\mathrm{t}} + \\Delta x_{t} ä¼˜ç‚¹ æ— éœ€æ‰‹åŠ¨è®¾ç½®å­¦ä¹ çŽ‡ï¼šAdadeltaèƒ½å¤Ÿè‡ªé€‚åº”åœ°è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½® è§£å†³äº†å­¦ä¹ çŽ‡è¡°å‡é—®é¢˜ï¼šç”±äºŽé‡‡ç”¨äº†è¡°å‡å¹³å‡çš„æ–¹å¼ï¼ŒAdadeltaèƒ½å¤Ÿè§£å†³å­¦ä¹ çŽ‡éšæ—¶é—´è¡°å‡è¿‡å¿«çš„é—®é¢˜ï¼Œä½¿å¾—æ¨¡åž‹èƒ½å¤Ÿæ›´å¥½åœ°æ”¶æ•› ä¸ä¾èµ–å…¨å±€å­¦ä¹ çŽ‡ï¼šAdadeltaä¸éœ€è¦è®¾ç½®å…¨å±€å­¦ä¹ çŽ‡ï¼Œå› æ­¤å¯ä»¥é€‚åº”ä¸åŒå‚æ•°çš„å­¦ä¹ é€Ÿåº¦éœ€æ±‚ å¯¹åˆå§‹å­¦ä¹ çŽ‡ä¸æ•æ„Ÿï¼šAdadeltaç›¸å¯¹äºŽå…¶ä»–ä¼˜åŒ–å™¨å¯¹åˆå§‹å­¦ä¹ çŽ‡çš„é€‰æ‹©å¹¶ä¸æ•æ„Ÿï¼Œä½¿å¾—æ¨¡åž‹æ›´å…·é²æ£’æ€§ ç¼ºç‚¹ å­˜å‚¨é¢å¤–çš„çŠ¶æ€ä¿¡æ¯ï¼šAdadeltaéœ€è¦ä¿å­˜é¢å¤–çš„çŠ¶æ€ä¿¡æ¯(å¦‚æ¢¯åº¦å¹³æ–¹çš„ç´¯ç§¯)ï¼Œå¢žåŠ äº†å­˜å‚¨çš„å¼€é”€ ç®—æ³•å‚æ•°è¦è°ƒæ•´ï¼šAdadeltaä¸­çš„è¡°å‡ç³»æ•°\\rhoéœ€è¦è¿›è¡Œé€‚å½“çš„è°ƒæ•´ï¼Œä¸åŒä»»åŠ¡å¯èƒ½éœ€è¦ä¸åŒçš„è®¾ç½® Adam Adam(Adaptive Moment Estimation)è‡ªé€‚åº”çŸ©ä¼°è®¡ï¼Œæ˜¯å¦ä¸€ç§è‡ªé€‚åº”å­¦ä¹ çŽ‡çš„ç®—æ³•ï¼Œæœ¬è´¨ä¸Šæ˜¯å¸¦æœ‰åŠ¨é‡é¡¹çš„Adadeltaæˆ–RMSprop æ˜¯Diederik P. Kingmaç­‰äººåœ¨2014å¹´æå‡ºçš„ä¼˜åŒ–ç®—æ³•ï¼Œå¼•å…¥äº†ä¸¤ä¸ªå‚æ•°\\beta 1å’Œ\\beta 2 æ€è·¯ Adamä¸ä»…å¦‚RMSPropç®—æ³•é‚£æ ·åŸºäºŽä¸€é˜¶çŸ©å‡å€¼è®¡ç®—é€‚åº”æ€§å‚æ•°å­¦ä¹ çŽ‡ï¼Œå®ƒåŒæ—¶è¿˜å……åˆ†åˆ©ç”¨äº†æ¢¯åº¦çš„äºŒé˜¶çŸ©å‡å€¼(å³æœ‰åæ–¹å·®)ï¼Œé€‚åˆè§£å†³å«å¤§è§„æ¨¡çš„æ•°æ®å’Œå‚æ•°çš„ä¼˜åŒ–ç›®æ ‡ï¼Œä¹Ÿé€‚åˆè§£å†³åŒ…å«é«˜å™ªå£°æˆ–ç¨€ç–æ¢¯åº¦çš„é—®é¢˜ï¼Œè®©å‚æ•°æ›´æ–°æ—¶ä¿æŒç¨³å®š \\begin{aligned} m_{t} & =\\beta_{1} m_{t-1}+\\left(1-\\beta_{1}\\right) g_{t} \\\\ \\\\ v_{t} & =\\beta_{2} v_{t-1}+\\left(1-\\beta_{2}\\right) g_{t}^{2} \\\\ \\\\ \\hat{m}_{t} & =\\frac{m_{t}}{1-\\beta_{1}^{t}} \\\\ \\\\ \\hat{v}_{t} & =\\frac{v_{t}}{1-\\beta_{2}^{t}} \\\\ \\\\ \\end{aligned} å…¶ä¸­\\beta _1æŽ§åˆ¶ä¸€é˜¶åŠ¨é‡ï¼Œ\\beta _2æŽ§åˆ¶äºŒé˜¶åŠ¨é‡ æœ€ç»ˆçš„å‚æ•°æ›´æ–°å…¬å¼ä¸º w_{t+1} = w_{t}- \\eta \\frac{\\hat{m}_{t}}{\\sqrt{\\hat{v}_{t}}+\\epsilon} é»˜è®¤å€¼è®¾ç½®\\alpha=0.001 ï¼Œ \\beta 1=0.9 ï¼Œ \\beta 2=0.999 ï¼Œ \\varepsilon=10-8 ä¼˜ç‚¹ è‡ªé€‚åº”å­¦ä¹ çŽ‡ï¼šAdamé€šè¿‡è‡ªé€‚åº”åœ°è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ çŽ‡ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åº”å¯¹ä¸åŒå‚æ•°çš„æ¢¯åº¦å˜åŒ–æƒ…å†µã€‚è¿™ä½¿å¾—å®ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´å®¹æ˜“æ”¶æ•›ï¼Œå¹¶ä¸”å¯¹äºŽå¤§å¤šæ•°ä»»åŠ¡å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ï¼Œä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯å®ƒçš„æ•ˆæžœæœ‰æ—¶å€™ä¸å¦‚SGDM é€Ÿåº¦å¿«ï¼šAdamç»“åˆäº†åŠ¨é‡æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç§¯ç´¯æ¢¯åº¦çš„åŠ¨é‡ï¼Œä»Žè€ŒåŠ é€Ÿå‚æ•°æ›´æ–°çš„é€Ÿåº¦ï¼Œå°¤å…¶åœ¨å…·æœ‰å¹³å¦æˆ–ç¨€ç–æ¢¯åº¦çš„æƒ…å†µä¸‹æ›´åŠ æ˜Žæ˜¾ ç»“åˆäº†Adagradå–„äºŽå¤„ç†ç¨€ç–æ¢¯åº¦å’ŒRMSpropå–„äºŽå¤„ç†éžå¹³ç¨³ç›®æ ‡çš„ä¼˜ç‚¹ é€‚ç”¨æ€§å¹¿æ³›ï¼šä¹Ÿé€‚ç”¨äºŽå¤§å¤šéžå‡¸ä¼˜åŒ–ï¼Œé€‚ç”¨äºŽå¤§æ•°æ®é›†å’Œé«˜ç»´ç©ºé—´ ç¼ºç‚¹ å†…å­˜æ¶ˆè€—è¾ƒå¤§ï¼šAdaméœ€è¦å­˜å‚¨æ¯ä¸ªå‚æ•°çš„åŠ¨é‡å’Œå¹³æ–¹æ¢¯åº¦ä¼°è®¡ï¼Œè¿™ä¼šå ç”¨è¾ƒå¤§çš„å†…å­˜ç©ºé—´ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰å¤§é‡å‚æ•°çš„æ·±åº¦ç¥žç»ç½‘ç»œä¸­ AdaMax AdaMaxæ˜¯ä¸€ç§è‡ªé€‚åº”å­¦ä¹ çŽ‡ä¼˜åŒ–ç®—æ³•ï¼Œæ˜¯Adamä¼˜åŒ–å™¨çš„ä¸€ç§å˜ä½“ AdaMaxä½¿ç”¨äº†æ¢¯åº¦çš„æ— ç©·èŒƒæ•°æ¥ä¼°è®¡æ¢¯åº¦çš„å¤§å°ï¼Œè€ŒAdamä½¿ç”¨äº†æ¢¯åº¦çš„äºŒèŒƒæ•°(æ ¸å¿ƒåŒºåˆ«)ï¼Œå˜åŒ–å¦‚ä¸‹æ‰€ç¤º v_{t} = \\beta_{2} v_{t-1}+\\left(1-\\beta_{2}\\right) g_{t}^{2} \\longrightarrow v_{t} = \\beta_{2} v_{t-1}+\\left(1-\\beta_{2}\\right) |g_{t}|^{p} è®ºæ–‡ä¸­AdaMaxçš„p= \\infty ä¸ºä»€ä¹ˆæ˜¯é€‰æ‹©äº†æ— ç©·èŒƒæ•° AdaMaxé€‰æ‹©äº†æ— ç©·èŒƒæ•°(\\inftyèŒƒæ•°)æ˜¯å› ä¸ºåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œ\\inftyèŒƒæ•°å…·æœ‰ç¨³å®šçš„è¡Œä¸º å¯¹äºŽä¸€äº›é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œ\\inftyèŒƒæ•°å¯ä»¥æä¾›æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ ç›¸æ¯”äºŽå…¶ä»–èŒƒæ•°ï¼Œ\\inftyèŒƒæ•°èƒ½å¤Ÿæ›´å¥½åœ°æŽ§åˆ¶æ¢¯åº¦çš„æœ€å¤§å€¼ï¼Œä»Žè€Œå‡å°‘å‚æ•°æ›´æ–°çš„ä¸ç¨³å®šæ€§ å› æ­¤ï¼ŒAdaMaxé€‰æ‹©äº†\\inftyèŒƒæ•°ä½œä¸ºå…¶æ›´æ–°è§„åˆ™çš„ä¸€éƒ¨åˆ†ï¼Œä»¥æé«˜ä¼˜åŒ–ç®—æ³•çš„ç¨³å®šæ€§å’Œæ•ˆæžœ Nadam æ·±åº¦å­¦ä¹ ä¼˜åŒ–ç­–ç•¥Nadam Nadam(Nesterov-accelerated Adaptive Moment Estimation)æ˜¯å°†Adamä¸ŽNesterovåŠ é€Ÿæ¢¯åº¦ç»“åˆåœ¨ä¸€èµ·ï¼Œå®ƒå¯¹å­¦ä¹ çŽ‡çš„çº¦æŸå°†æ›´å¼ºï¼Œå…·å¤‡äºŒè€…çš„ä¼˜åŠ¿ï¼Œä½¿å¾—æ­¤ç®—æ³•åœ¨æŸäº›é—®é¢˜ä¸Šçš„æ•ˆæžœæ›´å¥½ Nadamçš„æ›´æ–°è§„åˆ™ä¸ŽAdamç±»ä¼¼ï¼Œä½†åœ¨è®¡ç®—æ¢¯åº¦æ›´æ–°æ—¶å¼•å…¥äº†NesterovåŠ¨é‡é¡¹ã€‚å…·ä½“è€Œè¨€ï¼ŒNadamåœ¨è®¡ç®—æ¢¯åº¦çš„ç§»åŠ¨å¹³å‡å’Œæ¢¯åº¦æ›´æ–°æ—¶ï¼Œä½¿ç”¨äº†NesterovåŠ¨é‡çš„ä¿®æ­£æ¢¯åº¦æ¥æ›´æ–°æ¨¡åž‹å‚æ•°ã€‚è¿™ä½¿å¾—Nadamåœ¨å¤„ç†å‡¸ä¼˜åŒ–é—®é¢˜æ—¶èƒ½å¤Ÿæ›´å¥½åœ°é€¼è¿‘æœ€ä¼˜è§£ï¼Œå¹¶ä¸”åœ¨å¤„ç†éžå‡¸é—®é¢˜æ—¶èƒ½å¤Ÿæ›´å¿«åœ°æ”¶æ•› å…¶ä»–ä¼˜åŒ–å™¨ AdamWï¼ˆAdam with Weight Decayï¼‰ï¼š AdamWæ˜¯å¯¹Adamä¼˜åŒ–å™¨çš„æ”¹è¿›ï¼Œé€šè¿‡æ·»åŠ æƒé‡è¡°å‡ï¼ˆWeight Decayï¼‰çš„æ­£åˆ™åŒ–é¡¹æ¥è§£å†³æƒé‡è¡°å‡å¯¹Adamä¼˜åŒ–å™¨çš„å½±å“ã€‚ä¼ ç»Ÿçš„Adamä¼˜åŒ–å™¨åœ¨è®¡ç®—æ¢¯åº¦æ›´æ–°æ—¶ï¼Œä¼šå°†æƒé‡è¡°å‡é¡¹ä¹Ÿçº³å…¥æ¢¯åº¦è®¡ç®—ä¸­ï¼Œå¯¼è‡´æƒé‡è¡°å‡æ•ˆæžœä¸å‡†ç¡®ã€‚è€ŒAdamWåœ¨è®¡ç®—æ¢¯åº¦æ›´æ–°æ—¶å°†æƒé‡è¡°å‡é¡¹å•ç‹¬å¤„ç†ï¼Œä½¿å¾—æƒé‡è¡°å‡çš„æ•ˆæžœæ›´åŠ å‡†ç¡®å’Œç¨³å®š ASGDï¼ˆAverage Stochastic Gradient Descentï¼‰ï¼š ASGDæ˜¯ä¸€ç§éšæœºæ¢¯åº¦ä¸‹é™æ³•çš„å˜ä½“ï¼Œå®ƒé€šè¿‡è®¡ç®—ä¸€å®šæ•°é‡çš„éšæœºæ¢¯åº¦çš„å¹³å‡å€¼æ¥æ›´æ–°æ¨¡åž‹å‚æ•°ã€‚ASGDä½¿ç”¨ä¸€ä¸ªå¹³å‡æ¨¡åž‹å‚æ•°çš„åŽ†å²è®°å½•ï¼Œä»¥å‡å°è®­ç»ƒè¿‡ç¨‹ä¸­å‚æ•°æ›´æ–°çš„æ–¹å·®ã€‚è¿™æ ·å¯ä»¥ä½¿æ¨¡åž‹çš„æ”¶æ•›é€Ÿåº¦æ›´ç¨³å®šï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å‡å°å­¦ä¹ çŽ‡ï¼Œä½¿å¾—æ¨¡åž‹åœ¨è®­ç»ƒåŽæœŸæ›´åŠ è¶‹äºŽæ”¶æ•› LBFGSï¼ˆLimited-memory Broyden-Fletcher-Goldfarb-Shannoï¼‰ï¼š LBFGSæ˜¯ä¸€ç§åŸºäºŽæ‹Ÿç‰›é¡¿æ³•çš„ä¼˜åŒ–ç®—æ³•ï¼Œç”¨äºŽè§£å†³æ— çº¦æŸéžçº¿æ€§ä¼˜åŒ–é—®é¢˜ã€‚å®ƒåˆ©ç”¨å‡½æ•°çš„ä¸€é˜¶å¯¼æ•°å’ŒäºŒé˜¶å¯¼æ•°ä¿¡æ¯æ¥é€¼è¿‘ç›®æ ‡å‡½æ•°çš„å±€éƒ¨äºŒæ¬¡æ¨¡åž‹ï¼Œå¹¶é€šè¿‡è¿­ä»£æ›´æ–°å‚æ•°æ¥å¯»æ‰¾æœ€ä¼˜è§£ã€‚LBFGSä½¿ç”¨æœ‰é™çš„å†…å­˜æ¥å­˜å‚¨åŽ†å²ä¿¡æ¯ï¼Œä»¥å‡å°‘å†…å­˜æ¶ˆè€—ã€‚ç”±äºŽå®ƒä¸éœ€è¦æ˜¾å¼è®¡ç®—äºŒé˜¶å¯¼æ•°çŸ©é˜µï¼ŒLBFGSé€‚ç”¨äºŽå‚æ•°è¾ƒå¤šçš„é—®é¢˜ï¼Œå¹¶ä¸”é€šå¸¸å…·æœ‰è¾ƒå¥½çš„æ”¶æ•›æ€§èƒ½ æ€»ç»“ï¼š AdamWæ˜¯å¯¹Adamä¼˜åŒ–å™¨çš„æ”¹è¿›ï¼Œè§£å†³äº†æƒé‡è¡°å‡å¯¹Adamä¼˜åŒ–å™¨çš„å½±å“ ASGDæ˜¯ä¸€ç§éšæœºæ¢¯åº¦ä¸‹é™æ³•çš„å˜ä½“ï¼Œé€šè¿‡å¹³å‡éšæœºæ¢¯åº¦æ¥å‡å°å‚æ•°æ›´æ–°çš„æ–¹å·®ï¼Œæé«˜æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§ LBFGSæ˜¯ä¸€ç§åŸºäºŽæ‹Ÿç‰›é¡¿æ³•çš„ä¼˜åŒ–ç®—æ³•ï¼Œé€šè¿‡é€¼è¿‘ç›®æ ‡å‡½æ•°çš„å±€éƒ¨äºŒæ¬¡æ¨¡åž‹æ¥å¯»æ‰¾æœ€ä¼˜è§£ï¼Œå…·æœ‰è¾ƒå¥½çš„æ”¶æ•›æ€§èƒ½å’Œé€‚ç”¨æ€§ å­¦ä¹ çŽ‡è¡°å‡ åœ¨æ¨¡åž‹ä¼˜åŒ–ä¸­ï¼Œå¸¸ç”¨åˆ°çš„å‡ ç§å­¦ä¹ çŽ‡è¡°å‡æ–¹æ³•æœ‰ï¼šåˆ†æ®µå¸¸æ•°è¡°å‡ã€å¤šé¡¹å¼è¡°å‡ã€æŒ‡æ•°è¡°å‡ã€è‡ªç„¶æŒ‡æ•°è¡°å‡ã€ä½™å¼¦è¡°å‡ã€çº¿æ€§ä½™å¼¦è¡°å‡ã€å™ªå£°çº¿æ€§ä½™å¼¦è¡°å‡ æ·±åº¦å­¦ä¹ ä¼˜åŒ–å™¨æ–¹æ³•åŠå­¦ä¹ çŽ‡è¡°å‡æ–¹å¼ç»¼è¿° Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æŸå¤±å‡½æ•°.html":{"url":"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æŸå¤±å‡½æ•°.html","title":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æŸå¤±å‡½æ•°.md","summary":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æŸå¤±å‡½æ•°","keywords":"","body":"æ¦‚è¿°å›žå½’æŸå¤±å‡½æ•°L1 LossL2 LossSmooth L1 LossHuber LossQuantile LossIoU Lossåˆ†ç±»æŸå¤±å‡½æ•°Binary Cross EntropyCross Entropy Lossæœ€å¤§ä¼¼ç„¶è§’åº¦ä¿¡æ¯è®ºè§’åº¦Hinge LossFocal LossåŸºäºŽæ¦‚çŽ‡çš„æŸå¤±KLæ•£åº¦æ­£åˆ™åŒ–æŠ€æœ¯L1æ­£åˆ™åŒ–L2æ­£åˆ™åŒ–å¼¹æ€§ç½‘æ­£åˆ™åŒ–å…¶ä»–æ­£åˆ™ æ¦‚è¿° ä¸€æ–‡çœ‹å°½æ·±åº¦å­¦ä¹ ä¸­çš„å„ç§æŸå¤±å‡½æ•° å¸¸ç”¨çš„æŸå¤±å‡½æ•°åˆé›† æ·±åº¦å­¦ä¹ å¸¸ç”¨æŸå¤±å‡½æ•°çš„åŸºæœ¬å½¢å¼ã€åŽŸç†åŠç‰¹ç‚¹ Loss Functions æŸå¤±å‡½æ•°(Loss Function)æ˜¯ç”¨æ¥è¡¡é‡æ¨¡åž‹é¢„æµ‹å€¼ä¸ŽçœŸå®žå€¼ä¹‹é—´å·®å¼‚çš„å‡½æ•°ï¼Œå®ƒæ˜¯æ·±åº¦å­¦ä¹ ä¸­çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ï¼Œç”¨äºŽè¯„ä¼°æ¨¡åž‹çš„æ€§èƒ½å¹¶æŒ‡å¯¼æ¨¡åž‹çš„ä¼˜åŒ–è¿‡ç¨‹ æŸå¤±å‡½æ•°ã€ä»£ä»·å‡½æ•°ã€ç›®æ ‡å‡½æ•°çš„å…³ç³» æŸå¤±å‡½æ•°(Loss Function)ï¼šæŸå¤±å‡½æ•°æ˜¯ç”¨æ¥è¡¡é‡æ¨¡åž‹åœ¨å•ä¸ªæ ·æœ¬ä¸Šçš„é¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾ä¹‹é—´çš„å·®å¼‚ã€‚å®ƒæ˜¯ä¸€ä¸ªæ ‡é‡å€¼ï¼Œè¡¨ç¤ºæ¨¡åž‹é¢„æµ‹çš„è¯¯å·®æˆ–æŸå¤±ç¨‹åº¦ã€‚æŸå¤±å‡½æ•°é€šå¸¸æ˜¯é’ˆå¯¹å•ä¸ªæ ·æœ¬è®¡ç®—çš„ï¼Œä¾‹å¦‚å‡æ–¹è¯¯å·®(MSE)ã€äº¤å‰ç†µæŸå¤±ç­‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡åž‹å‚æ•°ï¼Œä½¿æ¨¡åž‹çš„é¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾æ›´æŽ¥è¿‘ ä»£ä»·å‡½æ•°(Cost Function)ï¼šä»£ä»·å‡½æ•°æ˜¯æŒ‡æ•´ä¸ªè®­ç»ƒé›†ä¸Šçš„å¹³å‡æŸå¤±æˆ–è¯¯å·®å‡½æ•°ã€‚ä»£ä»·å‡½æ•°æ˜¯æŸå¤±å‡½æ•°çš„æ±‚å’Œæˆ–å¹³å‡ï¼Œç”¨äºŽè¡¡é‡æ¨¡åž‹åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šçš„é¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾ä¹‹é—´çš„æ€»ä½“å·®å¼‚ã€‚ä»£ä»·å‡½æ•°é€šå¸¸æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„ï¼Œç”¨äºŽè®¡ç®—æ¢¯åº¦å¹¶æ›´æ–°æ¨¡åž‹å‚æ•° ç›®æ ‡å‡½æ•°(Objective Function)ï¼šç›®æ ‡å‡½æ•°æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¦æœ€å°åŒ–æˆ–æœ€å¤§åŒ–çš„å‡½æ•°ï¼Œå¯ä»¥æ˜¯æŸå¤±å‡½æ•°æˆ–ä»£ä»·å‡½æ•°ã€‚ç›®æ ‡å‡½æ•°æ˜¯æ¨¡åž‹è®­ç»ƒçš„ç›®æ ‡ï¼Œé€šè¿‡ä¼˜åŒ–ç›®æ ‡å‡½æ•°æ¥è°ƒæ•´æ¨¡åž‹å‚æ•°ï¼Œä½¿å¾—æ¨¡åž‹åœ¨è®­ç»ƒé›†ä¸Šçš„æ€§èƒ½è¾¾åˆ°æœ€ä¼˜ å®šä¹‰ æŸå¤±å‡½æ•°(Loss Function) ä»£ä»·å‡½æ•°(Cost Function) ç›®æ ‡å‡½æ•°(Objective Function) æ•°æ®é›† å•ä¸ªæ ·æœ¬ æ•´ä¸ªè®­ç»ƒé›† è®­ç»ƒè¦ä¼˜åŒ–å‡½æ•° åœ¨å®žé™…åº”ç”¨ä¸­ï¼ŒæŸå¤±å‡½æ•°ã€ä»£ä»·å‡½æ•°å’Œç›®æ ‡å‡½æ•°è¿™äº›æœ¯è¯­æœ‰æ—¶ä¼šè¢«æ··ç”¨ï¼Œä½†å®ƒä»¬éƒ½æ¶‰åŠåˆ°è¡¡é‡æ¨¡åž‹çš„é¢„æµ‹ç»“æžœä¸ŽçœŸå®žæ ‡ç­¾ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”¨äºŽä¼˜åŒ–æ¨¡åž‹ æŸå¤±å‡½æ•°å¤§è‡´å¯åˆ†ä¸ºä¸¤ç§ï¼šå›žå½’æŸå¤±(é’ˆå¯¹è¿žç»­åž‹å˜é‡)å’Œåˆ†ç±»æŸå¤±(é’ˆå¯¹ç¦»æ•£åž‹å˜é‡) å…·ä½“ä½¿ç”¨å“ªä¸ªæœ¯è¯­å–å†³äºŽä¸Šä¸‹æ–‡å’Œä¸ªäººåå¥½ï¼Œä½†å®ƒä»¬éƒ½æŒ‡å‘ç±»ä¼¼çš„æ¦‚å¿µ å›žå½’æŸå¤±å‡½æ•° æ·±åº¦å­¦ä¹ å¸¸ç”¨æŸå¤±å‡½æ•°æ€»è§ˆï¼šåŸºæœ¬å½¢å¼ã€åŽŸç†ã€ç‰¹ç‚¹ L1 Loss L1 Lossä¹Ÿç§°ä¸ºMean Absolute Errorï¼Œå³å¹³å‡ç»å¯¹è¯¯å·®(MAE)ï¼Œå…¬å¼å®šä¹‰ä¸º J_{M A E}=\\frac{1}{N} \\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| ä¼˜ç‚¹: å¯¹ç¦»ç¾¤ç‚¹(Outliers)æˆ–è€…å¼‚å¸¸å€¼æ›´å…·æœ‰é²æ£’æ€§ ç¼ºç‚¹: ç”±å›¾å¯çŸ¥å…¶åœ¨0ç‚¹å¤„çš„å¯¼æ•°ä¸è¿žç»­ï¼Œä½¿å¾—æ±‚è§£æ•ˆçŽ‡ä½Žä¸‹ï¼Œå¯¼è‡´æ”¶æ•›é€Ÿåº¦æ…¢ï¼›å¯¹äºŽè¾ƒå°çš„æŸå¤±å€¼ï¼Œå…¶æ¢¯åº¦ä¹ŸåŒå…¶ä»–åŒºé—´æŸå¤±å€¼çš„æ¢¯åº¦ä¸€æ ·å¤§ï¼Œæ‰€ä»¥ä¸åˆ©äºŽç½‘ç»œçš„å­¦ä¹  æ¨¡åž‹é¢„æµ‹ä¸ŽçœŸå®žå€¼ä¹‹é—´çš„è¯¯å·®æœä»Žæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒLaplace distribution å¯ä»¥åœ¨ä¸€å®šçš„å‡è®¾ä¸‹é€šè¿‡æœ€å¤§åŒ–ä¼¼ç„¶å¯ä»¥å¾—åˆ°MAEæŸå¤±çš„å½¢å¼ï¼Œå‡è®¾æ¨¡åž‹é¢„æµ‹ä¸ŽçœŸå®žå€¼ä¹‹é—´çš„è¯¯å·®æœä»Žæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒLaplace distribution (\\mu=0, b=1)ï¼Œåˆ™ç»™å®šä¸€ä¸ªè¾“å…¥x_{i}ï¼Œæ¨¡åž‹è¾“å‡ºçœŸå®žå€¼y_{i}çš„æ¦‚çŽ‡ä¸º p\\left(y_{i} \\mid x_{i}\\right)=\\frac{1}{2} \\exp \\left(-\\left|y_{i}-\\hat{y}_{i}\\right|\\right) å¯¹å…¶æ±‚å¯¹æ•°å¯ä»¥å¾—åˆ°çš„è´Ÿå¯¹æ•°ä¼¼ç„¶å®žé™…ä¸Šå°±æ˜¯MAEæŸå¤±çš„å½¢å¼ \\begin{array}{l} L(x, y)=\\prod_{i=1}^{N} \\frac{1}{2} \\exp \\left(-\\left|y_{i}-\\hat{y}_{i}\\right|\\right) \\\\ \\\\ L L(x, y)=-\\frac{N}{2}-\\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| \\\\ \\\\ N L L(x, y)=\\sum_{i=1}^{N}\\left|y_{i}-\\hat{y}_{i}\\right| \\end{array} L2 Loss L2 Lossä¹Ÿç§°ä¸ºMean Squred Errorï¼Œå³å‡æ–¹å·®(MSE)ï¼Œå®ƒè¡¡é‡çš„æ˜¯é¢„æµ‹å€¼ä¸ŽçœŸå®žå€¼ä¹‹é—´è·ç¦»çš„å¹³æ–¹å’Œ J_{M S E}=\\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2} ä¼˜ç‚¹: æ”¶æ•›é€Ÿåº¦å¿«ï¼Œèƒ½å¤Ÿå¯¹æ¢¯åº¦ç»™äºˆåˆé€‚çš„æƒ©ç½šæƒé‡ï¼Œè€Œä¸æ˜¯ä¸€è§†åŒä»ï¼Œä½¿æ¢¯åº¦æ›´æ–°çš„æ–¹å‘å¯ä»¥æ›´åŠ ç²¾ç¡® ç¼ºç‚¹: å¯¹å¼‚å¸¸å€¼ååˆ†æ•æ„Ÿï¼Œæ¢¯åº¦æ›´æ–°çš„æ–¹å‘å¾ˆå®¹æ˜“å—ç¦»ç¾¤ç‚¹æ‰€ä¸»å¯¼ï¼Œä¸å…·å¤‡é²æ£’æ€§ï¼Œå‡å¦‚æˆ‘ä»¬è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨è¾ƒå¤§çš„å¼‚å¸¸å€¼ï¼Œæ­¤æ—¶æˆ‘ä»¬å°†ä¼šæœ‰ä¸€ä¸ªå·¨å¤§çš„æƒé‡æ›´æ–°ï¼Œè¿™æœ‰å¯èƒ½ä¼šä½¿æ¨¡åž‹å¤±åŽ»å¹³è¡¡ åœ¨æ¨¡åž‹è¾“å‡ºä¸ŽçœŸå®žå€¼çš„è¯¯å·®æœä»Žé«˜æ–¯åˆ†å¸ƒçš„å‡è®¾ä¸‹ï¼Œæœ€å°åŒ–å‡æ–¹å·®æŸå¤±å‡½æ•°ä¸Žæžå¤§ä¼¼ç„¶ä¼°è®¡æœ¬è´¨ä¸Šæ˜¯ä¸€è‡´çš„ MSEå‡è®¾äº†è¯¯å·®æœä»Žé«˜æ–¯åˆ†å¸ƒï¼Œåœ¨é«˜æ–¯åˆ†å¸ƒå‡è®¾ä¸‹ï¼Œå¯ä»¥ä½¿ç”¨æœ€å¤§åŒ–ä¼¼ç„¶å¾—åˆ°å‡æ–¹å·®æŸå¤±çš„å½¢å¼ï¼Œå‡è®¾æ¨¡åž‹é¢„æµ‹ä¸ŽçœŸå®žå€¼ä¹‹é—´çš„è¯¯å·®æœä»Žæ ‡å‡†é«˜æ–¯åˆ†å¸ƒ(\\mu=0, \\sigma=1)ï¼Œåˆ™ç»™å®šä¸€ä¸ªè¾“å…¥x_{i}ï¼Œæ¨¡åž‹è¾“å‡ºçœŸå®žå€¼y_{i}çš„æ¦‚çŽ‡ä¸º p\\left(y_{i} \\mid x_{i}\\right) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left[-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}\\right] =\\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{2}\\right) è¿›ä¸€æ­¥æˆ‘ä»¬å‡è®¾æ•°æ®é›†ä¸­\\mathrm{N}ä¸ªæ ·æœ¬ç‚¹ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼Œåˆ™ç»™å®šæ‰€æœ‰xè¾“å‡ºæ‰€æœ‰çœŸå®žå€¼yçš„æ¦‚çŽ‡ï¼Œå³ä¼¼ç„¶Likelihoodä¸ºæ‰€æœ‰p\\left(y_{i} \\mid x_{i}\\right)çš„ç´¯ä¹˜ L(x, y)=\\prod_{i=1}^{N} \\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}{2}\\right) é€šå¸¸ä¸ºäº†è®¡ç®—æ–¹ä¾¿ï¼Œæˆ‘ä»¬é€šå¸¸æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶Log-Likelihood L L(x, y)=\\log (L(x, y))=-\\frac{N}{2} \\log 2 \\pi-\\frac{1}{2} \\sum_{i=1}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2} åŽ»æŽ‰ä¸Ž\\hat{y}_{i}æ— å…³çš„ç¬¬ä¸€é¡¹ï¼Œç„¶åŽè½¬åŒ–ä¸ºæœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶Negative Log-Likelihood N L L(x, y)=\\frac{1}{2} \\sum_{i=1}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2} å¯ä»¥çœ‹åˆ°è¿™ä¸ªå®žé™…ä¸Šå°±æ˜¯å‡æ–¹å·®æŸå¤±çš„å½¢å¼ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨æ¨¡åž‹è¾“å‡ºä¸ŽçœŸå®žå€¼çš„è¯¯å·®æœä»Žé«˜æ–¯åˆ†å¸ƒçš„å‡è®¾ä¸‹ï¼Œæœ€å°åŒ–å‡æ–¹å·®æŸå¤±å‡½æ•°ä¸Žæžå¤§ä¼¼ç„¶ä¼°è®¡æœ¬è´¨ä¸Šæ˜¯ä¸€è‡´çš„ å› æ­¤åœ¨è¿™ä¸ªå‡è®¾èƒ½è¢«æ»¡è¶³çš„åœºæ™¯ä¸­(æ¯”å¦‚å›žå½’)ï¼Œå‡æ–¹å·®æŸå¤±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æŸå¤±å‡½æ•°é€‰æ‹© å½“è¿™ä¸ªå‡è®¾æ²¡èƒ½è¢«æ»¡è¶³çš„åœºæ™¯ä¸­(æ¯”å¦‚åˆ†ç±»)ï¼Œå‡æ–¹å·®æŸå¤±ä¸æ˜¯ä¸€ä¸ªå¥½çš„é€‰æ‹© MAEå’ŒMSEä½œä¸ºæŸå¤±å‡½æ•°çš„ä¸»è¦åŒºåˆ«æ˜¯ MSEæŸå¤±ç›¸æ¯”MAEé€šå¸¸å¯ä»¥æ›´å¿«åœ°æ”¶æ•› å½“ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æ—¶ï¼ŒMSEçš„æ¢¯åº¦ä¸º-\\hat{y_{i}}ï¼Œè€ŒMAEæŸå¤±çš„æ¢¯åº¦ä¸º\\pm 1 ï¼Œå³MSEçš„æ¢¯åº¦çš„scaleä¼šéšè¯¯å·®å¤§å°å˜åŒ–ï¼Œè€ŒMAEçš„æ¢¯åº¦çš„scaleåˆ™ä¸€ç›´ä¿æŒä¸º1ï¼Œå³ä¾¿åœ¨ç»å¯¹è¯¯å·®\\left|y_{i}-\\hat{y_{i}}\\right|å¾ˆå°çš„æ—¶å€™ï¼ŒMAEçš„æ¢¯åº¦scaleä¹ŸåŒæ ·ä¸º1ï¼Œè¿™å®žé™…ä¸Šæ˜¯éžå¸¸ä¸åˆ©äºŽæ¨¡åž‹çš„è®­ç»ƒçš„ å½“ç„¶ä½ å¯ä»¥é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´å­¦ä¹ çŽ‡ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯æ€»çš„æ¥è¯´ï¼ŒæŸå¤±å‡½æ•°æ¢¯åº¦ä¹‹é—´çš„å·®å¼‚å¯¼è‡´äº†MSEåœ¨å¤§éƒ¨åˆ†æ—¶å€™æ¯”MAEæ”¶æ•›åœ°æ›´å¿«ï¼Œè¿™ä¹Ÿæ˜¯MSEæ›´ä¸ºæµè¡Œçš„åŽŸå›  MAEæŸå¤±å¯¹äºŽoutlieræ›´åŠ å¥å£®ï¼Œå³æ›´åŠ ä¸æ˜“å—åˆ°outlierå½±å“ï¼Œå½“è¯¯å·®éžå¸¸å¤§çš„æ—¶å€™ï¼ŒMSEæŸå¤±ä¼šè¿œè¿œå¤§äºŽMAEæŸå¤± MSEå‡è®¾äº†è¯¯å·®æœä»Žé«˜æ–¯åˆ†å¸ƒï¼ŒMAEå‡è®¾äº†è¯¯å·®æœä»Žæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒï¼Œæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒæœ¬èº«å¯¹äºŽoutlieræ›´åŠ robust é€‚ç”¨åœºæ™¯ Smooth L1 Loss pytorch SMOOTHL LOSS Smooth L1 Losså³å¹³æ»‘çš„L1æŸå¤±(SLL)ï¼Œå‡ºè‡ªFast RCNNï¼Œä¹Ÿç§°ä¸ºSLLï¼ŒSmooth L1 lossä¹Ÿå…·å¤‡äº†L1 losså’ŒL2 losså„è‡ªçš„ä¼˜ç‚¹ï¼Œæœ¬è´¨å°±æ˜¯L1å’ŒL2çš„ç»„åˆ J_{SLL} =\\left\\{ \\begin{array}{ll}0.5\\left(y_{i}-\\hat{y}_{i}\\right)^{2} / \\beta , & \\text { if }\\left|y_{i}-\\hat{y}_{i}\\right| Huber Loss pytorch Huber LOSS Huber Lossæ˜¯ä¸€ç§ç±»ä¼¼äºŽSmooth L1 Lossçš„æŸå¤±å‡½æ•°ï¼Œå®ƒä¹Ÿèƒ½å¤Ÿå¹³è¡¡L2èŒƒæ•°å’ŒL1èŒƒæ•°ä¹‹é—´çš„æƒè¡¡ Huber losså’ŒSmooth L1 losså…·æœ‰ç›¸åŒçš„æ›²çº¿èµ°åŠ¿ï¼Œå½“Huber lossä¸­çš„Î´ç­‰äºŽ1æ—¶ï¼ŒHuber lossç­‰ä»·äºŽSmooth L1 loss J_{HL} =\\left\\{ \\begin{array}{ll}0.5\\left(y_{i}-\\hat{y}_{i}\\right)^{2} , & \\text { if }\\left|y_{i}-\\hat{y}_{i}\\right| å¯¹äºŽHuberæŸå¤±æ¥è¯´ï¼Œ\\deltaçš„é€‰æ‹©ååˆ†é‡è¦ï¼Œå®ƒå†³å®šäº†æ¨¡åž‹å¤„ç†å±€å¤–ç‚¹çš„è¡Œä¸ºã€‚å½“æ®‹å·®å¤§äºŽ\\deltaæ—¶ä½¿ç”¨L1æŸå¤±ï¼Œå¾ˆå°æ—¶åˆ™ä½¿ç”¨æ›´ä¸ºåˆé€‚çš„L2æŸå¤±æ¥è¿›è¡Œä¼˜åŒ– ä¼˜ç‚¹ é›¶ç‚¹å¯¼æ•°è¿žç»­: HuberæŸå¤±å‡½æ•°å…‹æœäº†MAEå’ŒMSEçš„ç¼ºç‚¹ï¼Œä¸ä»…å¯ä»¥ä¿æŒæŸå¤±å‡½æ•°å…·æœ‰è¿žç»­çš„å¯¼æ•° è§£å†³ç¦»ç¾¤ç‚¹æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜: åˆ©ç”¨MSEæ¢¯åº¦éšè¯¯å·®å‡å°çš„ç‰¹æ€§æ¥å¾—åˆ°æ›´ç²¾ç¡®çš„æœ€å°å€¼ï¼Œä¹Ÿå¯¹å±€å¤–ç‚¹å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ ä½†HuberæŸå¤±å‡½æ•°çš„è‰¯å¥½è¡¨çŽ°å¾—ç›ŠäºŽç²¾å¿ƒè®­ç»ƒçš„è¶…å‚æ•°\\deltaï¼Œå½“\\deltaè¶‹å‘äºŽ0æ—¶å®ƒå°±é€€åŒ–æˆäº†MAEï¼Œè€Œå½“\\deltaè¶‹å‘äºŽæ— ç©·æ—¶åˆ™é€€åŒ–ä¸ºäº†MSE Quantile Loss åˆ†ä½æ•°å›žå½’Quantile Regressionæ˜¯ä¸€ç±»åœ¨å®žé™…åº”ç”¨ä¸­éžå¸¸æœ‰ç”¨çš„å›žå½’ç®—æ³•ï¼Œé€šå¸¸çš„å›žå½’ç®—æ³•æ˜¯æ‹Ÿåˆç›®æ ‡å€¼çš„æœŸæœ›æˆ–è€…ä¸­ä½æ•°ï¼Œè€Œåˆ†ä½æ•°å›žå½’å¯ä»¥é€šè¿‡ç»™å®šä¸åŒçš„åˆ†ä½ç‚¹ï¼Œæ‹Ÿåˆç›®æ ‡å€¼çš„ä¸åŒåˆ†ä½æ•° IoU Loss UnitBox: An Advanced Object Detection Network 2016 åˆ†ç±»æŸå¤±å‡½æ•° Binary Cross Entropy ç®€å•çš„äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œä½ çœŸçš„æ‡‚äº†å— å¯¹äºŽåˆ†ç±»é—®é¢˜ï¼Œæœ€å¸¸ç”¨çš„æŸå¤±å‡½æ•°æ˜¯äº¤å‰ç†µæŸå¤±å‡½æ•°Cross Entropy Loss è€ƒè™‘äºŒåˆ†ç±»ï¼Œåœ¨äºŒåˆ†ç±»ä¸­æˆ‘ä»¬é€šå¸¸ä½¿ç”¨Sigmoidå‡½æ•°å°†æ¨¡åž‹çš„è¾“å‡ºåŽ‹ç¼©åˆ°(0,1)åŒºé—´å†…\\hat{y_{i}} \\in(0,1)ï¼Œç”¨æ¥ä»£è¡¨ç»™å®šè¾“å…¥x_{i}ï¼Œæ¨¡åž‹åˆ¤æ–­ä¸ºæ­£ç±»çš„æ¦‚çŽ‡ ç”±äºŽåªæœ‰æ­£è´Ÿä¸¤ç±»ï¼Œ å› æ­¤åŒæ—¶ä¹Ÿå¾—åˆ°äº†è´Ÿç±»çš„æ¦‚çŽ‡ \\begin{array}{l} p\\left(y_{i}=1 \\mid x_{i}\\right)=\\hat{y_{i}} \\\\ p\\left(y_{i}=0 \\mid x_{i}\\right)=1-\\hat{y_{i}} \\end{array} å°†ä¸¤æ¡å¼å­åˆå¹¶æˆä¸€æ¡ p\\left(y_{i} \\mid x_{i}\\right)=\\left(\\hat{y}_{i}\\right)^{y_{i}}\\left(1-\\hat{y}_{i}\\right)^{1-y_{i}} å‡è®¾æ•°æ®ç‚¹ä¹‹é—´ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œåˆ™ä¼¼ç„¶å¯ä»¥è¡¨ç¤ºä¸º L(x, y)=\\prod_{i=1}^{N}\\left(\\hat{y}_{i}\\right)^{y_{i}}\\left(1-\\hat{y}_{i}\\right)^{1-y_{i}} å¯¹ä¼¼ç„¶å–å¯¹æ•°ï¼Œç„¶åŽåŠ è´Ÿå·å˜æˆæœ€å°åŒ–è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼Œå³ä¸ºäº¤å‰ç†µæŸå¤±å‡½æ•°çš„å½¢å¼ N L L(x, y)=J_{C E}=-\\sum_{i=1}^{N}\\left(y_{i} \\log \\left(\\hat{y}_{i}\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\hat{y_{i}}\\right)\\right) å¯è§†åŒ– ä¸‹å›¾æ˜¯å¯¹äºŒåˆ†ç±»çš„äº¤å‰ç†µæŸå¤±å‡½æ•°çš„å¯è§†åŒ–ï¼Œè“çº¿æ˜¯ç›®æ ‡å€¼ä¸º0æ—¶è¾“å‡ºä¸åŒè¾“å‡ºçš„æŸå¤±ï¼Œé»„çº¿æ˜¯ç›®æ ‡å€¼ä¸º1æ—¶çš„æŸå¤± å¯ä»¥çœ‹åˆ°çº¦æŽ¥è¿‘ç›®æ ‡å€¼æŸå¤±è¶Šå°ï¼Œéšç€è¯¯å·®å˜å·®ï¼ŒæŸå¤±å‘ˆæŒ‡æ•°å¢žé•¿ å›¾ä¸­è“çº¿æ˜¯y_i=0çš„å›¾çº¿ï¼Œæ­¤æ—¶æŸå¤±å‡½æ•°å˜ä¸º J_{CE} = -log(1-\\hat{y_{i}}) å›¾ä¸­é»„çº¿æ˜¯y_i=1çš„å›¾çº¿ï¼Œæ­¤æ—¶æŸå¤±å‡½æ•°å˜ä¸º J_{CE} = -log (\\hat{y_{i}}) ä»Žå›¾å½¢ä¸­æˆ‘ä»¬å¯ä»¥å‘çŽ°ï¼šé¢„æµ‹è¾“å‡ºä¸Žyå·®å¾—è¶Šå¤šï¼ŒJ_{CE}çš„å€¼è¶Šå¤§ï¼Œä¹Ÿå°±æ˜¯è¯´å¯¹å½“å‰æ¨¡åž‹çš„æƒ©ç½šè¶Šå¤§ï¼Œè€Œä¸”æ˜¯éžçº¿æ€§å¢žå¤§ï¼Œæ˜¯ä¸€ç§ç±»ä¼¼æŒ‡æ•°å¢žé•¿çš„çº§åˆ« è¿™æ˜¯ç”±logå‡½æ•°æœ¬èº«çš„ç‰¹æ€§æ‰€å†³å®šçš„ï¼Œè¿™æ ·çš„å¥½å¤„æ˜¯æ¨¡åž‹ä¼šå€¾å‘äºŽè®©é¢„æµ‹è¾“å‡ºæ›´æŽ¥è¿‘çœŸå®žæ ·æœ¬æ ‡ç­¾y Cross Entropy Loss äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆCrossEntropy Lossï¼‰ åœ¨å¤šåˆ†ç±»çš„ä»»åŠ¡ä¸­ï¼Œäº¤å‰æ¨€æŸå¤±å‡½æ•°çš„æŽ¨å¯¼æ€è·¯å’ŒäºŒåˆ†ç±»æ˜¯ä¸€æ ·çš„ï¼Œå˜åŒ–çš„åœ°æ–¹ä¸»è¦æœ‰ä¸¤ä¸ª ç»´åº¦å˜åŒ–: çœŸå®žå€¼y_{i}çŽ°åœ¨æ˜¯ä¸€ä¸ªone-hotå‘é‡ æ¿€æ´»å‡½æ•°: æ¨¡åž‹è¾“å‡ºçš„æœ€åŽçš„æ¿€æ´»å‡½æ•°ç”±åŽŸæ¥çš„Sigmoidå‡½æ•°æ¢æˆSoftmaxå‡½æ•° ä¸ºä»€ä¹ˆåˆ†ç±»ç”¨äº¤å‰ç†µæŸå¤±ï¼Œè€Œä¸æ˜¯å‡æ–¹å·®æŸå¤± å‡æ–¹å·®æŸå¤±å®žé™…ä¸Šå‡æ–¹å·®æŸå¤±å‡è®¾äº†è¯¯å·®æœä»Žé«˜æ–¯åˆ†å¸ƒï¼Œåœ¨åˆ†ç±»ä»»åŠ¡ä¸‹è¿™ä¸ªå‡è®¾æ²¡åŠžæ³•è¢«æ»¡è¶³ï¼Œå› æ­¤æ•ˆæžœä¼šå¾ˆå·® ä¸ºä»€ä¹ˆæ˜¯äº¤å‰ç†µæŸå¤±å‘¢? æœ‰ä¸¤ä¸ªè§’åº¦å¯ä»¥è§£é‡Šè¿™ä¸ªäº‹æƒ…ï¼Œä¸€ä¸ªè§’åº¦ä»Žæœ€å¤§ä¼¼ç„¶çš„è§’åº¦ï¼Œå¦ä¸€ä¸ªè§’åº¦æ˜¯å¯ä»¥ç”¨ä¿¡æ¯è®ºæ¥è§£é‡Šäº¤å‰ç†µæŸå¤± æœ€å¤§ä¼¼ç„¶è§’åº¦ Softmaxå‡½æ•°å°†æ¯ä¸ªç»´åº¦çš„è¾“å‡ºèŒƒå›´éƒ½é™å®šåœ¨(0,1)ä¹‹é—´ï¼ŒåŒæ—¶æ‰€æœ‰ç»´åº¦çš„è¾“å‡ºå’Œä¸º1ï¼Œç”¨äºŽè¡¨ç¤ºä¸€ä¸ªæ¦‚çŽ‡åˆ†å¸ƒ p\\left(y_{i} \\mid x_{i}\\right)=\\prod_{k=1}^{K}\\left(y_{i}^{k}\\right)^{y_{i}^{k}} å…¶ä¸­k \\in Kè¡¨ç¤º\\mathrm{K}ä¸ªç±»åˆ«ä¸­çš„ä¸€ç±»ï¼ŒåŒæ ·çš„å‡è®¾æ•°æ®ç‚¹ä¹‹é—´ç‹¬ç«‹åŒåˆ†å¸ƒï¼Œå¯å¾—åˆ°è´Ÿå¯¹æ•°ä¼¼ç„¶ä¸º N L L(x, y)=J_{C E}=-\\sum_{i=1}^{N} \\sum_{k=1}^{K} y_{i}^{k} \\log \\left(y_{i}^{k}\\right) ç”±äºŽy_{i}æ˜¯ä¸€ä¸ªone-hotå‘é‡ï¼Œé™¤äº†ç›®æ ‡ç±»ä¸º1ä¹‹å¤–å…¶ä»–ç±»åˆ«ä¸Šçš„è¾“å‡ºéƒ½ä¸º0ï¼Œå› æ­¤ä¸Šå¼ä¹Ÿå¯ä»¥å†™ä¸º J_{C E}=-\\sum_{i=1}^{N} y_{i}^{c_{i}} \\log \\left(y_{i}^{\\hat{c}_{i}}\\right) å…¶ä¸­c_{i}æ˜¯æ ·æœ¬x_{i}çš„ç›®æ ‡ç±»ã€‚é€šå¸¸è¿™ä¸ªåº”ç”¨äºŽå¤šåˆ†ç±»çš„äº¤å‰æ¨€æŸå¤±å‡½æ•°ä¹Ÿè¢«ç§°ä¸ºSoftmax Lossæˆ–è€…Categorical Cross Entropy Loss ä¿¡æ¯è®ºè§’åº¦ å‡è®¾å¯¹äºŽæ ·æœ¬x_{i}å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜åˆ†å¸ƒy_{i}^{\\star}çœŸå®žåœ°è¡¨æ˜Žäº†è¿™ä¸ªæ ·æœ¬å±žäºŽå„ä¸ªç±»åˆ«çš„æ¦‚çŽ‡ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¸Œæœ›æ¨¡åž‹çš„è¾“å‡º\\hat{y}_{i}å°½å¯èƒ½åœ°é€¼è¿‘è¿™ä¸ªæœ€ä¼˜åˆ†å¸ƒ åœ¨ä¿¡æ¯è®ºä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨KLæ•£åº¦(Kullback-Leibler Divergence)æ¥è¡¡é‡ä¸¤ä¸ªåˆ†å¸ƒçš„ç›¸ä¼¼æ€§ ç»™å®šåˆ†å¸ƒpå’Œåˆ†å¸ƒqï¼Œä¸¤è€…çš„KLæ•£åº¦å…¬å¼å¦‚ä¸‹ K L(p, q)=\\sum_{k=1}^{K} p^{k} \\log \\left(p^{k}\\right)-\\sum_{k=1}^{K} p^{k} \\log \\left(q^{k}\\right) å…¶ä¸­ç¬¬ä¸€é¡¹ä¸ºåˆ†å¸ƒpçš„ä¿¡æ¯ç†µï¼Œç¬¬äºŒé¡¹ä¸ºåˆ†å¸ƒpå’Œqçš„äº¤å‰ç†µã€‚å°†æœ€ä¼˜åˆ†å¸ƒy_{i}^{\\star}å’Œè¾“å‡ºåˆ†å¸ƒ\\hat{y}_{i}å¸¦å…¥på’Œqå¾—åˆ° K L\\left(y_{i}^{\\star}, \\hat{y_{i}}\\right)=\\sum_{k=1}^{K} y_{i}^{\\star k} \\log \\left(y_{i}^{\\star k}\\right)-\\sum_{k=1}^{K} y_{i}^{\\star k} \\log \\left(y_{i}^{\\hat{k}}\\right) ç”±äºŽæˆ‘ä»¬å¸Œæœ›ä¸¤ä¸ªåˆ†å¸ƒå°½é‡ç›¸è¿‘ï¼Œå› æ­¤æˆ‘ä»¬æœ€å°åŒ–KLæ•£åº¦ã€‚åŒæ—¶ç”±äºŽä¸Šå¼ç¬¬ä¸€é¡¹ä¿¡æ¯ç†µä»…ä¸Žæœ€ä¼˜åˆ†å¸ƒæœ¬èº«ç›¸å…³ï¼Œå› æ­¤æˆ‘ä»¬åœ¨æœ€å°åŒ–çš„è¿‡ç¨‹ä¸­å¯ä»¥å¿½ç•¥æŽ‰ï¼Œå˜æˆæœ€å°åŒ– -\\sum_{k=1}^{K} y_{i}^{\\star k} \\log \\left(y_{i}^{\\hat{k}}\\right) æˆ‘ä»¬å¹¶ä¸çŸ¥é“æœ€ä¼˜åˆ†å¸ƒy_{i}^{\\star}ï¼Œä½†è®­ç»ƒæ•°æ®é‡Œé¢çš„ç›®æ ‡å€¼y_{i}å¯ä»¥çœ‹åšæ˜¯y_{i}^{\\star}çš„ä¸€ä¸ªè¿‘ä¼¼åˆ†å¸ƒ -\\sum_{k=1}^{K} y_{i}^{k} \\log \\left(y_{i}^{\\hat{k}}\\right) è¿™ä¸ªæ˜¯é’ˆå¯¹å•ä¸ªè®­ç»ƒæ ·æœ¬çš„æŸå¤±å‡½æ•°ï¼Œå¦‚æžœè€ƒè™‘æ•´ä¸ªæ•°æ®é›†ï¼Œåˆ™ J_{K L}=-\\sum_{i=1}^{N} \\sum_{k=1}^{K} y_{i}^{k} \\log \\left(y_{i}^{\\hat{k}}\\right)=-\\sum_{i=1}^{N} y_{i}^{c_{i}} \\log \\left(y_{i}^{\\hat{c}_{i}}\\right) å¯ä»¥çœ‹åˆ°é€šè¿‡æœ€å°åŒ–äº¤å‰å«¡çš„è§’åº¦æŽ¨å¯¼å‡ºæ¥çš„ç»“æžœå’Œä½¿ç”¨æœ€å¤§åŒ–ä¼¼ç„¶å¾—åˆ°çš„ç»“æžœæ˜¯ä¸€è‡´çš„ Hinge Loss åˆé¡µæŸå¤±Hinge Lossæ˜¯å¦å¤–ä¸€ç§äºŒåˆ†ç±»æŸå¤±å‡½æ•°ï¼Œé€‚ç”¨äºŽmaximum-marginçš„åˆ†ç±»ï¼Œæ”¯æŒå‘é‡æœºSupport Vector Machine (SVM)æ¨¡åž‹çš„æŸå¤±å‡½æ•°æœ¬è´¨ä¸Šå°±æ˜¯Hinge Loss + L2æ­£åˆ™åŒ– J_{\\text {hinge }}=\\sum_{i=1}^{N} \\max \\left(0,1-\\operatorname{sgn}\\left(y_{i}\\right) \\hat{y_{i}}\\right) ä¸‹å›¾æ˜¯yä¸ºæ­£ç±»ï¼Œå³sgn(y)=1æ—¶ï¼Œä¸åŒè¾“å‡ºçš„åˆé¡µæŸå¤±ç¤ºæ„å›¾ å¯ä»¥çœ‹åˆ°å½“yä¸ºæ­£ç±»æ—¶ï¼Œæ¨¡åž‹è¾“å‡ºè´Ÿå€¼ä¼šæœ‰è¾ƒå¤§çš„æƒ©ç½šï¼Œå½“æ¨¡åž‹è¾“å‡ºä¸ºæ­£å€¼ä¸”åœ¨åŒºé—´æ—¶è¿˜ä¼šæœ‰ä¸€ä¸ªè¾ƒå°çš„æƒ©ç½š å³åˆé¡µæŸå¤±ä¸ä»…æƒ©ç½šé¢„æµ‹é”™çš„ï¼Œå¹¶ä¸”å¯¹äºŽé¢„æµ‹å¯¹äº†ä½†æ˜¯ç½®ä¿¡åº¦ä¸é«˜çš„ä¹Ÿä¼šç»™ä¸€ä¸ªæƒ©ç½šï¼Œåªæœ‰ç½®ä¿¡åº¦é«˜çš„æ‰ä¼šæœ‰é›¶æŸå¤± ä½¿ç”¨åˆé¡µæŸå¤±ç›´è§‰ä¸Šç†è§£æ˜¯è¦æ‰¾åˆ°ä¸€ä¸ªå†³ç­–è¾¹ç•Œï¼Œä½¿å¾—æ‰€æœ‰æ•°æ®ç‚¹è¢«è¿™ä¸ªè¾¹ç•Œæ­£ç¡®åœ°ã€é«˜ç½®ä¿¡åœ°è¢«åˆ†ç±» Focal Loss Focal Loss for Dense Object Detection 2018 ppt: Focal Loss for Dense Object Detection Focal LossæŸå¤±å‡½æ•°(è¶…çº§è¯¦ç»†çš„è§£è¯») Focal lossæŸå¤±å‡½æ•°æ˜¯ä¸ºäº†è§£å†³one-stageç›®æ ‡æ£€æµ‹ä¸­æ­£è´Ÿæ ·æœ¬æžåº¦ä¸å¹³è¡¡çš„é—®é¢˜ï¼Œç”±ä½•æºæ˜Ž(Kaiming He)å›¢é˜Ÿæå‡º Focal lossæ˜¯åŸºäºŽBCE(äºŒåˆ†ç±»äº¤å‰ç†µ)çš„ã€‚å®ƒæ˜¯ä¸€ä¸ªåŠ¨æ€ç¼©æ”¾çš„äº¤å‰ç†µæŸå¤±ï¼Œé€šè¿‡ä¸€ä¸ªåŠ¨æ€ç¼©æ”¾å› å­ï¼Œå¯ä»¥åŠ¨æ€é™ä½Žè®­ç»ƒè¿‡ç¨‹ä¸­æ˜“åŒºåˆ†æ ·æœ¬çš„æƒé‡ï¼Œä»Žè€Œå°†é‡å¿ƒå¿«é€Ÿèšç„¦åœ¨é‚£äº›éš¾åŒºåˆ†çš„æ ·æœ¬(æœ‰å¯èƒ½æ˜¯æ­£æ ·æœ¬ï¼Œä¹Ÿæœ‰å¯èƒ½æ˜¯è´Ÿæ ·æœ¬ï¼Œä½†éƒ½æ˜¯å¯¹è®­ç»ƒç½‘ç»œæœ‰å¸®åŠ©çš„æ ·æœ¬) æ­£è´Ÿæ ·æœ¬ä¸å¹³è¡¡(Class Imbalance) åœ¨ä¸€å¼ å›¾åƒä¸­èƒ½å¤ŸåŒ¹é…åˆ°ç›®æ ‡çš„å€™é€‰æ¡†(æ­£æ ·æœ¬)ä¸ªæ•°ä¸€èˆ¬åªæœ‰åå‡ ä¸ªæˆ–å‡ åä¸ªï¼Œè€Œæ²¡æœ‰åŒ¹é…åˆ°çš„å€™é€‰æ¡†(è´Ÿæ ·æœ¬)åˆ™æœ‰10000~100000ä¸ª è¿™ä¹ˆå¤šçš„è´Ÿæ ·æœ¬ä¸ä»…å¯¹è®­ç»ƒç½‘ç»œèµ·ä¸åˆ°ä»€ä¹ˆä½œç”¨ï¼Œåè€Œä¼šæ·¹æ²¡æŽ‰å°‘é‡ä½†æœ‰åŠ©äºŽè®­ç»ƒçš„æ ·æœ¬ Focal lossæ˜¯ä¸ºäº†è§£å†³ä¸€é˜¶æ®µç›®æ ‡æ£€æµ‹æ¨¡åž‹ï¼Œé‚£ä¸ºä»€ä¹ˆäºŒé˜¶æ®µä¸ç”¨è§£å†³ åœ¨two-stageä¸­åˆ†äº†ä¸¤æ­¥ï¼Œç¬¬ä¸€æ­¥æ—¶åŒæ ·ä¹Ÿä¼šç”Ÿæˆè®¸å¤šçš„è´Ÿæ ·æœ¬ä»¥åŠå¾ˆå°‘çš„æ­£æ ·æœ¬ï¼Œä½†åˆ°ç¬¬äºŒæ­¥æ—¶ï¼Œå®ƒä¼šåœ¨ç¬¬ä¸€æ­¥çš„åŸºç¡€ä¸Šé€‰å–ç‰¹å®šæ•°é‡çš„æ­£è´Ÿæ ·æœ¬åŽ»æ£€æµ‹ï¼Œæ‰€ä»¥æ­£è´Ÿæ ·æœ¬å¹¶ä¸ä¼šç‰¹åˆ«ä¸å¹³è¡¡ï¼ŒäºŒé˜¶æ®µæ¨¡åž‹è¿˜å¯ä»¥é‡‡ç”¨æ›´å¤æ‚çš„é‡‡æ ·ç­–ç•¥å’Œhard negative mining (éš¾ä¾‹æŒ–æŽ˜)ç­‰æ–¹æ³•æ¥å¤„ç†æ ·æœ¬ä¸å¹³è¡¡å’Œéš¾æ˜“æ ·æœ¬çš„é—®é¢˜ï¼Œå› æ­¤å¯¹äºŽäºŒé˜¶æ®µç›®æ ‡æ£€æµ‹æ¨¡åž‹æ¥è¯´ï¼ŒFocal Lossçš„ä¼˜åŠ¿å¯èƒ½ç›¸å¯¹è¾ƒå° å¼•å‡ºFocal loss ä¸ºäº†æ–¹ä¾¿æŽ¥ä¸‹æ¥çš„æè¿°ï¼Œè¿™é‡Œå…ˆå®šä¹‰p_tä¸º p_{\\mathrm{t}}=\\left\\{\\begin{array}{ll}p & \\text { if } y=1 \\\\ 1-p & \\text { otherwise }\\end{array}\\right. æ­¤æ—¶cross entropyå¯ä»¥å®šä¹‰ä¸º J_{FL}(p, y)=\\left\\{\\begin{array}{ll}-\\log (p) & \\text { if } y=1 \\\\ -\\log (1-p) & \\text { otherwise }\\end{array}\\right. \\longrightarrow J_{FL}(p, y)=J_{FL}\\left(p_{\\mathrm{t}}\\right)=-\\log \\left(p_{\\mathrm{t}}\\right) è§£å†³ç±»åˆ«ä¸å¹³è¡¡çš„å¸¸è§æ–¹æ³•æ˜¯ä¸ºç±»åˆ«1å¼•å…¥ä¸€ä¸ªæƒé‡å› å­ \\alpha \\in [0, 1]ï¼Œè€Œå¯¹äºŽç±»åˆ«éž1å¼•å…¥æƒé‡å› å­1-\\alphaï¼Œè¿™é‡Œå¼•å‡ºBalanced Cross Entropy(å¹³è¡¡äº¤å‰ç†µ) J_{FL}\\left(p_{\\mathrm{t}}\\right)=-\\alpha_{\\mathrm{t}} \\log \\left(p_{\\mathrm{t}}\\right) åœ¨è®ºæ–‡å®žéªŒä¸­æ˜¾ç¤ºï¼Œå¯†é›†æ£€æµ‹å™¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ä½¿å¾—äº¤å‰ç†µæŸå¤±å¤±åŽ»äº†æ•ˆæžœï¼Œæ˜“äºŽåˆ†ç±»çš„è´Ÿæ ·æœ¬å æ®äº†å¤§éƒ¨åˆ†æŸå¤±å¹¶ä¸»å¯¼äº†æ¢¯åº¦ è™½ç„¶\\alphaå¹³è¡¡äº†æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„é‡è¦æ€§ï¼Œä½†å®ƒæ— æ³•åŒºåˆ†æ˜“äºŽå’Œå›°éš¾çš„æ ·æœ¬ å› æ­¤ï¼Œè®ºæ–‡æå‡ºäº†æ–°çš„æŸå¤±å‡½æ•°ä»¥å‡å°æ˜“äºŽæ ·æœ¬çš„æƒé‡ï¼Œä»Žè€Œå°†è®­ç»ƒçš„é‡ç‚¹æ”¾åœ¨å›°éš¾çš„è´Ÿæ ·æœ¬ä¸Šï¼Œæ›´å…·ä½“åœ°è¯´ï¼Œè®ºæ–‡æå‡ºåœ¨äº¤å‰ç†µæŸå¤±ä¸­æ·»åŠ ä¸€ä¸ªè°ƒåˆ¶å› å­\\left(1-p_{\\mathrm{t}}\\right)^{\\gamma}ï¼Œå…¶ä¸­\\gammaæ˜¯å¯è°ƒçš„Focalå‚æ•°ã€‚æˆ‘ä»¬å°†è¿™ä¸ªæŸå¤±å‡½æ•°ç§°ä¸ºFocal lossï¼Œå®šä¹‰Focal Losså…¬å¼å¦‚ä¸‹ J_{FL}\\left(p_{\\mathrm{t}}\\right) = - \\alpha_{t} \\left(1-p_{\\mathrm{t}}\\right)^{\\gamma} \\log \\left(p_{\\mathrm{t}}\\right) å…¶ä¸­\\gammaä½œç”¨æ˜¯è°ƒèŠ‚éš¾æ˜“ï¼Œè¾ƒå°çš„\\gammaå€¼ä¼šä½¿å¾—æ˜“æ ·æœ¬çš„æŸå¤±æƒé‡ä¸‹é™æ›´æ…¢ï¼Œè€Œè¾ƒå¤§çš„\\gammaå€¼åˆ™ä¼šåŠ é€Ÿæ˜“æ ·æœ¬çš„æŸå¤±æƒé‡ä¸‹é™ \\alphaä½œç”¨æ˜¯å¹³è¡¡æ­£è´Ÿæ ·(æ­£è´Ÿæ ·æœ¬æ•°é‡ä¸å‡è¡¡)ï¼Œå½“\\alphaæŽ¥è¿‘0æ—¶ï¼Œè´Ÿæ ·æœ¬çš„æŸå¤±è´¡çŒ®è¢«æ”¾å¤§ï¼Œä»Žè€Œå¹³è¡¡äº†æ­£è´Ÿæ ·æœ¬ä¹‹é—´çš„é‡è¦æ€§ é€šè¿‡è°ƒæ•´\\alphaå’Œ\\gammaçš„å€¼ï¼Œå¯ä»¥æ ¹æ®å…·ä½“æƒ…å†µè°ƒèŠ‚æ¨¡åž‹å¯¹ä¸åŒæ ·æœ¬çš„å…³æ³¨ç¨‹åº¦ï¼Œæé«˜æ¨¡åž‹å¯¹éš¾æ ·æœ¬çš„å­¦ä¹ å’Œè®­ç»ƒæ•ˆæžœ å¯è§†åŒ– ä¸‹å›¾å¯è§†åŒ–äº†\\gamma \\in[0,5]çš„å€¼ï¼Œå¯ä»¥è§‚å¯Ÿåˆ° å¢žåŠ äº†åˆ†ç±»ä¸å‡†ç¡®æ ·æœ¬åœ¨æŸå¤±å‡½æ•°ä¸­çš„æƒé‡ å¢žåŠ äº†éš¾åˆ†æ ·æœ¬åœ¨æŸå¤±å‡½æ•°çš„æƒé‡ï¼Œä½¿å¾—æŸå¤±å‡½æ•°å€¾å‘äºŽéš¾åˆ†çš„æ ·æœ¬ï¼Œæœ‰åŠ©äºŽæé«˜éš¾åˆ†æ ·æœ¬çš„å‡†ç¡®åº¦ \\gammaä½œç”¨æ˜¯è°ƒèŠ‚éš¾æ˜“æ ·æœ¬å¯¹äºŽæ€»lossçš„æƒé‡(æ­£è´Ÿæ ·æœ¬ä¸­éƒ½æœ‰éš¾æ˜“ï¼Œéƒ½è¿›è¡Œäº†è°ƒèŠ‚) \\gammaè°ƒèŠ‚ç®€å•æ ·æœ¬æƒé‡é™ä½Žçš„é€ŸçŽ‡ï¼Œå½“\\gamma=0æ—¶å³ä¸ºäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå½“\\gammaå¢žåŠ æ—¶ï¼Œè°ƒæ•´å› å­çš„å½±å“ä¹Ÿåœ¨å¢žåŠ ã€‚å®žéªŒå‘çŽ°\\gamma=2æ˜¯æœ€ä¼˜ åŸºäºŽæ¦‚çŽ‡çš„æŸå¤± KLæ•£åº¦ KL-æ•£åº¦æŸå¤±å‡½æ•°çš„å®šä¹‰å¦‚ä¸‹ J_{KL} = -\\sum_{i=0}^{C} y_{i} \\log \\left(\\hat{y}_{i}\\right)-y_{i} \\log \\left(y_{i}\\right)=\\sum_{i=0}^{C} y_{i}\\left(\\frac{y_{i}}{\\hat{y}_{i}}\\right) ä¼˜ç‚¹ï¼š é€‚ç”¨äºŽè¿‘ä¼¼å¤æ‚çš„ç›®æ ‡åˆ†å¸ƒï¼Œå¦‚å›¾åƒ å¦‚ä¸Šæ‰€ç¤ºï¼ŒKLæ•£åº¦æŸå¤±æ˜¯ä»Žæˆ‘ä»¬ç½‘ç»œé¢„æµ‹çš„äº¤å‰ç†µåˆ†å¸ƒä¸Žç›®æ ‡åˆ†å¸ƒçš„ç†µä¹‹é—´çš„å·®å¼‚ã€‚å®ƒå‘Šè¯‰æˆ‘ä»¬æ¨¡åž‹ç¦»æœŸæœ›çš„åˆ†å¸ƒæœ‰å¤šè¿œ é‚£ä¹ˆæˆ‘ä»¬ä»€ä¹ˆæƒ…å†µä¸‹ä½¿ç”¨å®ƒ å¦‚æžœæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯ç”Ÿæˆå›¾åƒï¼Œé‚£ä¹ˆç›®æ ‡åˆ†å¸ƒè¦å¤æ‚å¾—å¤šï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½¿ç”¨KLæ•£åº¦æŸå¤±çš„æ•ˆæžœæœ€å¥½ æ­£åˆ™åŒ–æŠ€æœ¯ L1æ­£åˆ™åŒ– åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ æ¨¡åž‹å‚æ•°çš„ L1 èŒƒæ•°ä½œä¸ºæ­£åˆ™é¡¹ã€‚å®ƒä¿ƒä½¿æ¨¡åž‹å‚æ•°ç¨€ç–åŒ–ï¼Œå³å°†ä¸€äº›å‚æ•°åŽ‹ç¼©ä¸ºé›¶ï¼Œä»Žè€Œå®žçŽ°ç‰¹å¾é€‰æ‹©å’Œæ¨¡åž‹ç®€åŒ– L2æ­£åˆ™åŒ– åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ æ¨¡åž‹å‚æ•°çš„ L2 èŒƒæ•°ä½œä¸ºæ­£åˆ™é¡¹ã€‚å®ƒå¯¹æ¨¡åž‹å‚æ•°è¿›è¡Œå¹³æ»‘çº¦æŸï¼Œä½¿æ¨¡åž‹å‚æ•°å€¼è¶‹å‘äºŽè¾ƒå°çš„å€¼ï¼Œæœ‰åŠ©äºŽé˜²æ­¢è¿‡æ‹Ÿåˆ å¼¹æ€§ç½‘æ­£åˆ™åŒ– å¼¹æ€§ç½‘æ­£åˆ™åŒ–æ˜¯ L1 æ­£åˆ™åŒ–å’Œ L2 æ­£åˆ™åŒ–çš„ä¸€ç§ç»“åˆã€‚å®ƒåŒæ—¶å¯¹æ¨¡åž‹å‚æ•°ä½¿ç”¨ L1 å’Œ L2 æ­£åˆ™åŒ–ï¼Œä»Žè€Œç»¼åˆè€ƒè™‘äº†ç¨€ç–æ€§å’Œå¹³æ»‘æ€§çš„å½±å“ å…¶ä»–æ­£åˆ™ Dropoutï¼šDropout æ˜¯ä¸€ç§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥žç»å…ƒçš„æŠ€æœ¯ã€‚å®ƒå¯ä»¥é˜²æ­¢ç¥žç»ç½‘ç»œè¿‡æ‹Ÿåˆï¼Œå¹¶æé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»¥ä¸€å®šæ¦‚çŽ‡å°†éƒ¨åˆ†ç¥žç»å…ƒç½®é›¶ï¼ŒDropout å¯ä»¥å¼ºåˆ¶æ¨¡åž‹åœ¨æ²¡æœ‰å®Œæ•´ç¥žç»ç½‘ç»œçš„æƒ…å†µä¸‹è¿›è¡Œå­¦ä¹  æ•°æ®å¢žå¼º(Data Augmentation)ï¼šæ•°æ®å¢žå¼ºæ˜¯ä¸€ç§é€šè¿‡å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œéšæœºå˜æ¢æ¥æ‰©å……æ•°æ®é›†çš„æŠ€æœ¯ã€‚å¸¸è§çš„æ•°æ®å¢žå¼ºæ“ä½œåŒ…æ‹¬éšæœºè£å‰ªã€æ—‹è½¬ã€ç¿»è½¬ã€å¹³ç§»ã€ç¼©æ”¾ç­‰ã€‚æ•°æ®å¢žå¼ºå¯ä»¥å¢žåŠ è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ï¼Œæé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ å›¾åƒå¢žå¼ºæŠ€æœ¯ï¼šäº†è§£å¸¸è§çš„å›¾åƒå¢žå¼ºæ–¹æ³•ï¼Œå¦‚å¯¹æ¯”åº¦è°ƒæ•´ã€äº®åº¦è°ƒæ•´ã€è‰²å½©å¹³è¡¡ã€ç›´æ–¹å›¾å‡è¡¡åŒ–ç­‰ï¼Œä»¥åŠå®ƒä»¬åœ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æ¿€æ´»å‡½æ•°.html":{"url":"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æ¿€æ´»å‡½æ•°.html","title":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æ¿€æ´»å‡½æ•°.md","summary":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æ¿€æ´»å‡½æ•°","keywords":"","body":"æ¦‚è¿°å¸¸è§æ¿€æ´»å‡½æ•°SigmoidTanhReluLeaky ReLUPReLUELUGELUSoftplusMaxoutSwishMishSoftSignæ¿€æ´»å‡½æ•°çš„é€‰æ‹© æ¦‚è¿° æ¿€æ´»å‡½æ•°ï¼ˆActivation Functionï¼‰ æ¿€æ´»å‡½æ•°å¯è§†åŒ– æ¿€æ´»å‡½æ•°(Activation Function)æ˜¯ä¸€ç§æ·»åŠ åˆ°äººå·¥ç¥žç»ç½‘ç»œä¸­çš„å‡½æ•°ï¼Œæ—¨åœ¨å¸®åŠ©ç½‘ç»œå­¦ä¹ æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ å¼•å…¥æ¿€æ´»å‡½æ•°çš„ç›®çš„ ä¸ä½¿ç”¨æ¿€æ´»å‡½æ•°çš„è¯ï¼Œç¥žç»ç½‘ç»œçš„æ¯å±‚éƒ½åªæ˜¯åšçº¿æ€§å˜æ¢ï¼Œå¤šå±‚è¾“å…¥å åŠ åŽä¹Ÿè¿˜æ˜¯çº¿æ€§å˜æ¢ã€‚å› ä¸ºçº¿æ€§æ¨¡åž‹çš„è¡¨è¾¾èƒ½åŠ›é€šå¸¸ä¸å¤Ÿ æ‰€ä»¥è¿™æ—¶å€™å°±ä½“çŽ°äº†æ¿€æ´»å‡½æ•°çš„ä½œç”¨äº†ï¼Œæ¿€æ´»å‡½æ•°å¯ä»¥å¼•å…¥éžçº¿æ€§å› ç´ ï¼Œè®¾æœ‰ä¸‰ä¸ªçº¿æ€§å˜æ¢ \\begin{array}{l}\\mathrm{z}_{1}=\\mathrm{w}_{1} \\mathrm{x}+\\mathrm{b}_{1} \\\\ \\mathrm{z}_{2}=\\mathrm{w}_{2} \\mathrm{x}+\\mathrm{b}_{2} \\\\ \\mathrm{z}_{3}=\\mathrm{w}_{3} \\mathrm{x}+\\mathrm{b}_{3}\\end{array} å°†è¿™ä¸‰ä¸ªçº¿æ€§å˜æ¢åŠ åˆ°ä¸€èµ·ï¼Œå¯ä»¥å¾—åˆ° \\begin{aligned} \\mathrm{y} & =\\mathrm{w}_{4} \\mathrm{z}_{1}+\\mathrm{w}_{5} \\mathrm{z}_{2}+\\mathrm{w}_{6} \\mathrm{z}_{3}+\\mathrm{b}_{4} \\\\ & =\\left(\\mathrm{w}_{1} \\mathrm{w}_{4}+\\mathrm{w}_{2} \\mathrm{w}_{5}+\\mathrm{w}_{3} \\mathrm{w}_{6}\\right) \\mathrm{x}+\\left(\\mathrm{b}_{1} \\mathrm{w}_{4}+\\mathrm{b}_{2} \\mathrm{w}_{5}+\\mathrm{b}_{3} \\mathrm{w}_{6}+\\mathrm{b}_{4}\\right) \\\\ & =\\mathrm{ax}+\\mathrm{b}\\end{aligned} æ‰€ä»¥ï¼Œå¦‚æžœç¥žç»ç½‘ç»œåªæœ‰çº¿æ€§ï¼Œé‚£ä¹ˆä¸è®ºæœ‰å¤šå°‘éšå±‚ï¼Œæœ‰å¤šå°‘ç¥žç»å…ƒï¼Œæœ€ç»ˆè¿˜æ˜¯çº¿æ€§çš„ æ­¤æ—¶å°±éœ€è¦é€šè¿‡æ·»åŠ æ¿€æ´»å‡½æ•°æ¥å¯¹æ¯ä¸€å±‚çš„è¾“å‡ºåšå¤„ç†ï¼Œå¼•å…¥éžçº¿æ€§å› ç´ ï¼Œä½¿å¾—ç¥žç»ç½‘ç»œå¯ä»¥é€¼è¿‘ä»»æ„çš„éžçº¿æ€§å‡½æ•° æ¿€æ´»å‡½æ•°åœ¨ç¥žç»ç½‘ç»œä¸­çš„åº”ç”¨ï¼Œé™¤äº†å¼•å…¥éžçº¿æ€§è¡¨è¾¾èƒ½åŠ›ï¼Œå…¶åœ¨æé«˜æ¨¡åž‹é²æ£’æ€§ã€ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€å°†ç‰¹å¾è¾“å…¥æ˜ å°„åˆ°æ–°çš„ç‰¹å¾ç©ºé—´ä»¥åŠåŠ é€Ÿæ¨¡åž‹æ”¶æ•›ç­‰æ–¹é¢éƒ½æœ‰ä¸åŒç¨‹åº¦çš„æ”¹å–„ä½œç”¨ å°ç»“: å¼•å…¥éžçº¿æ€§è¡¨è¾¾èƒ½åŠ› æé«˜æ¨¡åž‹é²æ£’æ€§ï¼šéžçº¿æ€§çš„æ¿€æ´»å‡½æ•°èƒ½å¤Ÿå¼•å…¥éžçº¿æ€§å˜æ¢ï¼Œä»Žè€Œä½¿ç¥žç»ç½‘ç»œå…·æœ‰æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆå¤æ‚çš„æ•°æ®åˆ†å¸ƒå’Œæ¨¡å¼ ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼šåœ¨æ·±å±‚ç¥žç»ç½‘ç»œä¸­ï¼Œç”±äºŽé“¾å¼æ±‚å¯¼çš„å…³ç³»ï¼Œæ¢¯åº¦åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä¼šé€æ¸å‡å°ï¼Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ ä½¿ç”¨éžçº¿æ€§æ¿€æ´»å‡½æ•°å¯ä»¥å¸®åŠ©ç¼“è§£æ¢¯åº¦æ¶ˆå¤±ï¼Œå› ä¸ºè¿™äº›å‡½æ•°åœ¨è¾“å…¥çš„ä¸åŒèŒƒå›´å†…å…·æœ‰ä¸åŒçš„æ–œçŽ‡ï¼Œä»Žè€Œå…è®¸æ¢¯åº¦èƒ½å¤Ÿåœ¨åå‘ä¼ æ’­ä¸­æ›´å¥½åœ°ä¼ é€’ å¸¸è§æ¿€æ´»å‡½æ•° Activation Functions with Derivative and Python code: Sigmoid vs Tanh Vs Relu ã€æ¿€æ´»å‡½æ•°åˆé›†ã€‘ç›˜ç‚¹å½“å‰æœ€æµè¡Œçš„æ¿€æ´»å‡½æ•°åŠé€‰æ‹©ç»éªŒ æ¿€æ´»å‡½æ•°å‘å±•åŽ†ç¨‹ æ—©æœŸ 1970 1980 2010 2013 é˜¶è·ƒå‡½æ•°(Step Function) Sigmoid åŒæ›²æ­£åˆ‡(Tanh) ReLU(Rectified Linear Unit) Leaky ReLUMaxout 2015 2016 2017 2020 PReLU(Parametric ReLU) ELU(Exponential Linear Unit)GELUS(Gaussian Error Linear Units) Swish Mish ç›¸å¯¹åº”çš„è®ºæ–‡é“¾æŽ¥å¦‚ä¸‹ Maxout Networks 2013 Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification 2015 PReLU Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) 2016 Gaussian Error Linear Units (GELUS) 2016å¹´æå‡º Searching for Activation Functions (Swish) 2017 Swish: a Self-Gated Activation Function 2017 Mish: A Self Regularized Non-Monotonic Neural Activation Function 2019 Sigmoid Sigmoidå‡½æ•°(Logisticå‡½æ•°)å‡½æ•°çš„å›¾åƒçœ‹èµ·æ¥åƒä¸€ä¸ªSå½¢æ›²çº¿ï¼Œå‡½æ•°è¡¨è¾¾å¼å¦‚ä¸‹ f(x) = \\frac{1}{1 + e^{-x}} å¯¹åº”çš„å¯¼æ•°ä¸º \\begin{array}{l}f^{\\prime}(x)=-\\frac{1}{\\left(1+e^{-x}\\right)^{2}} \\times\\left(1+e^{-x}\\right)^{\\prime}=-\\frac{1}{\\left(1+e^{-x}\\right)^{2}} \\times\\left(-e^{-x}\\right)=\\frac{1}{1+e^{-x}} \\times \\frac{e^{-x}}{1+e^{-x}} \\\\ =\\frac{1}{1+e^{-x}} \\times \\frac{1+e^{-x}-1}{1+e^{-x}}=f(x)(1-f(x))\\end{array} å‡½æ•°å›¾åƒå’Œå¯¹åº”çš„å¯¼æ•°å›¾åƒå¦‚ä¸‹å›¾æ‰€ç¤º ä½œç”¨ å°†è¾“å…¥æ˜ å°„åˆ°0åˆ°1ä¹‹é—´çš„è¿žç»­å€¼ï¼Œå¸¸ç”¨äºŽäºŒåˆ†ç±»é—®é¢˜æˆ–è¾“å‡ºå±‚çš„æ¦‚çŽ‡é¢„æµ‹ Sigmoidæ¿€æ´»å‡½æ•°çš„ä¼˜ç¼ºç‚¹ ä¼˜ç‚¹ å¹³æ»‘ æ˜“äºŽæ±‚å¯¼ å¯ä»¥ä½œä¸ºæ¦‚çŽ‡ï¼Œè¾…åŠ©æ¨¡åž‹è§£ ç¼ºç‚¹ æ¢¯åº¦æ¶ˆå¤±: Sigmoidå‡½æ•°çš„å¯¼æ•°å½¢å¼ä¸º f'(x) = f(x)(1-f(x))ï¼Œå…¶ä¸­f(x)æ˜¯Sigmoidå‡½æ•° å½“è¾“å…¥å€¼éžå¸¸å¤§æ—¶ï¼ŒSigmoidå‡½æ•°æŽ¥è¿‘äºŽ1ï¼Œå¯¼æ•°æŽ¥è¿‘äºŽ0ï¼Œè€Œå½“è¾“å…¥å€¼éžå¸¸å°æ—¶ï¼ŒSigmoidå‡½æ•°æŽ¥è¿‘äºŽ0ï¼Œå¯¼æ•°åŒæ ·æŽ¥è¿‘äºŽ0 è¿™æ„å‘³ç€åœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦é€æ¸å˜å°å¹¶è¶‹è¿‘äºŽé›¶ï¼Œä¼ é€’åˆ°è¾ƒæ—©å±‚æ—¶ï¼Œæ¢¯åº¦å‡ ä¹Žæ¶ˆå¤±äº† æ¢¯åº¦æ›´æ–°æ…¢: å¦‚æžœç¥žç»å…ƒçš„è¾“å‡ºå¤§éƒ¨åˆ†ä½äºŽé¥±å’ŒåŒºåŸŸ(æŽ¥è¿‘0æˆ–1)ï¼Œé‚£ä¹ˆæ¢¯åº¦å°†éžå¸¸å°ï¼Œå› ä¸ºsigmoidå‡½æ•°åœ¨é¥±å’ŒåŒºåŸŸçš„å¯¼æ•°æŽ¥è¿‘äºŽ0(å¦‚å›¾æ‰€ç¤º) è¿™æ ·ï¼Œæƒé‡çš„æ›´æ–°å°†å˜å¾—éžå¸¸ç¼“æ…¢ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒè¿‡ç¨‹å˜å¾—å›°éš¾ï¼Œå¹¶ä¸”ç½‘ç»œçš„æ”¶æ•›é€Ÿåº¦å‡æ…¢ è®¡ç®—æ•ˆçŽ‡ä½Ž: Sigmoidå‡½æ•°æ‰§è¡ŒæŒ‡æ•°è¿ç®—ï¼Œè®¡ç®—æœºè¿è¡Œå¾—è¾ƒæ…¢ Tanh Tanhå‡½æ•°(åŒæ›²æ­£åˆ‡å‡½æ•°)å‡½æ•°çš„å›¾åƒçœ‹èµ·æ¥ä¹Ÿåƒä¸€ä¸ªSå½¢æ›²çº¿ï¼Œå‡½æ•°è¡¨è¾¾å¼å¦‚ä¸‹ \\tanh (x)=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}} å¯¹åº”çš„å¯¼æ•°ä¸º \\begin{aligned} \\tanh ^{\\prime}(x) & =\\left(\\left(e^{x}-e^{-x}\\right)\\left(e^{x}+e^{-x}\\right)^{-1}\\right)^{\\prime} \\\\ & =\\left(e^{x}+e^{-x}\\right)\\left(e^{x}+e^{-x}\\right)^{-1}-\\left(e^{x}-e^{-x}\\right)\\left(e^{x}+e^{-x}\\right)^{-2}\\left(e^{x}-e^{-x}\\right) \\\\ & =1-\\frac{\\left(e^{x}-e^{-x}\\right)^{2}}{\\left(e^{x}+e^{-x}\\right)^{2}} \\\\ & =1-\\tanh ^{2}(x)\\end{aligned} Tanhå›¾åƒå’Œsigmoidå‡½æ•°æ¯”è¾ƒå¦‚ä¸‹å›¾æ‰€ç¤º ä¸ŽSigmoidå‡½æ•°å¯¹æ¯” Tanhæ˜¯ä¸€ä¸ªåŒæ›²æ­£åˆ‡å‡½æ•°ï¼ŒTanhå‡½æ•°å’Œsigmoidå‡½æ•°çš„æ›²çº¿ç›¸å¯¹ç›¸ä¼¼ï¼Œä½†æ˜¯å®ƒæ¯”sigmoidå‡½æ•°æ›´æœ‰ä¸€äº›ä¼˜åŠ¿ï¼Œè¿™ä¸¤ç§æ¿€æ´»å‡½æ•°å‡ä¸ºé¥±å’Œæ¿€æ´»å‡½æ•° ä¼˜ç‚¹ï¼š èŒƒå›´æ›´å¹¿ï¼štanhå‡½æ•°çš„è¾“å‡ºèŒƒå›´æ˜¯(-1, 1)ï¼Œè€Œsigmoidå‡½æ•°çš„è¾“å‡ºèŒƒå›´æ˜¯(0, 1)ï¼Œtanhå‡½æ•°åœ¨å‡å€¼ä¸º0é™„è¿‘æ›´é›†ä¸­ï¼Œå¯¹äºŽæŸäº›ä»»åŠ¡å¯èƒ½æ›´é€‚ç”¨ æ”¶æ•›é€Ÿåº¦å¿«ï¼štanhå‡½æ•°åœ¨è¾“å…¥çš„ç»å¯¹å€¼è¾ƒå¤§æ—¶ï¼Œè¾“å‡ºçš„æ¢¯åº¦ä¹Ÿè¾ƒå¤§ï¼Œè¿™å¯ä»¥å¸®åŠ©ç½‘ç»œæ›´å¿«åœ°æ”¶æ•› å…·æœ‰é›¶ä¸­å¿ƒæ€§ï¼štanhå‡½æ•°çš„å‡å€¼ä¸º0ï¼Œç›¸å¯¹äºŽsigmoidå‡½æ•°æ¥è¯´æ›´å®¹æ˜“å¤„ç†æ­£è´Ÿå€¼çš„è¾“å…¥ï¼Œè®­ç»ƒç›¸å¯¹å®¹æ˜“ ç¼ºç‚¹ï¼š æ¢¯åº¦æ¶ˆå¤±é—®é¢˜: ä¸ŽSigmoidå‡½æ•°ç±»ä¼¼ï¼Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ä»ç„¶å­˜åœ¨ è®¡ç®—ä»£ä»·è¾ƒé«˜ï¼šç›¸å¯¹äºŽsigmoidå‡½æ•°æ¥è¯´ï¼Œtanhå‡½æ•°çš„è®¡ç®—ä»£ä»·è¾ƒé«˜ï¼Œå› ä¸ºå®ƒéœ€è¦è¿›è¡ŒæŒ‡æ•°è¿ç®— Relu ReLUå‡½æ•°çš„ä¸»è¦ä¼˜ç‚¹æ˜¯è®¡ç®—ç®€å•ã€éžçº¿æ€§è¡¨è¾¾èƒ½åŠ›å¼ºã€ä½¿ç½‘ç»œæ›´å¿«é€Ÿåœ°æ”¶æ•›ï¼Œå¹¶ä¸”åœ¨æ·±åº¦ç¥žç»ç½‘ç»œä¸­è¡¨çŽ°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œå‡½æ•°è¡¨è¾¾å¼å¦‚ä¸‹ \\operatorname{ReLU}(x)=\\left\\{\\begin{array}{ll}x & \\text { if } x>0 \\\\ 0 & \\text { if } x \\leq 0\\end{array}\\right. å¯¹åº”çš„å¯¼æ•°ä¸º \\operatorname{ReLU} ^{\\prime} (x)=\\left\\{\\begin{array}{ll}1 & \\text { if } x>0 \\\\ 0 & \\text { if } x \\leq 0\\end{array}\\right. å‡½æ•°å›¾åƒå’Œå¯¹åº”çš„å¯¼æ•°å›¾åƒå¦‚ä¸‹å›¾æ‰€ç¤º ä¸»è¦ä¼˜ç¼ºç‚¹ ä¼˜ç‚¹ï¼š è®¡ç®—é€Ÿåº¦å¿«ï¼šReLUå‡½æ•°çš„è®¡ç®—éžå¸¸ç®€å•ï¼Œåªæœ‰çº¿æ€§å…³ç³»ï¼Œä¸éœ€è¦æŒ‡æ•°è®¡ç®—ï¼Œä¸ç®¡åœ¨å‰å‘ä¼ æ’­è¿˜æ˜¯åå‘ä¼ æ’­ï¼Œè®¡ç®—é€Ÿåº¦éƒ½æ¯”sigmoidå’Œtanhå¿« ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼šç›¸æ¯”äºŽsigmoidå’Œtanhç­‰å‡½æ•°ï¼Œåœ¨æ­£åŒºé—´ä¸ŠReLUå‡½æ•°çš„å¯¼æ•°ä¸ºå¸¸æ•°1ï¼Œè¿™æœ‰åŠ©äºŽç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä½¿å¾—æ·±å±‚ç½‘ç»œçš„æ¢¯åº¦èƒ½å¤Ÿæ›´å¥½åœ°ä¼ æ’­ï¼Œæ›´å®¹æ˜“è¿›è¡Œåå‘ä¼ æ’­ç®—æ³•çš„ä¼˜åŒ–ï¼Œè‡³å°‘xåœ¨æ­£åŒºé—´å†…ï¼Œç¥žç»å…ƒä¸ä¼šé¥±å’Œ æ¿€æ´»ç¨€ç–æ€§ï¼šReLUå‡½æ•°å¯¹äºŽè´Ÿè¾“å…¥å€¼ç›´æŽ¥è¾“å‡ºä¸º0ï¼Œè¿™å¯¼è‡´ç¥žç»å…ƒçš„æ¿€æ´»å˜å¾—ç¨€ç–ï¼Œå³åªæœ‰éƒ¨åˆ†ç¥žç»å…ƒä¼šè¢«æ¿€æ´»ã€‚è¿™ç§ç¨€ç–æ€§æœ‰åŠ©äºŽå‡å°‘å‚æ•°ä¹‹é—´çš„å†—ä½™ï¼Œå¹¶ä¸”åœ¨ä¸€å®šç¨‹åº¦ä¸Šå…·æœ‰æ­£åˆ™åŒ–çš„æ•ˆæžœ ç¼ºç‚¹ï¼š ç¥žç»å…ƒæ­»äº¡é—®é¢˜ï¼šReLUå‡½æ•°åœ¨è´ŸåŒºé—´ä¸Šè¾“å‡ºæ’ä¸º0ï¼Œå½“ç¥žç»å…ƒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºçŽ°è´Ÿè¾“å…¥æ—¶ï¼Œä¼šå¯¼è‡´è¯¥ç¥žç»å…ƒæ°¸è¿œä¸ä¼šè¢«æ¿€æ´»ï¼Œç§°ä¸ºç¥žç»å…ƒæ­»äº¡é—®é¢˜ã€‚è¿™ä¼šå¯¼è‡´ä¸€éƒ¨åˆ†ç¥žç»å…ƒå¤±åŽ»äº†å­¦ä¹ èƒ½åŠ› è¾“å‡ºä¸æ˜¯é›¶ä¸­å¿ƒï¼šReLUå‡½æ•°çš„è¾“å‡ºèŒƒå›´æ˜¯[0, + \\infty)ï¼Œå¹¶ä¸ä»¥0ä¸ºä¸­å¿ƒï¼Œè¿™å¯èƒ½ä¼šå¯¹æŸäº›ä¼˜åŒ–ç®—æ³•çš„æ”¶æ•›é€Ÿåº¦äº§ç”Ÿå½±å“ è®­ç»ƒç¥žç»ç½‘ç»œçš„æ—¶å€™ï¼Œä¸€æ—¦å­¦ä¹ çŽ‡æ²¡æœ‰è®¾ç½®å¥½ï¼Œç¬¬ä¸€æ¬¡æ›´æ–°æƒé‡çš„æ—¶å€™ï¼Œè¾“å…¥çš„æ˜¯è´Ÿå€¼ï¼Œé‚£ä¹ˆè¿™ä¸ªå«æœ‰ReLUçš„ç¥žç»èŠ‚ç‚¹å°±ä¼šæ­»äº¡ï¼Œå†ä¹Ÿä¸ä¼šè¢«æ¿€æ´» åœ¨å®žé™…è®­ç»ƒä¸­ï¼Œå¦‚æžœå­¦ä¹ çŽ‡è®¾ç½®çš„å¤ªé«˜ï¼Œå¯èƒ½ä¼šå‘çŽ°ç½‘ç»œä¸­40%çš„ç¥žç»å…ƒéƒ½ä¼šæ­»æŽ‰ï¼Œä¸”åœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸­è¿™äº›ç¥žç»å…ƒéƒ½ä¸ä¼šè¢«æ¿€æ´» æ‰€ä»¥ï¼Œè®¾ç½®ä¸€ä¸ªåˆé€‚çš„è¾ƒå°çš„å­¦ä¹ çŽ‡ä¼šé™ä½Žè¿™ç§æƒ…å†µçš„å‘ç”Ÿ ä¸ºäº†è§£å†³ç¥žç»å…ƒèŠ‚ç‚¹æ­»äº¡çš„æƒ…å†µï¼Œæœ‰äººæå‡ºäº†Leaky ReLUã€P-ReLUã€R-ReLUã€ELUç­‰æ¿€æ´»å‡½æ•° Leaky ReLU Leaky ReLUå‡½æ•°åœ¨è´Ÿæ•°èŒƒå›´å†…å¼•å…¥äº†ä¸€ä¸ªå°çš„æ–œçŽ‡ï¼Œè§£å†³äº†ReLUå‡½æ•°ä¸­è´Ÿæ•°éƒ¨åˆ†çš„æ­»äº¡é—®é¢˜ï¼Œå‡½æ•°è¡¨è¾¾å¼å¦‚ä¸‹ f(x)=\\left\\{\\begin{array}{cc}x & x>0 \\\\ \\alpha x & x \\leq 0\\end{array}\\right. å¯¹åº”çš„å¯¼æ•°ä¸º f^{\\prime}(x)=\\left\\{\\begin{array}{ll}1 & x>0 \\\\ \\alpha & x å‡½æ•°å›¾åƒå’Œå¯¹åº”çš„å¯¼æ•°å›¾åƒå¦‚ä¸‹å›¾æ‰€ç¤º ä¼˜ç¼ºç‚¹ ä¼˜ç‚¹: Leaky ReLUä¸­å¼•å…¥äº†è¶…å‚æ•°ï¼Œä¸€èˆ¬è®¾ç½®ä¸º0.01ã€‚åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå¯¹äºŽLeaky ReLUçš„è¾“å…¥å°äºŽé›¶çš„æƒ…å†µï¼Œä¹Ÿå¯ä»¥è®¡ç®—å¾—åˆ°ä¸€ä¸ªæ¢¯åº¦(è€Œä¸æ˜¯åƒReLUä¸€æ ·å€¼ä¸º0)ï¼Œè¿™æ ·å°±é¿å…äº†ç¥žç»å…ƒæ­»äº¡çš„é—®é¢˜ ç¼ºç‚¹: ç¨€ç–æ€§å·®: ç›¸è¾ƒäºŽReLUï¼Œç¥žç»ç½‘ç»œçš„ç¨€ç–æ€§è¦å·®ä¸€äº› é¢å¤–çš„è¶…å‚æ•°: å¼•å…¥äº†é¢å¤–çš„è¶…å‚æ•°\\alpha ç¥žç»ç½‘ç»œä¸å­¦ä¹ \\alphaå€¼ ä¸ºä»€ä¹ˆLeaky ReLUæ¯”ReLUæ›´å¥½ è°ƒæ•´è´Ÿå€¼çš„é›¶æ¢¯åº¦: Leaky ReLUé€šè¿‡æŠŠxçš„éžå¸¸å°çš„çº¿æ€§åˆ†é‡ç»™äºˆè´Ÿè¾“å…¥(0.01x)æ¥è°ƒæ•´è´Ÿå€¼çš„é›¶æ¢¯åº¦(zero gradients)é—®é¢˜ æ‰©å¤§å‡½æ•°çš„èŒƒå›´: Leaky ReLUæœ‰åŠ©äºŽæ‰©å¤§ReLUå‡½æ•°çš„èŒƒå›´ï¼Œé€šå¸¸\\alphaçš„å€¼ä¸º0.01å·¦å³ å–å€¼èŒƒå›´: Leaky ReLUçš„å‡½æ•°èŒƒå›´æ˜¯(è´Ÿæ— ç©·åˆ°æ­£æ— ç©·) ä»Žç†è®ºä¸Šè®²ï¼ŒLeaky ReLUå…·æœ‰ReLUçš„æ‰€æœ‰ä¼˜ç‚¹ï¼Œè€Œä¸”Dead ReLUä¸ä¼šæœ‰ä»»ä½•é—®é¢˜ï¼Œä½†åœ¨å®žé™…æ“ä½œä¸­ï¼Œå°šæœªå®Œå…¨è¯æ˜ŽLeaky ReLUæ€»æ˜¯æ¯”ReLUæ›´å¥½ PReLU P-Reluæ¿€æ´»å‡½æ•°çš„è§£æžå¼ f\\left(x\\right)=\\left\\{\\begin{array}{ll}x, & \\text { if } x>0 \\\\ \\alpha_{i} x, & \\text { if } x \\leq 0\\end{array}\\right. P-Reluå‡½æ•°åŠå…¶å¯¼æ•°çš„å›¾åƒå¦‚ä¸‹å›¾æ‰€ç¤º å…¶ä¸­\\alphaæ˜¯è¶…å‚æ•°ã€‚è¿™é‡Œå¼•å…¥äº†ä¸€ä¸ªéšæœºçš„è¶…å‚æ•°\\alphaï¼Œå®ƒå¯ä»¥è¢«å­¦ä¹ ï¼Œå› ä¸ºä½ å¯ä»¥å¯¹å®ƒè¿›è¡Œåå‘ä¼ æ’­ è¿™ä½¿ç¥žç»å…ƒèƒ½å¤Ÿé€‰æ‹©è´ŸåŒºåŸŸæœ€å¥½çš„æ¢¯åº¦ï¼Œæœ‰äº†è¿™ç§èƒ½åŠ›ï¼Œå®ƒä»¬å¯ä»¥å˜æˆReLUæˆ–Leaky ReLU ä¸ŽReLUå’ŒLeaky ReLUçš„å…³ç³» çœ‹ä¸€ä¸‹PReLUçš„å…¬å¼ï¼šå‚æ•°Î±é€šå¸¸ä¸º0åˆ°1ä¹‹é—´çš„æ•°å­—ï¼Œå¹¶ä¸”é€šå¸¸ç›¸å¯¹è¾ƒå° å¦‚æžœ\\alpha_{i}=0ï¼Œåˆ™få˜ä¸ºReLU å¦‚æžœ\\alpha_{i} \\gt 0ï¼Œåˆ™få˜ä¸ºLeaky ReLU å¦‚æžœ\\alpha_{i}æ˜¯å¯å­¦ä¹ çš„å‚æ•°ï¼Œåˆ™få˜ä¸ºPReLU ELU ELU as an Activation Function in Neural Networks CUDAç¼–ç¨‹å…¥é—¨ä¹‹æ¿€æ´»å‡½æ•°ELU ELUæ¿€æ´»å‡½æ•°è§£å†³äº†ReLUçš„ä¸€äº›é—®é¢˜ï¼ŒåŒæ—¶ä¹Ÿä¿ç•™äº†ä¸€äº›å¥½çš„æ–¹é¢ã€‚è¿™ç§æ¿€æ´»å‡½æ•°è¦é€‰å–ä¸€ä¸ª\\alphaå€¼ï¼›å¸¸è§çš„å–å€¼æ˜¯åœ¨0.1åˆ°0.3ä¹‹é—´ f(x)=\\left\\{\\begin{aligned} a\\left(e^{x}-1\\right) \\quad \\quad & x å¯¹åº”çš„å¯¼æ•°ä¸º \\operatorname{ELU}^{\\prime}(x)=\\left\\{\\begin{array}{ll} \\operatorname{ELU}(x)+\\alpha & \\text { if } x \\lt 0 \\\\ 1 & \\text { if } x \\geq 0 \\end{array}\\right. å‡½æ•°åŠå…¶å¯¼æ•°çš„å›¾åƒå¦‚ä¸‹å›¾æ‰€ç¤º å¦‚æžœæˆ‘ä»¬è¾“å…¥çš„xå€¼å¤§äºŽ0ï¼Œåˆ™ç»“æžœä¸ŽReLUä¸€æ ·ï¼Œå³yå€¼ç­‰äºŽxå€¼ï¼›ä½†å¦‚æžœè¾“å…¥çš„xå€¼å°äºŽ0ï¼Œåˆ™æˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ªç¨å¾®å°äºŽ0çš„å€¼ï¼Œæ‰€å¾—åˆ°çš„yå€¼å–å†³äºŽè¾“å…¥çš„xå€¼ï¼Œä½†è¿˜è¦å…¼é¡¾å‚æ•°\\alphaä½ å¯ä»¥æ ¹æ®éœ€è¦æ¥è°ƒæ•´è¿™ä¸ªå‚æ•°ã€‚æ›´è¿›ä¸€æ­¥ï¼Œæˆ‘ä»¬å¼•å…¥äº†æŒ‡æ•°è¿ç®—e^xï¼Œå› æ­¤ELUçš„è®¡ç®—æˆæœ¬æ¯”ReLUé«˜ ä¼˜ç¼ºç‚¹ ä¼˜ç‚¹ ä¸ŽReLUä¸åŒï¼Œå®ƒæ²¡æœ‰ç¥žç»å…ƒæ­»äº¡çš„é—®é¢˜ã€‚ è¿™æ˜¯å› ä¸º ELU çš„æ¢¯åº¦å¯¹äºŽæ‰€æœ‰è´Ÿå€¼éƒ½æ˜¯éžé›¶çš„ ä¸Žå…¶ä»–çº¿æ€§éžé¥±å’Œæ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLU åŠå…¶å˜ä½“ï¼‰ç›¸æ¯”ï¼Œå®ƒæœ‰ç€æ›´å¿«çš„è®­ç»ƒæ—¶é—´ ä½œä¸ºéžé¥±å’Œæ¿€æ´»å‡½æ•°ï¼Œå®ƒä¸ä¼šé‡åˆ°æ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±çš„é—®é¢˜ æ‰€æœ‰ç‚¹ä¸Šéƒ½æ˜¯è¿žç»­çš„å’Œå¯å¾® ç¼ºç‚¹ åŒ…å«æŒ‡æ•°è¿ç®—ï¼Œè®¡ç®—æ—¶é—´é•¿ æ— æ³•é¿å…æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ ç¥žç»ç½‘ç»œæ— æ³•å­¦ä¹ \\alpha å€¼ ä¸ŽLeaky-ReLUå’ŒPReLUç±»ä¼¼ï¼Œä¸ŽReLUä¸åŒçš„æ˜¯ï¼ŒELUæ²¡æœ‰ç¥žç»å…ƒæ­»äº¡çš„é—®é¢˜(ReLU Dying é—®é¢˜æ˜¯æŒ‡å½“å‡ºçŽ°å¼‚å¸¸è¾“å…¥æ—¶ï¼Œåœ¨åå‘ä¼ æ’­ä¸­ä¼šäº§ç”Ÿå¤§çš„æ¢¯åº¦ï¼Œè¿™ç§å¤§çš„æ¢¯åº¦ä¼šå¯¼è‡´ç¥žç»å…ƒæ­»äº¡å’Œæ¢¯åº¦æ¶ˆå¤±)ã€‚ å®ƒå·²è¢«è¯æ˜Žä¼˜äºŽReLUåŠå…¶å˜ä½“ï¼Œå¦‚Leaky-ReLU(LReLU)å’ŒParameterized-ReLU(PReLU)ã€‚ä¸ŽReLUåŠå…¶å˜ä½“ç›¸æ¯”ï¼Œä½¿ç”¨ELUå¯åœ¨ç¥žç»ç½‘ç»œä¸­ç¼©çŸ­è®­ç»ƒæ—¶é—´å¹¶æé«˜å‡†ç¡®åº¦ GELU Gaussian Error Linear Units (GELUS) 2016å¹´æå‡º è®ºæ–‡åœ°å€ GELUå¯ä»¥çœ‹åšæ˜¯RELUçš„ä¸€ä¸ªå¹³æ»‘ç‰ˆæœ¬ï¼›GELUæ¿€æ´»å‡½æ•°çš„æœ€å¤§ç‰¹ç‚¹æ˜¯ï¼šå°†éžçº¿æ€§ä¸Žä¾èµ–è¾“å…¥æ•°æ®åˆ†å¸ƒçš„éšæœºæ­£åˆ™åŒ–å™¨ç›¸ç»“åˆåœ¨ä¸€ä¸ªæ¿€æ´»å‡½æ•°çš„è¡¨è¾¾ä¸­ \\begin{array}{c} GELU(x) = 0.5 x\\left(1+\\tanh \\left[\\sqrt{2 / \\pi}\\left(x+0.044715 x^{3}\\right)\\right]\\right) \\approx x \\sigma(1.702 x) \\end{array} åœ¨é¢„è®­ç»ƒè¯­è¨€æ¨¡åž‹ä¸­ï¼ŒGELUå¯ä»¥è¯´æ˜¯ä¸»æµçš„æ¿€æ´»å‡½æ•°ï¼›Bertï¼ŒRoBERTaï¼ŒALBERTï¼ŒGPT-2ç­‰é¡¶å°–çš„NLPé¢„è®­ç»ƒæ¨¡åž‹éƒ½æ˜¯ä½¿ç”¨çš„GELU bertä¸­ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Œä½œè€…ç»è¿‡å®žéªŒè¯æ˜Žæ¯”reluç­‰è¦å¥½ã€‚åŽŸç‚¹å¯å¯¼ï¼Œä¸ä¼šæœ‰Dead ReLUé—®é¢˜ ä¸ŽReluå’ŒELUæ¯”è¾ƒå¦‚ä¸‹ Softplus Softpluså‡½æ•°ç±»ä¼¼äºŽReLUå‡½æ•°ï¼Œä½†æ˜¯ç›¸å¯¹è¾ƒå¹³æ»‘ï¼ŒåƒReLUä¸€æ ·æ˜¯å•ä¾§æŠ‘åˆ¶ï¼Œå®ƒçš„æŽ¥å—èŒƒå›´å¾ˆå¹¿ f(x)=\\ln \\left(1+e^{x}\\right) å…¶å¯¹åº”çš„å¯¼æ•°å¦‚ä¸‹ \\left.f^{\\prime}(x)=\\ln \\left(e^{x}+1\\right)\\right)^{\\prime} = \\frac{1}{1 + e^{-x}} ä¼˜ç‚¹ï¼š ä½œä¸ºreluçš„ä¸€ä¸ªä¸é”™çš„æ›¿ä»£é€‰æ‹©ï¼Œsoftplusèƒ½å¤Ÿè¿”å›žä»»ä½•å¤§äºŽ0çš„å€¼ ä¸Žreluä¸åŒï¼Œsoftplusçš„å¯¼æ•°æ˜¯è¿žç»­çš„ã€éžé›¶çš„ï¼Œæ— å¤„ä¸åœ¨ï¼Œä»Žè€Œé˜²æ­¢å‡ºçŽ°æ­»ç¥žç»å…ƒ ç¼ºç‚¹ï¼š å¯¼æ•°å¸¸å¸¸å°äºŽ1ï¼Œä¹Ÿå¯èƒ½å‡ºçŽ°æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ softpluså¦ä¸€ä¸ªä¸åŒäºŽ reluçš„åœ°æ–¹åœ¨äºŽå…¶ä¸å¯¹ç§°æ€§ï¼Œä¸ä»¥é›¶ä¸ºä¸­å¿ƒï¼Œå¯èƒ½ä¼šå¦¨ç¢å­¦ä¹  Maxout ç­‰å¾…... Swish å°†Sigmoidå‡½æ•°ä¸Žçº¿æ€§å‡½æ•°çš„ä¹˜ç§¯ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œå¹³è¡¡äº†éžçº¿æ€§å’Œçº¿æ€§è¡¨è¾¾èƒ½åŠ› Mish Mish: A Self Regularized Non-Monotonic Neural Activation Function 2020 f(x)=x \\tanh (\\operatorname{softplus}(x))=x \\tanh \\left(\\ln \\left(1+e^{x}\\right)\\right) SoftSign ä¼˜ç‚¹ï¼š softsignæ˜¯ tanhæ¿€æ´»å‡½æ•°çš„å¦ä¸€ä¸ªæ›¿ä»£é€‰æ‹© softsignæ˜¯åå¯¹ç§°ã€åŽ»ä¸­å¿ƒã€å¯å¾®åˆ†ï¼Œå¹¶è¿”å›žâˆ’1å’Œ1ä¹‹é—´çš„å€¼ softsignæ›´å¹³å¦çš„æ›²çº¿ä¸Žæ›´æ…¢çš„ä¸‹é™å¯¼æ•°è¡¨æ˜Žå®ƒå¯ä»¥æ›´é«˜æ•ˆåœ°å­¦ä¹  ç¼ºç‚¹ï¼š å¯¼æ•°çš„è®¡ç®—æ¯”tanhæ›´éº»çƒ¦ æ¿€æ´»å‡½æ•°çš„é€‰æ‹© é€‰æ‹©ä¸€ä¸ªé€‚åˆçš„æ¿€æ´»å‡½æ•°å¹¶ä¸å®¹æ˜“ï¼Œéœ€è¦è€ƒè™‘å¾ˆå¤šå› ç´ ï¼Œé€šå¸¸çš„åšæ³•æ˜¯ï¼Œå¦‚æžœä¸ç¡®å®šå“ªä¸€ä¸ªæ¿€æ´»å‡½æ•°æ•ˆæžœæ›´å¥½ï¼Œå¯ä»¥æŠŠå®ƒä»¬éƒ½è¯•è¯•ï¼Œç„¶åŽçœ‹çœ‹åœ¨éªŒè¯é›†æˆ–è€…æµ‹è¯•é›†ä¸Šçš„æ•ˆæžœ ç„¶åŽçœ‹å“ªä¸€ç§è¡¨çŽ°çš„æ›´å¥½ï¼Œå°±åŽ»ä½¿ç”¨å®ƒ ä»¥ä¸‹æ˜¯å¸¸è§çš„é€‰æ‹©æƒ…å†µï¼š å¦‚æžœè¾“å‡ºæ˜¯0ã€1å€¼(äºŒåˆ†ç±»é—®é¢˜)ï¼Œåˆ™è¾“å‡ºå±‚é€‰æ‹©Sigmoidå‡½æ•°ï¼Œç„¶åŽå…¶å®ƒçš„æ‰€æœ‰å•å…ƒéƒ½é€‰æ‹©ReLUå‡½æ•° å¦‚æžœåœ¨éšè—å±‚ä¸Šä¸ç¡®å®šä½¿ç”¨å“ªä¸ªæ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆé€šå¸¸ä¼šä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ã€‚æœ‰æ—¶ï¼Œä¹Ÿä¼šä½¿ç”¨Tanhæ¿€æ´»å‡½æ•° Sigmoidæ¿€æ´»å‡½æ•°ï¼šé™¤äº†è¾“å‡ºå±‚æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜åŸºæœ¬ä¸ä¼šç”¨å®ƒ Tanhæ¿€æ´»å‡½æ•°ï¼šTanhæ˜¯éžå¸¸ä¼˜ç§€çš„ï¼Œå‡ ä¹Žé€‚åˆæ‰€æœ‰åœºåˆ ReLUæ¿€æ´»å‡½æ•°ï¼šæœ€å¸¸ç”¨çš„é»˜è®¤å‡½æ•°ï¼Œå¦‚æžœä¸ç¡®å®šç”¨å“ªä¸ªæ¿€æ´»å‡½æ•°ï¼Œå°±ä½¿ç”¨ReLUæˆ–è€…Leaky ReLUï¼Œå†åŽ»å°è¯•å…¶ä»–çš„æ¿€æ´»å‡½æ•° å¦‚æžœé‡åˆ°äº†ä¸€äº›æ­»çš„ç¥žç»å…ƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ Leaky ReLUå‡½æ•° Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒåŸºç¡€çŸ¥è¯†ç‚¹.html":{"url":"chapters/æ·±åº¦å­¦ä¹ æ ¸å¿ƒåŸºç¡€çŸ¥è¯†ç‚¹.html","title":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒåŸºç¡€çŸ¥è¯†ç‚¹.md","summary":"æ·±åº¦å­¦ä¹ æ ¸å¿ƒåŸºç¡€çŸ¥è¯†ç‚¹","keywords":"","body":"åŸºç¡€çŸ¥è¯†åå‘ä¼ æ’­ç®—æ³•æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸è§£å†³æ–¹æ¡ˆæ³›åŒ–é—®é¢˜è¿‡æ‹Ÿåˆæ¬ æ‹Ÿåˆæ ¸å¿ƒç½‘ç»œå±‚å…¨è¿žæŽ¥å±‚Convå·ç§¯æ“ä½œæ™®é€šå·ç§¯3Då·ç§¯æ‰©å¼ å·ç§¯(è†¨èƒ€ã€ç©ºæ´ž)åˆ†ç»„å·ç§¯åå·ç§¯(è½¬ç½®)å¯åˆ†ç¦»å·ç§¯å¯å˜å½¢å·ç§¯æ± åŒ–æ“ä½œæœ€å¤§æœ€å°æ± åŒ–å¹³å‡æ± åŒ–éšæœºæ± åŒ–Lpæ± åŒ–ç»„åˆæ± åŒ–SPPæ± åŒ–ROIæ± åŒ–åæ± åŒ–å…¶ä»–æ± åŒ–å½’ä¸€åŒ–æ‰¹å½’ä¸€åŒ–å±‚å½’ä¸€åŒ–å®žä¾‹å½’ä¸€åŒ–ç»„å½’ä¸€åŒ–Embeddingå±‚Dropoutå±‚æŒ‡æ ‡ åŸºç¡€çŸ¥è¯† ç®€å•è¯´æ˜Žä¸‹æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„ä¸»è¦åŒºåˆ«ï¼š æ¨¡åž‹ç»“æž„ï¼šä¸€èˆ¬æ·±åº¦å­¦ä¹ åŸºäºŽæ·±åº¦ç¥žç»ç½‘ç»œæž¶æž„è¾ƒä¸ºå¤æ‚åŒ– è‡ªåŠ¨æå–ç‰¹å¾ï¼šä¼ ç»Ÿæœºå™¨å­¦ä¹ éœ€è¦äººå·¥æž„é€ ç‰¹å¾ä½†æ·±åº¦å­¦ä¹ åŸºäºŽç¥žç»ç½‘ç»œè‡ªåŠ¨æå–ç‰¹å¾ æ•°æ®é‡ï¼šæ·±åº¦å­¦ä¹ éœ€è¦å¤§é‡çš„æ•°æ®é›†æ¥è®­ç»ƒå¤šå±‚ç¥žç»ç½‘ç»œ åå‘ä¼ æ’­ç®—æ³• åå‘ä¼ æ’­(Backpropagation)ç®—æ³•æ˜¯ä¸€ç§ç”¨äºŽè®¡ç®—ç¥žç»ç½‘ç»œä¸­å„ä¸ªå‚æ•°æ¢¯åº¦çš„æ–¹æ³•ï¼Œå®ƒåŸºäºŽé“¾å¼æ³•åˆ™å’Œæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼Œä¸‹é¢æ˜¯åå‘ä¼ æ’­ç®—æ³•çš„åŸºæœ¬æ­¥éª¤ï¼š å‰å‘ä¼ æ’­(Forward Propagation)ï¼š è¾“å…¥ä¸€ä¸ªæ ·æœ¬ï¼Œé€šè¿‡ç¥žç»ç½‘ç»œçš„å‰å‘ä¼ æ’­è®¡ç®—å¾—åˆ°é¢„æµ‹è¾“å‡º é€å±‚è®¡ç®—æ¯ä¸ªç¥žç»å…ƒçš„è¾“å‡ºå€¼ï¼Œç›´è‡³è¾“å‡ºå±‚ åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå°†æ¯ä¸€å±‚çš„è¾“å…¥ã€æƒé‡å’Œæ¿€æ´»å‡½æ•°çš„ç»“æžœä¿å­˜ä¸‹æ¥ï¼Œç”¨äºŽåŽç»­çš„åå‘ä¼ æ’­è®¡ç®— è®¡ç®—æŸå¤±å‡½æ•°(Loss Calculation)ï¼š æ ¹æ®é¢„æµ‹è¾“å‡ºå’ŒçœŸå®žæ ‡ç­¾è®¡ç®—æŸå¤±å‡½æ•°çš„å€¼ å¸¸è§çš„æŸå¤±å‡½æ•°åŒ…æ‹¬å‡æ–¹è¯¯å·®(Mean Squared Error)ã€äº¤å‰ç†µæŸå¤±(Cross-Entropy Loss)ç­‰ åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦(Backward Propagation)ï¼š ä»Žè¾“å‡ºå±‚å¼€å§‹ï¼Œæ ¹æ®é“¾å¼æ³•åˆ™è®¡ç®—æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ é€å±‚å‘åŽä¼ æ’­ï¼Œé€šè¿‡é“¾å¼æ³•åˆ™å°†ä¸Šä¸€å±‚çš„æ¢¯åº¦ä¹˜ä»¥å½“å‰å±‚çš„å±€éƒ¨æ¢¯åº¦ï¼Œå¾—åˆ°å½“å‰å±‚çš„æ¢¯åº¦ æ ¹æ®æ¢¯åº¦ä¸‹é™ç®—æ³•æ›´æ–°ç½‘ç»œå‚æ•° å‚æ•°æ›´æ–°(Parameter Update)ï¼š æ ¹æ®è®¡ç®—å¾—åˆ°çš„æ¢¯åº¦å€¼ï¼Œä½¿ç”¨æ¢¯åº¦ä¸‹é™ç®—æ³•æˆ–å…¶å˜ç§æ–¹æ³•æ¥æ›´æ–°ç½‘ç»œçš„å‚æ•° å¸¸è§çš„æ¢¯åº¦ä¸‹é™ç®—æ³•åŒ…æ‹¬éšæœºæ¢¯åº¦ä¸‹é™(Stochastic Gradient Descentï¼ŒSGD)ã€åŠ¨é‡æ³•(Momentum)ã€Adamç­‰ é‡å¤ä»¥ä¸Šæ­¥éª¤ï¼š å¯¹äºŽæ¯ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œé‡å¤æ‰§è¡Œå‰å‘ä¼ æ’­ã€æŸå¤±è®¡ç®—ã€åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°çš„æ­¥éª¤ è¿­ä»£è®­ç»ƒè¿‡ç¨‹ç›´åˆ°è¾¾åˆ°é¢„è®¾çš„åœæ­¢æ¡ä»¶ï¼Œå¦‚è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–æŸå¤±å‡½æ•°æ”¶æ•› æ³¨æ„ï¼Œåå‘ä¼ æ’­ç®—æ³•ä¼šé‡å¤åˆ©ç”¨å‰å‘ä¼ æ’­ä¸­å­˜å‚¨çš„ä¸­é—´å€¼ï¼Œä»¥é¿å…é‡å¤è®¡ç®—ï¼Œå› æ­¤ï¼Œéœ€è¦ä¿ç•™å‰å‘ä¼ æ’­çš„ä¸­é—´ç»“æžœï¼Œè¿™ä¹Ÿä¼šå¯¼è‡´æ¨¡åž‹è®­ç»ƒæ¯”å•çº¯çš„é¢„æµ‹éœ€è¦æ›´å¤šçš„å†…å­˜(æ˜¾å­˜) åŒæ—¶è¿™äº›ä¸­é—´ç»“æžœå ç”¨å†…å­˜(æ˜¾å­˜)å¤§å°ä¸Žç½‘ç»œå±‚çš„æ•°é‡å’Œæ‰¹é‡(batch_size)å¤§å°æˆæ­£æ¯” å› æ­¤ä½¿ç”¨å¤§batch_sizeè®­ç»ƒæ›´æ·±å±‚æ¬¡çš„ç½‘ç»œæ›´å®¹æ˜“å¯¼è‡´å†…å­˜ä¸è¶³(out of memory)çš„é”™è¯¯ åå‘ä¼ æ’­ç®—æ³•é€šè¿‡æœ‰æ•ˆåœ°è®¡ç®—æ¯ä¸ªå‚æ•°çš„æ¢¯åº¦ï¼Œä½¿å¾—ç¥žç»ç½‘ç»œå¯ä»¥é€šè¿‡æ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–æ–¹æ³•æ¥ä¸æ–­æ›´æ–°å‚æ•°ä»¥æœ€å°åŒ–æŸå¤±å‡½æ•° è¿™æ ·ï¼Œç¥žç»ç½‘ç»œå¯ä»¥é€æ­¥ä¼˜åŒ–è‡ªèº«çš„æƒé‡å’Œåç½®ï¼Œä»Žè€Œæé«˜æ¨¡åž‹çš„æ€§èƒ½å’Œå‡†ç¡®åº¦ æ·±åº¦å­¦ä¹ ä¼˜åŒ–å­˜åœ¨è®¸å¤šæŒ‘æˆ˜ï¼Œå…¶ä¸­ä¸€äº›æœ€ä»¤äººçƒ¦æ¼çš„æ˜¯å±€éƒ¨æœ€å°å€¼ã€éžç‚¹å’Œæ¢¯åº¦æ¶ˆå¤± å±€éƒ¨æœ€å°å€¼(local minimum): å¯¹äºŽä»»ä½•ç›®æ ‡å‡½æ•°f(x)ï¼Œå¦‚æžœåœ¨xå¤„å¯¹åº”çš„f(x)å€¼å°äºŽåœ¨xé™„è¿‘ä»»ä½•å…¶ä»–ç‚¹çš„f(x)å€¼ï¼Œé‚£ä¹ˆf(x)å¯èƒ½æ˜¯å±€éƒ¨æœ€å°å€¼ å¦‚æžœf(x)åœ¨xå¤„çš„å€¼æ˜¯æ•´ä¸ªåŸŸä¸Šç›®æ ‡å‡½æ•°çš„æœ€å°å€¼ï¼Œé‚£ä¹ˆf(x)æ˜¯å…¨å±€æœ€å°å€¼ éžç‚¹(saddle point): æŒ‡å‡½æ•°çš„æ‰€æœ‰æ¢¯åº¦éƒ½æ¶ˆå¤±ä½†æ—¢ä¸æ˜¯å…¨å±€æœ€å°å€¼ä¹Ÿä¸æ˜¯å±€éƒ¨æœ€å°å€¼çš„ä»»ä½•ä½ç½® æ¢¯åº¦æ¶ˆå¤±(vanishing gradient): å› ä¸ºæŸäº›åŽŸå› å¯¼è‡´ç›®æ ‡å‡½æ•°fçš„æ¢¯åº¦æŽ¥è¿‘é›¶(å³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜)ï¼Œæ˜¯åœ¨å¼•å…¥ReLUæ¿€æ´»å‡½æ•°å’ŒResNetä¹‹å‰è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡åž‹ç›¸å½“æ£˜æ‰‹çš„åŽŸå› ä¹‹ä¸€ åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå¤§å¤šæ•°ç›®æ ‡å‡½æ•°éƒ½å¾ˆå¤æ‚ï¼Œæ²¡æœ‰è§£æžè§£ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬éœ€ä½¿ç”¨æ•°å€¼ä¼˜åŒ–ç®—æ³• æ¢¯åº¦æ¶ˆå¤±å’Œçˆ†ç‚¸ æ¢¯åº¦ä¸ç¨³å®šçš„åŽŸå› ï¼šæ ¸å¿ƒåœ¨äºŽé“¾å¼æ³•åˆ™ï¼Œå‰é¢å±‚ä¸Šçš„æ¢¯åº¦æ˜¯æ¥è‡ªåŽé¢å±‚ä¸Šæ¢¯åº¦çš„ä¹˜ç§¯ã€‚å½“å­˜åœ¨è¿‡å¤šçš„å±‚æ—¶ï¼Œå°±ä¼šå‡ºçŽ°æ¢¯åº¦ä¸ç¨³å®šåœºæ™¯ï¼Œæ¯”å¦‚æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ æ¢¯åº¦çˆ†ç‚¸ åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­éœ€è¦å¯¹æ¿€æ´»å‡½æ•°è¿›è¡Œæ±‚å¯¼ï¼Œå¦‚æžœå¯¼æ•°å¤§äºŽ1ï¼Œé‚£ä¹ˆéšç€ç½‘ç»œå±‚æ•°çš„å¢žåŠ æ¢¯åº¦æ›´æ–°å°†ä¼šæœç€æŒ‡æ•°çˆ†ç‚¸çš„æ–¹å¼å¢žåŠ è¿™å°±æ˜¯æ¢¯åº¦çˆ†ç‚¸ æ¢¯åº¦æ¶ˆå¤± åŒæ ·å¦‚æžœå¯¼æ•°å°äºŽ1ï¼Œé‚£ä¹ˆéšç€ç½‘ç»œå±‚æ•°çš„å¢žåŠ æ¢¯åº¦æ›´æ–°ä¿¡æ¯ä¼šæœç€æŒ‡æ•°è¡°å‡çš„æ–¹å¼å‡å°‘è¿™å°±æ˜¯æ¢¯åº¦æ¶ˆå¤± æ ¹æœ¬åŽŸå›  æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ï¼Œå…¶æ ¹æœ¬åŽŸå› åœ¨äºŽåå‘ä¼ æ’­è®­ç»ƒæ³•åˆ™ï¼Œå±žäºŽå…ˆå¤©ä¸è¶³ è®¡ç®—æƒå€¼æ›´æ–°ä¿¡æ¯çš„æ—¶å€™éœ€è¦è®¡ç®—å‰å±‚åå¯¼ä¿¡æ¯ï¼Œå› æ­¤å¦‚æžœæ¿€æ´»å‡½æ•°é€‰æ‹©ä¸åˆé€‚ æ¯”å¦‚ä½¿ç”¨sigmoidï¼Œæ¢¯åº¦æ¶ˆå¤±å°±ä¼šå¾ˆæ˜Žæ˜¾äº†ï¼Œå¦‚æžœä½¿ç”¨sigmoidä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå…¶æ¢¯åº¦æ˜¯ä¸å¯èƒ½è¶…è¿‡0.25ï¼Œè¿™æ ·ç»è¿‡é“¾å¼æ±‚å¯¼ä¹‹åŽï¼Œå¾ˆå®¹æ˜“å‘ç”Ÿæ¢¯åº¦æ¶ˆå¤± è§£å†³æ–¹æ¡ˆ æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸æ˜¯åœ¨ç¥žç»ç½‘ç»œè®­ç»ƒè¿‡ç¨‹ä¸­å¸¸è§çš„é—®é¢˜ï¼Œå¯èƒ½å¯¼è‡´æ¨¡åž‹æ”¶æ•›å›°éš¾æˆ–æ— æ³•æœ‰æ•ˆæ›´æ–°æƒé‡ã€‚ä¸‹é¢æ˜¯æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸çš„äº§ç”ŸåŽŸå› å’Œè§£å†³æ–¹æ³•ï¼š æ¢¯åº¦æ¶ˆå¤±(Gradient Vanishing) åŽŸå› ï¼šåœ¨æ·±å±‚ç¥žç»ç½‘ç»œä¸­ï¼Œæ¢¯åº¦é€šè¿‡å¤šä¸ªå±‚ä¼ é€’æ—¶å¯èƒ½ä¼šé€æ¸è¡°å‡ã€‚ç‰¹åˆ«æ˜¯ä½¿ç”¨å…·æœ‰å°æ¢¯åº¦çš„æ¿€æ´»å‡½æ•°(å¦‚Sigmoidã€Tanh)æ—¶ï¼Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜æ›´ä¸ºä¸¥é‡ è§£å†³æ–¹æ³•ï¼š å¤§æ¢¯åº¦çš„æ¿€æ´»å‡½æ•°ï¼šé€‰æ‹©å…·æœ‰è¾ƒå¤§æ¢¯åº¦çš„æ¿€æ´»å‡½æ•°ï¼Œå¦‚ReLUã€Leaky ReLUç­‰ å‚æ•°åˆå§‹åŒ–ï¼šåˆç†åˆå§‹åŒ–æƒé‡ï¼Œé¿å…åˆå§‹æ¢¯åº¦è¿‡å°æˆ–è¿‡å¤§ æ‰¹å½’ä¸€åŒ–(Batch Normalization)ï¼šé€šè¿‡å¯¹æ¯ä¸€å±‚çš„è¾“å…¥è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¯ä»¥ä½¿å¾—æ¿€æ´»å‡½æ•°è¾“å…¥å€¼çš„åˆ†å¸ƒæ›´ç¨³å®šï¼Œæœ‰åŠ©äºŽç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ æ®‹å·®è¿žæŽ¥(Residual Connections)ï¼šå¼•å…¥è·¨å±‚çš„ç›´æŽ¥è¿žæŽ¥ï¼Œä½¿å¾—æ¢¯åº¦å¯ä»¥æ›´å®¹æ˜“åœ°é€šè¿‡ç½‘ç»œä¼ æ’­ï¼Œä¾‹å¦‚ResNetä¸­çš„æ®‹å·®è¿žæŽ¥ç»“æž„ æ¢¯åº¦çˆ†ç‚¸(Gradient Explosion) åŽŸå› ï¼šåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ¢¯åº¦å¯èƒ½ä¼šæŒ‡æ•°çº§å¢žé•¿ï¼Œå¯¼è‡´æ•°å€¼æº¢å‡º è§£å†³æ–¹æ³•ï¼š æ¢¯åº¦è£å‰ª(Gradient Clipping)ï¼šé™åˆ¶æ¢¯åº¦çš„èŒƒå›´ï¼Œé€šè¿‡è®¾ç½®é˜ˆå€¼æˆ–ç¼©æ”¾æ¢¯åº¦æ¥é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ å‚æ•°åˆå§‹åŒ–ï¼šåˆç†åˆå§‹åŒ–æƒé‡ï¼Œé¿å…åˆå§‹æ¢¯åº¦è¿‡å¤§ ä½¿ç”¨ç¨€ç–è¿žæŽ¥ï¼šå‡å°‘ç½‘ç»œä¸­çš„è¿žæŽ¥æ•°é‡ï¼Œå¯ä»¥é™ä½Žæ¢¯åº¦çˆ†ç‚¸çš„é£Žé™© æ›´å°çš„å­¦ä¹ çŽ‡ï¼šé™ä½Žå­¦ä¹ çŽ‡ï¼Œä½¿å¾—æ¢¯åº¦æ›´æ–°æ›´åŠ ç¨³å®š æ­£åˆ™åŒ–æ–¹æ³•å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ æ€»çš„æ¥è¯´ï¼Œè§£å†³æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜çš„æ–¹æ³•åŒ…æ‹¬é€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°ã€å‚æ•°åˆå§‹åŒ–ç­–ç•¥ã€æ‰¹å½’ä¸€åŒ–ã€æ®‹å·®è¿žæŽ¥ã€æ¢¯åº¦è£å‰ªç­‰ éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µç»¼åˆè€ƒè™‘å¹¶é€‚å½“è°ƒæ•´è¿™äº›æ–¹æ³•ä»¥æé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆæžœ æ³›åŒ–é—®é¢˜ è¿‡æ‹Ÿåˆ(Over fitting)å’Œæ¬ æ‹Ÿåˆ(Under fitting)æ˜¯æŒ‡æœºå™¨å­¦ä¹ æ¨¡åž‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹è®­ç»ƒæ•°æ®çš„æ‹Ÿåˆç¨‹åº¦ä¸åˆé€‚çš„é—®é¢˜ è¿‡æ‹Ÿåˆ çŽ°è±¡ è¿‡æ‹ŸåˆæŒ‡çš„æ˜¯æ¨¡åž‹è¿‡äºŽå¤æ‚ï¼Œè¿‡åº¦é€‚åº”äº†è®­ç»ƒæ•°æ®çš„ç‰¹å¾ï¼Œå¯¼è‡´åœ¨æ–°çš„æœªè§è¿‡çš„æ•°æ®ä¸Šè¡¨çŽ°ä¸ä½³ è¿‡æ‹Ÿåˆçš„è¡¨çŽ°æ˜¯åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨çŽ°å‡ºè¾ƒå¥½çš„æ‹Ÿåˆæ•ˆæžœï¼Œä½†åœ¨æµ‹è¯•æ•°æ®ä¸Šçš„è¡¨çŽ°è¾ƒå·® è¿‡æ‹Ÿåˆçš„åŽŸå› å¯èƒ½æ˜¯æ¨¡åž‹è¿‡äºŽå¤æ‚ï¼Œå‚æ•°è¿‡å¤šï¼Œå¯¼è‡´æ¨¡åž‹å…·æœ‰å¾ˆå¼ºçš„è®°å¿†èƒ½åŠ›è€Œå¿½ç•¥äº†æ•°æ®çš„çœŸå®žè§„å¾‹ äº§ç”ŸåŽŸå›  æ¨¡åž‹å¤ªå¤æ‚: è®­ç»ƒé›†çš„æ•°é‡çº§å’Œæ¨¡åž‹çš„å¤æ‚åº¦ä¸åŒ¹é…ï¼Œè®­ç»ƒé›†çš„æ•°é‡çº§è¦å°äºŽæ¨¡åž‹çš„å¤æ‚åº¦ ç‰¹å¾åˆ†å¸ƒä¸ä¸€è‡´: è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç‰¹å¾åˆ†å¸ƒä¸ä¸€è‡´ å­¦ä¹ åˆ°å™ªéŸ³: æ ·æœ¬é‡Œçš„å™ªéŸ³æ•°æ®å¹²æ‰°è¿‡å¤§ï¼Œå¤§åˆ°æ¨¡åž‹è¿‡åˆ†çš„è®°ä½äº†å™ªéŸ³ç‰¹å¾ï¼Œè€Œå¿½ç•¥äº†çœŸå®žçš„è¾“å…¥è¾“å‡ºé—´çš„å…³ç³» è¿­ä»£è¿‡å¤š: æƒå€¼å­¦ä¹ è¿­ä»£æ¬¡æ•°è¶³å¤Ÿå¤š(Over training)ï¼Œæ‹Ÿåˆäº†è®­ç»ƒæ•°æ®ä¸­çš„å™ªå£°å’Œè®­ç»ƒæ ·ä¾‹ä¸­æ²¡æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾ è§£å†³æ–¹æ¡ˆ ç®€åŒ–æ¨¡åž‹: ä½¿å…¶é€‚åˆè‡ªå·±è®­ç»ƒé›†çš„æ•°é‡çº§(ç¼©å°å®½åº¦å’Œå‡å°æ·±åº¦)ï¼Œä½¿æ¨¡åž‹æ›´å¥½åœ°å­¦ä¹ æ•°æ®çš„çœŸå®žåˆ†å¸ƒ æ•°æ®å¢žå¼º: è®­ç»ƒé›†è¶Šå¤šï¼Œè¿‡æ‹Ÿåˆçš„æ¦‚çŽ‡è¶Šå°ã€‚åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­ï¼Œå¢žå¹¿çš„æ–¹å¼æ˜¯å¯¹å›¾åƒæ—‹è½¬ï¼Œç¼©æ”¾ï¼Œå‰ªåˆ‡ï¼Œæ·»åŠ å™ªå£°ç­‰ æ­£åˆ™åŒ–: æŒ‡é€šè¿‡å¼•å…¥é¢å¤–æ–°ä¿¡æ¯æ¥è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜çš„ä¸€ç§ï¼Œè¿™ç§é¢å¤–ä¿¡æ¯é€šå¸¸çš„å½¢å¼æ˜¯æ¨¡åž‹å¤æ‚æ€§å¸¦æ¥çš„æƒ©ç½šåº¦ã€‚æ­£åˆ™åŒ–å¯ä»¥ä¿æŒæ¨¡åž‹ç®€å• dropout: åœ¨è®­ç»ƒçš„æ—¶å€™è®©ç¥žç»å…ƒä»¥ä¸€å®šæ¦‚çŽ‡ä¸å·¥ä½œ Early stopping: è¿­ä»£æ¬¡æ•°æˆªæ–­çš„æ–¹æ³•æ¥é˜²æ­¢è¿‡æ‹Ÿåˆçš„ï¼Œå³åœ¨æ¨¡åž‹å¯¹è®­ç»ƒæ•°æ®é›†è¿­ä»£æ”¶æ•›ä¹‹å‰åœæ­¢è¿­ä»£æ¥é˜²æ­¢è¿‡æ‹Ÿåˆ æ¬ æ‹Ÿåˆ çŽ°è±¡ æ¬ æ‹ŸåˆæŒ‡çš„æ˜¯æ¨¡åž‹è¿‡äºŽç®€å•ï¼Œä¸èƒ½å¾ˆå¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®çš„ç‰¹å¾ï¼Œå¯¼è‡´åœ¨è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®ä¸Šçš„è¡¨çŽ°éƒ½ä¸ä½³ æ¬ æ‹Ÿåˆçš„è¡¨çŽ°æ˜¯æ¨¡åž‹æ— æ³•æ•æ‰åˆ°æ•°æ®ä¸­çš„å¤æ‚å…³ç³»æˆ–è§„å¾‹ï¼Œæ— æ³•å¾ˆå¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ® æ¬ æ‹Ÿåˆçš„åŽŸå› å¯èƒ½æ˜¯æ¨¡åž‹è¿‡äºŽç®€å•ï¼Œå‚æ•°è¿‡å°‘ï¼Œæ— æ³•å……åˆ†å­¦ä¹ æ•°æ®çš„ç‰¹å¾ äº§ç”ŸåŽŸå›  æ¨¡åž‹å¤æ‚åº¦ä¸è¶³ï¼šæ¨¡åž‹çš„å¤æ‚åº¦ä¸è¶³ä»¥æ•æ‰æ•°æ®ä¸­çš„å¤æ‚å…³ç³»ã€‚ä¾‹å¦‚ï¼Œçº¿æ€§æ¨¡åž‹æ— æ³•å¾ˆå¥½åœ°æ‹Ÿåˆéžçº¿æ€§æ•°æ®ï¼Œå¯¼è‡´æ¬ æ‹Ÿåˆ ç‰¹å¾æå–ä¸è¶³ï¼šç‰¹å¾æå–ä¸è¶³æ„å‘³ç€æ¨¡åž‹æ— æ³•ä»ŽåŽŸå§‹æ•°æ®ä¸­æå–å‡ºæœ‰ç”¨çš„ç‰¹å¾ã€‚å¦‚æžœç‰¹å¾ä¸å…·å¤‡è¾ƒå¼ºçš„åŒºåˆ†æ€§ï¼Œæ¨¡åž‹å°±æ— æ³•å¾ˆå¥½åœ°è¿›è¡Œæ‹Ÿåˆ æ•°æ®é‡ä¸è¶³ï¼šå½“è®­ç»ƒæ•°æ®è¾ƒå°‘æ—¶ï¼Œæ¨¡åž‹éš¾ä»¥å­¦ä¹ æ•°æ®çš„çœŸå®žåˆ†å¸ƒå’Œè§„å¾‹ã€‚æœ‰é™çš„æ•°æ®æ ·æœ¬å¯èƒ½æ— æ³•æä¾›è¶³å¤Ÿçš„ä¿¡æ¯æ¥è®­ç»ƒä¸€ä¸ªå¤æ‚çš„æ¨¡åž‹ è¿‡åº¦æ­£åˆ™åŒ–ï¼šè¿‡åº¦æ­£åˆ™åŒ–å¯ä»¥å¯¼è‡´æ¨¡åž‹è¿‡äºŽç®€å•ï¼Œæ— æ³•å¾ˆå¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚ä¾‹å¦‚ï¼Œå¼ºåˆ¶æ–½åŠ è¾ƒå¼ºçš„æ­£åˆ™åŒ–é¡¹æˆ–ä½¿ç”¨è¾ƒé«˜çš„æ­£åˆ™åŒ–ç³»æ•°ä¼šé™åˆ¶æ¨¡åž‹çš„çµæ´»æ€§ æ•°æ®å™ªå£°ï¼šå½“è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨å™ªå£°æˆ–é”™è¯¯æ ‡ç­¾æ—¶ï¼Œæ¨¡åž‹å¯èƒ½ä¼šè¿‡äºŽå…³æ³¨è¿™äº›å¼‚å¸¸æ ·æœ¬ï¼Œä»Žè€Œå¯¼è‡´æ¬ æ‹Ÿåˆ è§£å†³æ–¹æ¡ˆ ç‰¹å¾å·¥ç¨‹: æ¬ æ‹Ÿåˆæ˜¯ç”±äºŽå­¦ä¹ ä¸è¶³ï¼Œå¯ä»¥è€ƒè™‘æ·»åŠ ç‰¹å¾ï¼Œä»Žæ•°æ®ä¸­æŒ–æŽ˜æ›´å¤šçš„ç‰¹å¾ï¼Œæœ‰æ—¶å€™è¿˜éœ€è¦å¯¹ç‰¹å¾è¿›è¡Œå˜æ¢ï¼Œä½¿ç”¨ç»„åˆç‰¹å¾å’Œé«˜æ¬¡ç‰¹å¾ æ›´å¼ºçš„æ¨¡åž‹: æ¨¡åž‹ç®€å•ä¹Ÿä¼šå¯¼è‡´æ¬ æ‹Ÿåˆï¼Œå¦‚çº¿æ€§æ¨¡åž‹åªèƒ½æ‹Ÿåˆä¸€æ¬¡å‡½æ•°çš„æ•°æ®ï¼Œå°è¯•ä½¿ç”¨æ›´é«˜çº§çš„æ¨¡åž‹æœ‰åŠ©äºŽè§£å†³æ¬ æ‹Ÿåˆ è°ƒæ•´è¶…å‚æ•°: è°ƒæ•´æ¨¡åž‹çš„è¶…å‚æ•°ï¼Œå¦‚å­¦ä¹ çŽ‡ã€æ­£åˆ™åŒ–ç³»æ•°ç­‰ï¼Œä»¥èŽ·å¾—æ›´å¥½çš„æ¨¡åž‹æ‹Ÿåˆæ•ˆæžœ æ ¸å¿ƒç½‘ç»œå±‚ å…¨è¿žæŽ¥å±‚ ç­‰å¾…... Convå·ç§¯æ“ä½œ ä¸€æ–‡è¯¦è§£å„ç§å·ç§¯æ“ä½œ pytorchä¸­å·ç§¯ç½‘ç»œçš„å‡ ç§å·ç§¯å’Œæ± åŒ– pytorchå®˜ç½‘å…³äºŽcnnçš„è¯´æ˜Ž å·ç§¯æ“ä½œæ˜¯ç¥žç»ç½‘ç»œä¸­å¸¸ç”¨çš„æ“ä½œä¹‹ä¸€ï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒå¤„ç†å’Œè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­ å·ç§¯æ“ä½œé€šè¿‡å°†è¾“å…¥æ•°æ®ä¸Žå·ç§¯æ ¸(ä¹Ÿç§°ä¸ºæ»¤æ³¢å™¨)è¿›è¡Œé€å…ƒç´ ç›¸ä¹˜ï¼Œå¹¶å°†ç»“æžœè¿›è¡Œæ±‚å’Œï¼Œä»Žè€Œäº§ç”Ÿè¾“å‡ºç‰¹å¾å›¾ åœ¨å·ç§¯ç¥žç»ç½‘ç»œ(Convolutional Neural Networkï¼ŒCNN)ä¸­ï¼Œå·ç§¯æ“ä½œç”¨äºŽæå–è¾“å…¥æ•°æ®ä¸­çš„å±€éƒ¨ç‰¹å¾ï¼Œå®ƒåˆ©ç”¨äº†ç‰¹å¾çš„å±€éƒ¨ç›¸å…³æ€§å’Œå¹³ç§»ä¸å˜æ€§ å±€éƒ¨ç›¸å…³æ€§: å±€éƒ¨ç›¸å…³æ€§æŒ‡çš„æ˜¯æ¯ä¸ªç¥žç»å…ƒåªä¸Žè¾“å…¥æ•°æ®çš„ä¸€å°å—åŒºåŸŸè¿žæŽ¥ï¼Œå¯ä»¥æ•æ‰åˆ°è¾“å…¥æ•°æ®çš„å±€éƒ¨ç‰¹å¾ï¼Œå‡å°‘äº†å‚æ•°æ•°é‡ï¼Œé™ä½Žäº†è®¡ç®—å¤æ‚åº¦ å¹³ç§»ä¸å˜æ€§: å¹³ç§»ä¸å˜æ€§æŒ‡çš„æ˜¯å®ƒå¯¹è¾“å…¥æ•°æ®çš„å¹³ç§»å…·æœ‰ä¸å˜æ€§ï¼Œå·ç§¯å±‚å¯ä»¥é€šè¿‡å…±äº«æƒé‡å’Œå±€éƒ¨è¿žæŽ¥çš„æ–¹å¼æ¥æå–ç‰¹å¾ï¼Œä»Žè€Œä½¿å¾—å¯¹äºŽä¸åŒä½ç½®çš„ç‰©ä½“èƒ½å¤Ÿäº§ç”Ÿç›¸ä¼¼çš„ç‰¹å¾è¡¨ç¤º å·ç§¯è¾“å‡ºå¤§å°è®¡ç®—å…¬å¼ L_{out} = \\lfloor \\frac {L_{in} + 2 \\times padding - dilation \\times (kernel\\_size-1) -1}{stride}+1 \\rfloor å…¶ä¸­L_{in}è¡¨ç¤ºè¾“å…¥çš„ç‰¹å¾å¤§å°ï¼Œpaddingæ˜¯å¡«å……ï¼Œkernel\\_sizeæ˜¯å·ç§¯æ ¸å¤§å°ï¼Œstrideæ˜¯æ­¥é•¿ ä¸€ç»´å·ç§¯åœ¨çº¿å¯è§†åŒ– äºŒç»´å·ç§¯åœ¨çº¿å¯è§†åŒ– æ™®é€šå·ç§¯ æ·±åº¦å­¦ä¹ ä¸­å·ç§¯çš„æ¦‚å¿µä¸Žä¿¡å·å¤„ç†é¢†åŸŸçš„å·ç§¯ç›¸ä¼¼(åªæ˜¯æ·±åº¦å­¦ä¹ çš„å·ç§¯åœ¨è¿ç®—è¿‡ç¨‹ä¸­çš„æ»¤æ³¢å™¨ä¸ç»è¿‡ç¿»è½¬)ï¼Œå·ç§¯æ ¸ä»¥ä¸€å®šçš„æ­¥é•¿åœ¨è¾“å…¥å›¾ç‰‡ä¸Šæ»‘åŠ¨ï¼Œæ¯ä¸€æ­¥éƒ½å°†å¯¹åº”å…ƒç´ ç›¸ä¹˜åŽæ±‚å’Œçš„è¿‡ç¨‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º å·ç§¯æ ¸å¤§å°(kernel_size) å·ç§¯æ ¸å¤§å°å®šä¹‰äº†å·ç§¯çš„è§†å›¾ï¼Œæ ¹æ®å·ç§¯æ ¸çš„å¤§å°ï¼Œå¸¸è§çš„å·ç§¯å°ºå¯¸æœ‰1Ã—1å·ç§¯ã€3Ã—3 å·ç§¯ã€5Ã—5å·ç§¯ã€7Ã—7å·ç§¯ç­‰ 1 \\times 1å·ç§¯ï¼šé€šå¸¸ç”¨äºŽè¾“å‡ºç»´åº¦çš„å‡ç»´æˆ–é™ç»´ã€‚è‹¥ç‰¹å¾å›¾æ˜¯å°ºå¯¸æ˜¯ H \\times W \\times Dï¼Œå·ç§¯æ ¸å°ºå¯¸æ˜¯1 \\times 1 \\times Dï¼Œè¾“å‡ºé€šé“å°ºå¯¸æ˜¯H \\times W \\times 1ã€‚å½“æˆ‘ä»¬å°†Næ¬¡1 \\times 1å·ç§¯ç»“æžœè¿žæŽ¥åœ¨ä¸€èµ·æ—¶ï¼Œå¯ä»¥å¾—åˆ° H \\times W \\times Nçš„è¾“å‡ºï¼Œä»Žè€Œå®žçŽ°å‡ç»´æˆ–é™ç»´çš„åŠŸèƒ½ 3 \\times 3å·ç§¯ï¼šç”±äºŽå¤§å°ºå¯¸çš„å·ç§¯æ ¸çš„å‚æ•°é‡è¾ƒå¤§ï¼Œç ”ç©¶äººå‘˜å‘çŽ°ä¸¤ä¸ª 3 \\times 3å·ç§¯çš„å †å ï¼Œæ„Ÿå—é‡Žç­‰åŒäºŽä¸€ä¸ª 5 \\times 5 å·ç§¯ï¼Œä½†æ˜¯å‚æ•°é‡å´å‡å°‘äº†ï¼Œæ‰€ä»¥ä»ŽVGGçš„æ—¶ä»£å¼€å§‹ï¼ŒåŸºæœ¬åŽé¢çš„ç½‘ç»œéƒ½ç¦»ä¸å¼€å®ƒçš„èº«å½± 5 \\times 5å·ç§¯ï¼šå·ç§¯æ ¸è¶Šå¤§ï¼Œæ„Ÿå—é‡Žè¶Šå¤§ï¼Œçœ‹åˆ°çš„å›¾ç‰‡ä¿¡æ¯è¶Šå¤šï¼Œæ‰€èŽ·å¾—çš„å…¨å±€ç‰¹å¾è¶Šå¥½ã€‚ä½†æ˜¯è¿™æ ·å‚æ•°å¾ˆå¤šï¼Œä¼šå¯¼è‡´è®¡ç®—é‡æš´å¢žï¼Œå±‚æ¬¡å°‘ä¸åˆ©äºŽæ¨¡åž‹æ·±åº¦çš„å¢žåŠ ï¼Œè¡¨è¾¾èƒ½åŠ›å¼±ã€‚æ‰€ä»¥æˆ‘ä»¬ä¼šçœ‹åˆ°åœ¨æ—©æœŸçš„ç½‘ç»œä¼šå‡ºçŽ°å¤§å·ç§¯æ ¸çš„å †å ï¼Œæˆ–è€…å½“ä¸‹ç ”ç©¶äººå‘˜ä¸€èˆ¬å°†å¤§å°ºå¯¸å·ç§¯æ”¾åœ¨å¯¹è¾“å…¥å›¾ç‰‡çš„åˆå§‹æ“ä½œå¤„(7 \\times 7åŒç†) æ­¥é•¿(stride) æ ¸çš„æ­¥é•¿å®šä¹‰äº†å·ç§¯æ ¸åœ¨å›¾åƒä¸­ç§»åŠ¨çš„æ¯ä¸€æ­¥çš„å¤§å°ï¼Œä»£è¡¨æå–çš„ç²¾åº¦ï¼Œé€šå¸¸ä¸º1ï¼Œä¹Ÿå¯ä»¥ç”¨å¤§äºŽç­‰äºŽ2çš„æ­¥é•¿ï¼Œå¯¹å›¾åƒè¿›è¡Œä¸‹é‡‡æ ·ï¼Œæ›¿ä»£æ± åŒ–æ“ä½œ å¡«å……(padding) å·ç§¯æ ¸ä¸Žè¾“å…¥å›¾åƒçš„å°ºå¯¸ä¸åŒ¹é…ï¼Œè¿™æ—¶å°±éœ€è¦å¡«å……å›¾åƒï¼Œä¾‹å¦‚è¾“å…¥å›¾ç‰‡å°ºå¯¸ä¸º5 \\times 5ï¼Œå·ç§¯æ ¸çš„å¤§å°ä¸º3 \\times 3 å¦‚æžœä¸è¿›è¡Œå¡«å……ï¼Œæ­¥é•¿ä¸º1çš„è¯ï¼Œå½“å·ç§¯æ ¸æ²¿ç€å›¾ç‰‡æ»‘åŠ¨åŽåªèƒ½æ»‘åŠ¨å‡ºä¸€ä¸ª3 \\times 3çš„å›¾ç‰‡å‡ºæ¥ï¼Œå·ç§¯åŽçš„å›¾ç‰‡è¶Šå˜è¶Šå°ï¼Œä¸”è¾“å…¥å›¾ç‰‡è¾¹ç¼˜åƒç´ åªè¢«è®¡ç®—è¿‡ä¸€æ¬¡ è€Œä¸­é—´åƒç´ ä¼šè¢«å·ç§¯è®¡ç®—å¤šæ¬¡ï¼Œæ„å‘³ç€ä¸¢å¤±å›¾åƒè§’è½ä¿¡æ¯ï¼Œæ‰€ä»¥ä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œéœ€è¦å…ˆå¯¹åŽŸå§‹å›¾ç‰‡åšè¾¹ç•Œå¡«å……å¤„ç† 3Då·ç§¯ 3Då·ç§¯çš„å·ç§¯æ ¸å¯ä»¥åœ¨è¾“å…¥å›¾åƒçš„3ä¸ªæ–¹å‘ï¼Œå³å›¾åƒçš„é«˜åº¦ï¼Œå®½åº¦ï¼Œæ·±åº¦ä¸Šç§»åŠ¨ã€‚å¹¶ä¸ŽäºŒç»´å·ç§¯ç±»ä¼¼ï¼Œåœ¨æ¯ä¸ªä½ç½®å„å…ƒç´ å…ˆç›¸ä¹˜å†ç›¸åŠ ï¼Œæœ€åŽè¾“å‡ºä¸€ä¸ª3Dæ•°æ® å·ç§¯ç‰¹æ€§ï¼šç›¸æ¯”äºŽæ™®é€šçš„äºŒç»´å·ç§¯ï¼Œå¤šäº†ä¸€ä¸ªç»´åº¦(æ·±åº¦)ï¼Œå¯ä»¥æŠŠè¿™ä¸ªæ·±åº¦å½“ä½œè§†é¢‘ä¸­çš„è¿žç»­å¸§ï¼Œæˆ–è€…æ˜¯ç«‹ä½“å›¾åƒä¸­çš„ä¸åŒçš„åˆ‡ç‰‡ã€‚ä½†æ˜¯å…¶å‚æ•°é‡è¾ƒå¤§ï¼Œä¼šå»¶ç¼“ç½‘ç»œçš„æŽ¨ç†é€Ÿåº¦ åº”ç”¨åœºæ™¯ï¼š3Då·ç§¯å¸¸åº”ç”¨åœ¨è§†é¢‘åˆ†ç±»ã€åŒ»å­¦å½±åƒã€ç‚¹äº‘å¤„ç†ç­‰é¢†åŸŸã€‚æ¯”å¦‚ç»å…¸çš„VoxelNetç½‘ç»œå°±é‡‡ç”¨3D CNNæå–ç‚¹äº‘çš„ä½“ç´ ç‰¹å¾åšç›®æ ‡æ£€æµ‹ä»»åŠ¡ æ‰©å¼ å·ç§¯(è†¨èƒ€ã€ç©ºæ´ž) æ‰©å¼ å·ç§¯(Dilated Convolution)ï¼Œä¹Ÿç§°ä¸ºç©ºæ´žå·ç§¯(Atrous Convolution)ï¼Œæœ€æ—©æ˜¯ç”±DeepLabå›¢é˜Ÿæå‡ºçš„ DeepLabæ˜¯ç”±Google Brainå¼€å‘çš„ä¸€ç§ç”¨äºŽå›¾åƒè¯­ä¹‰åˆ†å‰²çš„æ·±åº¦å­¦ä¹ æž¶æž„ï¼ŒéšåŽï¼Œæ‰©å¼ å·ç§¯è¢«å¹¿æ³›åº”ç”¨äºŽå…¶ä»–è®¡ç®—æœºè§†è§‰ä»»åŠ¡ï¼Œå¦‚å›¾åƒè¶…åˆ†è¾¨çŽ‡ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒç”Ÿæˆå’Œå›¾åƒä¿®å¤ç­‰ æ‰©å¼ å·ç§¯çš„ä¸»è¦ç›®çš„æ˜¯å¢žåŠ å·ç§¯æ“ä½œçš„æ„Ÿå—é‡Žï¼Œä»Žè€Œæ•æ‰æ›´å¤§èŒƒå›´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ ä¼ ç»Ÿçš„å·ç§¯æ“ä½œå…·æœ‰å›ºå®šçš„å·ç§¯æ ¸å°ºå¯¸å’Œæ­¥å¹…ï¼Œé™åˆ¶äº†æ„Ÿå—é‡Žçš„å¤§å°ã€‚è€Œæ‰©å¼ å·ç§¯é€šè¿‡åœ¨å·ç§¯æ ¸çš„å…ƒç´ ä¹‹é—´å¼•å…¥å›ºå®šçš„é—´éš”(æ‰©å¼ çŽ‡æˆ–ç©ºæ´žçŽ‡)ï¼Œä½¿å¾—å·ç§¯æ ¸åœ¨è¾“å…¥ç‰¹å¾å›¾ä¸Šçš„é‡‡æ ·é—´éš”æ‰©å¤§ï¼Œä»Žè€Œå®žçŽ°æ„Ÿå—é‡Žçš„æ‰©å¤§ æ‰©å¼ å·ç§¯æœ€åˆç”¨äºŽå›¾åƒè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ï¼Œæ—¨åœ¨æé«˜åˆ†å‰²ç»“æžœçš„ç²¾åº¦ã€‚è¯­ä¹‰åˆ†å‰²éœ€è¦å°†å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ åˆ†ç±»åˆ°ä¸åŒçš„è¯­ä¹‰ç±»åˆ«ä¸­ï¼Œå› æ­¤éœ€è¦å……åˆ†è€ƒè™‘åƒç´ å‘¨å›´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ é€šè¿‡ä½¿ç”¨æ‰©å¼ å·ç§¯ï¼ŒDeepLabå›¢é˜Ÿå¯ä»¥æ›´å¥½åœ°æ•æ‰åƒç´ ä¹‹é—´çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼Œæé«˜åˆ†å‰²æ¨¡åž‹å¯¹ç»†ç²’åº¦è¾¹ç•Œå’Œå°å°ºå¯¸ç‰©ä½“çš„æ„ŸçŸ¥èƒ½åŠ› å®ƒåœ¨è¿™äº›ä»»åŠ¡ä¸­çš„åº”ç”¨ä¸»è¦æ˜¯ä¸ºäº†å¢žåŠ æ„Ÿå—é‡Žã€æé«˜åˆ†è¾¨çŽ‡å’Œå®žçŽ°å¤šå°ºåº¦ç‰¹å¾èžåˆï¼Œä»¥å¢žå¼ºæ¨¡åž‹çš„æ„ŸçŸ¥èƒ½åŠ›å’Œè¡¨è¾¾èƒ½åŠ› æ‰©å¼ çš„å¥½å¤„ï¼šä½¿å¾—åœ¨ç›¸åŒçš„è®¡ç®—æˆæœ¬ä¸‹ï¼Œé¿å…å› æ± åŒ–æŸå¤±ä¿¡æ¯è€Œå¢žå¤§äº†æ„Ÿå—é‡Ž è†¨èƒ€å·ç§¯ä½¿ç”¨çš„æ–¹æ³• è¿žç»­ä½¿ç”¨å¤šä¸ªè†¨èƒ€å·ç§¯æ—¶åº”è¯¥å¦‚ä½•è®¾è®¡å®ƒçš„è†¨èƒ€ç³»æ•° å°†è†¨èƒ€ç³»æ•°è®¾ç½®ä¸ºé”¯é½¿å½¢çŠ¶ï¼Œä¾‹å¦‚[1,2,3,1,2,3] å…¬çº¦æ•°ä¸èƒ½å¤§äºŽ1ï¼Œæ¯”å¦‚å¯ä»¥æ˜¯[1,2,3]ï¼Œè€Œä¸æ˜¯[2,4,8] åˆ†ç»„å·ç§¯ åˆ†ç»„å·ç§¯ï¼ˆGroup Convolutionï¼‰ Depthwiseå·ç§¯ä¸ŽPointwiseå·ç§¯ åˆ†ç»„å·ç§¯æœ€å¼€å§‹è¢«ä½¿ç”¨åœ¨ç»å…¸å…¥é—¨å·ç§¯ç¥žç»ç½‘ç»œAlexNetä¸Šï¼Œç”¨äºŽè§£å†³æ˜¾å­˜ä¸è¶³çš„é—®é¢˜ã€‚åœ¨çŽ°åœ¨è¢«å¹¿æ³›ç”¨äºŽå„ç§è½»é‡åŒ–æ¨¡åž‹ä¸­ï¼Œç”¨äºŽå‡å°‘è¿ç®—é‡å’Œå‚æ•°é‡ï¼Œå…¶ä¸­åº”ç”¨æœ€å¹¿çš„å°±æ˜¯æ·±åº¦å¯åˆ†ç¦»å·ç§¯(Depthwise Separable Convolution) Depthwiseå·ç§¯(æ·±åº¦å·ç§¯)å’ŒPointwiseå·ç§¯(é€ç‚¹å·ç§¯) Depthwiseå·ç§¯(æ·±åº¦å·ç§¯)å’ŒPointwiseå·ç§¯(é€ç‚¹å·ç§¯)æ˜¯MobileNetç­‰è½»é‡çº§ç¥žç»ç½‘ç»œä¸­å¸¸ç”¨çš„å·ç§¯æ“ä½œå·ç§¯ï¼Œåˆèµ·æ¥è¢«ç§°ä½œDepthwise Separable Convolution(å‚è§Googleçš„Xception)ï¼Œè¯¥ç»“æž„å’Œå¸¸è§„å·ç§¯æ“ä½œç±»ä¼¼ï¼Œå¯ç”¨æ¥æå–ç‰¹å¾ï¼Œä½†ç›¸æ¯”äºŽå¸¸è§„å·ç§¯æ“ä½œï¼Œå…¶å‚æ•°é‡å’Œè¿ç®—æˆæœ¬è¾ƒä½Žã€‚æ‰€ä»¥åœ¨ä¸€äº›è½»é‡çº§ç½‘ç»œä¸­ä¼šç¢°åˆ°è¿™ç§ç»“æž„å¦‚MobileNet å¯ä»¥å°†æ·±åº¦å·ç§¯å’Œé€ç‚¹å·ç§¯ç»“åˆä½¿ç”¨ï¼Œä½œä¸ºåˆ†ç»„å·ç§¯çš„ä¸€ç§å®žçŽ°æ–¹å¼ï¼Œä»¥æé«˜æ¨¡åž‹çš„è®¡ç®—æ•ˆçŽ‡å’Œå‚æ•°æ•ˆçŽ‡ æ·±åº¦å·ç§¯ç”¨äºŽæ•æ‰ç©ºé—´ä¸Šçš„ç›¸å…³ä¿¡æ¯ï¼Œé€ç‚¹å·ç§¯ç”¨äºŽæ•´åˆå’Œè½¬æ¢é€šé“é—´çš„ç‰¹å¾å…³ç³»ã€‚è¿™æ ·çš„ç»„åˆå¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šå‡å°‘è®¡ç®—é‡ï¼Œå¹¶ä¿æŒæ¨¡åž‹çš„è¡¨è¾¾èƒ½åŠ› ä¼ ç»Ÿå’Œåˆ†ç»„å·ç§¯çš„æ¯”è¾ƒ åœ¨ä¼ ç»Ÿçš„å·ç§¯æ“ä½œä¸­ï¼Œè¾“å…¥ç‰¹å¾å›¾çš„æ¯ä¸ªé€šé“éƒ½ä¸Žå·ç§¯æ ¸çš„æ¯ä¸ªé€šé“è¿›è¡Œå·ç§¯è¿ç®—ï¼Œè¾“å‡ºçš„ç‰¹å¾å›¾æ˜¯æ‰€æœ‰é€šé“çš„å åŠ  åœ¨åˆ†ç»„å·ç§¯ä¸­ï¼Œå°†è¾“å…¥ç‰¹å¾å›¾å’Œå·ç§¯æ ¸åˆ†æˆå¤šä¸ªç»„ï¼Œæ¯ä¸ªç»„ä¸­çš„é€šé“è¿›è¡Œç‹¬ç«‹çš„å·ç§¯è¿ç®—ï¼Œæœ€åŽå°†å„ç»„çš„è¾“å‡ºç‰¹å¾å›¾è¿›è¡Œè¿žæŽ¥ï¼Œå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºç»“æžœ å·¦å›¾æ˜¯æ™®é€šçš„å·ç§¯ï¼Œå³å›¾æ˜¯åˆ†ç»„å·ç§¯ å¯¹äºŽå°ºå¯¸ä¸ºH_{1} \\times W_{1} \\times C_{1}çš„è¾“å…¥çŸ©é˜µï¼Œå½“æ ‡å‡†å·ç§¯æ ¸çš„å°ºå¯¸ä¸ºh_{1} \\times w_{1} \\times C_{1}ï¼Œå…±æœ‰C_{2}ä¸ªæ ‡å‡†å·ç§¯æ ¸æ—¶ï¼Œæ ‡å‡†å·ç§¯ä¼šå¯¹å®Œæ•´çš„è¾“å…¥æ•°æ®è¿›è¡Œè¿ç®—ï¼Œæœ€ç»ˆå¾—åˆ°çš„è¾“å‡ºçŸ©é˜µå°ºå¯¸ä¸º H_{2} \\times W_{2} \\times C_{2}ã€‚è¿™é‡Œæˆ‘ä»¬å‡è®¾å·ç§¯è¿ç®—å‰åŽçš„ç‰¹å¾å›¾å°ºå¯¸ä¿æŒä¸å˜ï¼Œåˆ™ä¸Šè¿°è¿‡ç¨‹å¯ä»¥å±•ç¤ºä¸ºå·¦å›¾ åˆ†ç»„å·ç§¯ä¸­ï¼Œé€šè¿‡æŒ‡å®šç»„æ•°gæ¥ç¡®å®šåˆ†ç»„æ•°é‡ï¼Œå°†è¾“å…¥æ•°æ®åˆ†æˆgç»„ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™é‡Œçš„åˆ†ç»„æŒ‡çš„æ˜¯åœ¨æ·±åº¦ä¸Šè¿›è¡Œåˆ†ç»„ï¼Œè¾“å…¥çš„å®½å’Œé«˜ä¿æŒä¸å˜ï¼Œå³å°†æ¯\\frac{C_{1}}{g}ä¸ªé€šé“çš„æ•°æ®åˆ†ä¸ºä¸€ç»„ã€‚å› ä¸ºè¾“å…¥æ•°æ®å‘ç”Ÿäº†æ”¹å˜ï¼Œç›¸åº”çš„å·ç§¯æ ¸ä¹Ÿéœ€è¦è¿›è¡Œå¯¹åº”çš„å˜åŒ–ï¼Œå³æ¯ä¸ªå·ç§¯æ ¸çš„è¾“å…¥é€šé“æ•°ä¹Ÿå°±å˜ä¸ºäº†\\frac{C_{1}}{g}ï¼Œè€Œå·ç§¯æ ¸çš„å¤§å°æ˜¯ä¸éœ€è¦æ”¹å˜çš„ åŒæ—¶ï¼Œæ¯ç»„çš„å·ç§¯æ ¸ä¸ªæ•°ä¹Ÿç”±åŽŸæ¥çš„C_{2}å˜ä¸º\\frac{C_{2}}{g}ã€‚å¯¹äºŽæ¯ä¸ªç»„å†…çš„å·ç§¯è¿ç®—ï¼ŒåŒæ ·é‡‡ç”¨æ ‡å‡†å·ç§¯è¿ç®—çš„è®¡ç®—æ–¹å¼ï¼Œè¿™æ ·å°±å¯ä»¥å¾—åˆ°gç»„å°ºå¯¸ä¸ºH_{2} \\times W_{2} \\times \\frac{C_{2}}{g}çš„è¾“å‡ºçŸ©é˜µï¼Œæœ€ç»ˆå°†è¿™gç»„è¾“å‡ºçŸ©é˜µè¿›è¡Œæ‹¼æŽ¥å°±å¯ä»¥å¾—åˆ°æœ€ç»ˆçš„ç»“æžœã€‚è¿™æ ·æ‹¼æŽ¥å®ŒæˆåŽï¼Œæœ€ç»ˆçš„è¾“å‡ºå°ºå¯¸å°±å¯ä»¥ä¿æŒä¸å˜ï¼Œä»ç„¶æ˜¯H_{2} \\times W_{2} \\times C_{2}ã€‚åˆ†ç»„å·ç§¯çš„è¿ç®—è¿‡ç¨‹å¦‚å³å›¾æ‰€ç¤º åˆ†ç»„å·ç§¯çš„ä¸»è¦ä¼˜ç‚¹æ˜¯å‡å°‘äº†è®¡ç®—é‡å’Œå‚æ•°æ•°é‡ï¼Œå› ä¸ºæ¯ä¸ªç»„å†…çš„å·ç§¯æ“ä½œæ˜¯ç‹¬ç«‹è¿›è¡Œçš„ï¼Œç›¸å½“äºŽå°†æ•´ä¸ªå·ç§¯æ“ä½œæ‹†åˆ†æˆäº†å¤šä¸ªè¾ƒå°çš„å·ç§¯æ“ä½œ è¿™åœ¨ä¸€äº›è®¡ç®—èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œå¦‚ç§»åŠ¨è®¾å¤‡æˆ–åµŒå…¥å¼ç³»ç»Ÿä¸­ï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘è®¡ç®—æˆæœ¬ï¼Œæé«˜æ¨¡åž‹çš„é€Ÿåº¦å’Œæ•ˆçŽ‡ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåˆ†ç»„å·ç§¯çš„ä½¿ç”¨éœ€è¦åœ¨è€ƒè™‘è®¡ç®—æ•ˆçŽ‡çš„åŒæ—¶æƒè¡¡æ¨¡åž‹æ€§èƒ½ã€‚åˆ†ç»„å·ç§¯å¯èƒ½ä¼šæŸå¤±ä¸€å®šçš„è¡¨ç¤ºèƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¯¹äºŽé‚£äº›å…·æœ‰è·¨é€šé“ç›¸å…³æ€§çš„ç‰¹å¾ å› æ­¤ï¼Œåœ¨è®¾è®¡ç½‘ç»œç»“æž„æ—¶ï¼Œéœ€è¦æ ¹æ®ä»»åŠ¡çš„éœ€æ±‚å’Œèµ„æºçš„é™åˆ¶æ¥é€‰æ‹©åˆé€‚çš„åˆ†ç»„æ•°å’Œç»„å†…é€šé“æ•°ï¼Œä»¥åœ¨æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ç‚¹ åå·ç§¯(è½¬ç½®) UNet Architecture Breakdown Pytorch è½¬ç½®å·ç§¯ è½¬ç½®å·ç§¯(Transposed Convolution)ï¼Œä¹Ÿç§°ä¸ºåå·ç§¯(Deconvolution)ï¼Œæ˜¯å·ç§¯ç¥žç»ç½‘ç»œä¸­å¸¸ç”¨çš„ä¸€ç§æ“ä½œ å®ƒä¸Žæ ‡å‡†å·ç§¯æ“ä½œç›¸åï¼Œç”¨äºŽå°†ä½Žç»´ç‰¹å¾æ˜ å°„æ‰©å±•ä¸ºé«˜ç»´ç‰¹å¾æ˜ å°„ åœ¨ä¼ ç»Ÿçš„å·ç§¯æ“ä½œä¸­ï¼Œè¾“å…¥ç‰¹å¾å›¾é€šè¿‡å·ç§¯æ ¸è¿›è¡Œå·ç§¯è¿ç®—ï¼Œå¾—åˆ°è¾“å‡ºç‰¹å¾å›¾ã€‚è€Œè½¬ç½®å·ç§¯åˆ™æ˜¯é€šè¿‡å¯¹è¾“å‡ºç‰¹å¾å›¾åº”ç”¨åå‘å·ç§¯æ“ä½œï¼Œä»¥é‡å»ºé«˜ç»´ç‰¹å¾æ˜ å°„ è½¬ç½®å·ç§¯å¸¸ç”¨äºŽä»¥ä¸‹å‡ ä¸ªä»»åŠ¡å’Œåº”ç”¨ä¸­ï¼š å›¾åƒç”Ÿæˆï¼šè½¬ç½®å·ç§¯è¢«å¹¿æ³›åº”ç”¨äºŽå›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œå¦‚å›¾åƒç”Ÿæˆã€å›¾åƒä¿®å¤ç­‰ã€‚é€šè¿‡å°†ä½Žç»´ç‰¹å¾æ˜ å°„è½¬æ¢ä¸ºé«˜ç»´ç‰¹å¾æ˜ å°„ï¼Œå¯ä»¥ç”Ÿæˆå…·æœ‰æ›´é«˜åˆ†è¾¨çŽ‡å’Œæ›´å¤šç»†èŠ‚çš„å›¾åƒ å›¾åƒåˆ†å‰²ï¼šåœ¨å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œè½¬ç½®å·ç§¯å¸¸ç”¨äºŽå°†ä½Žåˆ†è¾¨çŽ‡çš„è¯­ä¹‰ç‰¹å¾æ˜ å°„æ¢å¤åˆ°ä¸Žè¾“å…¥å›¾åƒç›¸åŒçš„å°ºå¯¸ï¼Œä»¥èŽ·å¾—åƒç´ çº§åˆ«çš„åˆ†å‰²ç»“æžœ ç›®æ ‡æ£€æµ‹ï¼šè½¬ç½®å·ç§¯åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­è¢«ç”¨äºŽç”Ÿæˆé«˜åˆ†è¾¨çŽ‡çš„ç‰¹å¾æ˜ å°„ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°å®šä½å’Œè¯†åˆ«ç›®æ ‡ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè½¬ç½®å·ç§¯çš„åç§°å¯èƒ½ä¼šå¼•èµ·ä¸€äº›è¯¯è§£ï¼Œå› ä¸ºå®ƒå®žé™…ä¸Šå¹¶ä¸æ˜¯çœŸæ­£çš„å·ç§¯æ“ä½œçš„é€†è¿ç®—ã€‚è½¬ç½®å·ç§¯çš„åç§°èµ·æºäºŽå…¶ä¸Žå·ç§¯æ“ä½œçš„ç›¸ä¼¼æ€§ï¼Œä½†å…¶è®¡ç®—è¿‡ç¨‹ä¸Žå·ç§¯å¹¶ä¸å®Œå…¨ç›¸åŒ åœ¨ç¥žç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦ä¸Šé‡‡æ ·æ¥æé«˜ä½Žåˆ†è¾¨çŽ‡å›¾ç‰‡çš„åˆ†è¾¨çŽ‡ã€‚è€Œè½¬ç½®å·ç§¯å°±å¯ä»¥ä½œä¸ºä¸€ç§é€šè¿‡å·ç§¯å­¦ä¹ å‚æ•°ï¼Œä»Žè€ŒèŽ·å¾—æœ€ä¼˜ä¸Šé‡‡æ ·çš„æ–¹æ³• å¯è§†åŒ–è§£é‡Š ä¸‹å›¾æ˜¯ä¸€ä¸ª4 \\times 4çš„è¾“å…¥çŸ©é˜µï¼Œç”¨3 \\times 3çš„å·ç§¯æ ¸è¿›è¡Œæ²¡æœ‰å¡«å……ï¼Œæ­¥é•¿ä¸º1çš„å·ç§¯æ“ä½œï¼Œç»“æžœæ˜¯ä¸€ä¸ª2 \\times 2çš„çŸ©é˜µ æˆ‘ä»¬å°†3 \\times 3çš„å·ç§¯æ ¸é‡æŽ’ä¸º4 \\times 16çš„å½¢å¼(ä¸‹å›¾ç¬¬ä¸€é¡¹)ï¼ŒåŒæ—¶å°†4 \\times 4çš„è¾“å…¥çŸ©é˜µå±•å¼€ä¸º16 \\times 1çš„åˆ—å‘é‡çš„å½¢å¼(ä¸‹å›¾ç¬¬äºŒé¡¹)ã€‚é€šè¿‡çŸ©é˜µä¹˜æ³•å¾—åˆ°ä¸€ä¸ª4 \\times 1çš„åˆ—å‘é‡ï¼Œå¯ä»¥çœ‹å‡ºè¿™ä¸ªåˆ—å‘é‡æ­£æ˜¯ç”±ä¸Šå›¾çš„2 \\times 2å·ç§¯è¾“å‡ºçŸ©é˜µå±•å¼€å¾—åˆ°çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬å¯ä»¥å°†å·ç§¯æ“ä½œå†™æˆçŸ©é˜µä¹˜æ³•è¿ç®— é€šè¿‡è¿™æ ·çš„æ“ä½œï¼Œå¯ä»¥æŠŠ16(4 \\times 4çš„çŸ©é˜µ)ä¸ªå€¼æ˜ å°„ä¸º4(2 \\times 2çš„çŸ©é˜µ)ä¸ªå€¼ï¼Œé‚£ä¹ˆå°†è¿™ä¸ªæ“ä½œåè¿‡æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠ4(2 \\times 2çš„çŸ©é˜µ)ä¸ªå€¼æ˜ å°„ä¸º16(4 \\times 4çš„çŸ©é˜µ) æœ€åŽå°†è¾“å‡ºçŸ©é˜µå¯ä»¥reshapeä¸º4 \\times 4çš„å½¢å¼ å·ç§¯ç‰¹å¾ï¼šè™½ç„¶è½¬ç½®å·ç§¯èƒ½å¤Ÿé€šè¿‡å­¦ä¹ å‚æ•°è¿›è¡Œæœ€ä¼˜çš„ä¸Šé‡‡æ ·ï¼Œä½†æ˜¯å®žé™…åº”ç”¨ä¸­ï¼Œç ”ç©¶äººå‘˜å¾€å¾€æ›´åŠ å€¾å‘äºŽä½¿ç”¨çº¿æ€§æ’å€¼çš„æ–¹å¼åšä¸Šé‡‡æ ·ï¼Œæ•ˆçŽ‡æ›´é«˜ å¯åˆ†ç¦»å·ç§¯ ç©ºé—´å¯åˆ†ç¦»å·ç§¯ ç©ºé—´å¯åˆ†ç¦»å·ç§¯ä¸»è¦å¤„ç†å›¾åƒå’Œå·ç§¯æ ¸çš„ç©ºé—´ç»´åº¦ï¼šå®½åº¦å’Œé«˜åº¦ å°†ä¸€ä¸ªå·ç§¯æ ¸åˆ’åˆ†ä¸ºä¸¤ä¸ªè¾ƒå°çš„å·ç§¯æ ¸ï¼Œå¦‚å°†3 \\times 3çš„å·ç§¯æ ¸åˆ†ä¸º3 \\times 1å’Œ1 \\times 3çš„å·ç§¯æ ¸ï¼Œå†ä¾æ¬¡è¿›è¡Œå·ç§¯ å¦‚æ­¤ï¼Œåˆ™å¯ä»¥å°†ä¸€æ¬¡å·ç§¯çš„9æ¬¡ä¹˜æ³•å‡å°‘ä¸ºä¸¤æ¬¡å·ç§¯å…±6æ¬¡ä¹˜æ³•ï¼Œå‡å°‘è®¡ç®—é‡ï¼Œä»Žè€ŒåŠ å¿«ç½‘ç»œè¿è¡Œé€Ÿåº¦ \\left[\\begin{array}{lll}-1 & 0 & 1 \\\\ -2 & 0 & 2 \\\\ -1 & 0 & 1\\end{array}\\right]=\\left[\\begin{array}{l}1 \\\\ 2 \\\\ 1\\end{array}\\right] \\times\\left[\\begin{array}{lll}-1 & 0 & 1\\end{array}\\right] æ·±åº¦å¯åˆ†ç¦»å·ç§¯ æ·±åº¦å¯åˆ†ç¦»å·ç§¯ä¸ä»…æ¶‰åŠç©ºé—´ç»´åº¦ï¼Œè¿˜å¯¹æ·±åº¦ç»´åº¦è¿›è¡Œå¤„ç†ã€‚å®ƒä¸»è¦åˆ†ä¸ºä¸¤ä¸ªè¿‡ç¨‹ï¼Œåˆ†åˆ«ä¸ºé€é€šé“å·ç§¯å’Œé€ç‚¹å·ç§¯ é€é€šé“å·ç§¯: é€é€šé“å·ç§¯çš„å·ç§¯æ ¸ä¸Žé€šé“æ˜¯ä¸€ä¸€å¯¹åº”çš„ï¼Œæ‰€ä»¥è¾“å‡ºçš„ç‰¹å¾å›¾ç‰‡çš„æ·±åº¦å’Œè¾“å…¥çš„æ·±åº¦å®Œå…¨ä¸€æ · é€ç‚¹å·ç§¯: é€ç‚¹å·ç§¯çš„è¿ç®—ä¸Žå¸¸è§„å·ç§¯è¿ç®—ç›¸ä¼¼ï¼Œå®ƒçš„å·ç§¯æ ¸çš„å°ºå¯¸ä¸º1 \\times 1 \\times Mï¼ŒMä¸ºä¸Šä¸€å±‚çš„æ·±åº¦ã€‚å®ƒæ˜¯å°†ä¸Šä¸€æ­¥çš„ç‰¹å¾å›¾åœ¨æ·±åº¦æ–¹å‘ä¸Šè¿›è¡ŒåŠ æƒç›¸åŠ ï¼Œç”Ÿæˆæ–°çš„ç‰¹å¾å›¾,æœ‰å‡ ä¸ªå·ç§¯æ ¸å°±æœ‰å‡ å±‚æ–°çš„ç‰¹å¾å›¾è¾“å‡º å·ç§¯ç‰¹æ€§ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„ä¼˜åŠ¿åœ¨äºŽéœ€è¦æå–çš„å±žæ€§è¶Šå¤šï¼Œå°±èƒ½å¤ŸèŠ‚çœè¶Šå¤šçš„å‚æ•°ï¼Œå‡å°‘è®¡ç®—é‡ã€‚æœ€æ—©å‡ºçŽ°åœ¨mobilenetä¸­ï¼Œä¹Ÿæ˜¯ç”¨äºŽè½»é‡åŒ–ç½‘ç»œçš„ç‰¹å¾æå–éƒ¨åˆ†ï¼Œä½¿åµŒå…¥å¼éƒ¨ç½²çš„ç¥žç»ç½‘ç»œæŽ¨ç†æ›´å¿«é€Ÿ ç›¸è¾ƒäºŽä¼ ç»Ÿçš„æ ‡å‡†å·ç§¯ï¼Œå®ƒåªéœ€è¦å¯¹æ¯ä¸ªé€šé“è¿›è¡Œå·ç§¯æ“ä½œï¼Œè€Œä¸æ˜¯å¯¹æ¯ä¸ªé€šé“å’Œæ¯ä¸ªä½ç½®éƒ½è¿›è¡Œå·ç§¯æ“ä½œã€‚å› æ­¤ï¼Œå®ƒèƒ½å¤Ÿåœ¨ä¿æŒæ¨¡åž‹æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘è®¡ç®—å¼€é”€ï¼Œç‰¹åˆ«é€‚ç”¨äºŽè½»é‡çº§æ¨¡åž‹å’Œè®¡ç®—èµ„æºå—é™çš„åœºæ™¯ å¯åˆ†ç¦»å·ç§¯å¸¸ç”¨äºŽç§»åŠ¨è®¾å¤‡ã€åµŒå…¥å¼è®¾å¤‡å’Œè®¡ç®—èµ„æºæœ‰é™çš„çŽ¯å¢ƒä¸­ï¼Œå¦‚ç§»åŠ¨ç«¯çš„å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡ é€šè¿‡é‡‡ç”¨å¯åˆ†ç¦»å·ç§¯ï¼Œå¯ä»¥å®žçŽ°è½»é‡çº§çš„æ¨¡åž‹ç»“æž„ï¼Œæé«˜æ¨¡åž‹çš„è®¡ç®—æ•ˆçŽ‡å’Œé€Ÿåº¦ï¼ŒåŒæ—¶é™ä½Žæ¨¡åž‹çš„å­˜å‚¨ç©ºé—´å’Œå†…å­˜æ¶ˆè€— å¯å˜å½¢å·ç§¯ Deformable Convolutional Networks 2017 å¯å˜å½¢å·ç§¯(Deformable Convolution)æ˜¯ä¸€ç§å…·æœ‰è‡ªé€‚åº”æ„Ÿå—é‡Žçš„å·ç§¯æ“ä½œï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å›¾åƒä¸­éžåˆšæ€§å½¢å˜çš„ç‰¹å¾ã€‚ä¸Žä¼ ç»Ÿçš„å·ç§¯æ“ä½œç›¸æ¯”ï¼Œå¯å˜å½¢å·ç§¯å¼•å…¥äº†å¯å­¦ä¹ çš„åç§»å‚æ•°ï¼Œç”¨äºŽè°ƒæ•´å·ç§¯æ ¸åœ¨è¾“å…¥ç‰¹å¾å›¾ä¸Šçš„é‡‡æ ·ä½ç½® åœ¨ä¼ ç»Ÿçš„å·ç§¯æ“ä½œä¸­ï¼Œå·ç§¯æ ¸çš„é‡‡æ ·ä½ç½®æ˜¯å›ºå®šçš„ï¼Œå¯¹è¾“å…¥ç‰¹å¾å›¾çš„ä¸åŒåŒºåŸŸåº”ç”¨ç›¸åŒçš„é‡‡æ ·æ¨¡å¼ã€‚è€Œå¯å˜å½¢å·ç§¯é€šè¿‡åœ¨æ¯ä¸ªä½ç½®å¼•å…¥åç§»å‚æ•°ï¼Œä½¿å¾—å·ç§¯æ ¸å¯ä»¥è‡ªé€‚åº”åœ°è°ƒæ•´é‡‡æ ·ä½ç½®ï¼Œä»Žè€Œé€‚åº”ä¸åŒåŒºåŸŸçš„éžåˆšæ€§å½¢å˜ æ€è·¯ å¯å˜å½¢å·ç§¯æ˜¯ä¸€ç§å·ç§¯æ ¸å†…éƒ¨ç‚¹æŒ‰ä¸è§„åˆ™çš„æ–¹å¼ç»„åˆï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º (a)æ™®é€šå·ç§¯é‡‡æ ·çš„9ä¸ªç‚¹(ç»¿ç‚¹)ï¼›(b)(c)(d)éƒ½ä¸ºå¯å˜å½¢å·ç§¯ï¼Œåœ¨æ™®é€šå·ç§¯é‡‡æ ·åæ ‡ä¸ŠåŠ ä¸Šä¸€ä¸ªä½ç§»é‡(è“è‰²ç®­å¤´)ï¼Œå¾—åˆ°å˜å½¢çš„é‡‡æ ·ä½ç½®(æ·±è“ç‚¹) å¯¹äºŽè¾“å…¥çš„ä¸€å¼ ç‰¹å¾å›¾ï¼ŒæŠŠæ™®é€šå·ç§¯çš„è¿‡ç¨‹åˆ†æˆä¸¤è·¯ï¼Œå…ˆé€šè¿‡ä¸Šé¢ä¸€è·¯å­¦ä¹ å¾—åˆ°offsetï¼›ä¸‹é¢çš„å¯å˜å½¢å·ç§¯æ˜¯åŸºäºŽä¸Šé¢ç”Ÿæˆçš„offsetï¼Œæˆ‘ä»¬çš„å·ç§¯çª—å£å°†ç”±è§„æ•´çš„ç»¿è‰²çª—å£å˜æˆè“è‰²éƒ¨åˆ†ï¼Œç„¶åŽå†æ‰§è¡Œæ™®é€šçš„å·ç§¯ï¼Œè¿™ç§å®žçŽ°æ–¹å¼ç›¸å½“äºŽäºŽæ¯”æ­£å¸¸çš„å·ç§¯æ“ä½œå¤šå­¦ä¹ äº†å·ç§¯æ ¸çš„åç§»offset å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå·¦è¾¹æ™®é€šå·ç§¯æ–¹æ³•æ²¡æœ‰æå–åˆ°å®Œæ•´ç»µç¾Šçš„ç‰¹å¾ï¼Œè€Œå³è¾¹çš„å¯å˜å½¢å·ç§¯æ–¹æ³•æå–åˆ°äº†å®Œæ•´çš„ç»µç¾Šçš„ç‰¹å¾ å®žçŽ°DCNä¸­çš„ä¸¤ä¸ªé—®é¢˜QA QA1: å¦‚ä½•å°†å¯å˜å½¢å·ç§¯å˜æˆå•ç‹¬çš„ä¸€ä¸ªå±‚ï¼Œè€Œä¸å½±å“åˆ«çš„å±‚ åœ¨å®žé™…æ“ä½œæ—¶ï¼Œå¹¶ä¸æ˜¯çœŸæ­£åœ°æŠŠå·ç§¯æ ¸è¿›è¡Œæ‰©å±•ï¼Œè€Œæ˜¯å¯¹å·ç§¯å‰å›¾ç‰‡çš„åƒç´ é‡æ–°æ•´åˆï¼Œå˜ç›¸åœ°å®žçŽ°å·ç§¯æ ¸çš„æ‰©å¼ ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®žé™…ä¸Šå˜çš„æ˜¯æ¯æ¬¡è¿›è¡Œå·ç§¯åŽå¾—åˆ°çš„å¸¦åç§»å€¼çš„åæ ‡å€¼ï¼Œæ ¹æ®è¿™äº›åæ ‡å–åƒç´ ç‚¹ï¼Œç„¶åŽåŒçº¿æ€§å·®å€¼ï¼Œå¾—åˆ°æ–°feature mapï¼Œç„¶åŽä½œä¸ºè¾“å‡ºå¹¶æˆä¸ºä¸‹ä¸€å±‚çš„æ–°è¾“å…¥ QA2: åœ¨å‰å‘ä¼ æ’­å®žçŽ°å¯å˜æ€§å·ç§¯ä¸­ï¼Œå¦‚ä½•èƒ½æœ‰æ•ˆåœ°è¿›è¡Œåå‘ä¼ æ’­ åœ¨å›¾ç‰‡åƒç´ æ•´åˆæ—¶ï¼Œéœ€è¦å¯¹åƒç´ è¿›è¡Œåç§»æ“ä½œï¼Œåç§»é‡çš„ç”Ÿæˆä¼šäº§ç”Ÿæµ®ç‚¹æ•°ç±»åž‹ï¼Œè€Œåç§»é‡åˆå¿…é¡»è½¬æ¢ä¸ºæ•´å½¢ï¼Œç›´æŽ¥å¯¹åç§»é‡å–æ•´çš„è¯æ— æ³•è¿›è¡Œåå‘ä¼ æ’­ï¼Œè¿™æ—¶é‡‡ç”¨åŒçº¿æ€§å·®å€¼çš„æ–¹å¼æ¥å¾—åˆ°å¯¹åº”çš„åƒç´  å¯å˜å½¢å·ç§¯çš„ä½¿ç”¨ç¨‹åº¦å–å†³äºŽå…·ä½“çš„åº”ç”¨åœºæ™¯å’Œä»»åŠ¡è¦æ±‚ ç›®æ ‡æ£€æµ‹ï¼šå¯å˜å½¢å·ç§¯åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­è¢«å¹¿æ³›ä½¿ç”¨ã€‚ç”±äºŽç›®æ ‡åœ¨å›¾åƒä¸­å¯èƒ½å­˜åœ¨å°ºåº¦å˜åŒ–ã€å½¢å˜ç­‰éžåˆšæ€§å˜åŒ–ï¼Œä¼ ç»Ÿçš„å›ºå®šæ„Ÿå—é‡Žçš„å·ç§¯æ ¸éš¾ä»¥å‡†ç¡®æ•æ‰ç›®æ ‡çš„ç»†èŠ‚å’Œå½¢çŠ¶ä¿¡æ¯ã€‚å¯å˜å½¢å·ç§¯é€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„åç§»å‚æ•°ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°è°ƒæ•´æ„Ÿå—é‡Žï¼Œä»Žè€Œæé«˜ç›®æ ‡æ£€æµ‹çš„ç²¾åº¦å’Œé²æ£’æ€§ è¯­ä¹‰åˆ†å‰²ï¼šå¯¹äºŽè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ï¼Œå¯å˜å½¢å·ç§¯ä¹Ÿè¢«å¹¿æ³›ä½¿ç”¨ã€‚è¯­ä¹‰åˆ†å‰²éœ€è¦å¯¹å›¾åƒä¸­çš„æ¯ä¸ªåƒç´ è¿›è¡Œåˆ†ç±»ï¼Œå› æ­¤å‡†ç¡®åœ°æ•æ‰åƒç´ å‘¨å›´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯è‡³å…³é‡è¦ã€‚å¯å˜å½¢å·ç§¯èƒ½å¤Ÿé€šè¿‡è‡ªé€‚åº”è°ƒæ•´é‡‡æ ·ä½ç½®æ¥æ›´å¥½åœ°æ•æ‰éžåˆšæ€§å½¢å˜çš„ç›®æ ‡è¾¹ç•Œå’Œç»†èŠ‚ï¼Œæé«˜è¯­ä¹‰åˆ†å‰²çš„ç²¾åº¦å’Œç»†èŠ‚ä¿ç•™èƒ½åŠ› äººä½“å§¿æ€ä¼°è®¡ï¼šåœ¨äººä½“å§¿æ€ä¼°è®¡ä»»åŠ¡ä¸­ï¼Œå¯å˜å½¢å·ç§¯ä¹Ÿè¢«å¹¿æ³›åº”ç”¨ã€‚äººä½“å§¿æ€å…·æœ‰å¤æ‚çš„éžåˆšæ€§å½¢å˜ï¼Œä¼ ç»Ÿçš„å·ç§¯æ“ä½œå¾€å¾€æ— æ³•å‡†ç¡®åœ°æ•æ‰åˆ°äººä½“å…³èŠ‚çš„ä½ç½®å’Œå§¿æ€ä¿¡æ¯ã€‚é€šè¿‡å¼•å…¥å¯å˜å½¢å·ç§¯ï¼Œå¯ä»¥æ›´å¥½åœ°å»ºæ¨¡äººä½“çš„éžåˆšæ€§å½¢å˜ï¼Œæé«˜å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå¯å˜å½¢å·ç§¯çš„è®¡ç®—é‡è¾ƒå¤§ï¼Œå¯èƒ½ä¼šå¢žåŠ æ¨¡åž‹çš„å¤æ‚æ€§å’Œè®­ç»ƒçš„éš¾åº¦ å› æ­¤ï¼Œå®ƒé€šå¸¸åœ¨éœ€è¦å¯¹éžåˆšæ€§å½¢å˜å»ºæ¨¡çš„ä»»åŠ¡ä¸­ä½¿ç”¨ï¼Œå¹¶ä¸”åœ¨è®¾è®¡æ¨¡åž‹æ—¶éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µè¿›è¡Œæƒè¡¡å’Œé€‰æ‹© æ± åŒ–æ“ä½œ å·ç§¯ç¥žç»ç½‘ç»œæ± åŒ–æ–¹æ³•ç»¼è¿° é‚£äº›é¬¼æ–§ç¥žå·¥çš„æ± åŒ–æ“ä½œï¼Œçœ‹å®Œæˆ‘ç‚¸è£‚ï¼ æ± åŒ–çš„ä½œç”¨ æŠ‘åˆ¶å™ªå£°ï¼Œé™ä½Žä¿¡æ¯å†—ä½™ æå‡æ¨¡åž‹çš„å°ºåº¦ä¸å˜æ€§ã€æ—‹è½¬ä¸å˜æ€§ é™ä½Žæ¨¡åž‹è®¡ç®—é‡ é˜²æ­¢è¿‡æ‹Ÿåˆ æ± åŒ–å›žä¼ æ¢¯åº¦çš„åŽŸåˆ™æ˜¯ä¿è¯ä¼ é€’çš„loss(æˆ–è€…è¯´æ¢¯åº¦)æ€»å’Œä¸å˜ æœ€å¤§æ± åŒ–: å–æ¯ä¸ªå—çš„æœ€å¤§å€¼ä½œä¸ºä¸‹ä¸€å±‚çš„ä¸€ä¸ªå…ƒç´ å€¼ï¼Œå› æ­¤ä¸‹ä¸€ä¸ªå…ƒç´ çš„Lossåªæ¥æºäºŽè¿™ä¸ªæœ€å¤§å€¼ï¼Œå› æ­¤æ¢¯åº¦æ›´æ–°ä¹Ÿåªæ›´æ–°è¿™ä¸ªæœ€å¤§å€¼ï¼Œå…¶ä»–å€¼æ¢¯åº¦ä¸º0 å¹³å‡æ± åŒ–: å°†è¾“å…¥åŒºåŸŸå†…çš„æ¢¯åº¦å‡åŒ€åœ°åˆ†é…ç»™è¯¥åŒºåŸŸä¸­çš„æ¯ä¸ªä½ç½®ã€‚åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œå°†æ¢¯åº¦å‡åŒ€åˆ†é…ç»™è¾“å…¥åŒºåŸŸå†…çš„æ‰€æœ‰ä½ç½® æ± åŒ–è¾“å‡ºå¤§å°è®¡ç®—å…¬å¼ L_{out} = \\left\\lfloor \\frac{L_{in}-kernel\\_size}{stride}\\right\\rfloor+1 æœ€å¤§æœ€å°æ± åŒ– å®šä¹‰ æœ€å¤§æ± åŒ–(Max Pooling): é€‰æ‹©è¾“å…¥åŒºåŸŸä¸­çš„æœ€å¤§å€¼ä½œä¸ºè¾“å‡ºï¼Œå¿½ç•¥å…¶ä»–å€¼ æœ€å°æ± åŒ–(Min Pooling): é€‰æ‹©è¾“å…¥åŒºåŸŸä¸­çš„æœ€å°å€¼ä½œä¸ºè¾“å‡ºï¼Œå¿½ç•¥å…¶ä»–å€¼ ä¸‹å›¾æ˜¯æœ€å¤§æ± åŒ–çš„ç¤ºä¾‹å›¾ é‡å æ± åŒ–å’Œéžé‡å æ± åŒ– æ± åŒ–åˆåˆ†ä¸ºé‡å æ± åŒ–å’Œéžé‡å æ± åŒ– éžé‡å æ± åŒ–: stride=kernel sizeçš„æƒ…å†µ é‡å æ± åŒ–: stride é‡å æ± åŒ–ç›¸æ¯”äºŽéžé‡å æ± åŒ–ä¸ä»…å¯ä»¥æå‡é¢„æµ‹ç²¾åº¦ï¼ŒåŒæ—¶åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¯ä»¥ç¼“è§£è¿‡æ‹Ÿåˆ å¹³å‡æ± åŒ– å¹³å‡æ± åŒ–(Average Pooling): è®¡ç®—è¾“å…¥åŒºåŸŸå†…çš„å¹³å‡å€¼ä½œä¸ºè¾“å‡ºï¼Œå°†è¾“å…¥åŒºåŸŸçš„å€¼å¹³å‡åˆ†é… æœ€å¤§æ± åŒ–å’Œå‡å€¼æ± åŒ–çš„å¼Šç«¯å¦‚ä¸‹æ‰€ç¤º éšæœºæ± åŒ– Stochastic Pooling for Regularization of Deep Convolutional Neural Networks 2013 Stochastic poolingæ˜¯è®ºæ–‡ã€ŠStochastic Pooling for Regularization of Deep Convolutional Neural Networksã€‹ä¸­æåˆ°çš„ä¸€ç§æ± åŒ–ç­–ç•¥ï¼Œå¤§æ„æ˜¯åªéœ€å¯¹ç‰¹å¾åŒºåŸŸå…ƒç´ æŒ‰ç…§å…¶æ¦‚çŽ‡å€¼å¤§å°éšæœºé€‰æ‹©ï¼Œå…ƒç´ å€¼å¤§çš„è¢«é€‰ä¸­çš„æ¦‚çŽ‡ä¹Ÿå¤§ ä¸‹è¡¨æ˜¯éšæœºæ± åŒ–åœ¨CIFAR-10ä¸Šçš„è¡¨çŽ°ï¼Œå¯ä»¥çœ‹å‡ºï¼Œä½¿ç”¨éšæœºæ± åŒ–æ•ˆæžœå’Œé‡‡ç”¨dropoutçš„ç»“æžœæŽ¥è¿‘ï¼Œè¯æ˜Žäº†å…¶æœ‰ä¸€å®šé˜²æ­¢è¿‡æ‹Ÿåˆçš„ä½œç”¨ Lpæ± åŒ– Lpæ± åŒ–(Lp Pooling)æ˜¯é€šè¿‡è°ƒæ•´å‚æ•°pçš„å€¼æ¥å®žçŽ°ä¸åŒçš„æ± åŒ–æ–¹å¼ï¼Œå½“p=1æ—¶ï¼Œä¸ºå¹³å‡æ± åŒ–ï¼Œå½“pè¶‹è¿‘äºŽæ— ç©·å¤§æ—¶ï¼Œä¸ºæœ€å¤§æ± åŒ– Lpæ± åŒ–çš„å¥½å¤„æ˜¯å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šä¿ç•™æ›´å¤šçš„ä¿¡æ¯ã€‚å¹³å‡æ± åŒ–ä¼šå¹³å‡åŒ–å±€éƒ¨åŒºåŸŸçš„ç‰¹å¾ï¼Œå¯èƒ½ä¸¢å¤±ä¸€äº›ç»†èŠ‚ä¿¡æ¯ï¼›è€Œæœ€å¤§æ± åŒ–åªä¿ç•™å±€éƒ¨åŒºåŸŸçš„æœ€å¤§å€¼ï¼Œå¯èƒ½ä¸¢å¤±å…¶ä»–é‡è¦çš„ä¿¡æ¯ Lpæ± åŒ–é€šè¿‡è°ƒæ•´å‚æ•°pçš„å€¼ï¼Œå¯ä»¥åœ¨ç‰¹å¾æ±‡èšæ—¶å¹³è¡¡ä¿¡æ¯çš„ä¸°å¯Œæ€§å’ŒæŠ—å™ªæ€§èƒ½ æ± åŒ–å…·ä½“æ“ä½œå¦‚ä¸‹å…¬å¼æ‰€æè¿° f(X)=\\sqrt[p]{\\sum_{x \\in X} x^{p}} å½“p=1æ—¶ï¼Œä½¿ç”¨å±€éƒ¨æ±‚å’Œï¼Œè€Œpä¸ºæ— ç©·å¤§æ—¶ï¼Œå¯¹åº”max-pooling åœ¨Lpæ± åŒ–ä¸­ï¼Œpçš„é€‰æ‹©éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡å’Œæ•°æ®é›†è¿›è¡Œè°ƒæ•´ è¾ƒå°çš„på€¼å¯ä»¥æ›´åŠ æ³¨é‡ç»†èŠ‚ä¿¡æ¯ï¼Œé€‚ç”¨äºŽéœ€è¦ä¿ç•™ç»†ç²’åº¦ç‰¹å¾çš„ä»»åŠ¡ è¾ƒå¤§çš„på€¼å¯ä»¥æ›´åŠ æ³¨é‡å…¨å±€ä¿¡æ¯ï¼Œé€‚ç”¨äºŽæ›´åŠ æ•´ä½“åŒ–çš„ä»»åŠ¡ é€šå¸¸æƒ…å†µä¸‹ï¼Œpå–2æ—¶èƒ½å¤ŸèŽ·å¾—è¾ƒå¥½çš„æ€§èƒ½ ç»„åˆæ± åŒ– ç»„åˆæ± åŒ–åˆ™æ˜¯åŒæ—¶åˆ©ç”¨æœ€å¤§å€¼æ± åŒ–ä¸Žå‡å€¼æ± åŒ–ä¸¤ç§çš„ä¼˜åŠ¿è€Œå¼•ç”³çš„ä¸€ç§æ± åŒ–ç­–ç•¥ï¼Œå¸¸è§ç»„åˆç­–ç•¥æœ‰Catå’ŒAddè¿™ä¸¤ç§ å¸¸å¸¸è¢«å½“åšåˆ†ç±»ä»»åŠ¡çš„ä¸€ä¸ªtrickï¼Œå…¶ä½œç”¨å°±æ˜¯ä¸°å¯Œç‰¹å¾å±‚ï¼Œmaxpoolæ›´å…³æ³¨é‡è¦çš„å±€éƒ¨ç‰¹å¾ï¼Œè€Œaverage poolingæ›´å…³æ³¨å…¨å±€ç‰¹å¾ def add_avgmax_pool2d(x, output_size=1): x_avg = F.adaptive_avg_pool2d(x, output_size) x_max = F.adaptive_max_pool2d(x, output_size) return 0.5 * (x_avg + x_max) def cat_avgmax_pool2d(x, output_size=1): x_avg = F.adaptive_avg_pool2d(x, output_size) x_max = F.adaptive_max_pool2d(x, output_size) return torch.cat([x_avg, x_max], 1) SPPæ± åŒ– Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition 2015 SPP(ç©ºé—´é‡‘å­—å¡”æ± åŒ–)æ˜¯åœ¨SPPNetä¸­æå‡ºçš„ï¼ŒSPPNetæå‡ºæ¯”è¾ƒæ—©ï¼Œåœ¨RCNNä¹‹åŽæå‡ºçš„ï¼Œç”¨äºŽè§£å†³é‡å¤å·ç§¯è®¡ç®—å’Œå›ºå®šè¾“å‡ºçš„ä¸¤ä¸ªé—®é¢˜ï¼Œå…·ä½“æ–¹æ³•å¦‚ä¸‹å›¾æ‰€ç¤º ç©ºé—´é‡‘å­—å¡”æ± åŒ–çš„åŸºæœ¬æ€æƒ³æ˜¯å°†è¾“å…¥ç‰¹å¾å›¾åˆ†å‰²æˆå¤šä¸ªä¸åŒå¤§å°çš„å­åŒºåŸŸï¼Œå¹¶å¯¹æ¯ä¸ªå­åŒºåŸŸè¿›è¡Œæ± åŒ–æ“ä½œã€‚è¿™äº›å­åŒºåŸŸçš„å¤§å°å’Œæ•°é‡æž„æˆäº†ä¸€ä¸ªé‡‘å­—å¡”å½¢çŠ¶çš„å±‚æ¬¡ç»“æž„ ç„¶åŽï¼Œå¯¹æ¯ä¸ªå­åŒºåŸŸè¿›è¡Œæ± åŒ–æ“ä½œï¼ˆé€šå¸¸æ˜¯æœ€å¤§æ± åŒ–ï¼‰ï¼Œç”Ÿæˆå›ºå®šå¤§å°çš„ç‰¹å¾å‘é‡ã€‚æœ€åŽï¼Œå°†æ‰€æœ‰å°ºåº¦ä¸Šå¾—åˆ°çš„ç‰¹å¾å‘é‡æ‹¼æŽ¥åœ¨ä¸€èµ·ï¼Œå½¢æˆæœ€ç»ˆçš„ç‰¹å¾è¡¨ç¤º é€šè¿‡ç©ºé—´é‡‘å­—å¡”æ± åŒ–ï¼Œæ¨¡åž‹èƒ½å¤Ÿåœ¨ä¸åŒå°ºåº¦ä¸Šæ•æ‰åˆ°æ›´åŠ ä¸°å¯Œçš„å±€éƒ¨ç‰¹å¾ï¼Œä»Žè€Œå¢žå¼ºäº†æ¨¡åž‹å¯¹å°ºåº¦å˜åŒ–å’Œç‰©ä½“å¤§å°å˜åŒ–çš„é²æ£’æ€§ è¿™å¯¹äºŽå¤„ç†ä¸åŒå°ºåº¦çš„ç‰©ä½“æ£€æµ‹ã€å›¾åƒåˆ†ç±»å’Œè¯­ä¹‰åˆ†å‰²ç­‰ä»»åŠ¡éžå¸¸æœ‰ç”¨ ROIæ± åŒ– ROIæ± åŒ–(Region of Interest Pooling)æ˜¯åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å¹¿æ³›ä½¿ç”¨çš„æ“ä½œã€‚å®ƒå¯¹äºŽæ¥è‡ªè¾“å…¥åˆ—è¡¨çš„æ¯ä¸ªæ„Ÿå…´è¶£åŒºåŸŸï¼Œå®ƒé‡‡ç”¨ä¸Žå…¶å¯¹åº”çš„è¾“å…¥ç‰¹å¾å›¾çš„ä¸€éƒ¨åˆ†å¹¶å°†å…¶ç¼©æ”¾åˆ°æŸä¸ªé¢„å®šä¹‰çš„å¤§å°ã€‚è¿™å¯ä»¥æ˜¾ç€åŠ å¿«è®­ç»ƒå’Œæµ‹è¯•æ—¶é—´ï¼Œå®ƒå…è®¸é‡æ–°ä½¿ç”¨å·ç§¯ç½‘ç»œä¸­çš„ç‰¹å¾æ˜ å°„ï¼ŒåŒæ—¶ä¹Ÿå…è®¸ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è®­ç»ƒç‰©ä½“æ£€æµ‹ç³»ç»Ÿ ROI Poolingä¸ŽSPPæ± åŒ–çš„åŒºåˆ« é€šè¿‡ä¸Šé¢çš„ä»‹ç»ï¼Œå¯ä»¥çœ‹åˆ°ä¸¤è€…èµ·åˆ°çš„ä½œç”¨æ˜¯ç›¸åŒçš„ï¼ŒæŠŠä¸åŒå°ºå¯¸çš„ç‰¹å¾è¾“å…¥è½¬åŒ–ä¸ºç›¸åŒå°ºå¯¸çš„ç‰¹å¾è¾“å‡º SPPé’ˆå¯¹åŒä¸€ä¸ªè¾“å…¥ä½¿ç”¨äº†å¤šä¸ªä¸åŒå°ºå¯¸çš„æ± åŒ–æ“ä½œï¼ŒæŠŠä¸åŒå°ºåº¦çš„ç»“æžœæ‹¼æŽ¥ä½œä¸ºè¾“å‡ºï¼›è€ŒROI Poolingå¯çœ‹ä½œå•å°ºåº¦çš„SPPï¼Œå¯¹äºŽä¸€ä¸ªè¾“å…¥åªè¿›è¡Œä¸€æ¬¡æ± åŒ–æ“ä½œ åæ± åŒ– [CNN] å·ç§¯ã€åå·ç§¯ã€æ± åŒ–ã€åæ± åŒ– åæ± åŒ–(Unpooling)ä¸Žæ± åŒ–æ“ä½œç›¸åï¼Œç”¨äºŽæ¢å¤ç‰¹å¾å›¾çš„å°ºå¯¸ï¼Œå¸¸è§çš„æ–¹æ³•åŒ…æ‹¬æœ€å¤§åæ± åŒ–å’Œå¹³å‡åæ± åŒ– åœ¨ä¼ ç»Ÿçš„æ± åŒ–æ“ä½œä¸­ï¼Œé€šè¿‡å°†ç‰¹å¾å›¾çš„å¤§å°å‡å°ï¼Œä»¥å®žçŽ°ç‰¹å¾çš„é™ç»´å’Œå‡å°‘è®¡ç®—é‡ã€‚ç„¶è€Œï¼Œè¿™ä¹Ÿå¯¼è‡´äº†ä¿¡æ¯çš„æŸå¤±å’Œç©ºé—´åˆ†è¾¨çŽ‡çš„é™ä½Ž ä¸ºäº†è¡¥å¿è¿™ç§ä¿¡æ¯æŸå¤±ï¼Œåæ± åŒ–å’ŒUnpoolingæ“ä½œç”¨äºŽè¿˜åŽŸç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨çŽ‡ï¼Œä½¿å…¶ä¸Žè¾“å…¥ç‰¹å¾å›¾å…·æœ‰ç›¸åŒçš„å°ºå¯¸ åæ± åŒ–é€šå¸¸æ˜¯é€šè¿‡è½¬ç½®å·ç§¯(Transpose Convolution)æ¥å®žçŽ°çš„ã€‚è½¬ç½®å·ç§¯é€šè¿‡åœ¨ç‰¹å¾å›¾ä¹‹é—´æ’å…¥ç©ºç™½åƒç´ æˆ–é›¶å¡«å……ï¼Œå¹¶ä½¿ç”¨é€‚å½“çš„å·ç§¯æ ¸å¯¹è¿™äº›ç©ºç™½åƒç´ è¿›è¡Œå·ç§¯è¿ç®—ï¼Œä»¥æ¢å¤ç‰¹å¾å›¾çš„å°ºå¯¸ Unpoolingåˆ™æ˜¯åœ¨åæ± åŒ–æ“ä½œä¸­ä¸Žè½¬ç½®å·ç§¯ç»“åˆä½¿ç”¨çš„ä¸€ç§æ–¹å¼ã€‚åœ¨æ± åŒ–æ“ä½œä¸­ï¼Œé€šå¸¸ä¼šè®°å½•æ± åŒ–æ“ä½œæ—¶çš„æœ€å¤§å€¼æˆ–å¹³å‡å€¼çš„ä½ç½®ã€‚åœ¨Unpoolingä¸­ï¼Œæ ¹æ®è¿™äº›ä½ç½®ä¿¡æ¯ï¼Œå°†åæ± åŒ–æ“ä½œçš„è¾“å‡ºå€¼æ”¾ç½®å›žåŽŸå§‹ç‰¹å¾å›¾çš„å¯¹åº”ä½ç½®ã€‚è¿™æ ·å¯ä»¥åœ¨æ¢å¤ç©ºé—´åˆ†è¾¨çŽ‡çš„åŒæ—¶ä¿ç•™ä¸€å®šçš„ä½ç½®ä¿¡æ¯ åæ± åŒ–å’ŒUnpoolingåœ¨å·ç§¯ç¥žç»ç½‘ç»œä¸­èµ·ç€é‡è¦çš„ä½œç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯­ä¹‰åˆ†å‰²å’Œå›¾åƒé‡å»ºç­‰ä»»åŠ¡ä¸­ã€‚å®ƒä»¬å¸®åŠ©ç½‘ç»œæ¢å¤è¾“å…¥å›¾åƒçš„è¯¦ç»†ç»“æž„å’Œç©ºé—´ä¿¡æ¯ï¼Œä»Žè€Œæé«˜æ¨¡åž‹çš„ç²¾åº¦å’Œè´¨é‡ å…¶ä»–æ± åŒ– LIPæ± åŒ–: LIP: Local Importance-based Pooling è‡ªé€‚åº”æ± åŒ–(Adaptive Pooling): æ ¹æ®è¾“å…¥çš„å°ºå¯¸è‡ªåŠ¨è°ƒæ•´æ± åŒ–çª—å£çš„å¤§å°ï¼Œé€‚åº”ä¸åŒå¤§å°çš„è¾“å…¥ å½’ä¸€åŒ– BatchNormalizationã€LayerNormalizationã€InstanceNormã€GroupNormç®€ä»‹ ç¥žç»ç½‘ç»œä¸­æœ‰å„ç§å½’ä¸€åŒ–ç®—æ³•ï¼Œä»Žå…¬å¼çœ‹å®ƒä»¬éƒ½å·®ä¸å¤šï¼šæ— éžæ˜¯å‡åŽ»å‡å€¼ï¼Œé™¤ä»¥æ ‡å‡†å·®ï¼Œå†æ–½ä»¥çº¿æ€§æ˜ å°„ y=\\gamma\\left(\\frac{x-\\mu(x)}{\\sigma(x)}\\right)+\\beta å½’ä¸€åŒ–ç®—æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽæ“ä½œçš„feature mapç»´åº¦ä¸åŒ ä¸‹å›¾æ¥è‡ªä½•å‡¯æ˜Žçš„Group Normalization 2018 å¯ä»¥çœ‹å‡º BN: é’ˆå¯¹æ•´ä¸ªbatchä¸åŒé€šé“ï¼Œå…·ä½“æ¥è¯´ï¼Œå°±æ˜¯æŠŠç¬¬1ä¸ªæ ·æœ¬çš„ç¬¬1ä¸ªé€šé“ï¼ŒåŠ ä¸Šç¬¬2ä¸ªæ ·æœ¬ç¬¬1ä¸ªé€šé“...åŠ ä¸Šç¬¬Nä¸ªæ ·æœ¬ç¬¬1ä¸ªé€šé“ï¼Œæ±‚å¹³å‡ï¼Œå¾—åˆ°é€šé“1çš„å‡å€¼ \\begin{align}{c} \\mu_{c}(x)=\\frac{1}{N H W} \\sum_{n=1}^{N} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{n c h w} \\\\ \\sigma_{c}(x)=\\sqrt{\\frac{1}{N H W} \\sum_{n=1}^{N} \\sum_{h=1}^{H} \\sum_{w=1}^{W}\\left(x_{n c h w}-\\mu_{c}(x)\\right)^{2}+\\epsilon} \\end{align} LNï¼šé’ˆå¯¹æ¯ä¸ªæ ·æœ¬ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬çš„Cã€Hã€Wç»´åº¦ä¸Šçš„æ•°æ®æ±‚å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä¿ç•™Nç»´åº¦ \\begin{align}{c} \\mu_{n}(x)=\\frac{1}{C H W} \\sum_{c=1}^{C} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{n c h w} \\\\ \\sigma_{n}(x)=\\sqrt{\\frac{1}{C H W} \\sum_{c=1}^{C} \\sum_{h=1}^{H} \\sum_{w=1}^{W}\\left(x_{n c h w}-\\mu_{n}(x)\\right)^{2}+\\epsilon} \\end{align} INï¼šé’ˆå¯¹æ¯ä¸ªæ ·æœ¬ä¸‹çš„æ¯ä¸ªé€šé“ï¼Œå¯¹æ¯ä¸ªæ ·æœ¬çš„Hã€Wç»´åº¦çš„æ•°æ®æ±‚å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä¿ç•™N ã€Cç»´åº¦ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒåªåœ¨channelå†…éƒ¨æ±‚å‡å€¼å’Œæ ‡å‡†å·® \\begin{align}{c} \\mu_{n c}(x)=\\frac{1}{H W} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{n c h w} \\\\ \\sigma_{n c}(x)=\\sqrt{\\frac{1}{H W} \\sum_{h=1}^{H} \\sum_{w=1}^{W}\\left(x_{n c h w}-\\mu_{n c}(x)\\right)^{2}+\\epsilon} \\end{align} GNï¼šé’ˆå¯¹æ¯ä¸ªæ ·æœ¬ä¸‹çš„å¤šä¸ªé€šé“ï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®æ—¶ï¼ŒæŠŠæ¯ä¸€ä¸ªæ ·æœ¬feature mapçš„channelåˆ†æˆGç»„ï¼Œæ¯ç»„å°†æœ‰C/Gä¸ªchannelï¼Œç„¶åŽå°†è¿™äº›channelä¸­çš„å…ƒç´ æ±‚å‡å€¼å’Œæ ‡å‡†å·®ã€‚å„ç»„channelç”¨å…¶å¯¹åº”çš„å½’ä¸€åŒ–å‚æ•°ç‹¬ç«‹åœ°å½’ä¸€åŒ– \\begin{align}{c} \\mu_{n g}(x)=\\frac{1}{(C / G) H W} \\sum_{c=g C / G}^{(g+1) C / G} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{n c h w} \\\\ \\sigma_{n g}(x)=\\sqrt{\\frac{1}{(C / G) H W} \\sum_{c=g C / G}^{(g+1) C / G} \\sum_{h=1}^{H} \\sum_{w=1}^{W}\\left(x_{n c h w}-\\mu_{n g}(x)\\right)^{2}+\\epsilon} \\end{align} æ‰¹å½’ä¸€åŒ– èƒŒæ™¯ æœºå™¨å­¦ä¹ é¢†åŸŸæœ‰ä¸ªå¾ˆé‡è¦çš„å‡è®¾ï¼šIID ç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾ï¼Œå°±æ˜¯å‡è®¾è®­ç»ƒæ•°æ®å’Œæµ‹è¯•æ•°æ®æ˜¯æ»¡è¶³ç›¸åŒåˆ†å¸ƒçš„ï¼Œè¿™æ˜¯é€šè¿‡è®­ç»ƒæ•°æ®èŽ·å¾—çš„æ¨¡åž‹èƒ½å¤Ÿåœ¨æµ‹è¯•é›†èŽ·å¾—å¥½çš„æ•ˆæžœçš„ä¸€ä¸ªåŸºæœ¬ä¿éšœ åœ¨æŠŠæ•°æ®å–‚ç»™æœºå™¨å­¦ä¹ æ¨¡åž‹ä¹‹å‰ï¼Œç™½åŒ–(whitening)æ˜¯ä¸€ä¸ªé‡è¦çš„æ•°æ®é¢„å¤„ç†æ­¥éª¤ ç‹¬ç«‹: åŽ»é™¤ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ åŒåˆ†å¸ƒ: ä½¿å¾—æ‰€æœ‰ç‰¹å¾å…·æœ‰ç›¸åŒçš„å‡å€¼å’Œæ–¹å·® æ¯æ‰¹è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒå„ä¸ç›¸åŒï¼Œé‚£ä¹ˆç½‘ç»œéœ€è¦åœ¨æ¯æ¬¡è¿­ä»£ä¸­åŽ»å­¦ä¹ é€‚åº”ä¸åŒçš„åˆ†å¸ƒï¼Œè¿™æ ·å°†ä¼šå¤§å¤§é™ä½Žç½‘ç»œçš„è®­ç»ƒé€Ÿåº¦ã€‚å¯¹äºŽæ·±åº¦ç½‘ç»œçš„è®­ç»ƒæ˜¯ä¸€ä¸ªéžå¸¸å¤æ‚çš„è¿‡ç¨‹ï¼Œåªè¦ç½‘ç»œçš„å‰é¢å‡ å±‚å‘ç”Ÿå¾®å°çš„æ”¹å˜ï¼Œé‚£ä¹ˆè¿™äº›å¾®å°çš„æ”¹å˜åœ¨åŽé¢çš„å±‚å°±ä¼šè¢«ç´¯ç§¯æ”¾å¤§ä¸‹åŽ» ä¸€æ—¦ç½‘ç»œæŸä¸€å±‚çš„è¾“å…¥æ•°æ®çš„åˆ†å¸ƒå‘ç”Ÿæ”¹å˜ï¼Œé‚£ä¹ˆè¿™ä¸€å±‚ç½‘ç»œå°±éœ€è¦åŽ»é€‚åº”å­¦ä¹ è¿™ä¸ªæ–°çš„æ•°æ®åˆ†å¸ƒï¼Œæ‰€ä»¥å¦‚æžœè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè®­ç»ƒæ•°æ®çš„åˆ†å¸ƒä¸€ç›´åœ¨å‘ç”Ÿå˜åŒ–ï¼Œé‚£ä¹ˆå°†ä¼šå½±å“ç½‘ç»œçš„è®­ç»ƒé€Ÿåº¦ ä¸€æ–‡æžæ‡‚BNçš„åŽŸç†åŠå…¶å®žçŽ°è¿‡ç¨‹ï¼ˆBatch Normalizationï¼‰ æ·±å…¥ç†è§£NLPä¸­LayerNormçš„åŽŸç†ä»¥åŠLNçš„ä»£ç è¯¦è§£ å¼•å…¥æ‰¹å½’ä¸€åŒ–Batch Normalizationçš„åŽŸå› ï¼šåœ¨å›¾åƒé¢„å¤„ç†è¿‡ç¨‹ä¸­é€šå¸¸ä¼šå¯¹å›¾åƒè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œä¹Ÿå°±æ˜¯image normalizationï¼Œä½¿å¾—æ¯å¼ è¾“å…¥å›¾ç‰‡çš„æ•°æ®åˆ†å¸ƒèƒ½å¤Ÿç»Ÿå‡å€¼ä¸º\\muï¼Œæ–¹å·®ä¸º \\sigma ^2çš„åˆ†å¸ƒã€‚è¿™æ ·èƒ½å¤ŸåŠ é€Ÿç½‘ç»œçš„æ”¶æ•›ã€‚ä½†æ˜¯å½“ä¸€å¼ å›¾ç‰‡è¾“å…¥åˆ°ç¥žç»ç½‘ç»œç»è¿‡å·ç§¯è®¡ç®—ä¹‹åŽï¼Œè¿™ä¸ªåˆ†å¸ƒå°±ä¸ä¼šæ»¡è¶³åˆšæ‰ç»è¿‡image normalizationæ“ä½œä¹‹åŽçš„åˆ†å¸ƒäº†ï¼Œå¯èƒ½é€‚åº”äº†æ–°çš„æ•°æ®åˆ†å¸ƒè§„å¾‹ï¼Œè¿™ä¸ªæ—¶å€™å°†æ•°æ®æŽ¥å…¥æ¿€æ´»å‡½æ•°ä¸­ï¼Œå¾ˆå¯èƒ½ä¸€äº›æ–°çš„æ•°æ®ä¼šè½å…¥æ¿€æ´»å‡½æ•°çš„é¥±å’ŒåŒºï¼Œå¯¼è‡´ç¥žç»ç½‘ç»œè®­ç»ƒçš„æ¢¯åº¦æ¶ˆå¤± è¿™ä¸ªæ—¶å€™æˆ‘ä»¬å¼•å…¥Batch Normalizationçš„ç›®çš„å°±æ˜¯ä½¿æˆ‘ä»¬å·ç§¯ä»¥åŽçš„feature mapæ»¡è¶³å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„åˆ†å¸ƒè§„å¾‹ï¼Œå†æŽ¥å…¥æ¿€æ´»å‡½æ•°å°±ä¸ä¼šå‘ç”Ÿè¿™æ ·çš„æƒ…å†µ æ•°æ®å½’ä¸€åŒ–éƒ½æ˜¯åœ¨æ•°æ®è¾“å…¥æ—¶åšçš„ï¼Œä½†æ˜¯å®žé™…ä¸Šåœ¨ä»»ä½•ä½ç½®éƒ½æ˜¯å¯ä»¥è¿›è¡Œæ•°æ®å½’ä¸€åŒ–ï¼Œåœ¨ç¥žç»ç½‘ç»œé‡Œä¸Šä¸€å±‚ç½‘ç»œçš„è¾“å‡ºæ­£å¥½å°±æ˜¯ä¸‹ä¸€å±‚ç½‘ç»œçš„è¾“å…¥ ä¼˜ç‚¹ åŠ é€Ÿæ”¶æ•›ï¼šå½’ä¸€åŒ–æ“ä½œå¯ä»¥å‡å°‘ç½‘ç»œä¸­ä¸ç¨³å®šçš„å› ç´ ï¼Œæœ‰åŠ©äºŽæ¢¯åº¦çš„ä¼ æ’­å’Œæ”¶æ•›ã€‚å®ƒä½¿å¾—ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ›´å®¹æ˜“ä¼˜åŒ–ï¼ŒåŠ é€Ÿäº†è®­ç»ƒçš„é€Ÿåº¦ å‡å°‘æ¢¯åº¦å¼¥æ•£é—®é¢˜ï¼šç¥žç»ç½‘ç»œåœ¨æ·±å±‚æ—¶å®¹æ˜“å‡ºçŽ°æ¢¯åº¦æ¶ˆå¤±æˆ–æ¢¯åº¦çˆ†ç‚¸çš„é—®é¢˜ã€‚Batch Normalizationé€šè¿‡å°†æ•°æ®å½’ä¸€åŒ–åˆ°ä¸€ä¸ªåˆé€‚çš„èŒƒå›´ï¼Œä½¿å¾—æ¿€æ´»å‡½æ•°çš„è¾“å…¥æ›´åŠ ç¨³å®šï¼Œå‡å°‘äº†æ¢¯åº¦æ¶ˆå¤±çš„é£Žé™© æé«˜æ³›åŒ–èƒ½åŠ›ï¼šBatch Normalizationä½œä¸ºä¸€ç§æ­£åˆ™åŒ–æ–¹æ³•ï¼Œæœ‰åŠ©äºŽå‡å°‘è¿‡æ‹Ÿåˆçš„é£Žé™©ã€‚é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥ä¸€äº›å™ªå£°ï¼Œå®ƒå¯ä»¥æé«˜æ¨¡åž‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä½¿å¾—ç½‘ç»œå¯¹è¾“å…¥æ•°æ®çš„å˜åŒ–æ›´åŠ é²æ£’ Batch Normalizationåœ¨æ¯ä¸ªå°æ‰¹é‡è®­ç»ƒæ ·æœ¬ä¸­å¯¹è¾“å…¥è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä½¿å…¶å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ–¹å·® å›¾åƒä¸‹çš„BNç¤ºä¾‹ ä¸‹å›¾å±•ç¤ºäº†ä¸€ä¸ªbatch sizeä¸º2(ä¸¤å¼ å›¾ç‰‡ï¼Œæ¯å¼ å›¾ç‰‡æœ‰3ä¸ªé€šé“ï¼Œå…¶ä¸­é¢œè‰²çº¢ï¼Œç»¿ï¼Œè“åˆ†åˆ«ä»£è¡¨r,g,bé€šé“)çš„Batch Normalizationçš„åŽŸç†ï¼Œé¦–å…ˆä¼šç»Ÿè®¡æ¯ä¸ªé€šé“æ•°ç›®æ‰€æœ‰ç‚¹çš„åƒç´ å€¼ï¼Œæ±‚å¾—å‡å€¼å’Œæ–¹å·®ï¼Œç„¶åŽåœ¨æ¯ä¸ªé€šé“ä¸Šåˆ†åˆ«ç”¨è¯¥ç‚¹çš„åƒç´ å€¼å‡å‡å€¼é™¤æ–¹å·®å¾—åˆ°è¯¥ç‚¹çš„åƒç´ å€¼ï¼Œæ­¤è¿‡ç¨‹å°±æ˜¯BNã€‚æœ€åŽå°†å…¶æŽ¥å…¥åˆ°æ¿€æ´»å‡½æ•°ä¸­ å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¶ä¸­çº¢ï¼Œç»¿ï¼Œè“åˆ†åˆ«ä»£è¡¨å›¾åƒä¸åŒçš„é€šé“ï¼Œå‡è®¾å‡è®¾feature map1ã€feature map2åˆ†åˆ«æ˜¯ç”±image1ã€image2ç»è¿‡ä¸€ç³»åˆ—å·ç§¯æ± åŒ–åŽå¾—åˆ°çš„ç‰¹å¾çŸ©é˜µ å…¶ä¸­æ¯ä¸ªç½‘æ ¼çš„å€¼ä»£è¡¨è¯¥ç‚¹çš„åƒç´ å€¼ï¼Œåˆ†åˆ«ç»Ÿè®¡feature map1å’Œfeature map2æ¯ä¸ªé€šé“çš„åƒç´ å€¼ï¼Œå¾—åˆ°ä¸€ä¸ªçŸ©é˜µï¼Œåœ¨ä½¿ç”¨BNçš„è®¡ç®—å…¬å¼è®¡ç®—ç»è¿‡BNä»¥åŽæ¯ä¸ªé€šé“æ¯ä¸ªåƒç´ ç‚¹çš„åƒç´ å€¼ å®šä¹‰xä¸ºä»¥ä¸‹çŸ©é˜µ \\begin{array}{l}x^{(1)}=\\{1,1,1,2,0,-1,2,2\\} \\\\ x^{(2)}=\\{-1,1,0,1,0,-1,3,1\\} \\\\ x^{(3)}=\\{2,1,1,2,1,2,-1,0\\}\\end{array} å¯ä»¥è®¡ç®—å¾—åˆ°\\muå’Œ\\sigma ^2 \\begin{array}{l}\\mu_{1}=\\frac{1}{m} \\sum_{i=1}^{m} x_{i}^{(1)}=1 \\\\ \\mu_{2}=\\frac{1}{m} \\sum_{i=1}^{m} x_{i}^{(2)}=0.5 \\\\ \\mu_{3}=\\frac{1}{m} \\sum_{i=1}^{m} x_{i}^{(3)}=1 \\\\ \\sigma_{1}^{2}=\\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}^{(1)}-u_{1}\\right)^{2}=1 \\\\ \\sigma_{2}^{2}=\\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}^{(2)}-u_{2}\\right)^{2}=1.5 \\\\ \\sigma_{3}^{2}=\\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}^{(3)}-u_{3}\\right)^{2}=1 \\end{array} å³å¾—åˆ°å‡å€¼å’Œæ–¹å·®ä¸º\\mu=\\left[\\begin{array}{c}1 \\\\ 0.5 \\\\ 1\\end{array}\\right]å’Œ\\sigma^{2}=\\left[\\begin{array}{c}1 \\\\ 1.5 \\\\ 1\\end{array}\\right] è¿™æœ‰åŠ©äºŽè§£å†³è®­ç»ƒè¿‡ç¨‹ä¸­çš„å†…éƒ¨åå˜é‡åç§»(Internal Covariate Shift)é—®é¢˜ï¼Œå³ç½‘ç»œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¯ä¸€å±‚çš„è¾“å…¥åˆ†å¸ƒå‘ç”Ÿå˜åŒ–ï¼Œå¯¼è‡´ç½‘ç»œçš„è®­ç»ƒå˜å¾—å›°éš¾ ä»£ç ç¤ºä¾‹ import torch.nn as nn import torch data = [[[1, 2, 5], [2, 5, 8.5], [3, 3, 3]], [[2, 8, 4], [1, 3, 9], [2, 6, 4]], [[1, 1, 1], [1, 3, 5], [0.5, 6, 0.2]]] data = torch.tensor(data) data_bn = nn.BatchNorm1d(3)(data) data_ln = nn.LayerNorm(3)(data) mean = torch.sum(data_bn) mu = torch.sum(th.pow(data_bn - mean, 2) / 27) print(data_bn) print(mean) print(mu) >>> tensor([[[-0.7734, -0.3384, 0.9667], [-0.7714, 0.2967, 1.5428], [-0.0400, -0.0400, -0.0400]], [[-0.3384, 2.2718, 0.5317], [-1.1274, -0.4154, 1.7208], [-0.5542, 1.5027, 0.4742]], [[-0.7734, -0.7734, -0.7734], [-1.1274, -0.4154, 0.2967], [-1.3256, 1.5027, -1.4798]]], grad_fn=) tensor(-5.9605e-07, grad_fn=) # çº¦ç­‰äºŽ0 tensor(1.0000, grad_fn=) å±‚å½’ä¸€åŒ– æ·±åº¦å­¦ä¹ åŸºç¡€ä¹‹BatchNormå’ŒLayerNorm ä¸ºä»€ä¹ˆTransformerä½¿ç”¨LayerNorm ï¼Œè€Œä¸ä½¿ç”¨BatchNorm BNçš„ç‰¹ç‚¹æ˜¯å¼ºè¡Œæ‹‰å¹³æ•°æ®ä¹‹é—´çš„åˆ†å¸ƒï¼Œä½¿å¾—æ¨¡åž‹æ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”èµ·åˆ°äº†æ­£åˆ™åŒ–çš„ä½œç”¨ï¼Œä½¿æ¨¡åž‹æ•ˆæžœæ›´ä½³ã€‚ä½†æ˜¯ï¼ŒBatchNormå¯¹Batch Sizeå¤§å°å¾ˆæ•æ„Ÿï¼Œå¹¶ä¸”åœ¨LSTMç½‘ç»œä¸Šæ•ˆæžœæžå·®ã€‚ LayerNormæ˜¯æ¨ªå‘å½’ä¸€åŒ–ï¼Œä¸å—Batch Sizeå¤§å°çš„å½±å“ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå¥½åœ°åº”ç”¨åœ¨æ—¶åºæ•°æ®ä¸­ï¼Œè€Œä¸”ä¸éœ€è¦é¢å¤–çš„å‚¨å­˜ç©ºé—´ã€‚ ã€ŠRethinking Batch Normalization in Transformersã€‹ä¸€æ–‡å¯¹æ¯”äº†LayerNormå’ŒBatchNormå¯¹äºŽTransformerçš„ä½œç”¨ï¼Œå¹¶ä¸”æå‡ºäº†ä¸€ç§æ–°çš„å½’ä¸€åŒ–æ–¹å¼ æ‰¹å½’ä¸€åŒ–å’Œå±‚å½’ä¸€åŒ–æ¯”è¾ƒ é€‚ç”¨åœºæ™¯ batch norm: é€‚ç”¨äºŽCVï¼Œå› ä¸ºè®¡ç®—æœºè§†è§‰å–‚å…¥çš„æ•°æ®éƒ½æ˜¯åƒç´ ç‚¹ï¼Œå¯ä»¥è¯´æ•°æ®ç‚¹ä¸Žç‚¹ä¹‹é—´æ˜¯å¯ä»¥æ¯”è¾ƒçš„ï¼Œæ‰€ä»¥ä½¿ç”¨batch normå¯ä»¥æœ‰æ¯”è¾ƒå¥½çš„æ•ˆæžœï¼Œ layer norm: NLPé‡Œï¼Œæ¯ä¸ªè¯çš„è¯å‘é‡æ˜¯ä¸€ç»„å‘é‡è¡¨ç¤ºä¸€ä¸ªè¯ï¼Œä¸€ä¸ªè¯å‘é‡å‰²è£‚å¼€æ¥çœ‹æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼Œå› æ­¤ä¸åŒè¯å‘é‡é‡Œçš„æ•°æ®ç‚¹æ˜¯ä¸èƒ½æ··ä¸ºä¸€è°ˆçš„ æ‰€ä»¥batch normä¹‹åŽå¯èƒ½ä¼šä½¿å¾—è¯æŸå¤±è¯­ä¹‰ï¼Œæ•ˆæžœå°±å¯èƒ½ä¸å¥½äº†ï¼Œä½†æ˜¯ä½¿ç”¨layer normåªæ˜¯è®©å„ä¸ªè¯å‘é‡è¿›è¡Œæ ‡å‡†åŒ–ï¼Œå°±èƒ½å¤Ÿæœ‰æ¯”è¾ƒç†æƒ³çš„æ•ˆæžœäº† å½’ä¸€åŒ–ç»´åº¦ batch norm: ä»¥CVä¸ºä¾‹ï¼Œå½’ä¸€åŒ–çš„æ˜¯ç›¸åŒé€šé“ï¼Œå‡å€¼å’Œæ–¹å·®è®¡ç®—æ˜¯æ¯ä¸ªé€šé“çš„å€¼ layer norm: ä»¥NLPä¸ºä¾‹ï¼Œå½’ä¸€åŒ–çš„æ¯ä¸ªè¯å‘é‡ï¼Œä¸€ä¸ªè¯å‘é‡è‡ªå·±åšå½’ä¸€åŒ– å®žä¾‹å½’ä¸€åŒ– ç­‰å¾…... ç»„å½’ä¸€åŒ– def GroupNorm(x, gamma, beta, G, eps=1e-5): # x: input features with shape [N,C,H,W] # gamma, beta: scale and offset, with shape [1,C,1,1] # G: number of groups for GN N, C, H, W = x.shape x = tf.reshape(x, [N, G, C // G, H, W]) mean, var = tf.nn.moments(x, [2, 3, 4], keepdims=True) x = (x - mean) / tf.sqrt(var + eps) x = tf.reshape(x, [N, C, H, W]) return x * gamma + beta Embeddingå±‚ ç­‰å¾…... Dropoutå±‚ ç­‰å¾…... æŒ‡æ ‡ ç­‰å¾…... Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/æ·±åº¦å­¦ä¹ æ¨¡åž‹åŽ‹ç¼©æŠ€æœ¯.html":{"url":"chapters/æ·±åº¦å­¦ä¹ æ¨¡åž‹åŽ‹ç¼©æŠ€æœ¯.html","title":"æ·±åº¦å­¦ä¹ æ¨¡åž‹åŽ‹ç¼©æŠ€æœ¯.md","summary":"æ·±åº¦å­¦ä¹ æ¨¡åž‹åŽ‹ç¼©æŠ€æœ¯","keywords":"","body":"æ¨¡åž‹åŽ‹ç¼©æ¦‚è¿°å‚æ•°å‰ªæžæƒé‡å…±äº«ä½Žç§©è¿‘ä¼¼çŸ¥è¯†è’¸é¦æ¦‚è¿°è’¸é¦çš„ç›®çš„è’¸é¦æœºåˆ¶ç¦»çº¿è’¸é¦åœ¨çº¿è’¸é¦è‡ªè’¸é¦æ¸©åº¦å‚æ•°ç½‘ç»œé‡åŒ–ç½‘ç»œå‰ªæžç½‘ç»œè’¸é¦ æ¨¡åž‹åŽ‹ç¼© æ¦‚è¿° æ·±åº¦å­¦ä¹ æ¨¡åž‹åŽ‹ç¼©ä¸ŽåŠ é€Ÿä¸ƒå¤§æ–¹æ³•æ€»ç»“ï¼ éšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ä¸Žé«˜æ€§èƒ½GPUå¤„ç†èƒ½åŠ›çš„å¢žå¼ºï¼Œç¥žç»ç½‘ç»œç»“æž„å˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œæ¨¡åž‹å‚æ•°é‡ä¹Ÿè¶Šæ¥è¶Šåºžå¤§ï¼Œè¿™ä½¿å¾—æ·±åº¦å­¦ä¹ åœ¨ç§»åŠ¨åµŒå…¥å¼è®¾å¤‡ä¸Šçš„éƒ¨ç½²é‡åˆ°å·¨å¤§çš„å›°éš¾å’ŒæŒ‘æˆ˜ å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸å½±å“æ·±åº¦å­¦ä¹ æ¨¡åž‹æ€§èƒ½çš„æƒ…å†µä¸‹è¿›è¡Œæ¨¡åž‹åŽ‹ç¼©ä¸ŽåŠ é€Ÿæˆä¸ºäº†ç ”ç©¶çƒ­ç‚¹ åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ¨¡åž‹åŽ‹ç¼©æ˜¯ä¸€ç§é€šè¿‡å‡å°æ¨¡åž‹çš„å¤§å°ã€å‚æ•°æ•°é‡æˆ–è®¡ç®—é‡æ¥é™ä½Žæ¨¡åž‹å¤æ‚åº¦çš„æŠ€æœ¯ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å¸¸è§çš„æ¨¡åž‹åŽ‹ç¼©æŠ€æœ¯ï¼š å‚æ•°å‰ªæž(Pruning)ï¼šé€šè¿‡å‰ªé™¤æ¨¡åž‹ä¸­ä¸é‡è¦çš„è¿žæŽ¥æˆ–å‚æ•°ï¼Œå‡å°‘æ¨¡åž‹çš„å‚æ•°æ•°é‡å’Œè®¡ç®—é‡ã€‚å‰ªæžå¯ä»¥åŸºäºŽæƒé‡çš„é‡è¦æ€§è¿›è¡Œï¼Œå‰ªé™¤è¾ƒå°çš„æƒé‡æˆ–é€šè¿‡ç¨€ç–åŒ–æŠ€æœ¯å°†æƒé‡è®¾ç½®ä¸ºé›¶ æƒé‡å…±äº«(Weight Sharing)ï¼šå°†æ¨¡åž‹ä¸­çš„ä¸€äº›æƒé‡å…±äº«ï¼Œå‡å°‘æ¨¡åž‹ä¸­éœ€è¦å­˜å‚¨çš„å‚æ•°æ•°é‡ã€‚è¿™å¯ä»¥é€šè¿‡å¯¹æƒé‡è¿›è¡Œèšç±»æˆ–ä½¿ç”¨å“ˆå¸Œå‡½æ•°å°†ç›¸ä¼¼çš„æƒé‡æ˜ å°„åˆ°åŒä¸€ä¸ªå€¼æ¥å®žçŽ° ä½Žç§©è¿‘ä¼¼(Low-Rank Approximation)ï¼šé€šè¿‡å°†æ¨¡åž‹çš„æƒé‡çŸ©é˜µåˆ†è§£ä¸ºè¾ƒä½Žç§©çš„çŸ©é˜µä¹˜ç§¯å½¢å¼ï¼Œå‡å°‘æ¨¡åž‹çš„å‚æ•°æ•°é‡ã€‚å¸¸è§çš„æ–¹æ³•åŒ…æ‹¬å¥‡å¼‚å€¼åˆ†è§£(SVD)å’ŒçŸ©é˜µåˆ†è§£æŠ€æœ¯ çŸ¥è¯†è’¸é¦(Knowledge Distillation)ï¼šå°†ä¸€ä¸ªå¤æ‚çš„æ¨¡åž‹çš„çŸ¥è¯†ä¼ é€’ç»™ä¸€ä¸ªè¾ƒç®€å•çš„æ¨¡åž‹ï¼Œé€šè¿‡è®©å­¦ç”Ÿæ¨¡åž‹å­¦ä¹ æ•™å¸ˆæ¨¡åž‹çš„è¾“å‡ºæ¦‚çŽ‡åˆ†å¸ƒæˆ–ä¸­é—´è¡¨ç¤ºæ¥æé«˜å­¦ç”Ÿæ¨¡åž‹çš„æ€§èƒ½ ç½‘ç»œé‡åŒ–(Network Quantization)ï¼šå‡å°‘æ¨¡åž‹ä¸­å‚æ•°çš„ä½æ•°è¡¨ç¤ºï¼Œä¾‹å¦‚å°†æµ®ç‚¹æ•°å‚æ•°è½¬æ¢ä¸ºè¾ƒä½Žä½æ•°çš„æ•´æ•°è¡¨ç¤ºï¼Œä»Žè€Œå‡å°æ¨¡åž‹çš„å­˜å‚¨éœ€æ±‚å’Œè®¡ç®—å¤æ‚åº¦ ç½‘ç»œå‰ªæž(Network Pruning)ï¼šé™¤äº†å‰ªæžæƒé‡å’Œè¿žæŽ¥ä¹‹å¤–ï¼Œè¿˜å‰ªæžæ¨¡åž‹çš„ç½‘ç»œç»“æž„ã€‚è¿™åŒ…æ‹¬å‰ªæžå±‚ã€å‰ªæžé€šé“æˆ–å‰ªæžæ¨¡å—ç­‰ ç½‘ç»œè’¸é¦(Network Distillation)ï¼šç±»ä¼¼äºŽçŸ¥è¯†è’¸é¦ï¼Œä½†æ˜¯ä¸ä»…ä¼ é€’æ•™å¸ˆæ¨¡åž‹çš„è¾“å‡ºæ¦‚çŽ‡åˆ†å¸ƒæˆ–ä¸­é—´è¡¨ç¤ºï¼Œè¿˜ä¼ é€’æ•™å¸ˆæ¨¡åž‹çš„æ¿€æ´»å€¼æˆ–å…¶ä»–è¾…åŠ©ä¿¡æ¯ è¿™äº›æŠ€æœ¯å¯ä»¥å•ç‹¬åº”ç”¨æˆ–ç»“åˆä½¿ç”¨ï¼Œä»¥å‡å°æ·±åº¦å­¦ä¹ æ¨¡åž‹çš„å¤§å°ã€å¤æ‚åº¦å’Œè®¡ç®—éœ€æ±‚ï¼Œä»Žè€Œå®žçŽ°æ¨¡åž‹åŽ‹ç¼©å’ŒåŠ é€Ÿçš„æ•ˆæžœ å‚æ•°å‰ªæž å¯¹æ¨¡åž‹çš„ç½‘ç»œè¿›è¡Œä¿®å‰ªï¼Œæ¯”å¦‚å‡æŽ‰å¤šä½™çš„å¤´(å› ä¸ºTransformerä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶)ï¼Œæˆ–è€…ç›´æŽ¥ç²—æš´çš„ä½¿ç”¨æ›´å°‘çš„Transformerå±‚æ•° æƒé‡å…±äº« ç­‰å¾…... ä½Žç§©è¿‘ä¼¼ ç­‰å¾…... çŸ¥è¯†è’¸é¦ æ‰‹å†™æ•°å­—è¯†åˆ«ä¸­å¤šå…ƒåˆ†ç±»åŽŸç†_å¹¿å‘Šè¡Œä¸šä¸­é‚£äº›è¶£äº‹ç³»åˆ—21ï¼šä»Žç†è®ºåˆ°å®žæˆ˜BERTçŸ¥è¯†è’¸é¦... æ·±åº¦å­¦ä¹ ä¸­çš„çŸ¥è¯†è’¸é¦æŠ€æœ¯` ä¸€åˆ†é’Ÿå¸¦ä½ è®¤è¯†æ·±åº¦å­¦ä¹ ä¸­çš„çŸ¥è¯†è’¸é¦ æ¦‚è¿° çŸ¥è¯†è’¸é¦çš„æ¦‚å¿µæœ€æ—©æ˜¯2015å¹´Geoffrey Hintonåœ¨ã€ŠDistilling the Knowledge in a Neural Networkã€‹è¿™ç¯‡è®ºæ–‡ä¸­æå‡ºæ¥çš„ åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼ŒçŸ¥è¯†è’¸é¦(Knowledge Distillation)æŒ‡çš„æ˜¯å°†ä¸€ä¸ªå¤æ‚çš„æ¨¡åž‹(ç§°ä¸ºæ•™å¸ˆæ¨¡åž‹)çš„çŸ¥è¯†ä¼ é€’ç»™ä¸€ä¸ªè¾ƒç®€å•çš„æ¨¡åž‹(ç§°ä¸ºå­¦ç”Ÿæ¨¡åž‹)çš„è¿‡ç¨‹ è¿™ç§æ–¹æ³•æ—¨åœ¨é€šè¿‡è®­ç»ƒå­¦ç”Ÿæ¨¡åž‹ä½¿å…¶èƒ½å¤Ÿå­¦ä¹ æ•™å¸ˆæ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ› é€šå¸¸æƒ…å†µä¸‹ï¼Œæ•™å¸ˆæ¨¡åž‹æ˜¯ä¸€ä¸ªè¾ƒå¤§ã€å¤æ‚ã€å‡†ç¡®åº¦è¾ƒé«˜çš„æ¨¡åž‹ï¼Œè€Œå­¦ç”Ÿæ¨¡åž‹åˆ™æ˜¯ä¸€ä¸ªè¾ƒå°ã€ç®€åŒ–çš„æ¨¡åž‹ çŸ¥è¯†è’¸é¦é€šè¿‡è®©å­¦ç”Ÿæ¨¡åž‹å­¦ä¹ æ•™å¸ˆæ¨¡åž‹çš„è¾“å‡ºæ¦‚çŽ‡åˆ†å¸ƒæˆ–ä¸­é—´è¡¨ç¤ºï¼Œä»Žè€Œæé«˜å­¦ç”Ÿæ¨¡åž‹çš„æ€§èƒ½ã€‚è¿™ç§çŸ¥è¯†ä¼ é€’å¯ä»¥å¸®åŠ©å­¦ç”Ÿæ¨¡åž‹æ›´å¥½åœ°æ•æ‰æ•°æ®é›†çš„ç‰¹å¾ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”åœ¨å…·æœ‰è¾ƒå°‘è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å–å¾—è¾ƒå¥½çš„æ€§èƒ½ ä¾‹å­: TextCNNçŸ¥è¯†è’¸é¦ BERTè¿™ç±»å¤§æ¨¡åž‹ç²¾åº¦é«˜ä½†æ˜¯çº¿ä¸ŠæŽ¨ç†é€Ÿåº¦æ…¢ï¼Œä¼ ç»Ÿçš„æ–‡æœ¬åˆ†ç±»æ¨¡åž‹æ¯”å¦‚TextCNNç­‰çº¿ä¸ŠæŽ¨ç†é€Ÿåº¦å¿«(å› ä¸ºæ¨¡åž‹æ¯”è¾ƒå°)ä½†æ˜¯ç²¾åº¦æœ‰å¾…æå‡ã€‚é’ˆå¯¹ä¸Šé¢çš„é—®é¢˜ï¼Œæˆ‘ä»¬çš„éœ€æ±‚æ˜¯èŽ·å¾—åª²ç¾ŽBERTç­‰å¤§æ¨¡åž‹çš„ç²¾åº¦ï¼Œè¿˜èƒ½æ»¡è¶³çº¿ä¸ŠæŽ¨ç†é€Ÿåº¦çš„æ—¶å»¶è¦æ±‚ ä¸šåŠ¡ä¸­å¯ä»¥æŠŠBERTä½œä¸ºè€å¸ˆæ¨¡åž‹åŽ»æ•™ä½œä¸ºå­¦ç”Ÿæ¨¡åž‹çš„TextCNNæ¥å­¦ä¹ çŸ¥è¯†ï¼Œä»Žè€Œä½¿TextCNNä¸ä»…è¾¾åˆ°äº†åª²ç¾ŽBERTçš„åˆ†ç±»æ•ˆæžœï¼Œè€Œä¸”è¿˜èƒ½å¾ˆå¥½çš„æ»¡è¶³çº¿ä¸ŠæŽ¨ç†é€Ÿåº¦çš„è¦æ±‚ æš—çŸ¥è¯† å¯¹äºŽè€å¸ˆæˆ–è€…æ²¡æœ‰ä½¿ç”¨çŸ¥è¯†è’¸é¦çš„å°æ¨¡åž‹æ¥è¯´ï¼Œä¸»è¦æ˜¯é€šè¿‡è®­ç»ƒæ•°æ®æ¥å­¦ä¹ çŸ¥è¯†ã€‚æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†æ˜¯ä¸€å¼ ä¸€å¼ æ‰‹å†™æ•°å­—çš„å›¾ç‰‡ï¼Œè¿˜æœ‰å¯¹åº”0åˆ°9åä¸ªæ•°å­—çš„æ ‡ç­¾ã€‚åœ¨è¿™ç§å­¦ä¹ ä¸­æˆ‘ä»¬å¯ä»¥ç”¨çš„åªæœ‰åä¸ªç±»åˆ«å€¼ï¼Œæ¯”å¦‚ä¸€å¼ æ‰‹å†™æ•°å­—1çš„å›¾ç‰‡æ ·æœ¬çš„æ ‡ç­¾æ˜¯1ï¼Œå‘Šè¯‰æ¨¡åž‹çš„çŸ¥è¯†å°±æ˜¯è¿™ä¸ªæ ·æœ¬æ ‡ç­¾æ˜¯1ï¼Œä¸æ˜¯å…¶ä»–ç±»åˆ« è€Œä½¿ç”¨çŸ¥è¯†è’¸é¦çš„æ—¶å€™æ¨¡åž‹å¯ä»¥å­¦åˆ°æ›´å¤šçš„çŸ¥è¯†ï¼Œæ¯”å¦‚æ‰‹å†™æ•°å­—1çš„å›¾ç‰‡æ ·æœ¬æœ‰0.7çš„å¯èƒ½æ˜¯æ•°å­—1ï¼Œ0.2çš„å¯èƒ½æ˜¯æ•°å­—7ï¼Œè¿˜æœ‰0.1çš„å¯èƒ½æ˜¯æ•°å­—9 è¿™éžå¸¸æœ‰æ„æ€ï¼Œæ¨¡åž‹ä¸ä»…å­¦åˆ°äº†æ ‡ç­¾æœ¬èº«çš„çŸ¥è¯†ï¼Œè¿˜å­¦ä¹ åˆ°äº†æ ‡ç­¾ä¹‹é—´çš„å…³è”çŸ¥è¯†ï¼Œå°±æ˜¯1å’Œ7ã€9å¯èƒ½å­˜åœ¨æŸäº›å…³è”ï¼Œè¿™äº›çŸ¥è¯†ç§°ä¸ºæš—çŸ¥è¯† å…¶ä»–çš„è’¸é¦ å¯¹æŠ—è’¸é¦ã€å¤šæ•™å¸ˆè’¸é¦ã€è·¨æ¨¡æ€è’¸é¦ã€æ— æ•°æ®è’¸é¦ è’¸é¦çš„ç›®çš„ æ¨¡åž‹åŽ‹ç¼©(Model Compression)ï¼šé€šè¿‡çŸ¥è¯†è’¸é¦ï¼Œå¯ä»¥å°†ä¸€ä¸ªè¾ƒå¤§ã€å¤æ‚çš„æ¨¡åž‹åŽ‹ç¼©æˆä¸€ä¸ªæ›´å°ã€è½»é‡çº§çš„æ¨¡åž‹ï¼Œå‡å°‘æ¨¡åž‹çš„å­˜å‚¨ç©ºé—´å’Œè®¡ç®—èµ„æºçš„æ¶ˆè€—ã€‚è¿™ä½¿å¾—æ¨¡åž‹å¯ä»¥åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œï¼ŒåŒæ—¶ä»ä¿æŒè¾ƒé«˜çš„æ€§èƒ½ æ¨¡åž‹åŠ é€Ÿ(Model Acceleration)ï¼šçŸ¥è¯†è’¸é¦å¯ä»¥åŠ é€Ÿæ¨¡åž‹çš„æŽ¨ç†è¿‡ç¨‹ï¼Œä½¿å¾—æ¨¡åž‹åœ¨å®žæ—¶æ€§è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ä¸­èƒ½å¤Ÿæ›´å¿«åœ°è¿›è¡Œé¢„æµ‹ã€‚é€šè¿‡å°†è¾ƒå¤æ‚çš„æ¨¡åž‹çš„çŸ¥è¯†è½¬ç§»ç»™ç®€åŒ–çš„æ¨¡åž‹ï¼Œå¯ä»¥åŠ å¿«æŽ¨ç†é€Ÿåº¦ æå‡æ³›åŒ–èƒ½åŠ›(Improving Generalization)ï¼šçŸ¥è¯†è’¸é¦å¯ä»¥é€šè¿‡å°†ä¸€ä¸ªå¤æ‚æ¨¡åž‹çš„çŸ¥è¯†ä¼ é€’ç»™ä¸€ä¸ªç®€åŒ–æ¨¡åž‹ï¼Œå¸®åŠ©ç®€åŒ–æ¨¡åž‹å­¦ä¹ åˆ°æ›´å¥½çš„ç‰¹å¾è¡¨ç¤ºå’Œæ³›åŒ–èƒ½åŠ›ã€‚è¾ƒå¤æ‚çš„æ¨¡åž‹é€šå¸¸å…·æœ‰æ›´å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›å’Œè¡¨è¾¾èƒ½åŠ›ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦ï¼Œè¿™äº›èƒ½åŠ›å¯ä»¥ä¼ é€’ç»™ç®€åŒ–æ¨¡åž‹ï¼Œæå‡å…¶æ³›åŒ–æ€§èƒ½ è¿ç§»å­¦ä¹ (Transfer Learning)ï¼šçŸ¥è¯†è’¸é¦å¯ä»¥é€šè¿‡å°†ä¸€ä¸ªåœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒè¿‡çš„å¤æ‚æ¨¡åž‹çš„çŸ¥è¯†è¿ç§»åˆ°ä¸€ä¸ªç›¸ä¼¼ä»»åŠ¡çš„ç®€åŒ–æ¨¡åž‹ä¸Šï¼Œä»Žè€ŒåŠ å¿«ç®€åŒ–æ¨¡åž‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„å­¦ä¹ é€Ÿåº¦å’Œæ€§èƒ½ æ€»ä¹‹ï¼ŒçŸ¥è¯†è’¸é¦çš„ä¸»è¦ç›®çš„æ˜¯é€šè¿‡å°†ä¸€ä¸ªå¤æ‚æ¨¡åž‹çš„çŸ¥è¯†è½¬ç§»åˆ°ä¸€ä¸ªç®€åŒ–æ¨¡åž‹ä¸Šï¼Œä»Žè€Œå®žçŽ°æ¨¡åž‹åŽ‹ç¼©ã€åŠ é€Ÿã€æå‡æ³›åŒ–èƒ½åŠ›å’Œè¿ç§»å­¦ä¹ ç­‰ç›®æ ‡ è’¸é¦æœºåˆ¶ ã€æ·±åº¦å­¦ä¹ ã€‘ï¼ˆä¸€ï¼‰çŸ¥è¯†è’¸é¦ æ ¹æ®æ•™å¸ˆç½‘ç»œæ˜¯å¦å’Œå­¦ç”Ÿç½‘ç»œä¸€èµ·æ›´æ–°ï¼Œå¯ä»¥åˆ†ä¸ºç¦»çº¿è’¸é¦ï¼Œåœ¨çº¿è’¸é¦å’Œè‡ªè’¸é¦ æ„Ÿæ€§ä¸Šç†è§£ä¸‰ç§è’¸é¦æ–¹å¼ï¼š ç¦»çº¿è’¸é¦(Offline Distillation): å¯ä»¥ç†è§£ä¸ºçŸ¥è¯†æ¸Šåšçš„è€å¸ˆç»™å­¦ç”Ÿä¼ æŽˆçŸ¥è¯† åœ¨çº¿è’¸é¦(Online Distillation): å¯ä»¥ç†è§£ä¸ºæ•™å¸ˆå’Œå­¦ç”Ÿä¸€èµ·å­¦ä¹  è‡ªè’¸é¦(Self-Distillation): æ„å‘³ç€å­¦ç”Ÿè‡ªå·±å­¦ä¹ çŸ¥è¯† ç¦»çº¿è’¸é¦ æ—©æœŸçš„çŸ¥è¯†è’¸é¦æ–¹æ³•éƒ½å±žäºŽç¦»çº¿è’¸é¦ï¼Œå°†ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„æ•™å¸ˆæ¨¡åž‹çš„çŸ¥è¯†è¿ç§»åˆ°å­¦ç”Ÿç½‘ç»œï¼Œæ‰€ä»¥é€šå¸¸åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼š åœ¨è’¸é¦å‰ï¼Œæ•™å¸ˆç½‘ç»œåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œè®­ç»ƒ æ•™å¸ˆç½‘ç»œé€šè¿‡logitså±‚ä¿¡æ¯æˆ–è€…ä¸­é—´å±‚ä¿¡æ¯æå–çŸ¥è¯†ï¼Œå¼•å¯¼å­¦ç”Ÿç½‘ç»œçš„è®­ç»ƒ ç¬¬ä¸€ä¸ªé˜¶æ®µé€šå¸¸ä¸è¢«è®¤ä¸ºå±žäºŽçŸ¥è¯†è’¸é¦çš„ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºé»˜è®¤æ•™å¸ˆç½‘ç»œæœ¬èº«å°±æ˜¯å·²ç»é¢„è®­ç»ƒå¥½çš„ ä¸€èˆ¬ç¦»çº¿è’¸é¦ç®—æ³•å…³æ³¨ä¸Žæå‡çŸ¥è¯†è¿ç§»çš„ä¸åŒéƒ¨åˆ†ï¼ŒåŒ…æ‹¬ï¼šçŸ¥è¯†çš„å½¢å¼ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œåˆ†å¸ƒçš„åŒ¹é… ä¼˜ç‚¹ å®žçŽ°èµ·æ¥æ¯”è¾ƒç®€å•ï¼Œå½¢å¼ä¸Šé€šå¸¸æ˜¯å•å‘çš„çŸ¥è¯†è¿ç§»(å³ä»Žæ•™å¸ˆç½‘ç»œåˆ°å­¦ç”Ÿç½‘ç»œ)ï¼ŒåŒæ—¶éœ€è¦ä¸¤ä¸ªé˜¶æ®µçš„è®­ç»ƒ(è®­ç»ƒæ•™å¸ˆç½‘ç»œå’ŒçŸ¥è¯†è’¸é¦) ç¼ºç‚¹ æ•™å¸ˆç½‘ç»œé€šå¸¸å®¹é‡å¤§ï¼Œæ¨¡åž‹å¤æ‚ï¼Œéœ€è¦å¤§é‡è®­ç»ƒæ—¶é—´ï¼Œè¿˜éœ€è¦æ³¨æ„æ•™å¸ˆç½‘ç»œå’Œå­¦ç”Ÿç½‘ç»œä¹‹é—´çš„å®¹é‡å·®å¼‚ï¼Œå½“å®¹é‡å·®å¼‚è¿‡å¤§çš„æ—¶å€™ï¼Œå­¦ç”Ÿç½‘ç»œå¯èƒ½å¾ˆéš¾å­¦ä¹ å¥½è¿™äº›çŸ¥è¯† åœ¨çº¿è’¸é¦ æ•™å¸ˆæ¨¡åž‹å’Œå­¦ç”Ÿæ¨¡åž‹éƒ½æ˜¯to be trainedçš„çŠ¶æ€ï¼Œå³æ•™å¸ˆæ¨¡åž‹å¹¶æ²¡æœ‰é¢„è®­ç»ƒ åœ¨å¤§å®¹é‡æ•™å¸ˆç½‘ç»œæ²¡æœ‰çŽ°æˆæ¨¡åž‹çš„æ—¶å€™ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨online distillationã€‚ä½¿ç”¨åœ¨çº¿è’¸é¦çš„æ—¶å€™ï¼Œæ•™å¸ˆç½‘ç»œå’Œå­¦ç”Ÿç½‘ç»œçš„å‚æ•°ä¼šåŒæ—¶æ›´æ–°ï¼Œæ•´ä¸ªçŸ¥è¯†è’¸é¦æ¡†æž¶æ˜¯ç«¯åˆ°ç«¯è®­ç»ƒçš„ å¯ä»¥å‚è€ƒæœ¬ç«™å›¾åƒåˆ†ç±»ç®—æ³•ç« èŠ‚ä¸‹çš„DeiTModelï¼ŒDeiTModelæ¨¡åž‹æ˜¯å¯¹Vitæ¨¡åž‹çš„æ”¹è¿›å’Œä¼˜åŒ–ï¼Œä½¿ç”¨äº†åœ¨çº¿è’¸é¦ç­–ç•¥(è¿˜æ˜¯ç¦»çº¿?) è‡ªè’¸é¦ è‡ªè’¸é¦ä¸­ï¼Œæ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡åž‹ä½¿ç”¨ç›¸åŒçš„ç½‘ç»œã€‚è‡ªè’¸é¦å¯ä»¥çœ‹ä½œæ˜¯åœ¨çº¿è’¸é¦çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼Œå› ä¸ºæ•™å¸ˆç½‘ç»œå’Œå­¦ç”Ÿç½‘ç»œä½¿ç”¨çš„æ˜¯ç›¸åŒçš„æ¨¡åž‹ æ¸©åº¦å‚æ•° ç­‰å¾…... ç½‘ç»œé‡åŒ– ç­‰å¾…... ç½‘ç»œå‰ªæž ç­‰å¾…... ç½‘ç»œè’¸é¦ ç­‰å¾…... Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "},"chapters/ç›®æ ‡æ£€æµ‹ä¸Žè·Ÿè¸ªç®—æ³•.html":{"url":"chapters/ç›®æ ‡æ£€æµ‹ä¸Žè·Ÿè¸ªç®—æ³•.html","title":"ç›®æ ‡æ£€æµ‹ä¸Žè·Ÿè¸ªç®—æ³•.md","summary":"ç›®æ ‡æ£€æµ‹ä¸Žè·Ÿè¸ªç®—æ³•","keywords":"","body":"ç›®æ ‡æ£€æµ‹æ¦‚è¿°æŒ‡æ ‡å’Œæ•°æ®RCNNç³»åˆ—rcnnspp-netfast-rcnnfaster-rcnnYoloç³»åˆ—Yolov1ç½‘ç»œç»“æž„lossYolov2(Yolo9000)yolov3yolov5Yolov8å…¶ä»–æ£€æµ‹ç³»åˆ—SSDFPNRetinaNetDETRç›®æ ‡è·Ÿè¸ªSortDeepSortStrongSortBotSortByteTrackä¾èµ–çš„ç®—æ³•å¡å°”æ›¼æ»¤æ³¢åŒˆç‰™åˆ©åŒ¹é…ç®—æ³•è¿½è¸ªæŒ‡æ ‡ ç›®æ ‡æ£€æµ‹ ç»å…¸ç›®æ ‡æ£€æµ‹Object Detectionæ¨¡åž‹æ•´ç† æ·±å…¥æµ…å‡ºYoloç³»åˆ—ä¹‹Yolov5æ ¸å¿ƒåŸºç¡€çŸ¥è¯†å®Œæ•´è®²è§£ ç›®æ ‡æ£€æµ‹ YOLOç³»åˆ—ç®—æ³• Object Detection in 20 Years: A Survey è®ºæ–‡è¯¦è§£ R-CNNå²ä¸Šæœ€å…¨è®²è§£ YOLOv1è®ºæ–‡ç¿»è¯‘è§£è¯» YOLO v4ï¼šç‰©ä½“æ£€æµ‹çš„æœ€ä½³é€Ÿåº¦å’Œç²¾åº¦ Yoloç³»åˆ—ä»£ç  æ¦‚è¿° ç›®æ ‡æ£€æµ‹â€”â€”RCNNä¸ŽYOLOç³»åˆ— æ ¸å¿ƒé—®é¢˜ åˆ†ç±»é—®é¢˜ï¼šå³å›¾ç‰‡(æˆ–æŸä¸ªåŒºåŸŸ)ä¸­çš„å›¾åƒå±žäºŽå“ªä¸ªç±»åˆ« å®šä½é—®é¢˜ï¼šç›®æ ‡å¯èƒ½å‡ºçŽ°åœ¨å›¾åƒçš„ä»»ä½•ä½ç½® å¤§å°é—®é¢˜ï¼šç›®æ ‡æœ‰å„ç§ä¸åŒçš„å¤§å° å½¢çŠ¶é—®é¢˜ï¼šç›®æ ‡å¯èƒ½æœ‰å„ç§ä¸åŒçš„å½¢çŠ¶ ç®—æ³•åˆ†ç±» Anchor Basedæ¨¡åž‹ Anchor Freeæ¨¡åž‹ One-stageæ¨¡åž‹ YoloV2-5ç³»åˆ—ã€SSDã€RetinaNet YoloV1ã€FCOSã€CornerNet Two-stageæ¨¡åž‹ Faster RCNNã€Cascade RCNNã€MaskRCNN two stageï¼š å…ˆè¿›è¡ŒåŒºåŸŸç”Ÿæˆï¼Œè¯¥åŒºåŸŸç§°ä¸ºregion proposalï¼ˆRPï¼Œä¸€ä¸ªæœ‰å¯èƒ½åŒ…å«ç‰©ä½“çš„é¢„é€‰æ¡†ï¼‰ï¼›å†é€šè¿‡å·ç§¯ç¥žç»ç½‘ç»œè¿›è¡Œæ ·æœ¬åˆ†ç±» ä»»åŠ¡æµç¨‹ï¼šç‰¹å¾æå–â€”ç”ŸæˆRPâ€”åˆ†ç±»/å®šä½å›žå½’ å¸¸è§two stageï¼šR-CNNã€SPP-Netã€Fast R-CNNã€Faster R-CNNã€R-FCN one stageï¼š ä¸ç”¨RPï¼Œç›´æŽ¥åœ¨ç½‘ç»œä¸­æå–ç‰¹å¾æ¥é¢„æµ‹ç‰©ä½“çš„åˆ†ç±»å’Œä½ç½® ä»»åŠ¡æµç¨‹ï¼šç‰¹å¾æå–â€”åˆ†ç±»/å®šä½å›žå½’ å¸¸è§one stageï¼šOverFeatã€YOLOv1ã€YOLOv2ã€YOLOv3ã€SSDã€RetinaNet ç›®æ ‡æ£€æµ‹åˆ†ä¸ºä¸¤å¤§ç³»åˆ—â€”â€”RCNNç³»åˆ—å’ŒYOLOç³»åˆ—ï¼š RCNNç³»åˆ—æ˜¯åŸºäºŽåŒºåŸŸæ£€æµ‹çš„ä»£è¡¨æ€§ç®—æ³• YOLOæ˜¯åŸºäºŽåŒºåŸŸæå–çš„ä»£è¡¨æ€§ç®—æ³• è¿˜æœ‰è‘—åçš„SSDæ˜¯åŸºäºŽå‰ä¸¤ä¸ªç³»åˆ—çš„æ”¹è¿› å‘å±•è„‰ç»œ 2014 2015 2016 2017 2018 R-CNN Fast R-CNNFaster R-CNNYOLO YOLOSSD YOLOv2RetinaNetMask R-CNNFPN YOLOv3Cascade R-CNN 2020 2022 2023 YOLOv4YOLOv5EfficientDet YOLOv6(ç¾Žå›¢)YOLOv7 YOLOv8 æŒ‡æ ‡å’Œæ•°æ® mapæŒ‡æ ‡ mAPâ€”ç›®æ ‡æ£€æµ‹æ¨¡åž‹çš„è¯„ä¼°æŒ‡æ ‡ YOLO æ¨¡åž‹çš„è¯„ä¼°æŒ‡æ ‡â€”â€”IOUã€Precisionã€Recallã€F1-scoreã€mAP mAP@0.5 åœ¨YOLOæ¨¡åž‹ä¸­ï¼Œä½ ä¼šè§åˆ°mAP@0.5è¿™æ ·çš„è¡¨çŽ°å½¢å¼ï¼Œè¿™ç§å½¢å¼è¡¨ç¤ºåœ¨IOUé˜ˆå€¼ä¸º0.5çš„æƒ…å†µä¸‹ï¼ŒmAPçš„å€¼ä¸ºå¤šå°‘ã€‚å½“é¢„æµ‹æ¡†ä¸Žæ ‡æ³¨æ¡†çš„IOUå¤§äºŽ0.5æ—¶ï¼Œå°±è®¤ä¸ºè¿™ä¸ªå¯¹è±¡é¢„æµ‹æ­£ç¡®ï¼Œåœ¨è¿™ä¸ªå‰æä¸‹å†åŽ»è®¡ç®—mAPã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒmAP@0.5å³ä¸ºè¯„ä»·YOLOæ¨¡åž‹çš„æŒ‡æ ‡ä¹‹ä¸€ mAP@[0.5:0.95] YOLOæ¨¡åž‹ä¸­è¿˜å­˜åœ¨mAP@[0.5:0.95]è¿™æ ·ä¸€ç§è¡¨çŽ°å½¢å¼ï¼Œè¿™å½¢å¼æ˜¯å¤šä¸ªIOUé˜ˆå€¼ä¸‹çš„mAPï¼Œä¼šåœ¨qåŒºé—´[0.5,0.95]å†…ï¼Œä»¥0.05ä¸ºæ­¥é•¿ï¼Œå–10ä¸ªIOUé˜ˆå€¼ï¼Œåˆ†åˆ«è®¡ç®—è¿™10ä¸ªIOUé˜ˆå€¼ä¸‹çš„mAPï¼Œå†å–å¹³å‡å€¼ã€‚mAP@[0.5:0.95]è¶Šå¤§ï¼Œè¡¨ç¤ºé¢„æµ‹æ¡†è¶Šç²¾å‡†ï¼Œå› ä¸ºå®ƒåŽ»å–åˆ°äº†æ›´å¤šIOUé˜ˆå€¼å¤§çš„æƒ…å†µ æ•°æ®é›†å‡†å¤‡ How to Train YOLOv8 Object Detection on a Custom Dataset æ·±åº¦å­¦ä¹ ç³»åˆ—ä¹‹Anchor based å’Œ Anchor free ç›®æ ‡æ£€æµ‹æ–¹æ³• RCNNç³»åˆ— å€™é€‰åŒºåŸŸçš„äº§ç”Ÿ é€‰æ‹©æ€§æœç´¢ç®—æ³• ï¼ˆSelective Search) é€‰æ‹©æ€§æœç´¢ç®—æ³•(Selective Search)è¶…è¯¦è§£ï¼ˆé€šä¿—æ˜“æ‡‚ç‰ˆï¼‰ å¾ˆå¤šç›®æ ‡æ£€æµ‹æŠ€æœ¯éƒ½ä¼šæ¶‰åŠå€™é€‰æ¡†(bounding boxes)çš„ç”Ÿæˆï¼Œç‰©ä½“å€™é€‰æ¡†èŽ·å–å½“å‰ä¸»è¦ä½¿ç”¨å›¾åƒåˆ†å‰²ä¸ŽåŒºåŸŸç”Ÿé•¿æŠ€æœ¯ã€‚åŒºåŸŸç”Ÿé•¿(åˆå¹¶)ä¸»è¦ç”±äºŽæ£€æµ‹å›¾åƒä¸­å­˜åœ¨çš„ç‰©ä½“å…·æœ‰å±€éƒ¨åŒºåŸŸç›¸ä¼¼æ€§(é¢œè‰²ã€çº¹ç†ç­‰) æ»‘åŠ¨çª—å£æ³• æ»‘åŠ¨ï¼šé¦–å…ˆå¯¹è¾“å…¥å›¾åƒè¿›è¡Œä¸åŒçª—å£å¤§å°çš„æ»‘çª—è¿›è¡Œä»Žå·¦å¾€å³ã€ä»Žä¸Šåˆ°ä¸‹çš„æ»‘åŠ¨ æ£€æµ‹ï¼šæ¯æ¬¡æ»‘åŠ¨æ—¶å€™å¯¹å½“å‰çª—å£æ‰§è¡Œåˆ†ç±»å™¨(åˆ†ç±»å™¨æ˜¯äº‹å…ˆè®­ç»ƒå¥½çš„)ã€‚å¦‚æžœå½“å‰çª—å£å¾—åˆ°è¾ƒé«˜çš„åˆ†ç±»æ¦‚çŽ‡ï¼Œåˆ™è®¤ä¸ºæ£€æµ‹åˆ°äº†ç‰©ä½“ ä¸åŒå°ºåº¦ï¼šå¯¹æ¯ä¸ªä¸åŒçª—å£å¤§å°çš„æ»‘çª—éƒ½è¿›è¡Œæ£€æµ‹åŽï¼Œä¼šå¾—åˆ°ä¸åŒçª—å£æ£€æµ‹åˆ°çš„ç‰©ä½“æ ‡è®°ï¼Œè¿™äº›çª—å£å¤§å°ä¼šå­˜åœ¨é‡å¤è¾ƒé«˜çš„éƒ¨åˆ†ï¼Œ NMSï¼šé‡‡ç”¨éžæžå¤§å€¼æŠ‘åˆ¶(Non-Maximum Suppression, NMS)çš„æ–¹æ³•è¿›è¡Œç­›é€‰ï¼Œæœ€ç»ˆï¼Œç»è¿‡NMSç­›é€‰åŽèŽ·å¾—æ£€æµ‹åˆ°çš„ç‰©ä½“ é€‰æ‹©æ€§æœç´¢ï¼šselective search(ç®€ç§°SS)æ–¹æ³•æ˜¯å½“ä¸‹æœ€ä¸ºç†ŸçŸ¥çš„å›¾åƒbounding boxesæå–ç®—æ³•ï¼Œç”±Koen E.AäºŽ2011å¹´æå‡º åªå¯¹å›¾åƒä¸­æœ€æœ‰å¯èƒ½åŒ…å«ç‰©ä½“çš„åŒºåŸŸè¿›è¡Œæœç´¢ä»¥æ­¤æ¥æé«˜è®¡ç®—æ•ˆçŽ‡ï¼Œå›¾åƒä¸­ç‰©ä½“å¯èƒ½å­˜åœ¨çš„åŒºåŸŸåº”è¯¥æ˜¯æœ‰æŸäº›ç›¸ä¼¼æ€§æˆ–è€…è¿žç»­æ€§åŒºåŸŸçš„ åˆ†å‰²ï¼šå¯¹è¾“å…¥å›¾åƒè¿›è¡Œåˆ†å‰²ç®—æ³•äº§ç”Ÿè®¸å¤šå°çš„å­åŒºåŸŸ åˆå¹¶ï¼šæ ¹æ®è¿™äº›å­åŒºåŸŸä¹‹é—´ç›¸ä¼¼æ€§(ç›¸ä¼¼æ€§æ ‡å‡†ä¸»è¦æœ‰é¢œè‰²ã€çº¹ç†ã€å¤§å°ç­‰ç­‰)è¿›è¡ŒåŒºåŸŸåˆå¹¶ï¼Œä¸æ–­çš„è¿›è¡ŒåŒºåŸŸè¿­ä»£åˆå¹¶ å€™é€‰æ¡†ï¼šæ¯æ¬¡è¿­ä»£è¿‡ç¨‹ä¸­å¯¹è¿™äº›åˆå¹¶çš„å­åŒºåŸŸåšbounding boxes(å¤–åˆ‡çŸ©å½¢)ï¼Œè¿™äº›å­åŒºåŸŸå¤–åˆ‡çŸ©å½¢å°±æ˜¯é€šå¸¸æ‰€è¯´çš„å€™é€‰æ¡† æ»‘çª—æ³•ç®€å•æ˜“äºŽç†è§£ï¼Œä½†æ˜¯ä¸åŒçª—å£å¤§å°è¿›è¡Œå›¾åƒå…¨å±€æœç´¢å¯¼è‡´æ•ˆçŽ‡ä½Žä¸‹ï¼Œè€Œä¸”è®¾è®¡çª—å£å¤§å°æ—¶å€™è¿˜éœ€è¦è€ƒè™‘ç‰©ä½“çš„é•¿å®½æ¯”ã€‚æ‰€ä»¥ï¼Œå¯¹äºŽå®žæ—¶æ€§è¦æ±‚è¾ƒé«˜çš„åˆ†ç±»å™¨ï¼Œä¸æŽ¨èä½¿ç”¨æ»‘çª—æ³• é€‰æ‹©æœç´¢è®¡ç®—æ•ˆçŽ‡ä¼˜äºŽæ»‘çª—æ³•ï¼Œç”±äºŽé‡‡ç”¨å­åŒºåŸŸåˆå¹¶ç­–ç•¥ï¼Œæ‰€ä»¥å¯ä»¥åŒ…å«å„ç§å¤§å°çš„ç–‘ä¼¼ç‰©ä½“æ¡†ï¼Œåˆå¹¶åŒºåŸŸç›¸ä¼¼çš„æŒ‡æ ‡å¤šæ ·æ€§ï¼Œæé«˜äº†æ£€æµ‹ç‰©ä½“çš„æ¦‚çŽ‡ æ•°æ®è¡¨ç¤º é¢„æµ‹è¾“å‡ºå¯ä»¥è¡¨ç¤ºä¸ºï¼š \\mathrm{y}=\\left[\\begin{array}{l} \\mathrm{p}_{\\mathrm{c}} \\\\ \\mathrm{b}_{\\mathrm{x}} \\\\ \\mathrm{b}_{\\mathrm{y}} \\\\ \\mathrm{b}_{\\mathrm{w}} \\\\ \\mathrm{b}_{\\mathrm{h}} \\\\ \\mathrm{C}_{1} \\\\ \\mathrm{C}_{2} \\\\ \\mathrm{C}_{3} \\end{array}\\right] \\quad \\quad \\quad \\mathrm{y}_{\\text {true }}=\\left[\\begin{array}{c} 1 \\\\ 40 \\\\ 45 \\\\ 80 \\\\ 60 \\\\ 0 \\\\ 1 \\\\ 0 \\end{array}\\right] \\quad \\quad \\quad \\mathrm{y}_{\\mathrm{pred}}=\\left[\\begin{array}{c} 0.88 \\\\ 41 \\\\ 46 \\\\ 82 \\\\ 59 \\\\ 0.01 \\\\ 0.95 \\\\ 0.04 \\end{array}\\right] å…¶ä¸­ï¼Œ \\mathrm{p}_{\\mathrm{c}}ä¸ºé¢„æµ‹ç»“æžœçš„ç½®ä¿¡æ¦‚çŽ‡ï¼Œ \\mathrm{b}_{\\mathrm{x}}, \\mathrm{b}_{\\mathrm{y}}, \\mathrm{b}_{\\mathrm{w}}, \\mathrm{b}_{\\mathrm{h}}ä¸ºè¾¹æ¡†åæ ‡ï¼Œ \\mathrm{C}_{1}, \\mathrm{C}_{2}, \\mathrm{C}_{3}ä¸ºå±žäºŽæŸä¸ªç±»åˆ«çš„æ¦‚çŽ‡ï¼Œé€šè¿‡é¢„æµ‹ç»“æžœï¼Œå®žé™…ç»“æžœï¼Œæž„å»ºæŸå¤±å‡½æ•°ï¼ŒæŸå¤±å‡½æ•°åŒ…å«äº†åˆ†ç±»ã€å›žå½’ä¸¤éƒ¨åˆ†ç»„æˆ æ•ˆæžœè¯„ä¼° ä½¿ç”¨IoU(Intersection over Unionï¼Œäº¤å¹¶æ¯”)æ¥åˆ¤æ–­æ¨¡åž‹çš„å¥½åã€‚æ‰€è°“äº¤å¹¶æ¯”ï¼Œæ˜¯æŒ‡é¢„æµ‹è¾¹æ¡†ã€å®žé™…è¾¹æ¡†äº¤é›†å’Œå¹¶é›†çš„æ¯”çŽ‡ï¼Œä¸€èˆ¬çº¦å®š0.5ä¸ºä¸€ä¸ªå¯ä»¥æŽ¥å—çš„å€¼ éžæžå¤§å€¼æŠ‘åˆ¶ é¢„æµ‹ç»“æžœä¸­ï¼Œå¯èƒ½å¤šä¸ªé¢„æµ‹ç»“æžœé—´å­˜åœ¨é‡å éƒ¨åˆ†ï¼Œéœ€è¦ä¿ç•™äº¤å¹¶æ¯”æœ€å¤§çš„ã€åŽ»æŽ‰éžæœ€å¤§çš„é¢„æµ‹ç»“æžœï¼Œè¿™å°±æ˜¯éžæžå¤§å€¼æŠ‘åˆ¶(Non-Maximum Suppressionï¼Œç®€å†™ä½œNMS)ï¼Œéžæžå¤§å€¼æŠ‘åˆ¶çš„æµç¨‹å¦‚ä¸‹ï¼š æ ¹æ®ç½®ä¿¡åº¦å¾—åˆ†è¿›è¡ŒæŽ’åº é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æ¯”è¾¹ç•Œæ¡†æ·»åŠ åˆ°æœ€ç»ˆè¾“å‡ºåˆ—è¡¨ä¸­ï¼Œå°†å…¶ä»Žè¾¹ç•Œæ¡†åˆ—è¡¨ä¸­åˆ é™¤ è®¡ç®—æ‰€æœ‰è¾¹ç•Œæ¡†çš„é¢ç§¯ è®¡ç®—ç½®ä¿¡åº¦æœ€é«˜çš„è¾¹ç•Œæ¡†ä¸Žå…¶å®ƒå€™é€‰æ¡†çš„IoUã€‚ åˆ é™¤IoUå¤§äºŽé˜ˆå€¼çš„è¾¹ç•Œæ¡† é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œç›´è‡³è¾¹ç•Œæ¡†åˆ—è¡¨ä¸ºç©º bboxå›žå½’è®­ç»ƒï¼šå…¶å®žå°±æ˜¯è®­ç»ƒ d çŸ©é˜µå‘ t çŸ©é˜µé é½çš„è¿‡ç¨‹ ã€ç›®æ ‡æ£€æµ‹ã€‘åŸºç¡€çŸ¥è¯†ï¼šIoUã€NMSã€Bounding box regression å³: ç»™å®š \\left(P_{x}, P_{y}, P_{w}, P_{h}\\right)ï¼Œå¯»æ‰¾ä¸€ç§æ˜ å°„fï¼Œä½¿å¾— f\\left(P_{x}, P_{y}, P_{w}, P_{h}\\right)=\\left(G_{x}^{\\prime}, G_{y}^{\\prime}, G_{w}^{\\prime}, G_{h}^{\\prime}\\right) \\text { , ä¸” }\\left(G_{x}^{\\prime}, G_{y}^{\\prime}, G_{w}^{\\prime}, G_{h}^{\\prime}\\right) \\approx\\left(G_{x}, G_{y}, G_{w}, G_{h}\\right) ä¸»è¦æ“ä½œå°±æ˜¯å¹³ç§»+ç¼©æ”¾ rcnn RCNN åˆ†ä¸ºä¸‰ä¸ªmoduleï¼š ç‹¬ç«‹ç±»åˆ«çš„å€™é€‰åŒºåŸŸï¼ˆcategory-independent region proposalsï¼‰ï¼Œç”Ÿæˆä¸€ç»„å¯¹æ£€æµ‹å™¨å¯ç”¨çš„æ£€æµ‹åæ ‡ å¸¸è§çš„å€™é€‰åŒºç”Ÿæˆçš„æ–¹æ³•æœ‰å¾ˆå¤šï¼ˆobjectnessã€selective searchã€category-independent object proposalsã€constrained parametric min-cuts (CPMC) ã€multi-scale combinatorial groupingï¼‰ï¼Œæœ¬æ–‡ç”¨çš„æ˜¯é€‰æ‹©æœç´¢ã€‚äº§ç”Ÿäº†2000ä¸ªå€™é€‰åŒºåŸŸï¼ˆregion proposalï¼‰ ä½¿ç”¨å·ç§¯ç¥žç»ç½‘ç»œä»Žæ¯ä¸ªåŒºåŸŸä»Žæå–å›ºå®šçš„ç‰¹å¾å‘é‡ æœ¬æ–‡æ¯ä¸ªåŒºåŸŸæå–åˆ°çš„å›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡æ˜¯4096ï¼Œä½¿ç”¨çš„ç½‘ç»œæ˜¯AlexNet éœ€è¦æ³¨æ„çš„æ˜¯ Alextnet çš„è¾“å…¥å›¾åƒå¤§å°æ˜¯ 227\\times227ï¼Œè€Œé€šè¿‡ Selective Search äº§ç”Ÿçš„å€™é€‰åŒºåŸŸå¤§å°ä¸ä¸€ï¼Œä¸ºäº†ä¸Ž Alexnet å…¼å®¹ï¼ŒR-CNN é‡‡ç”¨äº†éžå¸¸æš´åŠ›çš„æ‰‹æ®µï¼Œé‚£å°±æ˜¯æ— è§†å€™é€‰åŒºåŸŸçš„å¤§å°å’Œå½¢çŠ¶ï¼Œç»Ÿä¸€å˜æ¢åˆ° 227\\times227çš„å°ºå¯¸(å°±æ˜¯åªæœ‰å€™é€‰æ¡†é‡Œä¿ç•™ï¼Œå‰©ä½™éƒ¨åˆ†å¡«å……å…¶å®ƒåƒç´ ï¼Œæˆ–è€…å…ˆåœ¨å€™é€‰æ¡†å‘¨å›´åŠ ä¸Š16çš„paddingï¼Œå†è¿›è¡Œå„å‘å¼‚æ€§ç¼©æ”¾ï¼Œè¿™ç§å½¢å˜ä½¿å¾—mApæé«˜äº†3åˆ°5ä¸ªç™¾åˆ†ç‚¹)ã€‚æœ‰ä¸€ä¸ªç»†èŠ‚ï¼Œåœ¨å¯¹ Region è¿›è¡Œå˜æ¢çš„æ—¶å€™ï¼Œé¦–å…ˆå¯¹è¿™äº›åŒºåŸŸè¿›è¡Œè†¨èƒ€å¤„ç†ï¼Œåœ¨å…¶ box å‘¨å›´é™„åŠ äº† p ä¸ªåƒç´ ï¼Œä¹Ÿå°±æ˜¯äººä¸ºæ·»åŠ äº†è¾¹æ¡†ï¼Œåœ¨è¿™é‡Œ p=16 åœ¨ ImageNet ä¸Šå…ˆè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åŽåˆ©ç”¨æˆç†Ÿçš„æƒé‡å‚æ•°åœ¨ PASCAL VOC æ•°æ®é›†ä¸Šè¿›è¡Œ fine-tuneï¼Œå¦‚æžœä¸é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œfine-tuningï¼Œè€Œæ˜¯æŠŠCNNå½“åšç‰¹å¾æå–å™¨ï¼Œå·ç§¯å±‚æ‰€å­¦åˆ°çš„ç‰¹å¾å…¶å®žå°±æ˜¯åŸºç¡€çš„å…±äº«ç‰¹å¾æå–å±‚ï¼Œå°±ç±»ä¼¼äºŽSIFTç®—æ³•ä¸€æ ·ï¼Œå¯ä»¥ç”¨äºŽæå–å„ç§å›¾ç‰‡çš„ç‰¹å¾ï¼Œè€Œf6ã€f7æ‰€å­¦ä¹ åˆ°çš„ç‰¹å¾æ˜¯ç”¨äºŽé’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„ç‰¹å¾ã€‚ è®­ç»ƒè¿‡ç¨‹ï¼šé¦–å…ˆå¯¹ PASCAL VOCæ•°æ®é›† è¿›è¡ŒSelective Searchï¼Œæœç´¢åˆ°2000ä¸ªRegion Proposalå¯¹Pre-trainedæ¨¡åž‹è¿›è¡Œfine-tuningã€‚å°†åŽŸæ¥é¢„è®­ç»ƒæ¨¡åž‹æœ€åŽçš„1000-wayçš„å…¨è¿žæŽ¥å±‚ï¼ˆåˆ†ç±»å±‚ï¼‰æ¢æˆ21-wayçš„åˆ†ç±»å±‚ï¼ˆ20ç±»ç‰©ä½“+èƒŒæ™¯ï¼‰ï¼Œç„¶åŽè®¡ç®—æ¯ä¸ªregion proposalå’Œground truth çš„IoUï¼Œå¯¹äºŽIoU>0.5çš„region proposalè¢«è§†ä¸ºæ­£æ ·æœ¬ï¼Œå¦åˆ™ä¸ºè´Ÿæ ·æœ¬ï¼ˆå³èƒŒæ™¯ï¼‰ã€‚å¦å¤–ï¼Œç”±äºŽå¯¹äºŽä¸€å¼ å›¾ç‰‡çš„å¤šæœ‰å€™é€‰åŒºåŸŸæ¥è¯´ï¼Œè´Ÿæ ·æœ¬æ˜¯è¿œè¿œå¤§äºŽæ­£æ ·æœ¬æ•°ï¼Œæ‰€ä»¥éœ€è¦å°†æ­£æ ·æœ¬è¿›è¡Œä¸Šé‡‡æ ·æ¥ä¿è¯æ ·æœ¬åˆ†å¸ƒå‡è¡¡ã€‚åœ¨æ¯æ¬¡è¿­ä»£çš„è¿‡ç¨‹ä¸­ï¼Œé€‰æ‹©å±‚æ¬¡é‡‡æ ·ï¼Œæ¯ä¸ªmini-batchä¸­é‡‡æ ·ä¸¤å¼ å›¾åƒï¼Œä»Žä¸­éšæœºé€‰å–32ä¸ªæ­£æ ·æœ¬å’Œ96ä¸ªè´Ÿæ ·æœ¬ç»„æˆä¸€ä¸ªmini-batchï¼ˆ128ï¼Œæ­£è´Ÿæ¯”ï¼š1ï¼š3ï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨0.001çš„å­¦ä¹ çŽ‡å’ŒSGDæ¥è¿›è¡Œè®­ç»ƒï¼Œæå–ç‰¹å¾çš„CNNç½‘ç»œç»è¿‡äº†é¢„è®­ç»ƒå’Œå¾®è°ƒåŽä¸å†è®­ç»ƒï¼Œå°±å›ºå®šä¸å˜äº†ï¼Œåªå•çº¯çš„ä½œä¸ºä¸€ä¸ªæç‰¹å¾çš„å·¥å…·äº† SVMçº¿æ€§åˆ†ç±»å™¨ï¼Œå¯¹ç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼šåœ¨è®­ç»ƒCNNæå–ç‰¹å¾æ—¶ï¼Œè®¾ç½®çš„IOUæ˜¯0.5ä»¥ä¸Šä¸ºæ­£æ ·æœ¬ï¼Œå°äºŽ0.5çš„æ˜¯è´Ÿæ ·æœ¬ã€‚ä½†åœ¨SVMåˆ†ç±»ä¸­ï¼Œåªæœ‰bboxå®Œå…¨åŒ…å›´äº†ç‰©ä½“ï¼ˆä¹Ÿå¯ä»¥ç†è§£ä¸ºIOUï¼ž0.7æ—¶ï¼‰æ‰æ˜¯æ­£æ ·æœ¬ï¼ŒIOUå°äºŽ0.3çš„æ˜¯è´Ÿæ ·æœ¬ã€‚å‰è€…æ˜¯å¤§æ ·æœ¬è®­ç»ƒï¼ŒåŽè€…æ˜¯å°æ ·æœ¬è®­ç»ƒï¼Œsvmé€‚ç”¨äºŽå°‘æ ·æœ¬è®­ç»ƒï¼Œå¦‚æžœç”¨CNNåè€Œä¸åˆé€‚ ç”¨SVMå¯¹æ¯ä¸ªç‰¹å¾å‘é‡è¿›è¡Œè¯„åˆ†ï¼Œç„¶åŽç”¨éžæžå¤§å€¼æŠ‘åˆ¶ ç®€å•è¯´å°±æ˜¯ï¼š ç»™å®šä¸€å¼ è¾“å…¥å›¾ç‰‡ï¼Œä»Žå›¾ç‰‡ä¸­æå– 2000 ä¸ªç±»åˆ«ç‹¬ç«‹çš„å€™é€‰åŒºåŸŸ å¯¹äºŽæ¯ä¸ªåŒºåŸŸåˆ©ç”¨ CNN æŠ½å–ä¸€ä¸ªå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ å†å¯¹æ¯ä¸ªç‰¹å¾å‘é‡åˆ©ç”¨ SVM è¿›è¡Œç›®æ ‡åˆ†ç±» æµ‹è¯•æ­¥éª¤ï¼š Region proposalçš„ç¡®å®šï¼šVOCæµ‹è¯•å›¾åƒè¾“å…¥åŽï¼Œåˆ©ç”¨SSæœç´¢æ–¹æ³•ï¼Œæ ¹æ®ç›¸ä¼¼åº¦ä»Žå¤§åˆ°å°æŽ’åºï¼Œç­›é€‰å‡º2000ä¸ªregion proposals RPçš„Featuresæå–ï¼šå°†RPé€šè¿‡resizeæˆ 227 \\times 227ï¼Œç„¶åŽåˆ†åˆ«è¾“å…¥è¿›CNNç‰¹å¾æå–ç½‘ç»œï¼Œå¾—åˆ°äº†2000ä¸ª4096ç»´features SVMåˆ†ç±»ï¼šå°†(2000,4096)ç»´çŸ©é˜µè¾“å…¥è¿›SVMåˆ†ç±»å™¨ä¸­ï¼Œæœ€ç»ˆå¾—åˆ°(2000ï¼Œ21)çŸ©é˜µã€‚æ¯ä¸€è¡Œçš„21ä¸ªåˆ—å€¼ï¼Œåˆ†åˆ«ä»£è¡¨äº†è¿™ä¸ªRPå±žäºŽæ¯ä¸€ä¸ªç±»çš„å¯èƒ½æ€§ã€‚é€šè¿‡æå‰è®¾ç½®å¥½çš„backgroundé˜ˆå€¼\\alphaå’Œæ‰€å±žäºŽç±»çš„é˜ˆå€¼\\betaï¼Œç­›é€‰å‡ºæ»¡è¶³æ¡ä»¶çš„mä¸ªRPåŒºåŸŸ BoundingBox-Regressionï¼šå°†(m,4096)ç»´çŸ©é˜µè¾“å…¥è¿› (4096,4)çš„å›žå½’çŸ©é˜µ d dd ä¸­ï¼Œæœ€åŽè¾“å‡º(m,4)åç§»çŸ©é˜µã€‚ä»£è¡¨RPä¸­å¿ƒç‚¹çš„ä½ç½®åç§» å’Œ bboxçš„å°ºå¯¸å˜æ¢ å°†SVMç­›é€‰å‡ºçš„mä¸ªRPåŒºåŸŸå¯¹åº”çš„ç‰¹å¾å‘é‡ï¼Œç»„æˆ(m,4096)çŸ©é˜µ ä»£å…¥ (4096,4)çš„å›žå½’çŸ©é˜µdä¸­ï¼Œæœ€åŽè¾“å‡º(m,4)åç§»çŸ©é˜µ Non-maximum suppressionå¤„ç†ï¼šåªç”»å‡ºSVMç­›é€‰å‡ºçš„mä¸ªRPåŒºåŸŸçš„ä¿®æ­£åŽçš„æ£€æµ‹æ¡†ï¼Œè¿›è¡Œéžæžå¤§å€¼æŠ‘åˆ¶(NMS)ï¼Œå¾—åˆ°æœ€ç»ˆæ£€æµ‹ç»“æžœ ç¼ºç‚¹ï¼š é‡å¤è®¡ç®—ï¼Œæ¯ä¸ªregion proposalï¼Œéƒ½éœ€è¦ç»è¿‡ä¸€ä¸ªAlexNetç‰¹å¾æå–ï¼Œä¸ºæ‰€æœ‰çš„RoIï¼ˆregion of interestï¼‰æå–ç‰¹å¾å¤§çº¦èŠ±è´¹47ç§’ï¼Œå ç”¨ç©ºé—´ selective searchæ–¹æ³•ç”Ÿæˆregion proposalï¼Œå¯¹ä¸€å¸§å›¾åƒï¼Œéœ€è¦èŠ±è´¹2ç§’ ä¸‰ä¸ªæ¨¡å—ï¼ˆæå–ã€åˆ†ç±»ã€å›žå½’ï¼‰æ˜¯åˆ†åˆ«è®­ç»ƒçš„ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒæ—¶å€™ï¼Œå¯¹äºŽå­˜å‚¨ç©ºé—´æ¶ˆè€—è¾ƒå¤§ spp-net SPP-Net: å‡ºè‡ª2015å¹´å‘è¡¨åœ¨IEEEä¸Šçš„è®ºæ–‡-ã€ŠSpatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognitionã€‹ æ‰€æœ‰çš„ç¥žç»ç½‘ç»œéƒ½æ˜¯éœ€è¦è¾“å…¥å›ºå®šå°ºå¯¸çš„å›¾ç‰‡ï¼Œæ¯”å¦‚ 224 \\times 224(ImageNet)ã€ 32 \\times 32(LenNet)ã€ 96\\times 96ç­‰ã€‚è¿™æ ·å¯¹äºŽæˆ‘ä»¬å¸Œæœ›æ£€æµ‹å„ç§å¤§å°çš„å›¾ç‰‡çš„æ—¶å€™ï¼Œéœ€è¦ç»è¿‡cropï¼Œæˆ–è€…warpç­‰ä¸€ç³»åˆ—æ“ä½œï¼Œè¿™éƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šå¯¼è‡´å›¾ç‰‡ä¿¡æ¯çš„ä¸¢å¤±å’Œå˜å½¢ï¼Œé™åˆ¶äº†è¯†åˆ«ç²¾ç¡®åº¦ ä¸ºä»€ä¹ˆè¦å›ºå®šè¾“å…¥å›¾ç‰‡çš„å¤§å°ï¼Ÿï¼šå·ç§¯å±‚çš„å‚æ•°å’Œè¾“å…¥å¤§å°æ— å…³ï¼Œå®ƒä»…ä»…æ˜¯ä¸€ä¸ªå·ç§¯æ ¸åœ¨å›¾åƒä¸Šæ»‘åŠ¨ï¼Œä¸ç®¡è¾“å…¥å›¾åƒå¤šå¤§éƒ½æ²¡å…³ç³»ï¼Œåªæ˜¯å¯¹ä¸åŒå¤§å°çš„å›¾ç‰‡å·ç§¯å‡ºä¸åŒå¤§å°çš„ç‰¹å¾å›¾ï¼Œä½†æ˜¯å…¨è¿žæŽ¥å±‚çš„å‚æ•°å°±å’Œè¾“å…¥å›¾åƒå¤§å°æœ‰å…³ï¼Œå› ä¸ºå®ƒè¦æŠŠè¾“å…¥çš„æ‰€æœ‰åƒç´ ç‚¹è¿žæŽ¥èµ·æ¥,éœ€è¦æŒ‡å®šè¾“å…¥å±‚ç¥žç»å…ƒä¸ªæ•°å’Œè¾“å‡ºå±‚ç¥žç»å…ƒä¸ªæ•°ï¼Œæ‰€ä»¥éœ€è¦è§„å®šè¾“å…¥çš„featureçš„å¤§å°ï¼Œå› æ­¤ï¼Œå›ºå®šé•¿åº¦çš„çº¦æŸä»…é™äºŽå…¨è¿žæŽ¥å±‚ SPP-Netåœ¨æœ€åŽä¸€ä¸ªå·ç§¯å±‚åŽï¼ŒæŽ¥å…¥äº†é‡‘å­—å¡”æ± åŒ–å±‚ï¼Œä½¿ç”¨è¿™ç§æ–¹å¼ï¼Œå¯ä»¥è®©ç½‘ç»œè¾“å…¥ä»»æ„çš„å›¾ç‰‡ï¼Œè€Œä¸”è¿˜ä¼šç”Ÿæˆå›ºå®šå¤§å°çš„è¾“å‡º é‡‘å­—å¡”æ± åŒ–ï¼Œä½¿å¾—ä»»æ„å¤§å°çš„ç‰¹å¾å›¾éƒ½èƒ½å¤Ÿè½¬æ¢æˆå›ºå®šå¤§å°çš„ç‰¹å¾å‘é‡ï¼Œè¿™å°±æ˜¯ç©ºé—´é‡‘å­—å¡”æ± åŒ–çš„æ„ä¹‰(å¤šå°ºåº¦ç‰¹å¾æå–å‡ºå›ºå®šå¤§å°çš„ç‰¹å¾å‘é‡) SPP-Netï¼Œæ•´ä¸ªè¿‡ç¨‹æ˜¯ï¼š é¦–å…ˆé€šè¿‡é€‰æ‹©æ€§æœç´¢ï¼Œå¯¹å¾…æ£€æµ‹çš„å›¾ç‰‡è¿›è¡Œæœç´¢å‡º2000ä¸ªå€™é€‰çª—å£ã€‚è¿™ä¸€æ­¥å’ŒR-CNNä¸€æ ·ã€‚ ç‰¹å¾æå–é˜¶æ®µã€‚è¿™ä¸€æ­¥å°±æ˜¯å’ŒR-CNNæœ€å¤§çš„åŒºåˆ«äº†ï¼Œè¿™ä¸€æ­¥éª¤çš„å…·ä½“æ“ä½œå¦‚ä¸‹ï¼šæŠŠæ•´å¼ å¾…æ£€æµ‹çš„å›¾ç‰‡ï¼Œè¾“å…¥CNNä¸­ï¼Œè¿›è¡Œä¸€æ¬¡æ€§ç‰¹å¾æå–ï¼Œå¾—åˆ°feature mapsï¼Œç„¶åŽåœ¨feature mapsä¸­æ‰¾åˆ°å„ä¸ªå€™é€‰æ¡†çš„åŒºåŸŸï¼Œå†å¯¹å„ä¸ªå€™é€‰æ¡†é‡‡ç”¨é‡‘å­—å¡”ç©ºé—´æ± åŒ–ï¼Œæå–å‡ºå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ã€‚è€ŒR-CNNè¾“å…¥çš„æ˜¯æ¯ä¸ªå€™é€‰æ¡†ï¼Œç„¶åŽåœ¨è¿›å…¥CNNï¼Œå› ä¸ºSPP-Netåªéœ€è¦ä¸€æ¬¡å¯¹æ•´å¼ å›¾ç‰‡è¿›è¡Œç‰¹å¾æå–ï¼Œé€Ÿåº¦ä¼šå¤§å¤§æå‡ æœ€åŽä¸€æ­¥ä¹Ÿæ˜¯å’ŒR-CNNä¸€æ ·ï¼Œé‡‡ç”¨SVMç®—æ³•è¿›è¡Œç‰¹å¾å‘é‡åˆ†ç±»è¯†åˆ« éš¾ç‚¹ å€™é€‰åŒºåŸŸï¼ˆåŽŸå›¾ä¸Žç‰¹å¾å›¾ï¼‰çš„æ˜ å°„ å‡è®¾(xâ€™,yâ€™)è¡¨ç¤ºç‰¹å¾å›¾ä¸Šçš„åæ ‡ç‚¹ï¼Œåæ ‡ç‚¹(x,y)è¡¨ç¤ºåŽŸè¾“å…¥å›¾ç‰‡ä¸Šçš„ç‚¹ï¼Œé‚£ä¹ˆå®ƒä»¬ä¹‹é—´æœ‰å¦‚ä¸‹è½¬æ¢å…³ç³»ï¼Œè¿™ç§æ˜ å°„å…³å¿ƒä¸Žç½‘ç»œç»“æž„æœ‰å…³ï¼š (x,y) = (S \\times x' , S \\times y' ) å…¶ä¸­Så°±æ˜¯CNNä¸­æ‰€æœ‰çš„stridesçš„ä¹˜ç§¯ï¼ŒåŒ…å«äº†æ± åŒ–ã€å·ç§¯çš„stride fast-rcnn Fast-Rcnnï¼šæå‡ºäº†ROI pooling R-CNNå­˜åœ¨ä¸€äº›é—®é¢˜ï¼š è®­ç»ƒåˆ†å¤šæ­¥ï¼šR-CNNçš„è®­ç»ƒå…ˆè¦fine tuningä¸€ä¸ªé¢„è®­ç»ƒçš„ç½‘ç»œï¼Œç„¶åŽé’ˆå¯¹æ¯ä¸ªç±»åˆ«éƒ½è®­ç»ƒä¸€ä¸ªSVMåˆ†ç±»å™¨ï¼Œæœ€åŽè¿˜è¦ç”¨regressorså¯¹bounding-boxè¿›è¡Œå›žå½’ï¼Œå¦å¤–region proposalä¹Ÿè¦å•ç‹¬ç”¨selective searchçš„æ–¹å¼èŽ·å¾—ï¼Œæ­¥éª¤æ¯”è¾ƒç¹ç æ—¶é—´å’Œå†…å­˜æ¶ˆè€—å¤§ï¼šåœ¨è®­ç»ƒSVMå’Œå›žå½’çš„æ—¶å€™éœ€è¦ç”¨ç½‘ç»œè®­ç»ƒçš„ç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œç‰¹å¾ä¿å­˜åœ¨ç£ç›˜ä¸Šå†è¯»å…¥çš„æ—¶é—´æ¶ˆè€—è¿˜æ˜¯æ¯”è¾ƒå¤§çš„ æµ‹è¯•æ…¢ï¼šæ¯å¼ å›¾ç‰‡çš„æ¯ä¸ªregion proposaléƒ½è¦åšå·ç§¯ï¼Œé‡å¤æ“ä½œå¤ªå¤š è™½ç„¶åœ¨Fast RCNNä¹‹å‰æœ‰æå‡ºè¿‡SPPnetç®—æ³•æ¥è§£å†³RCNNä¸­é‡å¤å·ç§¯çš„é—®é¢˜ï¼Œä½†æ˜¯SPPnetä¾ç„¶å­˜åœ¨å’ŒRCNNä¸€æ ·çš„ä¸€äº›ç¼ºç‚¹æ¯”å¦‚ï¼šè®­ç»ƒæ­¥éª¤è¿‡å¤šï¼Œéœ€è¦è®­ç»ƒSVMåˆ†ç±»å™¨ï¼Œéœ€è¦é¢å¤–çš„å›žå½’å™¨ï¼Œç‰¹å¾ä¹Ÿæ˜¯ä¿å­˜åœ¨ç£ç›˜ä¸Š å› æ­¤Fast RCNNç›¸å½“äºŽå…¨é¢æ”¹è¿›äº†åŽŸæœ‰çš„è¿™ä¸¤ä¸ªç®—æ³•ï¼Œä¸ä»…è®­ç»ƒæ­¥éª¤å‡å°‘äº†ï¼Œä¹Ÿä¸éœ€è¦é¢å¤–å°†ç‰¹å¾ä¿å­˜åœ¨ç£ç›˜ä¸Š åŸºäºŽVGG16çš„Fast RCNNç®—æ³•çš„é€Ÿåº¦ï¼š åœ¨è®­ç»ƒé€Ÿåº¦ä¸Šæ¯”RCNNå¿«äº†å°†è¿‘9å€ï¼Œæ¯”SPPnetå¿«å¤§æ¦‚3å€ æµ‹è¯•é€Ÿåº¦æ¯”RCNNå¿«äº†213å€ï¼Œæ¯”SPPnetå¿«äº†10å€ åœ¨VOC2012ä¸Šçš„mAPåœ¨66%å·¦å³ ç½‘ç»œæœ‰ä¸¤ä¸ªè¾“å…¥ï¼šå›¾åƒå’Œå¯¹åº”çš„region proposalã€‚å…¶ä¸­region proposalç”±selective searchæ–¹æ³•å¾—åˆ°ï¼Œæ²¡æœ‰è¡¨ç¤ºåœ¨æµç¨‹å›¾ä¸­ å¯¹æ¯ä¸ªç±»åˆ«éƒ½è®­ç»ƒä¸€ä¸ªå›žå½’å™¨ï¼Œä¸”åªæœ‰éžèƒŒæ™¯çš„region proposalæ‰éœ€è¦è¿›è¡Œå›žå½’ ROI poolingï¼šROI Poolingçš„ä½œç”¨æ˜¯å¯¹ä¸åŒå¤§å°çš„region proposalï¼Œä»Žæœ€åŽå·ç§¯å±‚è¾“å‡ºçš„feature mapæå–å¤§å°å›ºå®šçš„feature map(ROI Poolingä½¿ç”¨è‡ªé€‚åº”(æ ¹æ®è¾“å…¥featureçš„å¤§å°è‡ªè°ƒæ•´)æ± åŒ–åŒºåŸŸï¼Œä¸å†å›ºå®šæ± åŒ–åŒºåŸŸå¤§å°ï¼Œè€Œå›ºå®šæ± åŒ–åŒºåŸŸä¸ªæ•°ï¼Œè¿™æ ·å°±ç¡®ä¿äº†è¾“å…¥ä»€ä¹ˆå¤§å°çš„featureï¼Œè¾“å‡ºçš„featureå¤§å°å®Œå…¨ç›¸ç­‰ï¼Œç­‰äºŽæ± åŒ–åŒºåŸŸä¸ªæ•°)ã€‚ç®€å•è®²å¯ä»¥çœ‹åšæ˜¯SPPNetçš„ç®€åŒ–ç‰ˆæœ¬ï¼Œå› ä¸ºå…¨è¿žæŽ¥å±‚çš„è¾“å…¥éœ€è¦å°ºå¯¸å¤§å°ä¸€æ ·ï¼Œæ‰€ä»¥ä¸èƒ½ç›´æŽ¥å°†ä¸åŒå¤§å°çš„region proposalæ˜ å°„åˆ°feature mapä½œä¸ºè¾“å‡ºï¼Œéœ€è¦åšå°ºå¯¸å˜æ¢ã€‚åœ¨æ–‡ç« ä¸­ï¼ŒVGG16ç½‘ç»œä½¿ç”¨H = W = 7çš„å‚æ•°ï¼Œå³å°†ä¸€ä¸ªh \\times wçš„region proposalåˆ†å‰²æˆ H \\times Wå¤§å°çš„ç½‘æ ¼ï¼Œç„¶åŽå°†è¿™ä¸ªregion proposalæ˜ å°„åˆ°æœ€åŽä¸€ä¸ªå·ç§¯å±‚è¾“å‡ºçš„feature mapï¼Œæœ€åŽè®¡ç®—æ¯ä¸ªç½‘æ ¼é‡Œçš„æœ€å¤§å€¼ä½œä¸ºè¯¥ç½‘æ ¼çš„è¾“å‡ºï¼Œæ‰€ä»¥ä¸ç®¡ROI poolingä¹‹å‰çš„feature mapå¤§å°æ˜¯å¤šå°‘ï¼ŒROI poolingåŽå¾—åˆ°çš„feature mapå¤§å°éƒ½æ˜¯ H \\times W ç®€å•è¯´ROI poolingå°±æ˜¯ï¼š æŠŠå›¾ç‰‡ä¸Šselective searché€‰å‡ºçš„å€™é€‰æ¡†æ˜ å°„åˆ°ç‰¹å¾å›¾ä¸Šå¯¹åº”çš„ä½ç½®ï¼Œè¿™ä¸ªæ˜ å°„æ˜¯æ ¹æ®è¾“å…¥å›¾ç‰‡ç¼©å°çš„å°ºå¯¸æ¥çš„ï¼› å°†æ˜ å°„åŽçš„åŒºåŸŸåˆ’åˆ†ä¸ºç›¸åŒå¤§å°çš„sectionsï¼ˆsectionsæ•°é‡ä¸Žè¾“å‡ºçš„ç»´åº¦ç›¸åŒï¼‰ å¯¹æ¯ä¸ªsectionsè¿›è¡Œmax poolingæ“ä½œï¼› è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ä»Žä¸åŒå¤§å°çš„æ–¹æ¡†å¾—åˆ°å›ºå®šå¤§å°çš„ç›¸åº” çš„feature maps ä¸¤ä¸ªlossï¼šç¬¬ä¸€ä¸ªä¼˜åŒ–ç›®æ ‡æ˜¯åˆ†ç±»ï¼Œä½¿ç”¨softmaxï¼ˆå°±ä¸ç”¨åƒå‰é¢çš„R-CNNå’ŒSPPå†ç”¨SVMäº†ï¼‰ï¼Œç¬¬äºŒä¸ªä¼˜åŒ–ç›®æ ‡æ˜¯bbox regressionï¼Œä½¿ç”¨äº†ä¸€ä¸ªå¹³æ»‘çš„L1-loss ROI Pooling ä¸Ž SPP çš„åŒºåˆ«ï¼š é€šè¿‡ä¸Šé¢çš„ä»‹ç»ï¼Œå¯ä»¥çœ‹åˆ°ä¸¤è€…èµ·åˆ°çš„ä½œç”¨æ˜¯ç›¸åŒçš„ï¼ŒæŠŠä¸åŒå°ºå¯¸çš„ç‰¹å¾è¾“å…¥è½¬åŒ–ä¸ºç›¸åŒå°ºå¯¸çš„ç‰¹å¾è¾“å‡ºã€‚SPPé’ˆå¯¹åŒä¸€ä¸ªè¾“å…¥ä½¿ç”¨äº†å¤šä¸ªä¸åŒå°ºå¯¸çš„æ± åŒ–æ“ä½œï¼ŒæŠŠä¸åŒå°ºåº¦çš„ç»“æžœæ‹¼æŽ¥ä½œä¸ºè¾“å‡ºï¼›è€ŒROI Poolingå¯çœ‹ä½œå•å°ºåº¦çš„SPPï¼Œå¯¹äºŽä¸€ä¸ªè¾“å…¥åªè¿›è¡Œä¸€æ¬¡æ± åŒ–æ“ä½œ å¯ä»¥çœ‹å‡ºFast RCNNä¸»è¦æœ‰3ä¸ªæ”¹è¿›ï¼š å·ç§¯ä¸å†æ˜¯å¯¹æ¯ä¸ªregion proposalè¿›è¡Œï¼Œè€Œæ˜¯ç›´æŽ¥å¯¹æ•´å¼ å›¾åƒï¼Œè¿™æ ·å‡å°‘äº†å¾ˆå¤šé‡å¤è®¡ç®—ã€‚åŽŸæ¥RCNNæ˜¯å¯¹æ¯ä¸ªregion proposalåˆ†åˆ«åšå·ç§¯ï¼Œå› ä¸ºä¸€å¼ å›¾åƒä¸­æœ‰2000å·¦å³çš„region proposalï¼Œè‚¯å®šç›¸äº’ä¹‹é—´çš„é‡å çŽ‡å¾ˆé«˜ï¼Œå› æ­¤äº§ç”Ÿé‡å¤è®¡ç®— ç”¨ROI poolingè¿›è¡Œç‰¹å¾çš„å°ºå¯¸å˜æ¢ï¼Œå› ä¸ºå…¨è¿žæŽ¥å±‚çš„è¾“å…¥è¦æ±‚å°ºå¯¸å¤§å°ä¸€æ ·ï¼Œå› æ­¤ä¸èƒ½ç›´æŽ¥æŠŠregion proposalä½œä¸ºè¾“å…¥ å°†regressoræ”¾è¿›ç½‘ç»œä¸€èµ·è®­ç»ƒï¼Œæ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªregressorï¼ŒåŒæ—¶ç”¨softmaxä»£æ›¿åŽŸæ¥çš„SVMåˆ†ç±»å™¨ åœ¨å®žé™…è®­ç»ƒä¸­ï¼Œæ¯ä¸ªmini-batchåŒ…å«2å¼ å›¾åƒå’Œ128ä¸ªregion proposalï¼ˆæˆ–è€…å«ROIï¼‰ï¼Œä¹Ÿå°±æ˜¯æ¯å¼ å›¾åƒæœ‰64ä¸ªROIã€‚ç„¶åŽä»Žè¿™äº›ROIä¸­æŒ‘é€‰çº¦25%çš„ROIï¼Œè¿™äº›ROIå’Œground truthçš„IOUå€¼éƒ½å¤§äºŽ0.5ã€‚å¦å¤–åªé‡‡ç”¨éšæœºæ°´å¹³ç¿»è½¬çš„æ–¹å¼å¢žåŠ æ•°æ®é›† æµ‹è¯•çš„æ—¶å€™åˆ™æ¯å¼ å›¾åƒå¤§çº¦2000ä¸ªROI æ€»ç»“ï¼š Fast RCNNå°†RCNNä¼—å¤šæ­¥éª¤æ•´åˆåœ¨ä¸€èµ·ï¼Œä¸ä»…å¤§å¤§æé«˜äº†æ£€æµ‹é€Ÿåº¦ï¼Œä¹Ÿæé«˜äº†æ£€æµ‹å‡†ç¡®çŽ‡ã€‚å…¶ä¸­ï¼Œå¯¹æ•´å¼ å›¾åƒå·ç§¯è€Œä¸æ˜¯å¯¹æ¯ä¸ªregion proposalå·ç§¯ï¼ŒROI Poolingï¼Œåˆ†ç±»å’Œå›žå½’éƒ½æ”¾åœ¨ç½‘ç»œä¸€èµ·è®­ç»ƒçš„multi-task lossæ˜¯ç®—æ³•çš„ä¸‰ä¸ªæ ¸å¿ƒã€‚å¦å¤–è¿˜æœ‰SVDåˆ†è§£ç­‰æ˜¯åŠ é€Ÿçš„å°è´¡çŒ®ï¼Œæ•°æ®é›†çš„å¢žåŠ æ—¶mAPæé«˜çš„å°è´¡çŒ® å½“ç„¶Fast RCNNçš„ä¸»è¦ç¼ºç‚¹åœ¨äºŽregion proposalçš„æå–ä½¿ç”¨selective searchï¼Œç›®æ ‡æ£€æµ‹æ—¶é—´å¤§å¤šæ¶ˆè€—åœ¨è¿™ä¸Šé¢ï¼ˆæregion proposal 2~3sï¼Œè€Œæç‰¹å¾åˆ†ç±»åªéœ€0.32sï¼‰ï¼Œè¿™ä¹Ÿæ˜¯åŽç»­Faster RCNNçš„æ”¹è¿›æ–¹å‘ä¹‹ä¸€ ç¼ºç‚¹ï¼š ä¾æ—§é‡‡ç”¨selective searchæå–region proposalï¼ˆè€—æ—¶2~3ç§’ï¼Œç‰¹å¾æå–è€—æ—¶0.32ç§’ï¼‰ æ— æ³•æ»¡è¶³å®žæ—¶åº”ç”¨ï¼Œæ²¡æœ‰çœŸæ­£å®žçŽ°ç«¯åˆ°ç«¯è®­ç»ƒæµ‹è¯• åˆ©ç”¨äº†GPUï¼Œä½†æ˜¯region proposalæ–¹æ³•æ˜¯åœ¨CPUä¸Šå®žçŽ°çš„ æ€»ç»“ RCNN: ç»™å®šä¸€å¼ è¾“å…¥å›¾ç‰‡ï¼Œé€šè¿‡ Selective Searchä»Žå›¾ç‰‡ä¸­æå– 2000 ä¸ªç±»åˆ«ç‹¬ç«‹çš„å€™é€‰åŒºåŸŸ å¯¹äºŽæ¯ä¸ªåŒºåŸŸåˆ©ç”¨ CNN æŠ½å–ä¸€ä¸ªå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ å¯¹æ¯ä¸ªç‰¹å¾å‘é‡åˆ©ç”¨ SVM è¿›è¡Œç›®æ ‡åˆ†ç±» å¯¹äºŽSVMåˆ†å¥½ç±»çš„Region Proposalåšè¾¹æ¡†å›žå½’ï¼Œç”¨Bounding boxå›žå½’å€¼æ ¡æ­£åŽŸæ¥çš„å»ºè®®çª—å£ï¼Œç”Ÿæˆé¢„æµ‹çª—å£åæ ‡ ç¼ºç‚¹ï¼š é‡å¤è®¡ç®—ï¼Œæ¯ä¸ªregion proposalï¼Œéƒ½éœ€è¦ç»è¿‡ä¸€ä¸ªAlexNetç‰¹å¾æå– selective searchæ–¹æ³•ç”Ÿæˆregion proposalï¼Œå¯¹ä¸€å¸§å›¾åƒï¼Œéœ€è¦èŠ±è´¹2ç§’ ä¸‰ä¸ªæ¨¡å—(æå–ã€åˆ†ç±»ã€å›žå½’)æ˜¯åˆ†åˆ«è®­ç»ƒçš„ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒæ—¶å€™ï¼Œå¯¹äºŽå­˜å‚¨ç©ºé—´æ¶ˆè€—è¾ƒå¤§ è®­ç»ƒåˆ†ä¸ºå¤šä¸ªé˜¶æ®µï¼Œæ­¥éª¤ç¹çï¼šå¾®è°ƒç½‘ç»œ+è®­ç»ƒSVM+è®­ç»ƒè¾¹æ¡†å›žå½’å™¨ SVMå’Œå›žå½’æ˜¯äº‹åŽæ“ä½œï¼Œåœ¨SVMå’Œå›žå½’è¿‡ç¨‹ä¸­CNNç‰¹å¾æ²¡æœ‰è¢«å­¦ä¹ æ›´æ–° SPPNet: é‡‘å­—å¡”æ± åŒ–å±‚ å½“ç½‘ç»œè¾“å…¥çš„æ˜¯ä¸€å¼ ä»»æ„å¤§å°çš„å›¾ç‰‡ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬å¯ä»¥ä¸€ç›´è¿›è¡Œå·ç§¯ã€æ± åŒ–ï¼Œç›´åˆ°ç½‘ç»œçš„å€’æ•°å‡ å±‚çš„æ—¶å€™ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬å³å°†ä¸Žå…¨è¿žæŽ¥å±‚è¿žæŽ¥çš„æ—¶å€™ï¼Œå°±è¦ä½¿ç”¨é‡‘å­—å¡”æ± åŒ–ï¼Œä½¿å¾—ä»»æ„å¤§å°çš„ç‰¹å¾å›¾éƒ½èƒ½å¤Ÿè½¬æ¢æˆå›ºå®šå¤§å°çš„ç‰¹å¾å‘é‡ï¼Œè¿™å°±æ˜¯ç©ºé—´é‡‘å­—å¡”æ± åŒ–çš„æ„ä¹‰ï¼ˆå¤šå°ºåº¦ç‰¹å¾æå–å‡ºå›ºå®šå¤§å°çš„ç‰¹å¾å‘é‡ï¼‰ é¦–å…ˆé€šè¿‡é€‰æ‹©æ€§æœç´¢ï¼Œå¯¹å¾…æ£€æµ‹çš„å›¾ç‰‡è¿›è¡Œæœç´¢å‡º2000ä¸ªå€™é€‰çª—å£ã€‚è¿™ä¸€æ­¥å’ŒR-CNNä¸€æ · ç‰¹å¾æå–é˜¶æ®µ,æŠŠæ•´å¼ å¾…æ£€æµ‹çš„å›¾ç‰‡ï¼Œè¾“å…¥CNNä¸­ï¼Œè¿›è¡Œä¸€æ¬¡æ€§ç‰¹å¾æå–ï¼Œå¾—åˆ°feature mapsï¼Œç„¶åŽåœ¨feature mapsä¸­æ‰¾åˆ°å„ä¸ªå€™é€‰æ¡†çš„åŒºåŸŸï¼Œå†å¯¹å„ä¸ªå€™é€‰æ¡†é‡‡ç”¨é‡‘å­—å¡”ç©ºé—´æ± åŒ–ï¼Œæå–å‡ºå›ºå®šé•¿åº¦çš„ç‰¹å¾å‘é‡ï¼Œåªéœ€è¦ä¸€æ¬¡å¯¹æ•´å¼ å›¾ç‰‡è¿›è¡Œç‰¹å¾æå–ï¼Œé€Ÿåº¦ä¼šå¤§å¤§æå‡ æœ€åŽä¸€æ­¥ä¹Ÿæ˜¯å’ŒR-CNNä¸€æ ·ï¼Œé‡‡ç”¨SVMç®—æ³•è¿›è¡Œç‰¹å¾å‘é‡åˆ†ç±»è¯†åˆ« Fast-RCNN: ç»™å®šä¸€å¼ è¾“å…¥å›¾ç‰‡ï¼Œé€šè¿‡ Selective Searchä»Žå›¾ç‰‡ä¸­æå– 2000 ä¸ªç±»åˆ«ç‹¬ç«‹çš„å€™é€‰åŒºåŸŸ å¯¹æ¯ä¸ªç±»åˆ«éƒ½è®­ç»ƒä¸€ä¸ªå›žå½’å™¨ï¼Œä¸”åªæœ‰éžèƒŒæ™¯çš„region proposalæ‰éœ€è¦è¿›è¡Œå›žå½’ã€‚ ROI poolingï¼šROI Poolingçš„ä½œç”¨æ˜¯å¯¹ä¸åŒå¤§å°çš„region proposalï¼Œä»Žæœ€åŽå·ç§¯å±‚è¾“å‡ºçš„feature mapæå–å¤§å°å›ºå®šçš„feature mapã€‚ç®€å•è®²å¯ä»¥çœ‹åšæ˜¯SPPNetçš„ç®€åŒ–ç‰ˆæœ¬(æŠŠå›¾ç‰‡ä¸Šselective searché€‰å‡ºçš„å€™é€‰æ¡†æ˜ å°„åˆ°ç‰¹å¾å›¾ä¸Šå¯¹åº”çš„ä½ç½®ï¼Œè¿™ä¸ªæ˜ å°„æ˜¯æ ¹æ®è¾“å…¥å›¾ç‰‡ç¼©å°çš„å°ºå¯¸æ¥çš„)ï¼Œå› ä¸ºå…¨è¿žæŽ¥å±‚çš„è¾“å…¥éœ€è¦å°ºå¯¸å¤§å°ä¸€æ ·ï¼Œæ‰€ä»¥ä¸èƒ½ç›´æŽ¥å°†ä¸åŒå¤§å°çš„region proposalæ˜ å°„åˆ°feature mapä½œä¸ºè¾“å‡ºï¼Œéœ€è¦åšå°ºå¯¸å˜æ¢ ä¸¤ä¸ªlossï¼šç¬¬ä¸€ä¸ªä¼˜åŒ–ç›®æ ‡æ˜¯åˆ†ç±»ï¼Œä½¿ç”¨softmaxï¼ˆå°±ä¸ç”¨åƒå‰é¢çš„R-CNNå’ŒSPPå†ç”¨SVMäº†ï¼‰ï¼Œç¬¬äºŒä¸ªä¼˜åŒ–ç›®æ ‡æ˜¯bbox regressionï¼Œä½¿ç”¨äº†ä¸€ä¸ªå¹³æ»‘çš„L1-loss ä¼˜ç‚¹ å·ç§¯ä¸å†æ˜¯å¯¹æ¯ä¸ªregion proposalè¿›è¡Œï¼Œè€Œæ˜¯ç›´æŽ¥å¯¹æ•´å¼ å›¾åƒï¼Œè¿™æ ·å‡å°‘äº†å¾ˆå¤šé‡å¤è®¡ç®— ç”¨ROI poolingè¿›è¡Œç‰¹å¾çš„å°ºå¯¸å˜æ¢ï¼Œå› ä¸ºå…¨è¿žæŽ¥å±‚çš„è¾“å…¥è¦æ±‚å°ºå¯¸å¤§å°ä¸€æ · å°†regressoræ”¾è¿›ç½‘ç»œä¸€èµ·è®­ç»ƒï¼Œæ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªregressorï¼ŒåŒæ—¶ç”¨softmaxä»£æ›¿åŽŸæ¥çš„SVMåˆ†ç±»å™¨ ä¸‰ä¸ªæ ¸å¿ƒï¼šå¯¹æ•´å¼ å›¾åƒå·ç§¯ã€ROI Poolingã€åˆ†ç±»å’Œå›žå½’ä¸€èµ·è®­ç»ƒçš„multi-task loss ä¸»è¦ç¼ºç‚¹åœ¨äºŽregion proposalçš„æå–ä½¿ç”¨selective searchï¼Œç›®æ ‡æ£€æµ‹æ—¶é—´å¤§å¤šæ¶ˆè€—åœ¨è¿™ä¸Šé¢ ç›¸æ¯”R-CNNï¼Œä¸»è¦ä¸¤å¤„ä¸åŒï¼š æœ€åŽä¸€å±‚å·ç§¯å±‚åŽåŠ äº†ä¸€ä¸ªROI pooling layerï¼› æŸå¤±å‡½æ•°ä½¿ç”¨äº†å¤šä»»åŠ¡æŸå¤±å‡½æ•°(multi-task loss)ï¼Œå°†è¾¹æ¡†å›žå½’ç›´æŽ¥åŠ å…¥åˆ°CNNç½‘ç»œä¸­è®­ç»ƒ faster-rcnn æŽ¨èè¿™ç¯‡æ–‡ç« -Object Detection and Classification using R-CNNs Faster R-CNNï¼šæå‡ºäº†RPN(region proposal network) ä¸»è¦å°±æ˜¯å¤šäº†ä¸€ä¸ªRPN(region proposal network)ï¼Œå°±æ˜¯åœ¨å·ç§¯æå–ç‰¹å¾ä¹‹åŽï¼Œå¤šå‡ºä¸€æ¡è·¯æ¥è¿›è¡Œå€™é€‰æ¡†çš„æå– æŽ¨èæœ‰å…³RPNå±‚çš„æ–‡ç« ï¼šRPNå±‚è§£æž RPNåªæ˜¯å°†æ¡†å†…è®¤ä¸ºæ˜¯ç›®æ ‡ï¼Œæ¡†å¤–è®¤ä¸ºæ˜¯èƒŒæ™¯ï¼Œåšäº†ä¸ªäºŒåˆ†ç±»ï¼Œè‡³äºŽæ¡†å†…ç›®æ ‡å…·ä½“æ˜¯å•¥ï¼Œæœ€ç»ˆæ˜¯äº¤ç»™åˆ†ç±»ç½‘ç»œåŽ»åš ä¸‹å›¾æ¥è‡ªFaster-RCNNï¼ˆäºŒï¼‰ä¹‹RPNå±‚ Faster-RCNN: RPN(region proposal network)ï¼Œå°±æ˜¯åœ¨å·ç§¯æå–ç‰¹å¾ä¹‹åŽï¼Œå¤šå‡ºä¸€æ¡è·¯æ¥è¿›è¡Œå€™é€‰æ¡†çš„æå– å°†æ•´å¼ å›¾ç‰‡è¾“å…¥CNNï¼Œè¿›è¡Œç‰¹å¾æå– ç”¨RPNç”Ÿæˆå»ºè®®çª—å£(proposals)ï¼Œæ¯å¼ å›¾ç‰‡ç”Ÿæˆ300ä¸ªå»ºè®®çª—å£ é€šè¿‡RoI poolingå±‚ä½¿æ¯ä¸ªRoIç”Ÿæˆå›ºå®šå°ºå¯¸çš„feature map åˆ©ç”¨Softmax Loss(æŽ¢æµ‹åˆ†ç±»æ¦‚çŽ‡) å’ŒSmooth L1 Loss(æŽ¢æµ‹è¾¹æ¡†å›žå½’)å¯¹åˆ†ç±»æ¦‚çŽ‡å’Œè¾¹æ¡†å›žå½’(Bounding box regression)è”åˆè®­ç»ƒ ç›¸æ¯”Fast R-CNNï¼Œä¸»è¦ä¸¤å¤„ä¸åŒï¼š ä½¿ç”¨RPN(Region Proposal Network)ä»£æ›¿åŽŸæ¥çš„Selective Searchæ–¹æ³•äº§ç”Ÿå»ºè®®çª—å£ï¼› äº§ç”Ÿå»ºè®®çª—å£çš„CNNå’Œç›®æ ‡æ£€æµ‹çš„CNNå…±äº« å¦‚ä½•é«˜æ•ˆå¿«é€Ÿäº§ç”Ÿå»ºè®®æ¡†ï¼Ÿ Faster R-CNNåˆ›é€ æ€§åœ°é‡‡ç”¨å·ç§¯ç½‘ç»œè‡ªè¡Œäº§ç”Ÿå»ºè®®æ¡†ï¼Œå¹¶ä¸”å’Œç›®æ ‡æ£€æµ‹ç½‘ç»œå…±äº«å·ç§¯ç½‘ç»œï¼Œä½¿å¾—å»ºè®®æ¡†æ•°ç›®ä»ŽåŽŸæœ‰çš„çº¦2000ä¸ªå‡å°‘ä¸º300ä¸ªï¼Œä¸”å»ºè®®æ¡†çš„è´¨é‡ä¹Ÿæœ‰æœ¬è´¨çš„æé«˜ Yoloç³»åˆ— Yolov1 ç½‘ç»œç»“æž„ YOLO_v1è®²è§£ æµ…è°ˆä¸åŒç‰ˆæœ¬YOLOçš„åŒºåˆ«ï¼ˆV1-V3ï¼‰ è¾“å‡ºå±‚7 \\times 7 \\times 30çš„å«ä¹‰ 7 \\times 7æŠŠåŽŸå›¾å¹³å‡åˆ†æˆ49ä¸ªç½‘æ ¼ï¼Œæ¯ä¸ªç½‘æ ¼å…è®¸é¢„æµ‹å‡º2ä¸ªè¾¹æ¡†ï¼Œæ€»å…± 49*2=98 ä¸ªbounding boxã€‚å¯ä»¥ç†è§£ä¸º98ä¸ªå€™é€‰åŒºï¼Œå®ƒä»¬å¾ˆç²—ç•¥çš„è¦†ç›–äº†å›¾ç‰‡çš„æ•´ä¸ªåŒºåŸŸ 30ä»£è¡¨20ä¸ªç±»åˆ«çš„æ¡ä»¶æ¦‚çŽ‡å’Œä¸¤ä¸ªboundingboxçš„äº”ä¸ªå‚æ•°ï¼ˆä¸­å¿ƒåæ ‡xï¼Œyï¼Œæ¡†çš„å®½å’Œé«˜ï¼Œç½®ä¿¡åº¦ï¼‰ æ¯ä¸ªcellåªèƒ½é¢„æµ‹ä¸€ä¸ªç±»åˆ«ï¼Œå¹¶ä¸”æ— æ³•è§£å†³ç‰©ä½“é‡å çš„é—®é¢˜ï¼Œæ­¤å¤–ï¼ŒYOLOV1å¯¹å°ç‰©ä½“çš„æ£€æµ‹æ•ˆæžœä¹Ÿä¸ç†æƒ³ loss æœ€æ ¸å¿ƒçš„lossè¯¦è§£ å¯ä»¥è®¤ä¸ºYoloç³»åˆ—é‡Œæœ€æ ¸å¿ƒçš„å°±æ˜¯lossçš„è®¾è®¡ï¼Œç†è§£YOLOv1çš„æŸå¤±å‡½æ•°å¯ä»¥å¯¹åŽç»­çš„YOLOç³»åˆ—æœ‰ä¸€å®šçš„å¸®åŠ© å› ä¸ºåŽç»­çš„YOLOç‰ˆæœ¬åœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šæœ‰æ‰€æ”¹è¿›ï¼Œä½†ä»ç„¶ä¿ç•™äº†ä¸€äº›åŸºæœ¬çš„æ€æƒ³å’ŒåŽŸåˆ™ å…ˆçœ‹æ¥ä»¥ä¸‹lossçš„è®¡ç®—å…¬å¼ \\begin{array}{l} loss = \\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\mathrm{obj}}\\left(x_{i}-\\hat{x}_{i}\\right)^{2}+\\left(y_{i}-\\hat{y}_{i}\\right)^{2} \\\\ \\qquad + \\lambda_{\\text {coord }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\mathrm{obj}}\\left(\\sqrt{w_{i}}-\\sqrt{\\hat{w}_{i}}\\right)^{2}+\\left(\\sqrt{h_{i}}-\\sqrt{\\hat{h}_{i}}\\right)^{2} \\\\ \\qquad +\\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\mathrm{obj}}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ \\qquad + \\lambda_{\\text {noobj }} \\sum_{i=0}^{S^{2}} \\sum_{j=0}^{B} \\mathbb{1}_{i j}^{\\mathrm{noobj}}\\left(C_{i}-\\hat{C}_{i}\\right)^{2} \\\\ \\qquad +\\sum_{i=0}^{S^{2}} \\mathbb{1}_{i}^{\\mathrm{obj}} \\sum_{c \\in \\text { classes }} \\left(p_{i}(c)-\\hat{p}_{i}(c)\\right)^{2} \\end{array} è¿™é‡Œçš„lossåˆ†æˆäº†äº”ä¸ªéƒ¨åˆ†ï¼š å«ç›®æ ‡çš„xy: å«æœ‰ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellé‡Œï¼Œè´Ÿè´£é¢„æµ‹çš„bboxé¢„æµ‹å‡ºçš„xyçš„MSE å«ç›®æ ‡çš„wh: å«æœ‰ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellé‡Œï¼Œè´Ÿè´£é¢„æµ‹çš„bboxé¢„æµ‹å‡ºçš„whçš„MSE å«ç›®æ ‡çš„ç½®ä¿¡åº¦: å«æœ‰ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellé‡Œï¼Œè´Ÿè´£é¢„æµ‹çš„bboxé¢„æµ‹å‡ºçš„å­˜åœ¨ç‰©ä½“çš„ç½®ä¿¡åº¦çš„è¯¯å·® ä¸å«ç›®æ ‡çš„ç½®ä¿¡åº¦: ä¸å«æœ‰ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellé‡Œï¼Œæ¯ä¸€ä¸ªbboxéƒ½è¦å‚ä¸Žåˆ°lossçš„è®¡ç®—ï¼ŒC_i=0ï¼›\\hat{C}_{i}=bboxçš„é¢„æµ‹å€¼ï¼Œç„¶åŽç´¯åŠ MSE å«ç›®æ ‡çš„åˆ†ç±»æŸå¤±: å«æœ‰ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellé‡Œï¼Œé¢„æµ‹å‡ºçš„ç‰©ä½“ç±»åˆ«å‘é‡å’ŒGTå¯¹åº”çš„å‘é‡çš„MSE ä¸å«ç›®æ ‡çš„loss å½“cellä¸­ä¸åŒ…å«ç‰©ä½“çš„ä¸­å¿ƒç‚¹ï¼Œé‚£è¿™ä¸ªcellçš„bboxé¢„æµ‹å‡ºç‰©ä½“çš„ç½®ä¿¡åº¦å°±è¦è¶‹è¿‘äºŽ0 Aæ­¥éª¤ï¼šYoloå¯¹è¾“å…¥å›¾åƒå‰å‘ä¼ æ’­çš„è¾“å‡ºå¼ é‡ï¼Œä¸‹é¢æ˜¯è¯¥å›¾çš„ç›®æ ‡å¼ é‡ Bæ­¥éª¤ï¼šä¹˜ä»¥ä¸å«ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellçš„æŽ©ç ï¼Œç›¸å½“äºŽåªç•™ä¸‹æ— ç›®æ ‡çš„cell Cæ­¥éª¤ï¼šæŒ–åŽ»äº†ä¸‰ä¸ªæ´ž(åŽ»é™¤äº†3ä¸ªå«æœ‰ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellçš„æ•°æ®) Dæ­¥éª¤ï¼šä¸€å…±49ä¸ªæ ¼å­ï¼ŒæŒ–åŽ»3ä¸ªå‰©46ï¼ŒB=2ï¼Œå› æ­¤æ‹‰ç›´çš„å‘é‡é•¿åº¦ä¸º92 Eæ­¥éª¤ï¼šè®¡ç®—MSEï¼Œè¿™é‡Œå¯¹åº”å…¬å¼ä¸­çš„ç¬¬4éƒ¨åˆ† å«ç›®æ ‡çš„loss å¦‚æžœæœ‰ç‰©ä½“ï¼Œé¢„æµ‹æ­£ç¡®ç±»åˆ«è¯¯å·®å°±ç­‰äºŽ0 Aæ­¥éª¤ï¼šYoloå¯¹è¾“å…¥å›¾åƒå‰å‘ä¼ æ’­çš„è¾“å‡ºå¼ é‡ï¼Œä¸‹é¢æ˜¯è¯¥å›¾çš„ç›®æ ‡å¼ é‡ Bæ­¥éª¤ï¼šä¹˜ä»¥å«ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellçš„æŽ©ç ï¼Œï¼Œç›¸å½“äºŽåªç•™ä¸‹å«ç›®æ ‡çš„cell Cæ­¥éª¤ï¼šåªç•™ä¸‹ä¸‰ä¸ªå‘é‡(3ä¸ªå«æœ‰ç‰©ä½“ä¸­å¿ƒç‚¹çš„cellçš„æ•°æ®) Dæ­¥éª¤ï¼šå‘é‡åˆå¹¶ Eæ­¥éª¤ï¼šæå–å‡ºç±»åˆ«çš„å‘é‡ Fæ­¥éª¤ï¼šè®¡ç®—MSEï¼Œè¿™é‡Œå¯¹åº”å…¬å¼ä¸­çš„ç¬¬5éƒ¨åˆ† Gæ­¥éª¤ï¼šæå–å‡ºxywhå’Œç½®ä¿¡åº¦çš„å‘é‡ï¼Œå‘é‡åˆå¹¶ Hæ­¥éª¤ï¼šæ¯ä¸€ä¸ªcellä¼šæœ‰2ä¸ªbboxï¼Œè®¡ç®—æ¯ä¸ªbboxä¸Žground truthçš„IOUï¼Œç„¶åŽå¾—åˆ°ç´¢å¼•çŸ©é˜µ(å¯ä»¥ç”¨æ¥ç¡®å®šå“ªä¸ªbboxæ¥å¤„ç†è¿™ä¸ªcell) Iæ­¥éª¤ï¼šæå–å‡ºæœ‰è´£ä»»çš„bboxçš„å‘é‡ Jæ­¥éª¤ï¼šbboxé¢„æµ‹å‡ºçš„xyä¸ŽGTç®—MSEï¼Œå¯¹åº”å…¬å¼ä¸­çš„ç¬¬1éƒ¨åˆ†ï¼›bboxé¢„æµ‹å‡ºçš„whä¸ŽGTç®—MSEï¼Œå¯¹åº”å…¬å¼ä¸­çš„ç¬¬2éƒ¨åˆ† Kæ­¥éª¤ï¼šbboxé¢„æµ‹å‡ºçš„ç½®ä¿¡åº¦ä¸ŽGTç®—MSEï¼Œå¯¹åº”å…¬å¼ä¸­çš„ç¬¬3éƒ¨åˆ† æµ‹è¯•é˜¶æ®µ è¾“å…¥å›¾åƒï¼Œç»è¿‡YOLOç½‘ç»œåŽï¼Œè¾“å‡º 7 \\times 7 \\times (2 \\times 5 + 20 )çš„å¼ é‡ è®¡ç®—æ¯ä¸ªbboxçš„ç±»åˆ«å¾—åˆ† ä»Žæ¯ä¸€ä¸ªcellä¸­æ‰¾å‡º20ä¸ªç±»åˆ«scoreä¸­æœ€å¤§çš„ç±»åˆ«ï¼Œä½œä¸ºcellä¸­ä¸¤boxé¢„æµ‹å‡ºçš„ç±»åˆ« é’ˆå¯¹æ¯ä¸€ä¸ªcellä¸­çš„ä¸¤ä¸ªbboxï¼Œé€‰æ‹©ç½®ä¿¡åº¦å¤§çš„boxæ¥ä»£è¡¨è¿™ä¸ªcellï¼Œå¹¶è®¡ç®—å‡ºboxçš„ç±»åˆ«å¾—åˆ† å‰©ä¸‹49ä¸ªbboxï¼Œæœ€åŽè¿›è¡ŒNMS Score_{i j} = P ( C_{i} | Object ) * Confidence _{j} Yolov2(Yolo9000) YOLOç®—æ³•ä¹‹YOLOv2ç²¾è®² ç›¸æ¯”è¾ƒäºŽYolov1ä¸»è¦æ”¹è¿›ç‚¹ï¼š ç½‘ç»œæ”¹è¿›ï¼šä½¿ç”¨DarckNet19ä»£æ›¿äº†YOLOv1çš„GoogLeNetç½‘ç»œï¼Œè¿™é‡Œä¸»è¦æ”¹è¿›æ˜¯åŽ»æŽ‰äº†å…¨è¿žæŽ¥å±‚ï¼Œç”¨å·ç§¯å’Œsoftmaxè¿›è¡Œä»£æ›¿ åŠ å…¥BNï¼šä½¿ç”¨Batch Normalizationå¯¹ç½‘ç»œè¿›è¡Œä¼˜åŒ–ï¼Œè®©ç½‘ç»œæé«˜äº†æ”¶æ•›æ€§ï¼ŒåŒæ—¶è¿˜æ¶ˆé™¤äº†å¯¹å…¶ä»–å½¢å¼çš„æ­£åˆ™åŒ–(regularization)çš„ä¾èµ– HighResolution Classifierï¼šæ–°çš„YOLOç½‘ç»œæŠŠåˆ†è¾¨çŽ‡ç›´æŽ¥æå‡åˆ°äº†448 \\times 448ï¼Œè¿™ä¹Ÿæ„å‘³ç€åŽŸæœ‰çš„ç½‘ç»œæ¨¡åž‹å¿…é¡»è¿›è¡ŒæŸç§è°ƒæ•´ä»¥é€‚åº”æ–°çš„åˆ†è¾¨çŽ‡è¾“å…¥ï¼ŒmAPèŽ·å¾—äº†4%çš„æå‡ Multi-ScaleTrainingï¼šè®©ç½‘ç»œåœ¨ä¸åŒçš„è¾“å…¥å°ºå¯¸ä¸Šéƒ½èƒ½è¾¾åˆ°ä¸€ä¸ªå¾ˆå¥½çš„é¢„æµ‹æ•ˆæžœï¼ŒåŒä¸€ç½‘ç»œèƒ½åœ¨ä¸åŒåˆ†è¾¨çŽ‡ä¸Šè¿›è¡Œæ£€æµ‹ã€‚å½“è¾“å…¥å›¾ç‰‡å°ºå¯¸æ¯”è¾ƒå°çš„æ—¶å€™è·‘çš„æ¯”è¾ƒå¿«ï¼Œè¾“å…¥å›¾ç‰‡å°ºå¯¸æ¯”è¾ƒå¤§çš„æ—¶å€™ç²¾åº¦é«˜ Anchoræœºåˆ¶ï¼šAnchoré¦–å…ˆè¦é¢„è®¾å¥½å‡ ä¸ªè™šæ‹Ÿæ¡†ï¼Œåœ¨ç”¨å›žå½’çš„æ–¹æ³•ç¡®å®šæœ€ç»ˆçš„é¢„æµ‹æ¡†ï¼Œåœ¨YOLOv2ä¸­ï¼Œä½¿ç”¨K-meansç®—æ³•æ¥ç”ŸæˆAnchor bboxï¼Œå¦‚å›¾1æ‰€ç¤ºï¼Œå½“k=5æ—¶ï¼Œæ¨¡åž‹çš„å¤æ‚åº¦ä¸Žå¬å›žçŽ‡è¾¾åˆ°äº†ä¸€ä¸ªæ¯”è¾ƒå¥½çš„å¹³è¡¡ï¼Œæ‰€ä»¥YOLOv2ä½¿ç”¨äº†5ä¸ªAnchor bbox åˆ†ç±»ã€æ£€æµ‹è®­ç»ƒé›†è”åˆè®­ç»ƒï¼šè”åˆè®­ç»ƒæ–¹æ³•æ€è·¯ç®€å•æ¸…æ™°ï¼ŒYolo v2ä¸­ç‰©ä½“çŸ©å½¢æ¡†ç”Ÿæˆï¼Œä¸ä¾èµ–äºŽç‰©ç†ç±»åˆ«é¢„æµ‹ï¼ŒäºŒè€…åŒæ—¶ç‹¬ç«‹è¿›è¡Œ å½“è¾“å…¥æ˜¯æ£€æµ‹æ•°æ®é›†æ—¶ï¼Œæ ‡æ³¨ä¿¡æ¯æœ‰ç±»åˆ«ã€æœ‰ä½ç½®ï¼Œé‚£ä¹ˆå¯¹æ•´ä¸ªlosså‡½æ•°è®¡ç®—lossï¼Œè¿›è¡Œåå‘ä¼ æ’­ å½“è¾“å…¥å›¾ç‰‡åªåŒ…å«åˆ†ç±»ä¿¡æ¯æ—¶ï¼Œlosså‡½æ•°åªè®¡ç®—åˆ†ç±»lossï¼Œå…¶ä½™éƒ¨åˆ†lossä¸ºé›¶ å½“ç„¶ï¼Œä¸€èˆ¬çš„è®­ç»ƒç­–ç•¥ä¸ºï¼Œå…ˆåœ¨æ£€æµ‹æ•°æ®é›†ä¸Šè®­ç»ƒä¸€å®šçš„epochï¼Œå¾…é¢„æµ‹æ¡†çš„lossåŸºæœ¬ç¨³å®šåŽï¼Œå†è”åˆåˆ†ç±»æ•°æ®é›†ã€æ£€æµ‹æ•°æ®é›†è¿›è¡Œäº¤æ›¿è®­ç»ƒï¼ŒåŒæ—¶ä¸ºäº†åˆ†ç±»ã€æ£€æµ‹æ•°æ®é‡å¹³è¡¡ï¼Œä½œè€…å¯¹cocoæ•°æ®é›†è¿›è¡Œäº†ä¸Šé‡‡æ ·ï¼Œä½¿å¾—cocoæ•°æ®æ€»æ•°å’ŒImageNetå¤§è‡´ç›¸åŒ è¾“å‡ºå’ŒYolov1æ¯”è¾ƒå¦‚ä¸‹ YOLOv1æ˜¯çš„è¾“å‡º7 \\times 7 \\times 30çš„å¤šç»´å‘é‡ï¼Œå…¶ä¸­7 \\times 7æ˜¯åˆ†è¾¨çŽ‡ï¼Œå¯¹åŽŸå›¾è¿›è¡Œäº†7 \\times 7çš„åˆ†å‰²ï¼Œæ¯ä¸ªç½‘æ ¼å¯¹åº”ä¸€ä¸ªåŒ…å«30ä¸ªå‚æ•°çš„å‘é‡ï¼Œæ¯ä¸ªå‘é‡ä¸­åŒ…å«ä¸¤ä¸ªbboxï¼Œæ¯ä¸ªbboxä¸­åŒ…å«5ä¸ªå‘é‡ï¼Œåˆ†åˆ«æ˜¯bboxçš„è´¨å¿ƒåæ ‡ï¼ˆx, yï¼‰å’Œbboxçš„é•¿å’Œå®½ï¼Œè¿˜æœ‰ä¸€ä¸ªbboxçš„ç½®ä¿¡åº¦ï¼Œå‰©ä¸‹20ä¸ªåˆ™æ˜¯ç±»åˆ«æ¦‚çŽ‡ YOLOv2è¾“å‡ºçš„æ˜¯13 \\times 13 \\times 5 \\times 25çš„ä¸€ä¸ªå¤šç»´å‘é‡ï¼Œå…¶ä¸­13 \\times 13æ˜¯åˆ†è¾¨çŽ‡ï¼Œä¹Ÿå°±æ˜¯è¯´ç½‘ç»œå°†è¾“å…¥å›¾ç‰‡åˆ†æˆäº†13 \\times 13çš„ç½‘æ ¼ï¼Œæ¯ä¸€ä¸ªç½‘æ ¼å¯¹åº”ä¸€ä¸ªåŒ…å«5 \\times 25 =125 ä¸ªå‚æ•°çš„ä¸€ç»´å‘é‡ï¼Œå…¶ä¸­5ä»£è¡¨5ä¸ªAnchor bboxï¼Œæ¯ä¸ªAnchor bboxä¸­åŒ…å«25ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯bboxçš„è´¨å¿ƒåæ ‡(x,y)å’Œbboxçš„é•¿å’Œå®½ï¼Œè¿˜æœ‰ä¸€ä¸ªbboxçš„ç½®ä¿¡åº¦ï¼Œå‰©ä¸‹20ä¸ªåˆ™æ˜¯ç±»åˆ«æ¦‚çŽ‡ã€‚è¿™æ ·çš„å¥½å¤„æ˜¯YOLOv2å¯ä»¥å¯¹ä¸€ä¸ªåŒºåŸŸè¿›è¡Œå¤šä¸ªæ ‡ç­¾çš„é¢„æµ‹ï¼Œæœ€ä¸»è¦çš„æ”¹å˜æ˜¯ï¼šbboxçš„å››ä¸ªä½ç½®å‚æ•°çš„æŸå¤±å‡½æ•°è®¡ç®—æ–¹æ³•å‘ç”Ÿäº†æ”¹å˜ è®­ç»ƒä¸»è¦åŒ…æ‹¬ä»¥ä¸‹ä¸‰ä¸ªé˜¶æ®µï¼š å…ˆåœ¨ImageNetåˆ†ç±»æ•°æ®é›†ä¸Šé¢„è®­ç»ƒDarknet-19ï¼Œæ­¤æ—¶æ¨¡åž‹è¾“å…¥224 \\times 224ï¼Œå…±è®­ç»ƒ160ä¸ªepochsã€‚ å°†ç½‘ç»œçš„è¾“å…¥è°ƒæ•´ä¸º448 \\times 448ï¼Œç»§ç»­åœ¨ImageNetæ•°æ®é›†ä¸Šfinetuneåˆ†ç±»æ¨¡åž‹ï¼Œè®­ç»ƒ10ä¸ªepochsï¼Œæ­¤æ—¶åˆ†ç±»æ¨¡åž‹çš„top-1å‡†ç¡®åº¦ä¸º76.5%ï¼Œè€Œtop-5å‡†ç¡®åº¦ä¸º93.3%ã€‚ ä¿®æ”¹Darknet-19åˆ†ç±»æ¨¡åž‹ä¸ºæ£€æµ‹æ¨¡åž‹ï¼šå³ç§»é™¤æœ€åŽä¸€ä¸ªå·ç§¯å±‚ã€global avg poolingå±‚ä»¥åŠsoftmaxå±‚ï¼Œå¹¶ä¸”æ–°å¢žäº†ä¸‰ä¸ª3 \\times 3 \\times 2014å·ç§¯å±‚ï¼ŒåŒæ—¶å¢žåŠ äº†ä¸€ä¸ªpassthroughå±‚ï¼Œæœ€åŽä½¿ç”¨1 \\times 1å·ç§¯å±‚è¾“å‡ºé¢„æµ‹ç»“æžœï¼Œå¹¶åœ¨æ£€æµ‹æ•°æ®é›†ä¸Šç»§ç»­finetuneç½‘ç»œ yolov3 ç¿æ™ºçš„ç›®æ ‡æ£€æµ‹26â€”â€”Pytorchæ­å»ºyolo3ç›®æ ‡æ£€æµ‹å¹³å° ä»Žç‰¹å¾èŽ·å–é¢„æµ‹ç»“æžœçš„è¿‡ç¨‹å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«æ˜¯ï¼š æž„å»ºFPNç‰¹å¾é‡‘å­—å¡”è¿›è¡ŒåŠ å¼ºç‰¹å¾æå– åˆ©ç”¨Yolo Headå¯¹ä¸‰ä¸ªæœ‰æ•ˆç‰¹å¾å±‚è¿›è¡Œé¢„æµ‹ åœ¨ç‰¹å¾åˆ©ç”¨éƒ¨åˆ†ï¼ŒYoloV3æå–å¤šç‰¹å¾å±‚è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œä¸€å…±æå–ä¸‰ä¸ªç‰¹å¾å±‚ï¼Œä¸‰ä¸ªç‰¹å¾å±‚ä½äºŽä¸»å¹²éƒ¨åˆ†Darknet53çš„ä¸åŒä½ç½®ï¼Œåˆ†åˆ«ä½äºŽä¸­é—´å±‚ï¼Œä¸­ä¸‹å±‚ï¼Œåº•å±‚ ä¸‰ä¸ªç‰¹å¾å±‚çš„shapeåˆ†åˆ«ä¸º(52,52,256)ã€(26,26,512)ã€(13,13,1024) è¾“å‡ºç»´åº¦è§£æž ç½‘ç»œæœ‰ä¸‰ä¸ªè¾“å‡ºï¼Œç»´åº¦åˆ†åˆ«ä¸ºbs \\times 13 \\times 13 \\times 75ã€bs \\times 26 \\times 26 \\times 75å’Œbs \\times 52 \\times 52 \\times 75ï¼Œå…¶ä¸­75å¯ä»¥åˆ†è§£æˆ3 \\times (4+1+20) 3è¡¨ç¤ºä¸‰ä¸ªå€™é€‰æ¡†ï¼Œ4è¡¨ç¤ºçš„æ˜¯xywhçš„ä½ç½®ä¿¡æ¯ï¼Œ1è¡¨ç¤ºæ˜¯å¦ä¸ºèƒŒæ™¯ï¼Œ20ä¸ºç‰©ä½“çš„ç±»åˆ«æ•°(è¿™é‡Œç”¨çš„æ˜¯vocæ•°æ®é›†) å› ä¸ºæœ‰ä¸‰ä¸ªè¾“å‡ºï¼Œå› æ­¤è¯¥ç½‘ç»œæœ‰ä¸ª13 \\times 13 \\times 3 + 26\\times 26\\times 3 + 52 \\times 52\\times 3 = 10647é¢„æµ‹æ¡† å¯¹äºŽè¿™äº›é¢„æµ‹æ¡†ï¼Œå¦‚æžœå…¶ä¸Žä»»ä½•çœŸå®žæ¡†çš„IoUå¤§äºŽä¸€å®šçš„é˜ˆå€¼ï¼ˆå¦‚0.5ï¼‰ï¼Œåˆ™å°†å…¶åˆ†é…ç»™å¯¹åº”çš„è¾“å‡ºå±‚ä½œä¸ºæ­£æ ·æœ¬ã€‚å¦åˆ™ï¼Œå°†å…¶è§†ä¸ºè´Ÿæ ·æœ¬ YOLOv3 ä½¿ç”¨çš„æŸå¤±å‡½æ•°æ˜¯ç»„åˆäº†å¤šä¸ªéƒ¨åˆ†çš„ç»¼åˆæŸå¤±å‡½æ•°ï¼Œå…¶ä¸­åŒ…æ‹¬å®šä½æŸå¤±ï¼ˆLocalization Lossï¼‰ã€åˆ†ç±»æŸå¤±ï¼ˆClassification Lossï¼‰å’Œç½®ä¿¡åº¦æŸå¤±ï¼ˆConfidence Lossï¼‰ L=L_{c l s}+L_{c o n f}+L_{l o c} åªæœ‰æ­£æ ·æœ¬æ‰æœ‰è¿™ä¸‰ç±»æŸå¤±ï¼Œè€Œè´Ÿæ ·æœ¬åªæœ‰ç½®ä¿¡åº¦æŸå¤± ä»¥ä¸‹æ˜¯ YOLOv3 çš„æŸå¤±å‡½æ•°çš„ä¼ªä»£ç å®žçŽ°ï¼ŒåŒ…å«è¯¦ç»†æ³¨é‡Šï¼š def yolo_loss(pred_boxes, pred_cls, target_boxes, target_cls): # pred_boxes: é¢„æµ‹çš„è¾¹ç•Œæ¡†åæ ‡ï¼Œshape ä¸º [batch_size, num_anchors, grid_size, grid_size, 4] # pred_cls: é¢„æµ‹çš„ç±»åˆ«æ¦‚çŽ‡ï¼Œshape ä¸º [batch_size, num_anchors, grid_size, grid_size, num_classes] # target_boxes: çœŸå®žçš„è¾¹ç•Œæ¡†åæ ‡ï¼Œshape ä¸º [batch_size, num_anchors, grid_size, grid_size, 4] # target_cls: çœŸå®žçš„ç±»åˆ«æ ‡ç­¾ï¼Œshape ä¸º [batch_size, num_anchors, grid_size, grid_size, num_classes] # è®¡ç®—é¢„æµ‹æ¡†å’ŒçœŸå®žæ¡†çš„IoU iou_scores = calculate_iou(pred_boxes, target_boxes) # shape: [batch_size, num_anchors, grid_size, grid_size] # è®¡ç®—ç±»åˆ«æŸå¤±ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•° cls_loss = cross_entropy_loss(pred_cls, target_cls) # shape: [batch_size, num_anchors, grid_size, grid_size] # è®¡ç®—è¾¹ç•Œæ¡†æŸå¤±ï¼Œä½¿ç”¨å¹³æ»‘L1æŸå¤±å‡½æ•° box_loss = smooth_l1_loss(pred_boxes, target_boxes) # shape: [batch_size, num_anchors, grid_size, grid_size] # è®¡ç®—æ­£æ ·æœ¬çš„æŽ©ç ï¼Œå³ä¸ŽçœŸå®žæ¡†IoUå¤§äºŽé˜ˆå€¼çš„ä½ç½®ä¸º1ï¼Œå…¶ä½™ä¸º0 pos_mask = (iou_scores > positive_iou_threshold).float() # shape: [batch_size, num_anchors, grid_size, grid_size] # è®¡ç®—è´Ÿæ ·æœ¬çš„æŽ©ç ï¼Œå³ä¸ŽçœŸå®žæ¡†IoUå°äºŽé˜ˆå€¼çš„ä½ç½®ä¸º1ï¼Œå…¶ä½™ä¸º0 neg_mask = (iou_scores æ­£è´Ÿæ ·æœ¬æ•° åœ¨ YOLOv3 ä¸­ï¼Œé€šå¸¸ä¼šä¸ºæ¯ä¸ªç›®æ ‡é€‰æ‹©ä¸€ä¸ªæ­£æ ·æœ¬ï¼Œå³ä¸ŽçœŸå®žç›®æ ‡æ¡†å…·æœ‰æœ€é«˜ IoU çš„é¢„æµ‹æ¡†ã€‚è¿™ç¡®ä¿äº†æ¯ä¸ªç›®æ ‡éƒ½æœ‰è‡³å°‘ä¸€ä¸ªæ­£æ ·æœ¬æ¥å‚ä¸ŽæŸå¤±å‡½æ•°çš„è®¡ç®—å’Œç½‘ç»œçš„è®­ç»ƒã€‚ è‡³äºŽè´Ÿæ ·æœ¬çš„é€‰æ‹©ï¼Œä¸€èˆ¬ä¼šè®¾ç½®ä¸€ä¸ªé˜ˆå€¼æ¥ç¡®å®šé¢„æµ‹æ¡†ä¸ŽçœŸå®žæ¡†ä¹‹é—´çš„ IoU é˜ˆå€¼ã€‚å¦‚æžœé¢„æµ‹æ¡†çš„ IoU ä½ŽäºŽè¯¥é˜ˆå€¼ï¼Œåˆ™è¢«è§†ä¸ºè´Ÿæ ·æœ¬ã€‚å¯¹äºŽæ¯ä¸ªè´Ÿæ ·æœ¬ï¼Œå¯ä»¥é€‰æ‹©ä¿ç•™ä¸€å®šæ•°é‡çš„è´Ÿæ ·æœ¬ï¼Œä»¥ç¡®ä¿æ­£è´Ÿæ ·æœ¬çš„å¹³è¡¡æ€§ã€‚ å…·ä½“æ¥è¯´ï¼Œå…³äºŽæ­£è´Ÿæ ·æœ¬çš„é€‰æ‹©æ•°é‡å¹¶æ²¡æœ‰ä¸€ä¸ªå›ºå®šçš„æ ‡å‡†ï¼Œå®ƒå¯ä»¥æ ¹æ®å…·ä½“çš„æ•°æ®é›†å’Œåº”ç”¨åœºæ™¯æ¥ç¡®å®šã€‚åœ¨å®žè·µä¸­ï¼Œå¯ä»¥æ ¹æ®æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯å’Œè®­ç»ƒæ•ˆæžœè¿›è¡Œè°ƒæ•´ï¼Œä»¥æ‰¾åˆ°ä¸€ä¸ªé€‚åˆçš„æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ï¼Œä»Žè€Œå¹³è¡¡ç›®æ ‡æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ã€‚ yolov5 Yolov8 Yolov8 githubåœ°å€å’Œæ–‡æ¡£ ç›®æ ‡æ£€æµ‹ Model size (pixels) mAPval 50-95 Speed CPU ONNX (ms) Speed A100 TensorRT (ms) params (M) FLOPs (B) YOLOv8n 640 37.3 80.4 0.99 3.2 8.7 YOLOv8s 640 44.9 128.4 1.20 11.2 28.6 YOLOv8m 640 50.2 234.7 1.83 25.9 78.9 YOLOv8l 640 52.9 375.2 2.39 43.7 165.2 YOLOv8x 640 53.9 479.1 3.53 68.2 257.8 tensorRtåŠ é€Ÿ å¯ä»¥ç”¨tensorRtåŠ é€Ÿï¼ŒçŽ¯å¢ƒæ•™ç¨‹å¯ä»¥å‚è€ƒè¿™ä¸ªæ–‡æ¡£ è¿›è¡ŒtensortåŠ é€Ÿï¼Œcmakeç¼–è¯‘å¤±è´¥ï¼Œç¼ºå°‘zlibwapi.dllæ–‡ä»¶ï¼Œè§£å†³åŠžæ³•ï¼ŒåŽ»cudnnå®˜ç½‘ä¸‹è½½zlib123dllx64 libæ–‡ä»¶æ”¾åˆ°C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1\\lib dllæ–‡ä»¶æ”¾åˆ°C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1\\bin YoloV8æä¾›äº†å¯¼å‡ºå·¥å…·ï¼Œè¯¦è§æ–‡æ¡£ï¼Œpythonä»£ç å¯¼å‡ºå¯ä»¥è¿™æ ·å­å†™ def run(): model = YOLO(\"../../weights/yolov8s.pt\") # load an official detection model model.export(format='engine', device='0', workspace=8, batch=4, dynamic=True) æˆ–è€…ç›´æŽ¥å‘½ä»¤è¡Œæ‰§è¡Œ yolo mode=export model=yolov8s.pt format=engine device=0 workspace=8 batch=4 dynamic=True å…³é”®å‚æ•°å¦‚ä¸‹ï¼š device: å…¶ä¸­deviceå¿…é¡»æ˜¯GPUï¼Œå¯ä»¥æ˜¯å¤šå¼ æ˜¾å¡ workspace: TensorRT: workspace size (GB) batch: æœ€å¤§æ‰¹æ¬¡å¤§å°ï¼Œå½“è®¾ç½®å‚æ•°æ—¶å¿…é¡»æœ‰dynamic=Trueï¼Œå¯ä»¥è¿è¡Œæœ€å¤§ä¸è¶…è¿‡batchçš„æ•°é‡ dynamic: åŠ¨æ€å‚æ•°ï¼ŒONNX/TF/TensorRT: dynamic axes imgsz: image size as scalar or (h, w) list, i.e. (640, 480) æ³¨æ„äº‹é¡¹ï¼š TensorRTå‘å¸ƒçš„æ¨¡åž‹(engine)ä¸èƒ½è·¨å¹³å°ä½¿ç”¨ ä¾‹å¦‚linuxå‘å¸ƒçš„æ¨¡åž‹ä¸èƒ½åœ¨windowsä¸‹ç”¨ TensorRTå‘å¸ƒçš„æ¨¡åž‹éœ€è¦åœ¨ç›¸åŒGPUç®—åŠ›(compute capability)çš„æƒ…å†µä¸‹ä½¿ç”¨ å¦åˆ™ä¼šå¯¼è‡´compute capabilityä¸åŒ¹é…é—®é¢˜ï¼Œä¾‹å¦‚ç®—åŠ›6.1å‘å¸ƒçš„æ¨¡åž‹ä¸èƒ½åœ¨7.5ä¸Šç”¨ åŠ¨æ€batchå’ŒåŠ¨æ€å®½é«˜çš„å¤„ç†æ–¹å¼ åŠ¨æ€batchï¼šæºè‡ªtensorRTç¼–è¯‘æ—¶å¯¹batchçš„å¤„ç†ï¼Œè‹¥é™æ€batchåˆ™æ„å‘³ç€æ— è®ºä½ å¤šå°‘å›¾ï¼Œéƒ½æŒ‰ç…§å›ºå®šå¤§å°batchæŽ¨ç†ï¼Œè€—æ—¶æ˜¯å›ºå®šçš„ å¯¼å‡ºæ¨¡åž‹æ—¶ï¼Œæ³¨æ„viewæ“ä½œä¸èƒ½å›ºå®šbatchç»´åº¦æ•°å€¼ï¼Œé€šå¸¸å†™-1 å¯¼å‡ºæ¨¡åž‹æ—¶ï¼Œé€šå¸¸å¯ä»¥æŒ‡å®šdynamic_axesï¼Œå®žé™…ä¸Šä¸æŒ‡å®šä¹Ÿæ²¡å…³ç³» åŠ¨æ€å®½é«˜ï¼šæºè‡ªonnxå¯¼å‡ºæ—¶æŒ‡å®šçš„å®½é«˜æ˜¯å›ºå®šçš„ï¼Œtrtç¼–è¯‘æ—¶ä¹Ÿå¾—åˆ°å›ºå®šå¤§å°å¼•æ“Žï¼Œæ­¤æ—¶è‹¥ä½ æƒ³å¾—åˆ°ä¸€ä¸ªä¸åŒå¤§å°çš„trtå¼•æ“Žæ—¶ï¼Œå°±éœ€è¦åŠ¨æ€å®½é«˜çš„å­˜åœ¨ã€‚è€Œä½¿ç”¨trtçš„åŠ¨æ€å®½é«˜ä¼šå¸¦æ¥å¤ªå¤šä¸å¿…è¦çš„å¤æ‚åº¦ï¼Œè¿™é‡Œä½¿ç”¨ä¸­é—´æ–¹æ¡ˆï¼Œç¼–è¯‘æ—¶ä¿®æ”¹onnxè¾“å…¥å®žçŽ°ç›¸å¯¹åŠ¨æ€ï¼Œé¿å…é‡å›žpytorchå†åšå¯¼å‡º ä¸å»ºè®®ä½¿ç”¨dynamic_axesæŒ‡å®š0ä»¥å¤–çš„ç»´åº¦ä¸ºåŠ¨æ€ï¼Œå¤æ‚åº¦å¤ªé«˜ï¼Œå¹¶ä¸”å­˜åœ¨æœ‰çš„layerä¸æ”¯æŒï¼Œè¿™ç§éœ€æ±‚ä¹Ÿä¸å¸¸ç”¨ï¼Œæ€§èƒ½ä¹Ÿå¾ˆå·® çœŸæ­£éœ€è¦çš„ï¼Œæ˜¯onnxæ–‡ä»¶å·²ç»å¯¼å‡ºï¼Œä½†æ˜¯è¾“å…¥shapeå›ºå®šäº†ï¼Œæ­¤æ—¶å¸Œæœ›ä¿®æ”¹è¿™ä¸ªonnxçš„è¾“å…¥shape æ­¥éª¤ä¸€: ä½¿ç”¨TRT::compileå‡½æ•°çš„inputsDimsSetupå‚æ•°é‡å®šä¹‰è¾“å…¥çš„shape æ­¥éª¤äºŒ: ä½¿ç”¨TRT:set_layer_hook_reshapeé’©å­åŠ¨æ€ä¿®æ”¹reshapeçš„å‚æ•°å®žçŽ°é€‚é… å…¶ä»–æ£€æµ‹ç³»åˆ— SSD FPN Feature Pyramid Networks for Object Detection æ¦‚è¿° FPN(feature pyramid networks) æ˜¯ä½•å‡¯æ˜Žç­‰ä½œè€…æå‡ºçš„é€‚ç”¨äºŽå¤šå°ºåº¦ç›®æ ‡æ£€æµ‹ç®—æ³• åŽŸæ¥å¤šæ•°çš„object detectionç®—æ³•(æ¯”å¦‚ faster rcnn)éƒ½æ˜¯åªé‡‡ç”¨é¡¶å±‚ç‰¹å¾åšé¢„æµ‹ï¼Œä½†æˆ‘ä»¬çŸ¥é“ä½Žå±‚çš„ç‰¹å¾è¯­ä¹‰ä¿¡æ¯æ¯”è¾ƒå°‘ï¼Œä½†æ˜¯ç›®æ ‡ä½ç½®å‡†ç¡®ï¼›é«˜å±‚çš„ç‰¹å¾è¯­ä¹‰ä¿¡æ¯æ¯”è¾ƒä¸°å¯Œï¼Œä½†æ˜¯ç›®æ ‡ä½ç½®æ¯”è¾ƒç²—ç•¥ å¦å¤–è™½ç„¶ä¹Ÿæœ‰äº›ç®—æ³•é‡‡ç”¨å¤šå°ºåº¦ç‰¹å¾èžåˆçš„æ–¹å¼ï¼Œä½†æ˜¯ä¸€èˆ¬æ˜¯é‡‡ç”¨èžåˆåŽçš„ç‰¹å¾åšé¢„æµ‹ï¼Œè€Œæœ¬æ–‡ä¸ä¸€æ ·çš„åœ°æ–¹åœ¨äºŽé¢„æµ‹æ˜¯åœ¨ä¸åŒç‰¹å¾å±‚ç‹¬ç«‹è¿›è¡Œçš„ï¼Œè¿™é‡Œä¸»è¦å€Ÿé‰´äº† ResNetçš„æ®‹å·®: ç»“åˆäº†æµ…å±‚ç‰¹å¾å’Œæ·±å±‚ç‰¹å¾ SSDçš„æ£€æµ‹ç­–ç•¥: åœ¨ä¸åŒåˆ†è¾¨çŽ‡çš„ç‰¹å¾å›¾ä¸Šåˆ†åˆ«åšé¢„æµ‹ ç‰¹å¾é‡‘å­—å¡”å›¾ç¤ºï¼Œè¶Šç²—è¡¨ç¤ºç‰¹å¾è¯­ä¹‰æ›´å¼º è–°é£Žè¯»è®ºæ–‡ï¼šFeature Pyramid Network è¯¦è§£ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œFPNçš„æ¥é¾™åŽ»è„‰ å›¾ä¸­å°†ç‰¹å¾é‡‘å­—å¡”å’Œå…¶ä»–çš„é‡‘å­—å¡”åšäº†æ¯”è¾ƒ (a)æ˜¯ä¼ ç»Ÿä¸­çš„å›¾ç‰‡é‡‘å­—å¡”ï¼Œå›¾ç‰‡ç¼©æ”¾åˆ°ä¸åŒçš„å¤§å°ï¼Œåˆ†åˆ«é¢„æµ‹ï¼Œæ¯ä¸ªç‰¹å¾æå–/é¢„æµ‹éƒ½æ˜¯ç‹¬ç«‹è¿›è¡Œçš„ï¼ŒåŒä¸€å¼ å›¾ç‰‡çš„ä¸åŒåˆ†è¾¨çŽ‡ï¼Œä¹Ÿå¾ˆéš¾å…±äº«å®ƒä»¬ä¸­é—´æå–çš„ç‰¹å¾ï¼Œè®©æ¨¡åž‹é¢„æµ‹çš„è¿‡ç¨‹è´¹æ—¶è´¹åŠ› (b)æ˜¯åŽŸç”Ÿçš„CNNæå–çš„ç‰¹å¾ï¼Œç”±äºŽåŽç»­å­˜åœ¨æ± åŒ–å’Œé™é‡‡æ ·ï¼Œæµ…å±‚ç½‘ç»œçš„ç‰¹å¾å›¾å¯ä»¥ä¿ç•™æ›´å¤šçš„åˆ†è¾¨çŽ‡ï¼Œä½†æ˜¯ç‰¹å¾è¯­ä¹‰è¾ƒä¸ºä½Žçº§ (c)æ˜¯SSDä¸­çš„ç‰¹å¾ï¼ŒæŠŠä¸åŒåˆ†è¾¨çŽ‡ç‰¹å¾ï¼Œåœ¨ä¸åŒåˆ†è¾¨çŽ‡çš„ç‰¹å¾ä¸Šç›´æŽ¥é¢„æµ‹ï¼Œé‚£ä¹ˆå¤§ç‰©ä½“å°ç‰©ä½“éƒ½èƒ½é¢„æµ‹åˆ°ï¼Œä½†ä»å­˜åœ¨åº•å±‚ç‰¹å¾è¯­ä¹‰ä¸å¤Ÿå’Œæœ€é«˜åˆ†è¾¨çŽ‡ä¸é«˜çš„é—®é¢˜ (d)æ˜¯FPNä¸­ç”¨çš„ç‰¹å¾é‡‘å­—å¡”ï¼Œç»“åˆæ·±æµ…ç‰¹å¾ï¼Œå…¼é¡¾åˆ†è¾¨çŽ‡ä¸Žç‰¹å¾è¯­ä¹‰ RetinaNet Focal Loss for Dense Object Detection 2018 ppt: Focal Loss for Dense Object Detection RetinaNetæ˜¯ä½¿ç”¨FPNå’ŒFocal Loss(è¯¦æƒ…çœ‹æœ¬ç«™æ·±åº¦å­¦ä¹ æ ¸å¿ƒä¹‹æŸå¤±å‡½æ•°éƒ¨åˆ†)çš„ç›®æ ‡æ£€æµ‹æ¨¡åž‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè§£å†³ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ å®ƒé€šè¿‡ç‰¹å¾é‡‘å­—å¡”ç½‘ç»œç”Ÿæˆå¤šå°ºåº¦çš„ç‰¹å¾å›¾ï¼Œå¹¶ä½¿ç”¨Focal Lossé‡ç‚¹å…³æ³¨éš¾ä»¥åˆ†ç±»çš„æ ·æœ¬ï¼Œä»Žè€Œæé«˜äº†æ£€æµ‹æ€§èƒ½ DETR End-to-End Object Detection with Transformers DETR 2020 æ·±åº¦å­¦ä¹ ä¹‹ç›®æ ‡æ£€æµ‹ï¼ˆåä¸€ï¼‰--DETRè¯¦è§£ ç»§Transformeråº”ç”¨äºŽå›¾åƒåˆ†ç±»åŽï¼ŒTransformeråº”ç”¨äºŽå›¾åƒç›®æ ‡æ£€æµ‹çš„å¼€å±±ä¹‹ä½œâ€“DEtection TRansformerï¼Œå…¶å¤§å¤§ç®€åŒ–äº†ç›®æ ‡æ£€æµ‹çš„æ¡†æž¶ï¼Œæ›´ç›´è§‚ DETRæ˜¯Facebookå›¢é˜ŸäºŽ2020å¹´æå‡ºçš„åŸºäºŽTransformerçš„ç«¯åˆ°ç«¯ç›®æ ‡æ£€æµ‹ï¼Œæ²¡æœ‰éžæžå¤§å€¼æŠ‘åˆ¶NMSåŽå¤„ç†æ­¥éª¤ã€æ²¡æœ‰anchorç­‰å…ˆéªŒçŸ¥è¯†å’Œçº¦æŸï¼Œæ•´ä¸ªç”±ç½‘ç»œå®žçŽ°ç«¯åˆ°ç«¯çš„ç›®æ ‡æ£€æµ‹å®žçŽ°ï¼Œå¤§å¤§ç®€åŒ–äº†ç›®æ ‡æ£€æµ‹çš„pipelineã€‚ç»“æžœåœ¨COCOæ•°æ®é›†ä¸Šæ•ˆæžœä¸ŽFaster RCNNç›¸å½“ï¼Œåœ¨å¤§ç›®æ ‡ä¸Šæ•ˆæžœæ¯”Faster RCNNå¥½ï¼Œä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°å°†DETRè¿ç§»åˆ°å…¶ä»–ä»»åŠ¡ä¾‹å¦‚å…¨æ™¯åˆ†å‰² ç›®æ ‡è·Ÿè¸ª ä¸‡å­—é•¿æ–‡ | å¤šç›®æ ‡è·Ÿè¸ªæœ€æ–°ç»¼è¿°(åŸºäºŽTransformer/å›¾æ¨¡åž‹/æ£€æµ‹å’Œå…³è”/å­ªç”Ÿç½‘ç»œ) ã€yolov4ç›®æ ‡æ£€æµ‹ã€‘(2) å¤šç›®æ ‡è·Ÿè¸ªï¼Œæ¡ˆä¾‹ï¼šè½¦è¾†è¡Œäººçš„è·Ÿè¸ªå’Œè®¡æ•°ï¼Œé™„pythonå®Œæ•´ä»£ç å’Œæ•°æ®é›† yolov4-deepsort tensorflowä»£ç  è½¬è½½ï¼šä¸€çº¿ç®—æ³•å·¥ç¨‹å¸ˆæ•´ç†ï¼è¶…å®žç”¨çš„3å¤§å¤šç›®æ ‡è·Ÿè¸ªç®—æ³• Deep-Sort å¤šç›®æ ‡è·Ÿè¸ªç®—æ³•åŽŸç†å’Œä»£ç è§£æž Darklabelå¤šç›®æ ‡è·Ÿè¸ªæ ‡æ³¨å·¥å…· ä¸‡å­—ç»¼è¿°ï¼šç›®æ ‡æ£€æµ‹æ¨¡åž‹YOLOv1-v7æ·±åº¦è§£æž ç›®æ ‡è·Ÿè¸ª = ç›®æ ‡æ£€æµ‹+ç›®æ ‡è·Ÿè¸ªç®—æ³• ç›®æ ‡è¿½è¸ªç®—æ³•åˆ†ä¸ºå•ç›®æ ‡è¿½è¸ªSOT(Single-Object Track)å’Œå¤šç›®æ ‡è¿½è¸ªMOT(Multi-Object Track)[1][2] åœ¨å•ç›®æ ‡è·Ÿè¸ªä¸­ï¼Œä½¿ç”¨ç»™å®šçš„åˆå§‹ç›®æ ‡ä½ç½®ï¼Œåœ¨åŽç»­è§†é¢‘å¸§ä¸­å¯¹ç»™å®šçš„ç‰©ä½“è¿›è¡Œä½ç½®é¢„æµ‹ å¤šç›®æ ‡è·Ÿè¸ªç®—æ³•ï¼Œå¤§éƒ¨åˆ†éƒ½æ˜¯ä¸è€ƒè™‘åˆå§‹ç›®æ ‡ä½ç½®çš„ï¼Œç›®æ ‡å¯è‡ªè¡Œæ¶ˆå¤±ä¸Žäº§ç”Ÿ ç›®æ ‡è·Ÿè¸ªåˆ†ç±» ç›®æ ‡è·Ÿè¸ªé€šå¸¸å¯åˆ†ä¸ºå•ç›®æ ‡è·Ÿè¸ªå’Œå¤šç›®æ ‡è·Ÿè¸ªä¸¤ç±» å•ç›®æ ‡è·Ÿè¸ª å¤šç›®æ ‡è·Ÿè¸ª SDE(separate detecting and embeding) æ¯éƒ¨åˆ†ç‹¬ç«‹ä¼˜åŒ–èƒ½å¤Ÿå–å¾—æ¯”è¾ƒé«˜çš„ç²¾åº¦ï¼Œç¼ºç‚¹å°±æ˜¯è®¡ç®—é‡ä¼šå¢žåŠ  JDE(joint detecting and embeding) JDEå°†ç›®æ ‡æ£€æµ‹ä¸ŽREIDç‰¹å¾æå–æ”¾åœ¨ä¸€ä¸ªç½‘ç»œï¼Œè¿™æ ·èƒ½æœ‰æ•ˆå‡å°‘è®¡ç®—é‡ï¼Œä½†æ˜¯å¤šä»»åŠ¡å­¦ä¹ çš„ç²¾åº¦ä¼šä½Žäº› è§£å†³çš„ä»»åŠ¡å’Œè§†é¢‘ç›®æ ‡æ£€æµ‹ç›¸åŒçš„ç‚¹åœ¨äºŽéƒ½éœ€è¦å¯¹æ¯å¸§å›¾åƒä¸­çš„ç›®æ ‡ç²¾å‡†å®šä½ï¼Œä¸åŒç‚¹åœ¨äºŽç›®æ ‡è·Ÿè¸ªä¸è€ƒè™‘ç›®æ ‡çš„è¯†åˆ«é—®é¢˜ SDEå°†REIDç‰¹å¾æå–å’Œç›®æ ‡æ£€æµ‹åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹ç½‘ç»œæ¥å®žçŽ°ï¼Œè¿™æ ·åšçš„ä¼˜ç‚¹æ˜¯æ¯éƒ¨åˆ†ç‹¬ç«‹ä¼˜åŒ–èƒ½å¤Ÿå–å¾—æ¯”è¾ƒé«˜çš„ç²¾åº¦ï¼Œç¼ºç‚¹å°±æ˜¯è®¡ç®—é‡ä¼šå¢žåŠ ï¼›JDEå°†ç›®æ ‡æ£€æµ‹ä¸ŽREIDç‰¹å¾æå–æ”¾åœ¨ä¸€ä¸ªç½‘ç»œï¼Œè¿™æ ·èƒ½æœ‰æ•ˆå‡å°‘è®¡ç®—é‡ï¼Œä½†æ˜¯å¤šä»»åŠ¡å­¦ä¹ çš„ç²¾åº¦ç›®å‰æ¥è¯´è¿˜æ²¡æœ‰SDEé«˜ã€‚åœ¨å·¥ç¨‹åº”ç”¨ä¸Šæˆ‘æ›´åå‘äºŽJDEï¼Œæ¯•ç«Ÿè·Ÿè¸ªè¦ä¿è¯å®žæ—¶æ€§ï¼Œåœ¨èƒ½å¤Ÿæå–ä¸€ä¸ªä¸å¤ªå·®çš„REIDç‰¹å¾åŸºç¡€ä¸Šï¼ŒåŠ å¼ºæ£€æµ‹å™¨æ€§èƒ½å’Œä¼˜åŒ–æ•°æ®å…³è”éƒ¨åˆ†ä¹Ÿèƒ½ä¸€å®šç¨‹åº¦ä¸Šå¼¥è¡¥REIDç‰¹å¾ä¸å¤Ÿå¥½å¸¦æ¥çš„æ€§èƒ½æŸå¤± Sort DeepSort ç›®æ ‡è·Ÿè¸ªåŸºç¡€â€”â€”DeepSORT ã€MOTã€‘è¯¦è§£DeepSORTå¤šç›®æ ‡è¿½è¸ªæ¨¡åž‹ StrongSort StrongSortç›¸æ¯”äºŽDeepSortçš„åŒºåˆ«ï¼š ä½¿ç”¨BoTæ›¿ä»£CNNåšå¤–è¡¨ç‰¹å¾çš„æå– ä½¿ç”¨EMA(exponential moving averageï¼šæŒ‡æ•°ç§»åŠ¨å¹³å‡)ç­–ç•¥æ›´æ–°æ–°å¸§ä¸­çš„ç›®æ ‡å¤–è§‚ç‰¹å¾ EMAæ›´æ–°ç­–ç•¥ä¸ä»…æé«˜äº†åŒ¹é…è´¨é‡ï¼Œè€Œä¸”å‡å°‘äº†æ—¶é—´æ¶ˆè€— åœ¨åšKalman filterä¹‹å‰ï¼Œä½¿ç”¨ECCï¼ˆenhanced correlation coefficientï¼šå¢žå¼ºç›¸å…³ç³»æ•°ï¼‰è¿›è¡Œç›¸æœºè¿åŠ¨è¡¥å¿ï¼›å¹¶ä½¿ç”¨NSA Kalmanä»£æ›¿Kalmanè¿›è¡Œè¿åŠ¨ç‰¹å¾èŽ·å– å°†è¿åŠ¨ä¿¡æ¯å’Œå¤–è§‚ä¿¡æ¯ç»“åˆæ¥è¿›è¡ŒåŒ¹é… ä½¿ç”¨Vanillaå…¨å±€çº¿æ€§èµ‹å€¼ä»£æ›¿äº†åŒ¹é…çº§è” BotSort BoT-SORT: Robust Associations Multi-Pedestrian Tracking BoT-SORT ï½œè¶…è¶Š DeepSORTã€StrongSORT++ å’Œ ByteTrack ByteTrack ByteTrack: Multi-Object Tracking by Associating Every Detection Box ä¾èµ–çš„ç®—æ³• å¡å°”æ›¼æ»¤æ³¢ å¡å°”æ›¼æ»¤æ³¢è¢«å¹¿æ³›åº”ç”¨äºŽæ— äººæœºã€è‡ªåŠ¨é©¾é©¶ã€å«æ˜Ÿå¯¼èˆªç­‰é¢†åŸŸ ç®€å•æ¥è¯´ï¼Œå…¶ä½œç”¨å°±æ˜¯åŸºäºŽä¼ æ„Ÿå™¨çš„æµ‹é‡å€¼æ¥æ›´æ–°é¢„æµ‹å€¼ï¼Œä»¥è¾¾åˆ°æ›´ç²¾ç¡®çš„ä¼°è®¡ å‡è®¾æˆ‘ä»¬è¦è·Ÿè¸ªå°è½¦çš„ä½ç½®å˜åŒ–ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè“è‰²çš„åˆ†å¸ƒæ˜¯å¡å°”æ›¼æ»¤æ³¢é¢„æµ‹å€¼ï¼Œæ£•è‰²çš„åˆ†å¸ƒæ˜¯ä¼ æ„Ÿå™¨çš„æµ‹é‡å€¼ï¼Œç°è‰²çš„åˆ†å¸ƒå°±æ˜¯é¢„æµ‹å€¼åŸºäºŽæµ‹é‡å€¼æ›´æ–°åŽçš„æœ€ä¼˜ä¼°è®¡ åœ¨ç›®æ ‡è·Ÿè¸ªä¸­ï¼Œéœ€è¦ä¼°è®¡trackçš„ä»¥ä¸‹ä¸¤ä¸ªçŠ¶æ€ï¼š å‡å€¼(Mean)ï¼šè¡¨ç¤ºç›®æ ‡çš„ä½ç½®ä¿¡æ¯ï¼Œç”±bboxçš„ä¸­å¿ƒåæ ‡ (cx, cy)ï¼Œå®½é«˜æ¯”rï¼Œé«˜hï¼Œä»¥åŠå„è‡ªçš„é€Ÿåº¦å˜åŒ–å€¼ç»„æˆ ç”±8ç»´å‘é‡è¡¨ç¤ºä¸º x = [cx, cy, r, h, vx, vy, vr, vh]ï¼Œå„ä¸ªé€Ÿåº¦å€¼åˆå§‹åŒ–ä¸º0 åæ–¹å·®(Covariance )ï¼šè¡¨ç¤ºç›®æ ‡ä½ç½®ä¿¡æ¯çš„ä¸ç¡®å®šæ€§ï¼Œç”±8x8çš„å¯¹è§’çŸ©é˜µè¡¨ç¤ºï¼ŒçŸ©é˜µä¸­æ•°å­—è¶Šå¤§åˆ™è¡¨æ˜Žä¸ç¡®å®šæ€§è¶Šå¤§ï¼Œå¯ä»¥ä»¥ä»»æ„å€¼åˆå§‹åŒ– å¡å°”æ›¼æ»¤æ³¢åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š(1) é¢„æµ‹trackåœ¨ä¸‹ä¸€æ—¶åˆ»çš„ä½ç½®ï¼Œ(2) åŸºäºŽdetectionæ¥æ›´æ–°é¢„æµ‹çš„ä½ç½®ã€‚ åŒˆç‰™åˆ©åŒ¹é…ç®—æ³• ç›®æ ‡è·Ÿè¸ªåˆæŽ¢(DeepSORT) å…ˆä»‹ç»ä¸€ä¸‹ä»€ä¹ˆæ˜¯åˆ†é…é—®é¢˜ï¼ˆAssignment Problemï¼‰ï¼šå‡è®¾æœ‰Nä¸ªäººå’ŒNä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡å¯ä»¥ä»»æ„åˆ†é…ç»™ä¸åŒçš„äººï¼Œå·²çŸ¥æ¯ä¸ªäººå®Œæˆæ¯ä¸ªä»»åŠ¡è¦èŠ±è´¹çš„ä»£ä»·ä¸å°½ç›¸åŒï¼Œé‚£ä¹ˆå¦‚ä½•åˆ†é…å¯ä»¥ä½¿å¾—æ€»çš„ä»£ä»·æœ€å° ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾çŽ°åœ¨æœ‰3ä¸ªä»»åŠ¡ï¼Œè¦åˆ†åˆ«åˆ†é…ç»™3ä¸ªäººï¼Œæ¯ä¸ªäººå®Œæˆå„ä¸ªä»»åŠ¡æ‰€éœ€ä»£ä»·çŸ©é˜µ(cost matrix)å¦‚ä¸‹æ‰€ç¤º(è¿™ä¸ªä»£ä»·å¯ä»¥æ˜¯é‡‘é’±ã€æ—¶é—´ç­‰ç­‰)ï¼š Task_1 Task_2 Task_3 Person_1 15 40 45 Person_2 20 60 35 Person_3 20 40 25 æ€Žæ ·æ‰èƒ½æ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜åˆ†é…ï¼Œä½¿å¾—å®Œæˆæ‰€æœ‰ä»»åŠ¡èŠ±è´¹çš„ä»£ä»·æœ€å°å‘¢ï¼Ÿ åŒˆç‰™åˆ©ç®—æ³•(åˆå«KMç®—æ³•)å°±æ˜¯ç”¨æ¥è§£å†³åˆ†é…é—®é¢˜çš„ä¸€ç§æ–¹æ³•ï¼Œå®ƒåŸºäºŽå®šç†ï¼š å¦‚æžœä»£ä»·çŸ©é˜µçš„æŸä¸€è¡Œæˆ–æŸä¸€åˆ—åŒæ—¶åŠ ä¸Šæˆ–å‡åŽ»æŸä¸ªæ•°ï¼Œåˆ™è¿™ä¸ªæ–°çš„ä»£ä»·çŸ©é˜µçš„æœ€ä¼˜åˆ†é…ä»ç„¶æ˜¯åŽŸä»£ä»·çŸ©é˜µçš„æœ€ä¼˜åˆ†é… ç®—æ³•æ­¥éª¤(å‡è®¾çŸ©é˜µä¸ºNé˜¶æ–¹é˜µ)ï¼š å¯¹äºŽçŸ©é˜µçš„æ¯ä¸€è¡Œï¼Œå‡åŽ»å…¶ä¸­æœ€å°çš„å…ƒç´  å¯¹äºŽçŸ©é˜µçš„æ¯ä¸€åˆ—ï¼Œå‡åŽ»å…¶ä¸­æœ€å°çš„å…ƒç´  ç”¨æœ€å°‘çš„æ°´å¹³çº¿æˆ–åž‚ç›´çº¿è¦†ç›–çŸ©é˜µä¸­æ‰€æœ‰çš„0 å¦‚æžœçº¿çš„æ•°é‡ç­‰äºŽNï¼Œåˆ™æ‰¾åˆ°äº†æœ€ä¼˜åˆ†é…ï¼Œç®—æ³•ç»“æŸï¼Œå¦åˆ™è¿›å…¥æ­¥éª¤5 æ‰¾åˆ°æ²¡æœ‰è¢«ä»»ä½•çº¿è¦†ç›–çš„æœ€å°å…ƒç´ ï¼Œæ¯ä¸ªæ²¡è¢«çº¿è¦†ç›–çš„è¡Œå‡åŽ»è¿™ä¸ªå…ƒç´ ï¼Œæ¯ä¸ªè¢«çº¿è¦†ç›–çš„åˆ—åŠ ä¸Šè¿™ä¸ªå…ƒç´ ï¼Œè¿”å›žæ­¥éª¤3 ç»§ç»­æ‹¿ä¸Šé¢çš„ä¾‹å­åšæ¼”ç¤ºï¼š step1 æ¯ä¸€è¡Œæœ€å°çš„å…ƒç´ åˆ†åˆ«ä¸º15ã€20ã€20ï¼Œå‡åŽ»å¾—åˆ°ï¼š Task_1 Task_2 Task_3 Person_1 0 25 30 Person_2 0 40 15 Person_3 0 20 5 step2 æ¯ä¸€åˆ—æœ€å°çš„å…ƒç´ åˆ†åˆ«ä¸º0ã€20ã€5ï¼Œå‡åŽ»å¾—åˆ°ï¼š Task_1 Task_2 Task_3 Person_1 0 5 25 Person_2 0 20 10 Person_3 0 0 0 step3 ç”¨æœ€å°‘çš„æ°´å¹³çº¿æˆ–åž‚ç›´çº¿è¦†ç›–æ‰€æœ‰çš„0ï¼Œå¾—åˆ°ï¼š Task_1 Task_2 Task_3 Person_1 0 5 25 Person_2 0 20 10 Person_3 0 0 0 step4 çº¿çš„æ•°é‡ä¸º2ï¼Œå°äºŽ3ï¼Œè¿›å…¥ä¸‹ä¸€æ­¥ï¼› step5 çŽ°åœ¨æ²¡è¢«è¦†ç›–çš„æœ€å°å…ƒç´ æ˜¯5ï¼Œæ²¡è¢«è¦†ç›–çš„è¡Œ(ç¬¬ä¸€å’Œç¬¬äºŒè¡Œ)å‡åŽ»5ï¼Œå¾—åˆ°ï¼š Task_1 Task_2 Task_3 Person_1 -5 0 20 Person_2 -5 15 5 Person_3 0 0 0 è¢«è¦†ç›–çš„åˆ—(ç¬¬ä¸€åˆ—)åŠ ä¸Š5ï¼Œå¾—åˆ°ï¼š Task_1 Task_2 Task_3 Person_1 0 0 20 Person_2 0 15 5 Person_3 5 0 0 è·³è½¬åˆ°step3ï¼Œç”¨æœ€å°‘çš„æ°´å¹³çº¿æˆ–åž‚ç›´çº¿è¦†ç›–æ‰€æœ‰çš„0ï¼Œå¾—åˆ°ï¼š Task_1 Task_2 Task_3 Person_1 0 0 20 Person_2 0 15 5 Person_3 5 0 0 step4ï¼šçº¿çš„æ•°é‡ä¸º3ï¼Œæ»¡è¶³æ¡ä»¶ï¼Œç®—æ³•ç»“æŸ æ˜¾ç„¶ï¼Œå°†ä»»åŠ¡2åˆ†é…ç»™ç¬¬1ä¸ªäººã€ä»»åŠ¡1åˆ†é…ç»™ç¬¬2ä¸ªäººã€ä»»åŠ¡3åˆ†é…ç»™ç¬¬3ä¸ªäººæ—¶ï¼Œæ€»çš„ä»£ä»·æœ€å°(0+0+0=0)ï¼š æ‰€ä»¥åŽŸçŸ©é˜µçš„æœ€å°æ€»ä»£ä»·ä¸º40+20+25=85 Task_1 Task_2 Task_3 Person_1 15 40 45 Person_2 20 60 35 Person_3 20 40 25 sklearné‡Œçš„linear_assignment()å‡½æ•°ä»¥åŠscipyé‡Œçš„linear_sum_assignment()å‡½æ•°éƒ½å®žçŽ°äº†åŒˆç‰™åˆ©ç®—æ³• import numpy as np from scipy.optimize import linear_sum_assignment cost_matrix = np.array([ [15,40,45], [20,60,35], [20,40,25] ]) matches = linear_sum_assignment(cost_matrix) print('scipy API result:\\n', matches) >>> scipy API result: (array([0, 1, 2], dtype=int64), array([1, 0, 2], dtype=int64)) è¿½è¸ªæŒ‡æ ‡ å¤šç›®æ ‡è·Ÿè¸ªè¯„ä»·æŒ‡æ ‡æ€»ç»“â€”â€”MOTAã€IDF1ã€HOTAç­‰ MOTA(Multiple Object Tracking Accuracy): æŒ‡æ ‡ä½“çŽ°å¤šç›®æ ‡è·Ÿè¸ªçš„å‡†ç¡®åº¦ MOTA=1-\\left(\\sum_{t}\\left(m_{t}+f p_{t}+m m e_{t}\\right)\\right) /\\left(\\sum_{t} g_{t}\\right) MOTAæŒ‡æ ‡æ˜¯è¡¡é‡å¤šç›®æ ‡è·Ÿè¸ªç®—æ³•ç²¾ç¡®æ€§æ–¹é¢æœ€é‡è¦çš„æŒ‡æ ‡ï¼Œä»¥1ä¸ºæœ€ä½³æƒ…å†µï¼Œæ•°å€¼è¶Šé«˜ä»£è¡¨è·Ÿè¸ªç²¾ç¡®åº¦è¶Šå¥½ IDF1: æŒ‡æ ‡ä»£è¡¨è¢«æ£€æµ‹å’Œè·Ÿè¸ªçš„ç›®æ ‡ä¸­èŽ·å–æ­£ç¡®çš„IDçš„æ£€æµ‹ç›®æ ‡çš„æ¯”ä¾‹ï¼Œç»¼åˆè€ƒè™‘IDå‡†ç¡®çŽ‡å’ŒIDå¬å›žçŽ‡ï¼Œä»£è¡¨ä¸¤è€…çš„è°ƒå’Œå‡å€¼ IDF1=2 /(1 / IDP+1 / IDR) å…¶ä¸­ï¼ŒIDPä»£è¡¨IDè·Ÿè¸ªçš„å‡†ç¡®çŽ‡ï¼ŒIDRä»£è¡¨IDè·Ÿè¸ªçš„å¬å›žçŽ‡ï¼ŒIDF1æŒ‡æ ‡æ›´èšç„¦äºŽè·Ÿè¸ªç®—æ³•è·Ÿè¸ªæŸä¸ªç›®æ ‡çš„æ—¶é—´é•¿çŸ­ï¼Œè€ƒå¯Ÿè·Ÿè¸ªçš„è¿žç»­æ€§å’Œé‡è¯†åˆ«çš„å‡†ç¡®æ€§ï¼ŒIDF1ä»¥1ä¸ºæœ€ä½³æƒ…å†µï¼Œæ•°å€¼è¶Šé«˜ä»£è¡¨è·Ÿè¸ªç‰¹å®šç›®æ ‡çš„ç²¾åº¦è¶Šå¥½ HOTA é“è·¯ç›‘æŽ§ç®¡ç† Roboflowæ•°æ®é›†æ ‡æ³¨ ç›®æ ‡æ£€æµ‹ç®—æ³•_æ¨¡åž‹è®­ç»ƒ ç›®æ ‡è·Ÿè¸ªç®—æ³•_ByteTrack(å®žæ—¶æ€§) ç‰©ä½“æ£€æµ‹åˆ†ç±» ä¸»åŠ¨å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹  ä¸»åŠ¨å­¦ä¹ ï¼šæ˜¯ä¸€ç§é€šè¿‡ä¸»åŠ¨é€‰æ‹©æœ€æœ‰ä»·å€¼çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨çš„æœºå™¨å­¦ä¹ æˆ–äººå·¥æ™ºèƒ½æ–¹æ³•ã€‚å…¶ç›®çš„æ˜¯ä½¿ç”¨å°½å¯èƒ½å°‘çš„ã€é«˜è´¨é‡çš„æ ·æœ¬æ ‡æ³¨ä½¿æ¨¡åž‹è¾¾åˆ°å°½å¯èƒ½å¥½çš„æ€§èƒ½ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä¸»åŠ¨å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿæé«˜æ ·æœ¬åŠæ ‡æ³¨çš„å¢žç›Šï¼Œåœ¨æœ‰é™æ ‡æ³¨é¢„ç®—çš„å‰æä¸‹ï¼Œæœ€å¤§åŒ–æ¨¡åž‹çš„æ€§èƒ½ï¼Œæ˜¯ä¸€ç§ä»Žæ ·æœ¬çš„è§’åº¦ï¼Œæé«˜æ•°æ®æ•ˆçŽ‡çš„æ–¹æ¡ˆï¼Œå› è€Œè¢«åº”ç”¨åœ¨æ ‡æ³¨æˆæœ¬é«˜ã€æ ‡æ³¨éš¾åº¦å¤§ç­‰ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚åŒ»ç–—å›¾åƒã€æ— äººé©¾é©¶ã€å¼‚å¸¸æ£€æµ‹ã€åŸºäºŽäº’è”ç½‘å¤§æ•°æ®çš„ç›¸å…³é—®é¢˜ å¼ºåŒ–å­¦ä¹ ä»‹ç»åŠåº”ç”¨ å¼ºåŒ–å­¦ä¹ ï¼šå¼ºåŒ–å­¦ä¹ æ˜¯ä¸€ä¸ªéžå¸¸å¸å¼•äººçš„äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œ2016å¹´ Alpha Goåœ¨å›´æ£‹é¢†åŸŸæŒ‘æˆ˜æŽä¸–çŸ³ï¼Œä»¥å‡ ä¹Žç¢¾åŽ‹çš„ç»“æžœå¤ºå† ï¼Œå¼•èµ·äº†äººä»¬å¯¹äºŽäººå·¥æ™ºèƒ½çš„å¹¿æ³›è®¨è®ºã€‚2019å¹´Alpha Staræ¨ªç©ºå‡ºä¸–ï¼Œåœ¨å¤æ‚çš„æ˜Ÿé™…äº‰éœ¸2æ¸¸æˆä¸­è¾¾åˆ°èƒ½å’Œäººç±»é¡¶çº§çŽ©å®¶PKçš„æ°´å¹³ï¼Œç™»ä¸ŠNatureã€‚è¿™ä¸¤æ¬¡ä¸Žäººç±»é¡¶çº§çŽ©å®¶çš„æŠ—è¡¡ä¹‹æˆ˜ï¼ŒèƒŒåŽçš„æŠ€æœ¯éƒ½æ˜¯å¼ºåŒ–å­¦ä¹ ã€‚å¼ºåŒ–å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸçš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå¼ºè°ƒåŸºäºŽçŽ¯å¢ƒè€Œè¡ŒåŠ¨ï¼Œä»¥å–å¾—æœ€å¤§åŒ–çš„é•¿æœŸåˆ©ç›Šã€‚ä¸Žç›‘ç£å­¦ä¹ ã€éžç›‘ç£å­¦ä¹ ä¸åŒï¼Œç›‘ç£å­¦ä¹ è§£å†³å¦‚åˆ†ç±»ã€å›žå½’ç­‰æ„ŸçŸ¥å’Œè®¤çŸ¥ç±»çš„ä»»åŠ¡ï¼Œè€Œå¼ºåŒ–å­¦ä¹ å¤„ç†å†³ç­–é—®é¢˜ï¼Œç€é‡äºŽçŽ¯å¢ƒçš„äº¤äº’ã€åºåˆ—å†³ç­–ã€å’Œé•¿æœŸæ”¶ç›Šã€‚å¼ºåŒ–å­¦ä¹ ä¸ŽçŽ¯å¢ƒçš„äº¤äº’æ¨¡å¼å¯ä»¥æŠ½è±¡ä¸ºï¼šæ™ºèƒ½ä½“Agentåœ¨çŽ¯å¢ƒEnvironmentä¸­å­¦ä¹ ï¼Œæ ¹ç»çŽ¯å¢ƒçš„çŠ¶æ€Stateï¼Œæ‰§è¡ŒåŠ¨ä½œActionï¼Œå¹¶æ ¹æ®çŽ¯å¢ƒåé¦ˆçš„å¥–åŠ±Rewardæ¥æŒ‡å¯¼è¾“å‡ºæ›´å¥½çš„åŠ¨ä½œ Copyright Â© narutohyc.com 2021 all right reservedï¼Œpowered by Gitbookè¯¥æ–‡ä»¶ä¿®è®¢æ—¶é—´ï¼š 2023-08-15 00:42:14 new Valine({el: \"#vcomments\",appId: 'evyLlP61gQN3G3OM2GQq1rzH-gzGzoHsz',appKey: 'utUrzoiqNaDEGlgr09JL1pXB',placeholder: 'æ¬¢è¿Žç•™ä¸‹è¯„è®ºäº¤æµ~',avatar: 'wavatar',meta: undefined,pageSize: 15,lang: 'zh-CN',recordIP: false}) "}}